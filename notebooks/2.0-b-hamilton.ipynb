{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import codecs\n",
    "import requests\n",
    "import progressbar\n",
    "import os\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "import lucene\n",
    "from org.apache.lucene.analysis.standard import StandardTokenizer\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "from org.apache.lucene.analysis.tokenattributes import CharTermAttribute\n",
    "from org.apache.lucene.util import Version\n",
    "from java.io import StringReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2.0\n"
     ]
    }
   ],
   "source": [
    "lucene.initVM()\n",
    "print Version.LUCENE_CURRENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4abbf2bba32d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbase_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www.speech.cs.cmu.edu/cgi-bin/tools/logios/lextool.pl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'wordfile'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'words.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marpabet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "arpabet = nltk.corpus.cmudict.dict()\n",
    "\n",
    "base_url = 'http://www.speech.cs.cmu.edu/cgi-bin/tools/logios/lextool.pl'\n",
    "\n",
    "file = {'wordfile': ('words.txt', \"\\n\".join([str(t).upper() for line in tokens for t in line if t not in arpabet.keys()]))}\n",
    "\n",
    "res = requests.post(base_url, files=file, allow_redirects=True)\n",
    "\n",
    "dict_re = re.compile(r\"(?<=DICT ).*?\\.dict\")\n",
    "\n",
    "dict_url = dict_re.search(res.text).group(0)\n",
    "\n",
    "res_dict = requests.get(dict_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    tokenizer = StandardTokenizer()\n",
    "    tokenizer.setReader(StringReader(string))\n",
    "    token = tokenizer.addAttribute(CharTermAttribute.class_)\n",
    "    tokenizer.reset()\n",
    "    lucene_tokens = []\n",
    "    while tokenizer.incrementToken():\n",
    "        lucene_tokens.append(token.toString())\n",
    "    return lucene_tokens\n",
    "\n",
    "def normalize(string):\n",
    "    analyzer = EnglishAnalyzer()\n",
    "    tokenstream = analyzer.tokenStream('token', StringReader(string))\n",
    "    token = tokenstream.addAttribute(CharTermAttribute.class_)\n",
    "    tokenstream.reset()\n",
    "    tokens = []\n",
    "    while tokenstream.incrementToken():\n",
    "        if not re.search('\\d', token.toString()):\n",
    "            tokens.append(token.toString())\n",
    "    return tokens\n",
    "\n",
    "# def get_phonemes(word):\n",
    "#     try:\n",
    "#         return arpabet[word][0]\n",
    "#     except:\n",
    "#         try:\n",
    "#             return custom_dict[word]\n",
    "#         except:\n",
    "#             print(word)\n",
    "#             return word\n",
    "        \n",
    "def get_speakers_list(speakers_string):\n",
    "    speakers = speakers_string.upper()\n",
    "    speakers = re.sub(' AND ', '/', speakers)\n",
    "    speakers = re.sub(' & ', '/', speakers)\n",
    "    speakers = re.sub('\\[.*\\d ', '', speakers)\n",
    "    speakers = re.sub(' \\(.*\\)', '', speakers)\n",
    "    speakers = re.sub('CHORUS ', '', speakers)\n",
    "    speakers = re.sub(' EXCEPT.*\\]', '', speakers)\n",
    "    speakers = re.sub('ALEXANDER HAMILTON', 'HAMILTON', speakers)\n",
    "    speakers = re.sub('GEORGE WASHINGTON', 'WASHINGTON', speakers)\n",
    "    speakers = re.sub('AARON BURR', 'BURR', speakers)\n",
    "    speakers = re.sub('JAMES MADISON', 'MADISON', speakers)\n",
    "    speakers = re.sub('\\[ENS\\]', 'ENSEMBLE', speakers)\n",
    "    speakers = re.sub('\\[WASH\\]', 'WASHINGTON', speakers)\n",
    "    speakers = re.sub('\\[WASH/', 'WASHINGTON/', speakers)\n",
    "    speakers = re.sub('/MULL/', '/MULLIGAN/', speakers)\n",
    "    speakers = re.sub('/LAUR/', '/LAURENS/', speakers)\n",
    "    speakers = re.sub('/LAF\\]', '/LAFAYETTE', speakers)\n",
    "    speakers = re.sub('\\[', '', speakers)\n",
    "    speakers = re.sub('\\]', '', speakers)\n",
    "    speakers = speakers.strip().split('/')\n",
    "    return speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hamilton_data = '../data/raw/hamilton/'\n",
    "hamilton_json = []\n",
    "for filename in os.listdir(hamilton_data):\n",
    "    with open(hamilton_data + filename, 'r') as f:\n",
    "        text = f.read()#.decode('utf-8')\\\n",
    "#         .replace(u'\\u2018', \"'\").replace(u'\\u2019', \"'\")\\\n",
    "#         .replace(u'\\u201c', '\"').replace(u'\\u201d', '\"')\\\n",
    "#         .replace(u'\\u2013', \"-\").replace(u'\\u2014', \"-\")\n",
    "    lines = text.split('\\n')\n",
    "    track_dict = dict()\n",
    "    track_dict['act#'], track_dict['track#'], track_dict['track'] = filename[:-4].split('_')\n",
    "    lyrics = []\n",
    "    current_speaker = None\n",
    "    i = 0\n",
    "    for line in lines:\n",
    "        if len(line.strip()) == 0: continue\n",
    "        if re.match('^\\[.*\\]$', line.strip()):\n",
    "            current_speaker = get_speakers_list(line)\n",
    "        else:\n",
    "            line_dict = {\n",
    "                'line#': i,\n",
    "                'speakers': current_speaker,\n",
    "                'original': line.strip(),\n",
    "                'tokenized': tokenize(line),\n",
    "                'normalized': tokenize(line)#,\n",
    "                #'phonemes': get_phonemes(line)\n",
    "            }\n",
    "            lyrics.append(line_dict)\n",
    "            i += 1\n",
    "    track_dict['lyrics'] = lyrics\n",
    "    hamilton_json.append(track_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Hey', u'hey', u'hey', u'hey'],\n",
       "    'original': 'Hey hey hey hey',\n",
       "    'speakers': ['HAMILTON', 'BURR', 'LAURENS', 'ALL WOMEN'],\n",
       "    'tokenized': [u'Hey', u'hey', u'hey', u'hey']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Ohh', u'I', u'do', u'I', u'do', u'I', u'do', u'I'],\n",
       "    'original': 'Ohh, I do I do I do I',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Ohh', u'I', u'do', u'I', u'do', u'I', u'do', u'I']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Dooo', u'Hey'],\n",
       "    'original': 'Dooo! Hey!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Dooo', u'Hey']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Ohh', u'I', u'do', u'I', u'do', u'I', u'do', u'I'],\n",
       "    'original': 'Ohh, I do I do I do I',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Ohh', u'I', u'do', u'I', u'do', u'I', u'do', u'I']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Dooo', u'Boy', u'you', u'got', u'me'],\n",
       "    'original': 'Dooo! Boy you got me',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Dooo', u'Boy', u'you', u'got', u'me']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Hey', u'hey', u'hey', u'hey'],\n",
       "    'original': 'Hey hey hey hey',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Hey', u'hey', u'hey', u'hey']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Hey', u'hey', u'hey', u'hey'],\n",
       "    'original': 'Hey hey hey hey',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Hey', u'hey', u'hey', u'hey']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Hey', u'hey', u'hey', u'hey'],\n",
       "    'original': 'Hey hey hey hey',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Hey', u'hey', u'hey', u'hey']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Hey', u'hey', u'hey'],\n",
       "    'original': 'Hey hey hey',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Hey', u'hey', u'hey']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Look',\n",
       "     u'into',\n",
       "     u'your',\n",
       "     u'eyes',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'sky',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'limit',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'helpless'],\n",
       "    'original': 'Look into your eyes, and the sky\\x92s the limit I\\x92m helpless!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'into',\n",
       "     u'your',\n",
       "     u'eyes',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'sky',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'limit',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'helpless']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Down',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'count',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'drownin',\n",
       "     u'in'],\n",
       "    'original': 'Down for the count, and I\\x92m drownin\\x92 in \\x91em',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Down',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'count',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'drownin',\n",
       "     u'in']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'never',\n",
       "     u'been',\n",
       "     u'the',\n",
       "     u'type',\n",
       "     u'to',\n",
       "     u'try',\n",
       "     u'and',\n",
       "     u'grab',\n",
       "     u'the',\n",
       "     u'spotlight'],\n",
       "    'original': 'I have never been the type to try and grab the spotlight',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'never',\n",
       "     u'been',\n",
       "     u'the',\n",
       "     u'type',\n",
       "     u'to',\n",
       "     u'try',\n",
       "     u'and',\n",
       "     u'grab',\n",
       "     u'the',\n",
       "     u'spotlight']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'We',\n",
       "     u'were',\n",
       "     u'at',\n",
       "     u'a',\n",
       "     u'revel',\n",
       "     u'with',\n",
       "     u'some',\n",
       "     u'rebels',\n",
       "     u'on',\n",
       "     u'a',\n",
       "     u'hot',\n",
       "     u'night'],\n",
       "    'original': 'We were at a revel with some rebels on a hot night',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'We',\n",
       "     u'were',\n",
       "     u'at',\n",
       "     u'a',\n",
       "     u'revel',\n",
       "     u'with',\n",
       "     u'some',\n",
       "     u'rebels',\n",
       "     u'on',\n",
       "     u'a',\n",
       "     u'hot',\n",
       "     u'night']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Laughin',\n",
       "     u'at',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'as',\n",
       "     u'she',\n",
       "     u's',\n",
       "     u'dazzling',\n",
       "     u'the',\n",
       "     u'roo'],\n",
       "    'original': 'Laughin\\x92 at my sister as she\\x92s dazzling the room',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Laughin',\n",
       "     u'at',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'as',\n",
       "     u'she',\n",
       "     u's',\n",
       "     u'dazzling',\n",
       "     u'the',\n",
       "     u'roo']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Then',\n",
       "     u'you',\n",
       "     u'walked',\n",
       "     u'in',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'heart',\n",
       "     u'went',\n",
       "     u'Boom'],\n",
       "    'original': 'Then you walked in and my heart went \\x93Boom!\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'you',\n",
       "     u'walked',\n",
       "     u'in',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'heart',\n",
       "     u'went',\n",
       "     u'Boom']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Tryin',\n",
       "     u'to',\n",
       "     u'catch',\n",
       "     u'your',\n",
       "     u'eye',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'ballroom'],\n",
       "    'original': 'Tryin\\x92 to catch your eye from the side of the ballroom',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Tryin',\n",
       "     u'to',\n",
       "     u'catch',\n",
       "     u'your',\n",
       "     u'eye',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'ballroom']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Everybody',\n",
       "     u's',\n",
       "     u'dancin',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'band',\n",
       "     u's',\n",
       "     u'top',\n",
       "     u'volu'],\n",
       "    'original': 'Everybody\\x92s dancin\\x92 and the band\\x92s top volume',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Everybody',\n",
       "     u's',\n",
       "     u'dancin',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'band',\n",
       "     u's',\n",
       "     u'top',\n",
       "     u'volu']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Grind',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'rhythm',\n",
       "     u'as',\n",
       "     u'we',\n",
       "     u'wine',\n",
       "     u'and',\n",
       "     u'dine'],\n",
       "    'original': 'Grind to the rhythm as we wine and dine',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Grind',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'rhythm',\n",
       "     u'as',\n",
       "     u'we',\n",
       "     u'wine',\n",
       "     u'and',\n",
       "     u'dine']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Grab', u'my', u'sister', u'and'],\n",
       "    'original': 'Grab my sister, and',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Grab', u'my', u'sister', u'and']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Whisper', u'Yo', u'this'],\n",
       "    'original': 'Whisper, \\x93Yo, this',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Whisper', u'Yo', u'this']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'One', u's', u'mine'],\n",
       "    'original': 'One\\x92s mine.\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'One', u's', u'mine']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'My',\n",
       "     u'sister',\n",
       "     u'made',\n",
       "     u'her',\n",
       "     u'way',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'to',\n",
       "     u'you'],\n",
       "    'original': 'My sister made her way across the room to you',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'My',\n",
       "     u'sister',\n",
       "     u'made',\n",
       "     u'her',\n",
       "     u'way',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'to',\n",
       "     u'you']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'nervous',\n",
       "     u'thinking',\n",
       "     u'What',\n",
       "     u's',\n",
       "     u'she',\n",
       "     u'gonna',\n",
       "     u'do'],\n",
       "    'original': 'And I got nervous, thinking \\x93What\\x92s she gonna do?\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'nervous',\n",
       "     u'thinking',\n",
       "     u'What',\n",
       "     u's',\n",
       "     u'she',\n",
       "     u'gonna',\n",
       "     u'do']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'She',\n",
       "     u'grabbed',\n",
       "     u'you',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'arm',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'thinkin',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'thro'],\n",
       "    'original': 'She grabbed you by the arm, I\\x92m thinkin\\x92 \\x93I\\x92m through\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'She',\n",
       "     u'grabbed',\n",
       "     u'you',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'arm',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'thinkin',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'thro']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Then',\n",
       "     u'you',\n",
       "     u'look',\n",
       "     u'back',\n",
       "     u'at',\n",
       "     u'me',\n",
       "     u'and',\n",
       "     u'suddenly',\n",
       "     u'I',\n",
       "     u'm'],\n",
       "    'original': 'Then you look back at me and suddenly I\\x92m',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'you',\n",
       "     u'look',\n",
       "     u'back',\n",
       "     u'at',\n",
       "     u'me',\n",
       "     u'and',\n",
       "     u'suddenly',\n",
       "     u'I',\n",
       "     u'm']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Oh', u'look', u'at', u'those', u'eyes'],\n",
       "    'original': 'Oh, look at those eyes',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Oh', u'look', u'at', u'those', u'eyes']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Yeah', u'I', u'm'],\n",
       "    'original': 'Yeah, I\\x92m',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Yeah', u'I', u'm']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Helpless', u'I', u'know'],\n",
       "    'original': 'Helpless, I know',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless', u'I', u'know']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'I', u'm', u'so', u'into', u'you'],\n",
       "    'original': 'I\\x92m so into you',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'm', u'so', u'into', u'you']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'I', u'am', u'so', u'into', u'you'],\n",
       "    'original': 'I am so into you',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'am', u'so', u'into', u'you']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'down',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'count'],\n",
       "    'original': 'I know I\\x92m down for the count',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'down',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'count']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'And', u'I', u'm', u'drownin', u'in', u'em'],\n",
       "    'original': 'And I\\x92m drownin\\x92 in \\x91em.',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'I', u'm', u'drownin', u'in', u'em']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Oooh'],\n",
       "    'original': 'Oooh',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Oooh']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Oooh'],\n",
       "    'original': 'Oooh',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Oooh']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Oooh'],\n",
       "    'original': 'Oooh',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Oooh']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Oooh'],\n",
       "    'original': 'Oooh',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Oooh']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Look', u'into', u'your', u'eyes'],\n",
       "    'original': 'Look into your eyes',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Look', u'into', u'your', u'eyes']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'And', u'the', u'sky', u's', u'the', u'limit'],\n",
       "    'original': 'And the sky\\x92s the limit',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And', u'the', u'sky', u's', u'the', u'limit']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'I', u'm'],\n",
       "    'original': 'I\\x92m',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'I', u'm']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Down', u'for', u'the', u'count'],\n",
       "    'original': 'Down for the count',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Down', u'for', u'the', u'count']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'And', u'I', u'm', u'drownin', u'in'],\n",
       "    'original': 'And I\\x92m drownin\\x92 in \\x91em',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And', u'I', u'm', u'drownin', u'in']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'I', u'm', u'helpless'],\n",
       "    'original': 'I\\x92m helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'I', u'm', u'helpless']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Look', u'into', u'your', u'eyes'],\n",
       "    'original': 'Look into your eyes',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Look', u'into', u'your', u'eyes']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'And',\n",
       "     u'the',\n",
       "     u'sky',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'limit',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'helpless'],\n",
       "    'original': 'And the sky\\x92s the limit I\\x92m helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And',\n",
       "     u'the',\n",
       "     u'sky',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'limit',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'helpless']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Down', u'for', u'the', u'count'],\n",
       "    'original': 'Down for the count',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Down', u'for', u'the', u'count']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'And', u'I', u'm', u'drownin', u'in', u'e'],\n",
       "    'original': 'And I\\x92m drownin\\x92 in \\x91em.',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And', u'I', u'm', u'drownin', u'in', u'e']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Where', u'are', u'you', u'taking', u'me'],\n",
       "    'original': 'Where are you taking me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Where', u'are', u'you', u'taking', u'me']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'I', u'm', u'about', u'to', u'change', u'your', u'life'],\n",
       "    'original': 'I\\x92m about to change your life',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'm', u'about', u'to', u'change', u'your', u'life']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Then', u'by', u'all', u'means', u'lead', u'the', u'way'],\n",
       "    'original': 'Then by all means, lead the way',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Then', u'by', u'all', u'means', u'lead', u'the', u'way']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Elizabeth',\n",
       "     u'Schuyler',\n",
       "     u'It',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'pleasure',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'you'],\n",
       "    'original': 'Elizabeth Schuyler. It\\x92s a pleasure to meet you',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Elizabeth',\n",
       "     u'Schuyler',\n",
       "     u'It',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'pleasure',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'you']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Schuyler'],\n",
       "    'original': 'Schuyler?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Schuyler']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'My', u'sister'],\n",
       "    'original': 'My sister',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'My', u'sister']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Thank', u'you', u'for', u'all', u'your', u'service'],\n",
       "    'original': 'Thank you for all your service',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Thank', u'you', u'for', u'all', u'your', u'service']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'If',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'fighting',\n",
       "     u'a',\n",
       "     u'war',\n",
       "     u'for',\n",
       "     u'us',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'it',\n",
       "     u'will',\n",
       "     u'have',\n",
       "     u'been',\n",
       "     u'worth',\n",
       "     u'it'],\n",
       "    'original': 'If it takes fighting a war for us to meet, it will have been worth it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'fighting',\n",
       "     u'a',\n",
       "     u'war',\n",
       "     u'for',\n",
       "     u'us',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'it',\n",
       "     u'will',\n",
       "     u'have',\n",
       "     u'been',\n",
       "     u'worth',\n",
       "     u'it']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'I', u'll', u'leave', u'you', u'to', u'it'],\n",
       "    'original': 'I\\x92ll leave you to it',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'll', u'leave', u'you', u'to', u'it']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'One', u'week', u'later'],\n",
       "    'original': 'One week later',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'One', u'week', u'later']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'I', u'm', u'writin', u'a', u'letter', u'nightl'],\n",
       "    'original': 'I\\x92m writin\\x92 a letter nightly',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'm', u'writin', u'a', u'letter', u'nightl']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Now',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'gets',\n",
       "     u'better',\n",
       "     u'every',\n",
       "     u'letter',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'me'],\n",
       "    'original': 'Now my life gets better, every letter that you write me',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'gets',\n",
       "     u'better',\n",
       "     u'every',\n",
       "     u'letter',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'me']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Laughin',\n",
       "     u'at',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'cuz',\n",
       "     u'she',\n",
       "     u'wants',\n",
       "     u'to',\n",
       "     u'form',\n",
       "     u'a',\n",
       "     u'harem'],\n",
       "    'original': 'Laughin\\x92 at my sister, cuz she wants to form a harem',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Laughin',\n",
       "     u'at',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'cuz',\n",
       "     u'she',\n",
       "     u'wants',\n",
       "     u'to',\n",
       "     u'form',\n",
       "     u'a',\n",
       "     u'harem']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'sayin',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'really',\n",
       "     u'loved',\n",
       "     u'me',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'share',\n",
       "     u'hi'],\n",
       "    'original': 'I\\x92m just sayin\\x92, if you really loved me, you would share him',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'sayin',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'really',\n",
       "     u'loved',\n",
       "     u'me',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'share',\n",
       "     u'hi']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Ha'],\n",
       "    'original': 'Ha!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Ha']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Two', u'weeks', u'later'],\n",
       "    'original': 'Two weeks later',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Two', u'weeks', u'later']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'In', u'the', u'living', u'room', u'stressin'],\n",
       "    'original': 'In the living room stressin\\x92',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'In', u'the', u'living', u'room', u'stressin']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'My', u'father', u's', u'stone', u'faced'],\n",
       "    'original': 'My father\\x92s stone-faced',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'My', u'father', u's', u'stone', u'faced']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'While',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'asking',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'blessin'],\n",
       "    'original': 'While you\\x92re asking for his blessin\\x92',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'While',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'asking',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'blessin']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'I', u'm', u'dying', u'inside', u'as'],\n",
       "    'original': 'I\\x92m dying inside, as',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'm', u'dying', u'inside', u'as']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'You', u'wine'],\n",
       "    'original': 'You wine',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You', u'wine']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'And', u'dine'],\n",
       "    'original': 'And dine',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'dine']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'And', u'I', u'm', u'tryin', u'not', u'to', u'cr'],\n",
       "    'original': 'And I\\x92m tryin\\x92 not to cry',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'I', u'm', u'tryin', u'not', u'to', u'cr']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'cause',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'nothing',\n",
       "     u'that',\n",
       "     u'your',\n",
       "     u'mind',\n",
       "     u'can',\n",
       "     u't'],\n",
       "    'original': '\\x91cause there\\x92s nothing that your mind can\\x92t do',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'cause',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'nothing',\n",
       "     u'that',\n",
       "     u'your',\n",
       "     u'mind',\n",
       "     u'can',\n",
       "     u't']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'My',\n",
       "     u'father',\n",
       "     u'makes',\n",
       "     u'his',\n",
       "     u'way',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'room'],\n",
       "    'original': 'My father makes his way across the room',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'My',\n",
       "     u'father',\n",
       "     u'makes',\n",
       "     u'his',\n",
       "     u'way',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'room']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'To', u'you'],\n",
       "    'original': 'To you',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'To', u'you']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'I', u'panic', u'for', u'a', u'second', u'thinking'],\n",
       "    'original': 'I panic for a second, thinking',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'panic', u'for', u'a', u'second', u'thinking']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'we', u're', u'throug'],\n",
       "    'original': '\\x93we\\x92re through\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'we', u're', u'throug']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'But',\n",
       "     u'then',\n",
       "     u'he',\n",
       "     u'shakes',\n",
       "     u'your',\n",
       "     u'hand',\n",
       "     u'and',\n",
       "     u'says'],\n",
       "    'original': 'But then he shakes your hand and says',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'But',\n",
       "     u'then',\n",
       "     u'he',\n",
       "     u'shakes',\n",
       "     u'your',\n",
       "     u'hand',\n",
       "     u'and',\n",
       "     u'says']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Be', u'true'],\n",
       "    'original': '\\x93Be true\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Be', u'true']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'And',\n",
       "     u'you',\n",
       "     u'turn',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'me',\n",
       "     u'smiling',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'm'],\n",
       "    'original': 'And you turn back to me, smiling, and I\\x92m',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And',\n",
       "     u'you',\n",
       "     u'turn',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'me',\n",
       "     u'smiling',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'm']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'Hoo'],\n",
       "    'original': 'Hoo!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Hoo']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'That', u'boy', u'is', u'mine'],\n",
       "    'original': 'That boy is mine',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'That', u'boy', u'is', u'mine']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'That', u'boy', u'is', u'mine'],\n",
       "    'original': 'That boy is mine!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'That', u'boy', u'is', u'mine']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Helpless', u'Helpless'],\n",
       "    'original': 'Helpless! Helpless!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless', u'Helpless']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'Down', u'for', u'the', u'count'],\n",
       "    'original': 'Down for the count',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Down', u'for', u'the', u'count']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'And', u'I', u'm', u'drownin', u'in', u'em'],\n",
       "    'original': 'And I\\x92m drownin\\x92 in em',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'I', u'm', u'drownin', u'in', u'em']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'Stressin'],\n",
       "    'original': 'Stressin\\x92',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Stressin']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'Blessin'],\n",
       "    'original': 'Blessin\\x92',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Blessin']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'Oooh'],\n",
       "    'original': 'Oooh',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Oooh']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Oooh'],\n",
       "    'original': 'Oooh',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Oooh']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'Oooh'],\n",
       "    'original': 'Oooh',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Oooh']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'Oooh'],\n",
       "    'original': 'Oooh',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Oooh']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'Look', u'into', u'your', u'eyes'],\n",
       "    'original': 'Look into your eyes',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Look', u'into', u'your', u'eyes']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'And', u'the', u'sky', u's', u'the'],\n",
       "    'original': 'And the sky\\x92s the',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And', u'the', u'sky', u's', u'the']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'Limit', u'I', u'm'],\n",
       "    'original': 'Limit I\\x92m',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Limit', u'I', u'm']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'Down', u'for', u'the', u'count'],\n",
       "    'original': 'Down for the count',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Down', u'for', u'the', u'count']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'And', u'I', u'm', u'drownin', u'i'],\n",
       "    'original': 'And I\\x92m drownin\\x92 in',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And', u'I', u'm', u'drownin', u'i']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'em', u'I'],\n",
       "    'original': '\\x91em I\\x92m',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'em', u'I']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'Look', u'into', u'your', u'eyes'],\n",
       "    'original': 'Look into your eyes',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Look', u'into', u'your', u'eyes']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'And', u'the', u'sky', u's', u'the'],\n",
       "    'original': 'And the sky\\x92s the',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And', u'the', u'sky', u's', u'the']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'Limit', u'I', u'm'],\n",
       "    'original': 'Limit I\\x92m',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Limit', u'I', u'm']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'Down', u'for', u'the', u'count'],\n",
       "    'original': 'Down for the count',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Down', u'for', u'the', u'count']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'And', u'I', u'm', u'drownin', u'in', u'e'],\n",
       "    'original': 'And I\\x92m drownin\\x92 in em',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And', u'I', u'm', u'drownin', u'in', u'e']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'Eliza',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'dollar',\n",
       "     u'to',\n",
       "     u'my',\n",
       "     u'name'],\n",
       "    'original': 'Eliza, I don\\x92t have a dollar to my name',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Eliza',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'dollar',\n",
       "     u'to',\n",
       "     u'my',\n",
       "     u'name']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'An',\n",
       "     u'acre',\n",
       "     u'of',\n",
       "     u'land',\n",
       "     u'a',\n",
       "     u'troop',\n",
       "     u'to',\n",
       "     u'command',\n",
       "     u'a',\n",
       "     u'dollop',\n",
       "     u'of',\n",
       "     u'fame'],\n",
       "    'original': 'An acre of land, a troop to command, a dollop of fame',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'An',\n",
       "     u'acre',\n",
       "     u'of',\n",
       "     u'land',\n",
       "     u'a',\n",
       "     u'troop',\n",
       "     u'to',\n",
       "     u'command',\n",
       "     u'a',\n",
       "     u'dollop',\n",
       "     u'of',\n",
       "     u'fame']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'All',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u's',\n",
       "     u'my',\n",
       "     u'honor',\n",
       "     u'a',\n",
       "     u'tolerance',\n",
       "     u'for',\n",
       "     u'pain'],\n",
       "    'original': 'All I have\\x92s my honor, a tolerance for pain',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'All',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u's',\n",
       "     u'my',\n",
       "     u'honor',\n",
       "     u'a',\n",
       "     u'tolerance',\n",
       "     u'for',\n",
       "     u'pain']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'A',\n",
       "     u'couple',\n",
       "     u'of',\n",
       "     u'college',\n",
       "     u'credits',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'top',\n",
       "     u'notch',\n",
       "     u'brain'],\n",
       "    'original': 'A couple of college credits and my top-notch brain',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'couple',\n",
       "     u'of',\n",
       "     u'college',\n",
       "     u'credits',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'top',\n",
       "     u'notch',\n",
       "     u'brain']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'Insane',\n",
       "     u'your',\n",
       "     u'family',\n",
       "     u'brings',\n",
       "     u'out',\n",
       "     u'a',\n",
       "     u'different',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'me'],\n",
       "    'original': 'Insane, your family brings out a different side of me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Insane',\n",
       "     u'your',\n",
       "     u'family',\n",
       "     u'brings',\n",
       "     u'out',\n",
       "     u'a',\n",
       "     u'different',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'me']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'Peggy',\n",
       "     u'confides',\n",
       "     u'in',\n",
       "     u'me',\n",
       "     u'Angelica',\n",
       "     u'tried',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'bite',\n",
       "     u'of',\n",
       "     u'me'],\n",
       "    'original': 'Peggy confides in me, Angelica tried to take a bite of me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Peggy',\n",
       "     u'confides',\n",
       "     u'in',\n",
       "     u'me',\n",
       "     u'Angelica',\n",
       "     u'tried',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'bite',\n",
       "     u'of',\n",
       "     u'me']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'No',\n",
       "     u'stress',\n",
       "     u'my',\n",
       "     u'love',\n",
       "     u'for',\n",
       "     u'you',\n",
       "     u'is',\n",
       "     u'never',\n",
       "     u'in',\n",
       "     u'doubt'],\n",
       "    'original': 'No stress, my love for you is never in doubt',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No',\n",
       "     u'stress',\n",
       "     u'my',\n",
       "     u'love',\n",
       "     u'for',\n",
       "     u'you',\n",
       "     u'is',\n",
       "     u'never',\n",
       "     u'in',\n",
       "     u'doubt']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'We',\n",
       "     u'll',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'place',\n",
       "     u'in',\n",
       "     u'Harlem',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'figure',\n",
       "     u'it',\n",
       "     u'ou'],\n",
       "    'original': 'We\\x92ll get a little place in Harlem and we\\x92ll figure it out',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'll',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'place',\n",
       "     u'in',\n",
       "     u'Harlem',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'figure',\n",
       "     u'it',\n",
       "     u'ou']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'I',\n",
       "     u've',\n",
       "     u'been',\n",
       "     u'livin',\n",
       "     u'without',\n",
       "     u'a',\n",
       "     u'family',\n",
       "     u'since',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'a',\n",
       "     u'chil'],\n",
       "    'original': 'I\\x92ve been livin\\x92 without a family since I was a child',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u've',\n",
       "     u'been',\n",
       "     u'livin',\n",
       "     u'without',\n",
       "     u'a',\n",
       "     u'family',\n",
       "     u'since',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'a',\n",
       "     u'chil']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'My',\n",
       "     u'father',\n",
       "     u'left',\n",
       "     u'my',\n",
       "     u'mother',\n",
       "     u'died',\n",
       "     u'I',\n",
       "     u'grew',\n",
       "     u'up',\n",
       "     u'buckwild'],\n",
       "    'original': 'My father left, my mother died, I grew up buckwild',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My',\n",
       "     u'father',\n",
       "     u'left',\n",
       "     u'my',\n",
       "     u'mother',\n",
       "     u'died',\n",
       "     u'I',\n",
       "     u'grew',\n",
       "     u'up',\n",
       "     u'buckwild']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'But',\n",
       "     u'I',\n",
       "     u'll',\n",
       "     u'never',\n",
       "     u'forget',\n",
       "     u'my',\n",
       "     u'mother',\n",
       "     u's',\n",
       "     u'face',\n",
       "     u'that',\n",
       "     u'was',\n",
       "     u'rea'],\n",
       "    'original': 'But I\\x92ll never forget my mother\\x92s face, that was real',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'I',\n",
       "     u'll',\n",
       "     u'never',\n",
       "     u'forget',\n",
       "     u'my',\n",
       "     u'mother',\n",
       "     u's',\n",
       "     u'face',\n",
       "     u'that',\n",
       "     u'was',\n",
       "     u'rea']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'And',\n",
       "     u'long',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'alive',\n",
       "     u'Eliza',\n",
       "     u'swear',\n",
       "     u'to',\n",
       "     u'God'],\n",
       "    'original': 'And long as I\\x92m alive, Eliza, swear to God',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'long',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'alive',\n",
       "     u'Eliza',\n",
       "     u'swear',\n",
       "     u'to',\n",
       "     u'God']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'You', u'll', u'never', u'feel', u'so'],\n",
       "    'original': 'You\\x92ll never feel so\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You', u'll', u'never', u'feel', u'so']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'I', u've', u'never', u'felt', u'so'],\n",
       "    'original': 'I\\x92ve never felt so\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u've', u'never', u'felt', u'so']},\n",
       "   {'line#': 126,\n",
       "    'normalized': [u'My',\n",
       "     u'life',\n",
       "     u'is',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'fine',\n",
       "     u'cuz',\n",
       "     u'Eliza',\n",
       "     u's',\n",
       "     u'in',\n",
       "     u'it'],\n",
       "    'original': 'My life is gon\\x92 be fine cuz Eliza\\x92s in it.',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My',\n",
       "     u'life',\n",
       "     u'is',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'fine',\n",
       "     u'cuz',\n",
       "     u'Eliza',\n",
       "     u's',\n",
       "     u'in',\n",
       "     u'it']},\n",
       "   {'line#': 127,\n",
       "    'normalized': [u'I', u'do', u'I', u'do', u'I', u'do', u'I', u'do'],\n",
       "    'original': 'I do I do I do I do!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'do', u'I', u'do', u'I', u'do', u'I', u'do']},\n",
       "   {'line#': 128,\n",
       "    'normalized': [u'I', u'do', u'I', u'do', u'I', u'do', u'I', u'do'],\n",
       "    'original': 'I do I do I do I do!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'do', u'I', u'do', u'I', u'do', u'I', u'do']},\n",
       "   {'line#': 129,\n",
       "    'normalized': [u'Hey', u'yeah', u'yeah'],\n",
       "    'original': 'Hey, yeah, yeah!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Hey', u'yeah', u'yeah']},\n",
       "   {'line#': 130,\n",
       "    'normalized': [u'I', u'm', u'down', u'for', u'the', u'count'],\n",
       "    'original': 'I\\x92m down for the count',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'm', u'down', u'for', u'the', u'count']},\n",
       "   {'line#': 131,\n",
       "    'normalized': [u'I', u'm'],\n",
       "    'original': 'I\\x92m\\x97',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'm']},\n",
       "   {'line#': 132,\n",
       "    'normalized': [u'I',\n",
       "     u'look',\n",
       "     u'into',\n",
       "     u'your',\n",
       "     u'eyes',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'sky',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'limit'],\n",
       "    'original': 'I look into your eyes, and the sky\\x92s the limit',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'look',\n",
       "     u'into',\n",
       "     u'your',\n",
       "     u'eyes',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'sky',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'limit']},\n",
       "   {'line#': 133,\n",
       "    'normalized': [u'I', u'm'],\n",
       "    'original': 'I\\x92m',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'm']},\n",
       "   {'line#': 134,\n",
       "    'normalized': [u'drownin', u'in', u'e'],\n",
       "    'original': '\\x85drownin\\x92 in \\x91em.',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'drownin', u'in', u'e']},\n",
       "   {'line#': 135,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 136,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 137,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 138,\n",
       "    'normalized': [u'Down', u'for', u'the', u'count'],\n",
       "    'original': 'Down for the count',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Down', u'for', u'the', u'count']},\n",
       "   {'line#': 139,\n",
       "    'normalized': [u'And', u'I', u'm', u'drownin', u'in'],\n",
       "    'original': 'And I\\x92m drownin\\x92 in \\x91em',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And', u'I', u'm', u'drownin', u'in']},\n",
       "   {'line#': 140,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 141,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 142,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 143,\n",
       "    'normalized': [u'Down', u'for', u'the', u'count'],\n",
       "    'original': 'Down for the count',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Down', u'for', u'the', u'count']},\n",
       "   {'line#': 144,\n",
       "    'normalized': [u'And', u'I', u'm', u'drownin', u'in', u'e'],\n",
       "    'original': 'And I\\x92m drownin\\x92 in \\x91em.',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'And', u'I', u'm', u'drownin', u'in', u'e']},\n",
       "   {'line#': 145,\n",
       "    'normalized': [u'Wedding', u'march', u'plays'],\n",
       "    'original': 'Wedding march plays',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Wedding', u'march', u'plays']},\n",
       "   {'line#': 146,\n",
       "    'normalized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man'],\n",
       "    'original': 'In New York, you can be a new man\\x85',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man']},\n",
       "   {'line#': 147,\n",
       "    'normalized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man'],\n",
       "    'original': 'In New York, you can be a new man\\x85',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man']},\n",
       "   {'line#': 148,\n",
       "    'normalized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man'],\n",
       "    'original': 'In New York, you can be a new man\\x85',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man']},\n",
       "   {'line#': 149,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless']}],\n",
       "  'track': 'Helpless',\n",
       "  'track#': '10'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Alright',\n",
       "     u'alright',\n",
       "     u'That',\n",
       "     u's',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'talkin',\n",
       "     u'abou'],\n",
       "    'original': 'Alright, alright. That\\x92s what I\\x92m talkin\\x92 about!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Alright',\n",
       "     u'alright',\n",
       "     u'That',\n",
       "     u's',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'talkin',\n",
       "     u'abou']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Now',\n",
       "     u'everyone',\n",
       "     u'give',\n",
       "     u'it',\n",
       "     u'up',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'maid',\n",
       "     u'of',\n",
       "     u'honor'],\n",
       "    'original': 'Now everyone give it up for the maid of honor',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'everyone',\n",
       "     u'give',\n",
       "     u'it',\n",
       "     u'up',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'maid',\n",
       "     u'of',\n",
       "     u'honor']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Angelica', u'Schuyler'],\n",
       "    'original': 'Angelica Schuyler!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Angelica', u'Schuyler']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'A', u'toast', u'to', u'the', u'groom'],\n",
       "    'original': 'A toast to the groom!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'A', u'toast', u'to', u'the', u'groom']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'From', u'your', u'sister'],\n",
       "    'original': 'From your sister',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'From', u'your', u'sister']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Who', u'is', u'always', u'by', u'your', u'side'],\n",
       "    'original': 'Who is always by your side',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Who', u'is', u'always', u'by', u'your', u'side']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'To', u'your', u'union'],\n",
       "    'original': 'To your union',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'To', u'your', u'union']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'And', u'the', u'hope', u'that', u'you', u'provide'],\n",
       "    'original': 'And the hope that you provide',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'the', u'hope', u'that', u'you', u'provide']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'May', u'you', u'always'],\n",
       "    'original': 'May you always\\x85',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'May', u'you', u'always']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'To', u'the', u'groom'],\n",
       "    'original': 'To the groom!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'groom']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'To', u'the', u'groom'],\n",
       "    'original': 'To the groom!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'groom']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'To', u'the', u'groom'],\n",
       "    'original': 'To the groom!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'groom']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'By', u'your', u'side'],\n",
       "    'original': 'By your side!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'By', u'your', u'side']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'To', u'the', u'union'],\n",
       "    'original': 'To the union!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'union']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'To', u'the', u'revolution'],\n",
       "    'original': 'To the revolution!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'revolution']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'You', u'provide'],\n",
       "    'original': 'You provide!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'You', u'provide']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'You', u'provide'],\n",
       "    'original': 'You provide!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'You', u'provide']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Always'],\n",
       "    'original': 'Always\\x97',\n",
       "    'speakers': ['HAMILTON', 'MEN'],\n",
       "    'tokenized': [u'Always']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Rewind'],\n",
       "    'original': 'Rewind\\x97',\n",
       "    'speakers': ['HAMILTON', 'MEN'],\n",
       "    'tokenized': [u'Rewind']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'To', u'the', u'groom'],\n",
       "    'original': 'To the groom!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'groom']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'By', u'your', u'side'],\n",
       "    'original': 'By your side!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'By', u'your', u'side']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'To', u'the', u'union'],\n",
       "    'original': 'To the union!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'union']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'To', u'the', u'revolution'],\n",
       "    'original': 'To the revolution!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'revolution']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'You', u'provide'],\n",
       "    'original': 'You provide!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'You', u'provide']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Always'],\n",
       "    'original': 'Always\\x97',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Always']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Rewind'],\n",
       "    'original': 'Rewind\\x97',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Rewind']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Rewind', u'Rewind'],\n",
       "    'original': 'Rewind, Rewind',\n",
       "    'speakers': ['RECORDED SAMPLES'],\n",
       "    'tokenized': [u'Rewind', u'Rewind']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Helpless', u\"sky's\", u\"sky's\"],\n",
       "    'original': \"Helpless, sky's, sky's\",\n",
       "    'speakers': ['RECORDED SAMPLES'],\n",
       "    'tokenized': [u'Helpless', u\"sky's\", u\"sky's\"]},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Drownin', u'in', u'em'],\n",
       "    'original': \"Drownin' in em\",\n",
       "    'speakers': ['RECORDED SAMPLES'],\n",
       "    'tokenized': [u'Drownin', u'in', u'em']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Drownin', u'rewind'],\n",
       "    'original': \"Drownin', rewind\",\n",
       "    'speakers': ['RECORDED SAMPLES'],\n",
       "    'tokenized': [u'Drownin', u'rewind']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'I',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'might',\n",
       "     u'rewind'],\n",
       "    'original': 'I remember that night, I just might (rewind)',\n",
       "    'speakers': ['RECORDED SAMPLES'],\n",
       "    'tokenized': [u'I',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'might',\n",
       "     u'rewind']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'I',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'might',\n",
       "     u'rewind'],\n",
       "    'original': 'I remember that night, I just might (rewind)',\n",
       "    'speakers': ['RECORDED SAMPLES'],\n",
       "    'tokenized': [u'I',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'might',\n",
       "     u'rewind']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'I',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'I',\n",
       "     u'remember',\n",
       "     u'that'],\n",
       "    'original': 'I remember that night, I remember that\\x97',\n",
       "    'speakers': ['RECORDED SAMPLES'],\n",
       "    'tokenized': [u'I',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'I',\n",
       "     u'remember',\n",
       "     u'that']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'I',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'might'],\n",
       "    'original': 'I remember that night, I just might',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'might']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Regret',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'rest',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'days'],\n",
       "    'original': 'Regret that night for the rest of my days',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Regret',\n",
       "     u'that',\n",
       "     u'night',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'rest',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'days']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'I', u'remember', u'those', u'soldier', u'boys'],\n",
       "    'original': 'I remember those soldier boys',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'remember', u'those', u'soldier', u'boys']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Tripping',\n",
       "     u'over',\n",
       "     u'themselves',\n",
       "     u'to',\n",
       "     u'win',\n",
       "     u'our',\n",
       "     u'praise'],\n",
       "    'original': 'Tripping over themselves to win our praise',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Tripping',\n",
       "     u'over',\n",
       "     u'themselves',\n",
       "     u'to',\n",
       "     u'win',\n",
       "     u'our',\n",
       "     u'praise']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'I', u'remember', u'that', u'dreamlike', u'candlelight'],\n",
       "    'original': 'I remember that dreamlike candlelight',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'remember', u'that', u'dreamlike', u'candlelight']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Like',\n",
       "     u'a',\n",
       "     u'dream',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'quite',\n",
       "     u'place'],\n",
       "    'original': 'Like a dream that you can\\x92t quite place',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Like',\n",
       "     u'a',\n",
       "     u'dream',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'quite',\n",
       "     u'place']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'But',\n",
       "     u'Alexander',\n",
       "     u'I',\n",
       "     u'll',\n",
       "     u'never',\n",
       "     u'forget',\n",
       "     u'the',\n",
       "     u'first'],\n",
       "    'original': 'But Alexander, I\\x92ll never forget the first',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'But',\n",
       "     u'Alexander',\n",
       "     u'I',\n",
       "     u'll',\n",
       "     u'never',\n",
       "     u'forget',\n",
       "     u'the',\n",
       "     u'first']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Time', u'I', u'saw', u'your', u'face'],\n",
       "    'original': 'Time I saw your face',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Time', u'I', u'saw', u'your', u'face']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'I', u'have', u'never', u'been', u'the', u'same'],\n",
       "    'original': 'I have never been the same',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'have', u'never', u'been', u'the', u'same']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Intelligent',\n",
       "     u'eyes',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'hunger',\n",
       "     u'pang',\n",
       "     u'frame'],\n",
       "    'original': 'Intelligent eyes in a hunger-pang frame',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Intelligent',\n",
       "     u'eyes',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'hunger',\n",
       "     u'pang',\n",
       "     u'frame']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'And',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'said',\n",
       "     u'Hi',\n",
       "     u'I',\n",
       "     u'forgot',\n",
       "     u'my',\n",
       "     u'dang',\n",
       "     u'nam'],\n",
       "    'original': 'And when you said \\x93Hi,\\x94 I forgot my dang name',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'said',\n",
       "     u'Hi',\n",
       "     u'I',\n",
       "     u'forgot',\n",
       "     u'my',\n",
       "     u'dang',\n",
       "     u'nam']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Set',\n",
       "     u'my',\n",
       "     u'heart',\n",
       "     u'aflame',\n",
       "     u'ev',\n",
       "     u'ry',\n",
       "     u'part',\n",
       "     u'aflame'],\n",
       "    'original': 'Set my heart aflame, ev\\x92ry part aflame',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Set',\n",
       "     u'my',\n",
       "     u'heart',\n",
       "     u'aflame',\n",
       "     u'ev',\n",
       "     u'ry',\n",
       "     u'part',\n",
       "     u'aflame']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'This', u'is', u'not', u'a', u'game'],\n",
       "    'original': 'This is not a game\\x85',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'This', u'is', u'not', u'a', u'game']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'You',\n",
       "     u'strike',\n",
       "     u'me',\n",
       "     u'as',\n",
       "     u'a',\n",
       "     u'woman',\n",
       "     u'who',\n",
       "     u'has',\n",
       "     u'never',\n",
       "     u'been',\n",
       "     u'satisfied'],\n",
       "    'original': 'You strike me as a woman who has never been satisfied',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'strike',\n",
       "     u'me',\n",
       "     u'as',\n",
       "     u'a',\n",
       "     u'woman',\n",
       "     u'who',\n",
       "     u'has',\n",
       "     u'never',\n",
       "     u'been',\n",
       "     u'satisfied']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'sure',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'mean',\n",
       "     u'You',\n",
       "     u'forget',\n",
       "     u'yoursel'],\n",
       "    'original': 'I\\x92m sure I don\\x92t know what you mean. You forget yourself',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'sure',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'mean',\n",
       "     u'You',\n",
       "     u'forget',\n",
       "     u'yoursel']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'You',\n",
       "     u're',\n",
       "     u'like',\n",
       "     u'me',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'never',\n",
       "     u'satisfie'],\n",
       "    'original': 'You\\x92re like me. I\\x92m never satisfied',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u're',\n",
       "     u'like',\n",
       "     u'me',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'never',\n",
       "     u'satisfie']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Is', u'that', u'right'],\n",
       "    'original': 'Is that right?',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Is', u'that', u'right']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'I', u'have', u'never', u'been', u'satisfied'],\n",
       "    'original': 'I have never been satisfied',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'have', u'never', u'been', u'satisfied']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'My', u'name', u'is', u'Angelica', u'Schuyler'],\n",
       "    'original': 'My name is Angelica Schuyler',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'My', u'name', u'is', u'Angelica', u'Schuyler']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Where', u's', u'your', u'fam', u'ly', u'from'],\n",
       "    'original': 'Where\\x92s your fam\\x92ly from?',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Where', u's', u'your', u'fam', u'ly', u'from']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Unimportant',\n",
       "     u'There',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'million',\n",
       "     u'things',\n",
       "     u'I',\n",
       "     u'haven',\n",
       "     u't',\n",
       "     u'done',\n",
       "     u'bu'],\n",
       "    'original': 'Unimportant. There\\x92s a million things I haven\\x92t done but',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Unimportant',\n",
       "     u'There',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'million',\n",
       "     u'things',\n",
       "     u'I',\n",
       "     u'haven',\n",
       "     u't',\n",
       "     u'done',\n",
       "     u'bu']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Just', u'you', u'wait', u'just', u'you', u'wait'],\n",
       "    'original': 'Just you wait, just you wait\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Just', u'you', u'wait', u'just', u'you', u'wait']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'So', u'so', u'so'],\n",
       "    'original': 'So so so\\x97',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'So', u'so', u'so']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'So',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'what',\n",
       "     u'it',\n",
       "     u'feels',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'match',\n",
       "     u'wits'],\n",
       "    'original': 'So this is what it feels like to match wits',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'So',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'what',\n",
       "     u'it',\n",
       "     u'feels',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'match',\n",
       "     u'wits']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'With',\n",
       "     u'someone',\n",
       "     u'at',\n",
       "     u'your',\n",
       "     u'level',\n",
       "     u'What',\n",
       "     u'the',\n",
       "     u'hell',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'catch',\n",
       "     u'It',\n",
       "     u's'],\n",
       "    'original': 'With someone at your level! What the hell is the catch? It\\x92s',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'With',\n",
       "     u'someone',\n",
       "     u'at',\n",
       "     u'your',\n",
       "     u'level',\n",
       "     u'What',\n",
       "     u'the',\n",
       "     u'hell',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'catch',\n",
       "     u'It',\n",
       "     u's']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'The',\n",
       "     u'feeling',\n",
       "     u'of',\n",
       "     u'freedom',\n",
       "     u'of',\n",
       "     u'seein',\n",
       "     u'the',\n",
       "     u'light'],\n",
       "    'original': 'The feeling of freedom, of seein\\x92 the light',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'The',\n",
       "     u'feeling',\n",
       "     u'of',\n",
       "     u'freedom',\n",
       "     u'of',\n",
       "     u'seein',\n",
       "     u'the',\n",
       "     u'light']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'It',\n",
       "     u's',\n",
       "     u'Ben',\n",
       "     u'Franklin',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'key',\n",
       "     u'and',\n",
       "     u'a',\n",
       "     u'kite',\n",
       "     u'You',\n",
       "     u'see',\n",
       "     u'it',\n",
       "     u'right'],\n",
       "    'original': 'It\\x92s Ben Franklin with a key and a kite! You see it, right?',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'It',\n",
       "     u's',\n",
       "     u'Ben',\n",
       "     u'Franklin',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'key',\n",
       "     u'and',\n",
       "     u'a',\n",
       "     u'kite',\n",
       "     u'You',\n",
       "     u'see',\n",
       "     u'it',\n",
       "     u'right']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'The',\n",
       "     u'conversation',\n",
       "     u'lasted',\n",
       "     u'two',\n",
       "     u'minutes',\n",
       "     u'maybe',\n",
       "     u'three',\n",
       "     u'minutes'],\n",
       "    'original': 'The conversation lasted two minutes, maybe three minutes',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'The',\n",
       "     u'conversation',\n",
       "     u'lasted',\n",
       "     u'two',\n",
       "     u'minutes',\n",
       "     u'maybe',\n",
       "     u'three',\n",
       "     u'minutes']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Ev',\n",
       "     u'rything',\n",
       "     u'we',\n",
       "     u'said',\n",
       "     u'in',\n",
       "     u'total',\n",
       "     u'agreement',\n",
       "     u'it'],\n",
       "    'original': 'Ev\\x92rything we said in total agreement, it\\x92s',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Ev',\n",
       "     u'rything',\n",
       "     u'we',\n",
       "     u'said',\n",
       "     u'in',\n",
       "     u'total',\n",
       "     u'agreement',\n",
       "     u'it']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'A',\n",
       "     u'dream',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'bit',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'dance'],\n",
       "    'original': 'A dream and it\\x92s a bit of a dance',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'A',\n",
       "     u'dream',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'bit',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'dance']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'A',\n",
       "     u'bit',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'posture',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'bit',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'stance',\n",
       "     u'He',\n",
       "     u's'],\n",
       "    'original': 'A bit of a posture, it\\x92s a bit of a stance. He\\x92s a',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'A',\n",
       "     u'bit',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'posture',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'bit',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'stance',\n",
       "     u'He',\n",
       "     u's']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Bit',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'flirt',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'give',\n",
       "     u'it',\n",
       "     u'a',\n",
       "     u'chanc'],\n",
       "    'original': 'Bit of a flirt, but I\\x92m \\x91a give it a chance',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Bit',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'flirt',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'give',\n",
       "     u'it',\n",
       "     u'a',\n",
       "     u'chanc']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'I',\n",
       "     u'asked',\n",
       "     u'about',\n",
       "     u'his',\n",
       "     u'fam',\n",
       "     u'ly',\n",
       "     u'did',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'his',\n",
       "     u'answer'],\n",
       "    'original': 'I asked about his fam\\x92ly, did you see his answer?',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'asked',\n",
       "     u'about',\n",
       "     u'his',\n",
       "     u'fam',\n",
       "     u'ly',\n",
       "     u'did',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'his',\n",
       "     u'answer']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'His',\n",
       "     u'hands',\n",
       "     u'started',\n",
       "     u'fidgeting',\n",
       "     u'he',\n",
       "     u'looked',\n",
       "     u'askance'],\n",
       "    'original': 'His hands started fidgeting, he looked askance?',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'His',\n",
       "     u'hands',\n",
       "     u'started',\n",
       "     u'fidgeting',\n",
       "     u'he',\n",
       "     u'looked',\n",
       "     u'askance']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'He',\n",
       "     u's',\n",
       "     u'penniless',\n",
       "     u'he',\n",
       "     u's',\n",
       "     u'flying',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'seat',\n",
       "     u'of',\n",
       "     u'his',\n",
       "     u'pant'],\n",
       "    'original': 'He\\x92s penniless, he\\x92s flying by the seat of his pants',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'He',\n",
       "     u's',\n",
       "     u'penniless',\n",
       "     u'he',\n",
       "     u's',\n",
       "     u'flying',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'seat',\n",
       "     u'of',\n",
       "     u'his',\n",
       "     u'pant']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Handsome', u'boy', u'does', u'he', u'know', u'it'],\n",
       "    'original': 'Handsome, boy, does he know it!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Handsome', u'boy', u'does', u'he', u'know', u'it']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Peach',\n",
       "     u'fuzz',\n",
       "     u'and',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'even',\n",
       "     u'grow',\n",
       "     u'it'],\n",
       "    'original': 'Peach fuzz, and he can\\x92t even grow it!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Peach',\n",
       "     u'fuzz',\n",
       "     u'and',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'even',\n",
       "     u'grow',\n",
       "     u'it']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'I',\n",
       "     u'wanna',\n",
       "     u'take',\n",
       "     u'him',\n",
       "     u'far',\n",
       "     u'away',\n",
       "     u'from',\n",
       "     u'this',\n",
       "     u'place'],\n",
       "    'original': 'I wanna take him far away from this place',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wanna',\n",
       "     u'take',\n",
       "     u'him',\n",
       "     u'far',\n",
       "     u'away',\n",
       "     u'from',\n",
       "     u'this',\n",
       "     u'place']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'Then',\n",
       "     u'I',\n",
       "     u'turn',\n",
       "     u'and',\n",
       "     u'see',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u's',\n",
       "     u'face',\n",
       "     u'and',\n",
       "     u'she',\n",
       "     u'is'],\n",
       "    'original': 'Then I turn and see my sister\\x92s face and she is\\x85',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'I',\n",
       "     u'turn',\n",
       "     u'and',\n",
       "     u'see',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u's',\n",
       "     u'face',\n",
       "     u'and',\n",
       "     u'she',\n",
       "     u'is']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'And', u'I', u'know', u'she', u'is'],\n",
       "    'original': 'And I know she is\\x85',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'I', u'know', u'she', u'is']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'And', u'her', u'eyes', u'are', u'just'],\n",
       "    'original': 'And her eyes are just\\x85',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'her', u'eyes', u'are', u'just']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'And', u'I', u'realize'],\n",
       "    'original': 'And I realize',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'I', u'realize']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'Three',\n",
       "     u'fundamental',\n",
       "     u'truths',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'exact',\n",
       "     u'same',\n",
       "     u'time'],\n",
       "    'original': 'Three fundamental truths at the exact same time\\x85',\n",
       "    'speakers': ['ANGELICA', 'COMPANY'],\n",
       "    'tokenized': [u'Three',\n",
       "     u'fundamental',\n",
       "     u'truths',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'exact',\n",
       "     u'same',\n",
       "     u'time']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'Where', u'are', u'you', u'taking', u'me'],\n",
       "    'original': 'Where are you taking me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Where', u'are', u'you', u'taking', u'me']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'I', u'm', u'about', u'to', u'change', u'your', u'life'],\n",
       "    'original': 'I\\x92m about to change your life',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'm', u'about', u'to', u'change', u'your', u'life']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'Then', u'by', u'all', u'means', u'lead', u'the', u'way'],\n",
       "    'original': 'Then by all means, lead the way',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Then', u'by', u'all', u'means', u'lead', u'the', u'way']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Number', u'one'],\n",
       "    'original': 'Number one!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'one']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'girl',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'world',\n",
       "     u'in',\n",
       "     u'which'],\n",
       "    'original': 'I\\x92m a girl in a world in which',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'girl',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'world',\n",
       "     u'in',\n",
       "     u'which']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'My', u'only', u'job', u'is', u'to', u'marry', u'rich'],\n",
       "    'original': 'My only job is to marry rich',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'My', u'only', u'job', u'is', u'to', u'marry', u'rich']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'My',\n",
       "     u'father',\n",
       "     u'has',\n",
       "     u'no',\n",
       "     u'sons',\n",
       "     u'so',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'the',\n",
       "     u'one'],\n",
       "    'original': 'My father has no sons so I\\x92m the one',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'My',\n",
       "     u'father',\n",
       "     u'has',\n",
       "     u'no',\n",
       "     u'sons',\n",
       "     u'so',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'the',\n",
       "     u'one']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'Who', u'has', u'to', u'social', u'climb', u'for', u'one'],\n",
       "    'original': 'Who has to social climb for one',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Who', u'has', u'to', u'social', u'climb', u'for', u'one']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'So',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'the',\n",
       "     u'oldest',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'wittiest',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'gossip',\n",
       "     u'in'],\n",
       "    'original': 'So I\\x92m the oldest and the wittiest and the gossip in',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'So',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'the',\n",
       "     u'oldest',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'wittiest',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'gossip',\n",
       "     u'in']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'New', u'York', u'City', u'is', u'insidious'],\n",
       "    'original': 'New York City is insidious',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'New', u'York', u'City', u'is', u'insidious']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'And', u'Alexander', u'is', u'penniless'],\n",
       "    'original': 'And Alexander is penniless',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'Alexander', u'is', u'penniless']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'Ha',\n",
       "     u'That',\n",
       "     u'doesn',\n",
       "     u't',\n",
       "     u'mean',\n",
       "     u'I',\n",
       "     u'want',\n",
       "     u'him',\n",
       "     u'any',\n",
       "     u'less'],\n",
       "    'original': 'Ha! That doesn\\x92t mean I want him any less',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Ha',\n",
       "     u'That',\n",
       "     u'doesn',\n",
       "     u't',\n",
       "     u'mean',\n",
       "     u'I',\n",
       "     u'want',\n",
       "     u'him',\n",
       "     u'any',\n",
       "     u'less']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'Elizabeth',\n",
       "     u'Schuyler',\n",
       "     u'It',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'pleasure',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'you'],\n",
       "    'original': 'Elizabeth Schuyler. It\\x92s a pleasure to meet you',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Elizabeth',\n",
       "     u'Schuyler',\n",
       "     u'It',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'pleasure',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'you']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'Schuyler'],\n",
       "    'original': 'Schuyler?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Schuyler']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'My', u'sister'],\n",
       "    'original': 'My sister',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'My', u'sister']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'Number', u'two'],\n",
       "    'original': 'Number two!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'two']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'He',\n",
       "     u's',\n",
       "     u'after',\n",
       "     u'me',\n",
       "     u'cuz',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'Schuyler',\n",
       "     u'siste'],\n",
       "    'original': 'He\\x92s after me cuz I\\x92m a Schuyler sister',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'He',\n",
       "     u's',\n",
       "     u'after',\n",
       "     u'me',\n",
       "     u'cuz',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'Schuyler',\n",
       "     u'siste']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'That', u'elevates', u'his', u'status', u'I', u'd'],\n",
       "    'original': 'That elevates his status, I\\x92d',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'That', u'elevates', u'his', u'status', u'I', u'd']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'Have',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'na\\xefve',\n",
       "     u'to',\n",
       "     u'set',\n",
       "     u'that',\n",
       "     u'aside'],\n",
       "    'original': 'Have to be na\\xefve to set that aside',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Have',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'na\\xefve',\n",
       "     u'to',\n",
       "     u'set',\n",
       "     u'that',\n",
       "     u'aside']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'Maybe',\n",
       "     u'that',\n",
       "     u'is',\n",
       "     u'why',\n",
       "     u'I',\n",
       "     u'introduce',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'Eliza'],\n",
       "    'original': 'Maybe that is why I introduce him to Eliza',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Maybe',\n",
       "     u'that',\n",
       "     u'is',\n",
       "     u'why',\n",
       "     u'I',\n",
       "     u'introduce',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'Eliza']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'Now', u'that', u's', u'his', u'bride'],\n",
       "    'original': 'Now that\\x92s his bride',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Now', u'that', u's', u'his', u'bride']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'Nice', u'going', u'Angelica', u'he', u'was', u'right'],\n",
       "    'original': 'Nice going, Angelica, he was right',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Nice', u'going', u'Angelica', u'he', u'was', u'right']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'You', u'will', u'never', u'be', u'satisfied'],\n",
       "    'original': 'You will never be satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'You', u'will', u'never', u'be', u'satisfied']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'Thank', u'you', u'for', u'all', u'your', u'service'],\n",
       "    'original': 'Thank you for all your service',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Thank', u'you', u'for', u'all', u'your', u'service']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'If',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'fighting',\n",
       "     u'a',\n",
       "     u'war',\n",
       "     u'for',\n",
       "     u'us',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'it',\n",
       "     u'will',\n",
       "     u'have',\n",
       "     u'been',\n",
       "     u'worth',\n",
       "     u'it'],\n",
       "    'original': 'If it takes fighting a war for us to meet, it will have been worth it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'fighting',\n",
       "     u'a',\n",
       "     u'war',\n",
       "     u'for',\n",
       "     u'us',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'it',\n",
       "     u'will',\n",
       "     u'have',\n",
       "     u'been',\n",
       "     u'worth',\n",
       "     u'it']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'I', u'll', u'leave', u'you', u'to', u'it'],\n",
       "    'original': 'I\\x92ll leave you to it',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'll', u'leave', u'you', u'to', u'it']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'Number', u'three'],\n",
       "    'original': 'Number three!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'three']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'like',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'mind'],\n",
       "    'original': 'I know my sister like I know my own mind',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'like',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'mind']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'You',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'find',\n",
       "     u'anyone',\n",
       "     u'as',\n",
       "     u'trusting',\n",
       "     u'or',\n",
       "     u'as',\n",
       "     u'kind'],\n",
       "    'original': 'You will never find anyone as trusting or as kind',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'find',\n",
       "     u'anyone',\n",
       "     u'as',\n",
       "     u'trusting',\n",
       "     u'or',\n",
       "     u'as',\n",
       "     u'kind']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'If',\n",
       "     u'I',\n",
       "     u'tell',\n",
       "     u'her',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'love',\n",
       "     u'him',\n",
       "     u'she',\n",
       "     u'd',\n",
       "     u'be',\n",
       "     u'silently',\n",
       "     u'resigned'],\n",
       "    'original': 'If I tell her that I love him she\\x92d be silently resigned',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'If',\n",
       "     u'I',\n",
       "     u'tell',\n",
       "     u'her',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'love',\n",
       "     u'him',\n",
       "     u'she',\n",
       "     u'd',\n",
       "     u'be',\n",
       "     u'silently',\n",
       "     u'resigned']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'He', u'd', u'be', u'mine'],\n",
       "    'original': 'He\\x92d be mine',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'He', u'd', u'be', u'mine']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'She', u'would', u'say', u'I', u'm', u'fin'],\n",
       "    'original': 'She would say, \\x93I\\x92m fine\\x94',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'She', u'would', u'say', u'I', u'm', u'fin']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'She', u'd', u'be', u'lying'],\n",
       "    'original': 'She\\x92d be lying',\n",
       "    'speakers': ['ANGELICA', 'COMPANY'],\n",
       "    'tokenized': [u'She', u'd', u'be', u'lying']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'But', u'when', u'I', u'fantasize', u'at', u'night'],\n",
       "    'original': 'But when I fantasize at night',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'But', u'when', u'I', u'fantasize', u'at', u'night']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'It', u's', u'Alexander', u's', u'eye'],\n",
       "    'original': 'It\\x92s Alexander\\x92s eyes',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'It', u's', u'Alexander', u's', u'eye']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'As', u'I', u'romanticize', u'what', u'might'],\n",
       "    'original': 'As I romanticize what might',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'As', u'I', u'romanticize', u'what', u'might']},\n",
       "   {'line#': 126,\n",
       "    'normalized': [u'Have',\n",
       "     u'been',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'hadn',\n",
       "     u't',\n",
       "     u'sized',\n",
       "     u'him'],\n",
       "    'original': 'Have been if I hadn\\x92t sized him',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Have',\n",
       "     u'been',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'hadn',\n",
       "     u't',\n",
       "     u'sized',\n",
       "     u'him']},\n",
       "   {'line#': 127,\n",
       "    'normalized': [u'Up', u'so', u'quickly'],\n",
       "    'original': 'Up so quickly',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Up', u'so', u'quickly']},\n",
       "   {'line#': 128,\n",
       "    'normalized': [u'At',\n",
       "     u'least',\n",
       "     u'my',\n",
       "     u'dear',\n",
       "     u'Eliza',\n",
       "     u's',\n",
       "     u'his',\n",
       "     u'wife'],\n",
       "    'original': 'At least my dear Eliza\\x92s his wife;',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'At',\n",
       "     u'least',\n",
       "     u'my',\n",
       "     u'dear',\n",
       "     u'Eliza',\n",
       "     u's',\n",
       "     u'his',\n",
       "     u'wife']},\n",
       "   {'line#': 129,\n",
       "    'normalized': [u'At',\n",
       "     u'least',\n",
       "     u'I',\n",
       "     u'keep',\n",
       "     u'his',\n",
       "     u'eyes',\n",
       "     u'in',\n",
       "     u'my',\n",
       "     u'life'],\n",
       "    'original': 'At least I keep his eyes in my life\\x85',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'At',\n",
       "     u'least',\n",
       "     u'I',\n",
       "     u'keep',\n",
       "     u'his',\n",
       "     u'eyes',\n",
       "     u'in',\n",
       "     u'my',\n",
       "     u'life']},\n",
       "   {'line#': 130,\n",
       "    'normalized': [u'To', u'the', u'groom'],\n",
       "    'original': 'To the groom!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'To', u'the', u'groom']},\n",
       "   {'line#': 131,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 132,\n",
       "    'normalized': [u'From', u'your', u'sister'],\n",
       "    'original': 'From your sister',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'From', u'your', u'sister']},\n",
       "   {'line#': 133,\n",
       "    'normalized': [u'Who', u'is', u'always', u'by', u'your', u'side'],\n",
       "    'original': 'Who is always by your side',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Who', u'is', u'always', u'by', u'your', u'side']},\n",
       "   {'line#': 134,\n",
       "    'normalized': [u'To', u'your', u'union'],\n",
       "    'original': 'To your union',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'To', u'your', u'union']},\n",
       "   {'line#': 135,\n",
       "    'normalized': [u'And', u'the', u'hope', u'that', u'you', u'provide'],\n",
       "    'original': 'And the hope that you provide',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'the', u'hope', u'that', u'you', u'provide']},\n",
       "   {'line#': 136,\n",
       "    'normalized': [u'May', u'you', u'always'],\n",
       "    'original': 'May you always',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'May', u'you', u'always']},\n",
       "   {'line#': 137,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 138,\n",
       "    'normalized': [u'And', u'I', u'know'],\n",
       "    'original': 'And I know',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'I', u'know']},\n",
       "   {'line#': 139,\n",
       "    'normalized': [u'She', u'll', u'be', u'happy', u'as'],\n",
       "    'original': 'She\\x92ll be happy as',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'She', u'll', u'be', u'happy', u'as']},\n",
       "   {'line#': 140,\n",
       "    'normalized': [u'His', u'bride'],\n",
       "    'original': 'His bride',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'His', u'bride']},\n",
       "   {'line#': 141,\n",
       "    'normalized': [u'And', u'I', u'know'],\n",
       "    'original': 'And I know',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'I', u'know']},\n",
       "   {'line#': 142,\n",
       "    'normalized': [u'To', u'the', u'groom'],\n",
       "    'original': 'To the groom!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'groom']},\n",
       "   {'line#': 143,\n",
       "    'normalized': [u'To', u'the', u'groom'],\n",
       "    'original': 'To the groom!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'groom']},\n",
       "   {'line#': 144,\n",
       "    'normalized': [u'To', u'the', u'groom'],\n",
       "    'original': 'To the groom!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'groom']},\n",
       "   {'line#': 145,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 146,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 147,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 148,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 149,\n",
       "    'normalized': [u'By', u'your', u'side'],\n",
       "    'original': 'By your side',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'By', u'your', u'side']},\n",
       "   {'line#': 150,\n",
       "    'normalized': [u'To', u'the', u'union'],\n",
       "    'original': 'To the union!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'union']},\n",
       "   {'line#': 151,\n",
       "    'normalized': [u'To', u'the', u'revolution'],\n",
       "    'original': 'To the revolution!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'To', u'the', u'revolution']},\n",
       "   {'line#': 152,\n",
       "    'normalized': [u'You', u'provide'],\n",
       "    'original': 'You provide!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'You', u'provide']},\n",
       "   {'line#': 153,\n",
       "    'normalized': [u'You', u'provide'],\n",
       "    'original': 'You provide!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'You', u'provide']},\n",
       "   {'line#': 154,\n",
       "    'normalized': [u'Always'],\n",
       "    'original': 'Always\\x97',\n",
       "    'speakers': ['HAMILTON', 'MEN'],\n",
       "    'tokenized': [u'Always']},\n",
       "   {'line#': 155,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['HAMILTON', 'MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 156,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['HAMILTON', 'MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 157,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 158,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 159,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 160,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 161,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 162,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 163,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 164,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 165,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 166,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied.',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 167,\n",
       "    'normalized': [u'To', u'the', u'groom'],\n",
       "    'original': 'To the groom!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'groom']},\n",
       "   {'line#': 168,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 169,\n",
       "    'normalized': [u'To', u'the', u'bride'],\n",
       "    'original': 'To the bride!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'bride']},\n",
       "   {'line#': 170,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 171,\n",
       "    'normalized': [u'By', u'your', u'side'],\n",
       "    'original': 'By your side',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'By', u'your', u'side']},\n",
       "   {'line#': 172,\n",
       "    'normalized': [u'To', u'the', u'union'],\n",
       "    'original': 'To the union!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'union']},\n",
       "   {'line#': 173,\n",
       "    'normalized': [u'To', u'the', u'revolution'],\n",
       "    'original': 'To the revolution!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'To', u'the', u'revolution']},\n",
       "   {'line#': 174,\n",
       "    'normalized': [u'You', u'provide'],\n",
       "    'original': 'You provide!',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'You', u'provide']},\n",
       "   {'line#': 175,\n",
       "    'normalized': [u'Always'],\n",
       "    'original': 'Always\\x97',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Always']},\n",
       "   {'line#': 176,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['ELIZA', 'WOMEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 177,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 178,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 179,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied.',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 180,\n",
       "    'normalized': [u'He', u'will', u'never', u'be', u'satisfied'],\n",
       "    'original': 'He will never be satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'He', u'will', u'never', u'be', u'satisfied']},\n",
       "   {'line#': 181,\n",
       "    'normalized': [u'I', u'will', u'never', u'be', u'satisfied'],\n",
       "    'original': 'I will never be satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'will', u'never', u'be', u'satisfied']}],\n",
       "  'track': 'Satisfied',\n",
       "  'track#': '11'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'I',\n",
       "     u'may',\n",
       "     u'not',\n",
       "     u'live',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'our',\n",
       "     u'glory'],\n",
       "    'original': 'I may not live to see our glory!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'I',\n",
       "     u'may',\n",
       "     u'not',\n",
       "     u'live',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'our',\n",
       "     u'glory']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'I',\n",
       "     u'may',\n",
       "     u'not',\n",
       "     u'live',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'our',\n",
       "     u'glory'],\n",
       "    'original': 'I may not live to see our glory!',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'may',\n",
       "     u'not',\n",
       "     u'live',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'our',\n",
       "     u'glory']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'But',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'seen',\n",
       "     u'wonders',\n",
       "     u'great',\n",
       "     u'and',\n",
       "     u'small'],\n",
       "    'original': 'But I\\x92ve seen wonders great and small',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'But',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'seen',\n",
       "     u'wonders',\n",
       "     u'great',\n",
       "     u'and',\n",
       "     u'small']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I',\n",
       "     u've',\n",
       "     u'seen',\n",
       "     u'wonders',\n",
       "     u'great',\n",
       "     u'and',\n",
       "     u'small'],\n",
       "    'original': 'I\\x92ve seen wonders great and small',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE'],\n",
       "    'tokenized': [u'I',\n",
       "     u've',\n",
       "     u'seen',\n",
       "     u'wonders',\n",
       "     u'great',\n",
       "     u'and',\n",
       "     u'small']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Cause',\n",
       "     u'if',\n",
       "     u'the',\n",
       "     u'tomcat',\n",
       "     u'can',\n",
       "     u'get',\n",
       "     u'married'],\n",
       "    'original': '\\x91Cause if the tomcat can get married',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Cause',\n",
       "     u'if',\n",
       "     u'the',\n",
       "     u'tomcat',\n",
       "     u'can',\n",
       "     u'get',\n",
       "     u'married']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'If', u'Alexander', u'can', u'get', u'married'],\n",
       "    'original': 'If Alexander can get married\\x97',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE'],\n",
       "    'tokenized': [u'If', u'Alexander', u'can', u'get', u'married']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'There',\n",
       "     u's',\n",
       "     u'hope',\n",
       "     u'for',\n",
       "     u'our',\n",
       "     u'ass',\n",
       "     u'after',\n",
       "     u'all'],\n",
       "    'original': 'There\\x92s hope for our ass, after all!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'There',\n",
       "     u's',\n",
       "     u'hope',\n",
       "     u'for',\n",
       "     u'our',\n",
       "     u'ass',\n",
       "     u'after',\n",
       "     u'all']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Raise', u'a', u'glass', u'to', u'freedom'],\n",
       "    'original': 'Raise a glass to freedom',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Raise', u'a', u'glass', u'to', u'freedom']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey!',\n",
       "    'speakers': ['LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Something', u'you', u'will', u'never', u'see', u'again'],\n",
       "    'original': 'Something you will never see again!',\n",
       "    'speakers': ['LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Something', u'you', u'will', u'never', u'see', u'again']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'No', u'matter', u'what', u'she', u'tells', u'you'],\n",
       "    'original': 'No matter what she tells you',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'No', u'matter', u'what', u'she', u'tells', u'you']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Let', u's', u'have', u'another', u'round', u'tonight'],\n",
       "    'original': 'Let\\x92s have another round tonight!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Let', u's', u'have', u'another', u'round', u'tonight']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Raise',\n",
       "     u'a',\n",
       "     u'glass',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'four',\n",
       "     u'of',\n",
       "     u'us'],\n",
       "    'original': 'Raise a glass to the four of us!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Raise',\n",
       "     u'a',\n",
       "     u'glass',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'four',\n",
       "     u'of',\n",
       "     u'us']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Ho'],\n",
       "    'original': 'Ho!',\n",
       "    'speakers': ['LAFAYETTE', 'HAMILTON'],\n",
       "    'tokenized': [u'Ho']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'To', u'the', u'newly', u'not', u'poor', u'of', u'us'],\n",
       "    'original': 'To the newly not poor of us!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'To', u'the', u'newly', u'not', u'poor', u'of', u'us']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Woo'],\n",
       "    'original': 'Woo!',\n",
       "    'speakers': ['LAURENS', 'LAFAYETTE', 'HAMILTON'],\n",
       "    'tokenized': [u'Woo']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'We', u'll', u'tell', u'the', u'story', u'of', u'tonight'],\n",
       "    'original': 'We\\x92ll tell the story of tonight',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'We', u'll', u'tell', u'the', u'story', u'of', u'tonight']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Let', u's', u'have', u'another', u'round'],\n",
       "    'original': 'Let\\x92s have another round\\x97',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Let', u's', u'have', u'another', u'round']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Well', u'if', u'it', u'isn', u't', u'Aaron', u'Burr'],\n",
       "    'original': 'Well, if it isn\\x92t Aaron Burr',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Well', u'if', u'it', u'isn', u't', u'Aaron', u'Burr']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'I',\n",
       "     u'didn',\n",
       "     u't',\n",
       "     u'think',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'make',\n",
       "     u'it'],\n",
       "    'original': 'I didn\\x92t think that you would make it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'didn',\n",
       "     u't',\n",
       "     u'think',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'make',\n",
       "     u'it']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'To', u'be', u'sure'],\n",
       "    'original': 'To be sure',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'To', u'be', u'sure']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr!',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'I', u'came', u'to', u'say', u'congratulations'],\n",
       "    'original': 'I came to say congratulations',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'came', u'to', u'say', u'congratulations']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Spit', u'a', u'verse', u'Burr'],\n",
       "    'original': 'Spit a verse, Burr!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Spit', u'a', u'verse', u'Burr']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'I', u'see', u'the', u'whole', u'gang', u'is', u'here'],\n",
       "    'original': 'I see the whole gang is here',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'see', u'the', u'whole', u'gang', u'is', u'here']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'You', u'are', u'the', u'worst', u'Burr'],\n",
       "    'original': 'You are the worst, Burr!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'You', u'are', u'the', u'worst', u'Burr']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Ignore',\n",
       "     u'them',\n",
       "     u'Congrats',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'Lieutenant',\n",
       "     u'Colonel'],\n",
       "    'original': 'Ignore them. Congrats to you, Lieutenant Colonel',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ignore',\n",
       "     u'them',\n",
       "     u'Congrats',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'Lieutenant',\n",
       "     u'Colonel']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'I',\n",
       "     u'wish',\n",
       "     u'I',\n",
       "     u'had',\n",
       "     u'your',\n",
       "     u'command',\n",
       "     u'instead',\n",
       "     u'of',\n",
       "     u'manning',\n",
       "     u'George',\n",
       "     u's',\n",
       "     u'journal'],\n",
       "    'original': 'I wish I had your command instead of manning George\\x92s journal',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wish',\n",
       "     u'I',\n",
       "     u'had',\n",
       "     u'your',\n",
       "     u'command',\n",
       "     u'instead',\n",
       "     u'of',\n",
       "     u'manning',\n",
       "     u'George',\n",
       "     u's',\n",
       "     u'journal']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'No', u'you', u'don', u't'],\n",
       "    'original': 'No, you don\\x92t',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'you', u'don', u't']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Yes', u'I', u'do'],\n",
       "    'original': 'Yes, I do',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes', u'I', u'do']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Now', u'be', u'sensible'],\n",
       "    'original': 'Now, be sensible',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Now', u'be', u'sensible']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'From',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'hear',\n",
       "     u'you',\n",
       "     u've',\n",
       "     u'made',\n",
       "     u'yourself',\n",
       "     u'indispensable'],\n",
       "    'original': 'From what I hear, you\\x92ve made yourself indispensable',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'From',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'hear',\n",
       "     u'you',\n",
       "     u've',\n",
       "     u'made',\n",
       "     u'yourself',\n",
       "     u'indispensable']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Well', u'well', u'I', u'heard'],\n",
       "    'original': 'Well, well, I heard',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Well', u'well', u'I', u'heard']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'You',\n",
       "     u've',\n",
       "     u'got',\n",
       "     u'a',\n",
       "     u'special',\n",
       "     u'someone',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'side',\n",
       "     u'Burr'],\n",
       "    'original': 'You\\x92ve got a special someone on the side, Burr',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'You',\n",
       "     u've',\n",
       "     u'got',\n",
       "     u'a',\n",
       "     u'special',\n",
       "     u'someone',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'side',\n",
       "     u'Burr']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Is', u'that', u'so'],\n",
       "    'original': 'Is that so?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is', u'that', u'so']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'What', u'are', u'you', u'tryin', u'to', u'hide', u'Burr'],\n",
       "    'original': 'What are you tryin\\x92 to hide, Burr?',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'What', u'are', u'you', u'tryin', u'to', u'hide', u'Burr']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'I', u'should', u'go'],\n",
       "    'original': 'I should go',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'should', u'go']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'No', u'these', u'guys', u'should', u'go'],\n",
       "    'original': 'No, these guys should go',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No', u'these', u'guys', u'should', u'go']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Leave', u'us', u'alone'],\n",
       "    'original': 'Leave us alone',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Leave', u'us', u'alone']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Man'],\n",
       "    'original': 'Man\\x85',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Man']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'It',\n",
       "     u's',\n",
       "     u'alright',\n",
       "     u'Burr',\n",
       "     u'I',\n",
       "     u'wish',\n",
       "     u'you',\n",
       "     u'd',\n",
       "     u'brought',\n",
       "     u'this',\n",
       "     u'girl',\n",
       "     u'with',\n",
       "     u'you',\n",
       "     u'tonight',\n",
       "     u'Bur'],\n",
       "    'original': 'It\\x92s alright, Burr. I wish you\\x92d brought this girl with you tonight, Burr',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'It',\n",
       "     u's',\n",
       "     u'alright',\n",
       "     u'Burr',\n",
       "     u'I',\n",
       "     u'wish',\n",
       "     u'you',\n",
       "     u'd',\n",
       "     u'brought',\n",
       "     u'this',\n",
       "     u'girl',\n",
       "     u'with',\n",
       "     u'you',\n",
       "     u'tonight',\n",
       "     u'Bur']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'You',\n",
       "     u're',\n",
       "     u'very',\n",
       "     u'kind',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'afraid',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'unlawful',\n",
       "     u's'],\n",
       "    'original': 'You\\x92re very kind, but I\\x92m afraid it\\x92s unlawful, sir',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u're',\n",
       "     u'very',\n",
       "     u'kind',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'afraid',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'unlawful',\n",
       "     u's']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'What', u'do', u'you', u'mean'],\n",
       "    'original': 'What do you mean?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'mean']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'She', u's', u'married'],\n",
       "    'original': 'She\\x92s married',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'She', u's', u'married']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'I', u'see'],\n",
       "    'original': 'I see',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'see']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'She',\n",
       "     u's',\n",
       "     u'married',\n",
       "     u'to',\n",
       "     u'a',\n",
       "     u'British',\n",
       "     u'officer'],\n",
       "    'original': 'She\\x92s married to a British officer',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'She',\n",
       "     u's',\n",
       "     u'married',\n",
       "     u'to',\n",
       "     u'a',\n",
       "     u'British',\n",
       "     u'officer']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Oh', u'shit'],\n",
       "    'original': 'Oh shit\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Oh', u'shit']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Congrats', u'again', u'Alexander', u'Smile', u'more'],\n",
       "    'original': 'Congrats again, Alexander. Smile more',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Congrats', u'again', u'Alexander', u'Smile', u'more']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'I',\n",
       "     u'll',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'war'],\n",
       "    'original': 'I\\x92ll see you on the other side of the war',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'll',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'war']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'I', u'will', u'never', u'understand', u'you'],\n",
       "    'original': 'I will never understand you',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'will', u'never', u'understand', u'you']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'love',\n",
       "     u'this',\n",
       "     u'woman',\n",
       "     u'go',\n",
       "     u'get',\n",
       "     u'her',\n",
       "     u'What',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'waiting',\n",
       "     u'for'],\n",
       "    'original': 'If you love this woman, go get her! What are you waiting for?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'love',\n",
       "     u'this',\n",
       "     u'woman',\n",
       "     u'go',\n",
       "     u'get',\n",
       "     u'her',\n",
       "     u'What',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'waiting',\n",
       "     u'for']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'I',\n",
       "     u'll',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'war'],\n",
       "    'original': 'I\\x92ll see you on the other side of the war',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'll',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'war']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'I',\n",
       "     u'll',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'war'],\n",
       "    'original': 'I\\x92ll see you on the other side of the war',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'll',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'war']}],\n",
       "  'track': 'The Story Of Tonight (Reprise)',\n",
       "  'track#': '12'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Theodosia',\n",
       "     u'writes',\n",
       "     u'me',\n",
       "     u'a',\n",
       "     u'letter',\n",
       "     u'every',\n",
       "     u'day'],\n",
       "    'original': 'Theodosia writes me a letter every day',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Theodosia',\n",
       "     u'writes',\n",
       "     u'me',\n",
       "     u'a',\n",
       "     u'letter',\n",
       "     u'every',\n",
       "     u'day']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u\"I'm\",\n",
       "     u'keeping',\n",
       "     u'the',\n",
       "     u'bed',\n",
       "     u'warm',\n",
       "     u'while',\n",
       "     u'her',\n",
       "     u'husband',\n",
       "     u'is',\n",
       "     u'away'],\n",
       "    'original': \"I'm keeping the bed warm while her husband is away\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u\"I'm\",\n",
       "     u'keeping',\n",
       "     u'the',\n",
       "     u'bed',\n",
       "     u'warm',\n",
       "     u'while',\n",
       "     u'her',\n",
       "     u'husband',\n",
       "     u'is',\n",
       "     u'away']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u\"He's\",\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'side',\n",
       "     u'in',\n",
       "     u'Georgia'],\n",
       "    'original': \"He's on the British side in Georgia\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u\"He's\",\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'side',\n",
       "     u'in',\n",
       "     u'Georgia']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u\"He's\",\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'keep',\n",
       "     u'the',\n",
       "     u'colonies',\n",
       "     u'in',\n",
       "     u'line'],\n",
       "    'original': \"He's trying to keep the colonies in line\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u\"He's\",\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'keep',\n",
       "     u'the',\n",
       "     u'colonies',\n",
       "     u'in',\n",
       "     u'line']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'But', u'he', u'can', u'keep', u'all', u'of', u'Georgia'],\n",
       "    'original': 'But he can keep all of Georgia',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But', u'he', u'can', u'keep', u'all', u'of', u'Georgia']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Theodosia', u\"she's\", u'mine'],\n",
       "    'original': \"Theodosia, she's mine\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Theodosia', u\"she's\", u'mine']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Love', u\"doesn't\", u'discriminate'],\n",
       "    'original': \"Love doesn't discriminate\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Love', u\"doesn't\", u'discriminate']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Between', u'the', u'sinners'],\n",
       "    'original': 'Between the sinners',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Between', u'the', u'sinners']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'And', u'the', u'saints'],\n",
       "    'original': 'And the saints',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'the', u'saints']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes'],\n",
       "    'original': 'It takes and it takes and it takes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'And', u'we', u'keep', u'loving', u'anyway'],\n",
       "    'original': 'And we keep loving anyway',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'we', u'keep', u'loving', u'anyway']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'We', u'laugh', u'and', u'we', u'cry'],\n",
       "    'original': 'We laugh and we cry',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'We', u'laugh', u'and', u'we', u'cry']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'And', u'we', u'break'],\n",
       "    'original': 'And we break',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'we', u'break']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'And', u'we', u'make', u'our', u'mistakes'],\n",
       "    'original': 'And we make our mistakes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'we', u'make', u'our', u'mistakes']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'And',\n",
       "     u'if',\n",
       "     u\"there's\",\n",
       "     u'a',\n",
       "     u'reason',\n",
       "     u\"I'm\",\n",
       "     u'by',\n",
       "     u'her',\n",
       "     u'side'],\n",
       "    'original': \"And if there's a reason I'm by her side\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'if',\n",
       "     u\"there's\",\n",
       "     u'a',\n",
       "     u'reason',\n",
       "     u\"I'm\",\n",
       "     u'by',\n",
       "     u'her',\n",
       "     u'side']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'When', u'so', u'many', u'have', u'tried'],\n",
       "    'original': 'When so many have tried',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'When', u'so', u'many', u'have', u'tried']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Then', u\"I'm\", u'willing', u'to', u'wait', u'for', u'it'],\n",
       "    'original': \"Then I'm willing to wait for it\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Then', u\"I'm\", u'willing', u'to', u'wait', u'for', u'it']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u\"I'm\", u'willing', u'to', u'wait', u'for', u'it'],\n",
       "    'original': \"I'm willing to wait for it\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u\"I'm\", u'willing', u'to', u'wait', u'for', u'it']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'My',\n",
       "     u'grandfather',\n",
       "     u'was',\n",
       "     u'a',\n",
       "     u'fire',\n",
       "     u'and',\n",
       "     u'brimstone',\n",
       "     u'preacher'],\n",
       "    'original': 'My grandfather was a fire and brimstone preacher',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'My',\n",
       "     u'grandfather',\n",
       "     u'was',\n",
       "     u'a',\n",
       "     u'fire',\n",
       "     u'and',\n",
       "     u'brimstone',\n",
       "     u'preacher']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'But', u'there', u'are', u'things', u'that', u'the'],\n",
       "    'original': 'But there are things that the',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But', u'there', u'are', u'things', u'that', u'the']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Homilies', u'and', u'hymns', u\"won't\", u'teach', u'ya'],\n",
       "    'original': \"Homilies and hymns won't teach ya\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Homilies', u'and', u'hymns', u\"won't\", u'teach', u'ya']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'My', u'mother', u'was', u'a', u'genius'],\n",
       "    'original': 'My mother was a genius',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'My', u'mother', u'was', u'a', u'genius']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'My', u'father', u'commanded', u'respect'],\n",
       "    'original': 'My father commanded respect',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'My', u'father', u'commanded', u'respect']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'When',\n",
       "     u'they',\n",
       "     u'died',\n",
       "     u'they',\n",
       "     u'left',\n",
       "     u'no',\n",
       "     u'instructions'],\n",
       "    'original': 'When they died they left no instructions',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'When',\n",
       "     u'they',\n",
       "     u'died',\n",
       "     u'they',\n",
       "     u'left',\n",
       "     u'no',\n",
       "     u'instructions']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Just', u'a', u'legacy', u'to', u'protect'],\n",
       "    'original': 'Just a legacy to protect',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Just', u'a', u'legacy', u'to', u'protect']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Preacher', u'preacher'],\n",
       "    'original': 'Preacher, preacher',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Preacher', u'preacher']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Preacher'],\n",
       "    'original': 'Preacher',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Preacher']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Teach', u'ya', u'teach', u'ya', u'teach', u'ya'],\n",
       "    'original': 'Teach ya, teach ya, teach ya',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Teach', u'ya', u'teach', u'ya', u'teach', u'ya']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Respect', u'respect'],\n",
       "    'original': 'Respect, respect',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Respect', u'respect']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Genius'],\n",
       "    'original': 'Genius',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Genius']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Death', u'doesn', u't', u'discriminate'],\n",
       "    'original': 'Death doesn\\x92t discriminate',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Death', u'doesn', u't', u'discriminate']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Between', u'the', u'sinners'],\n",
       "    'original': 'Between the sinners',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Between', u'the', u'sinners']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'And', u'the', u'saints'],\n",
       "    'original': 'And the saints',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And', u'the', u'saints']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes'],\n",
       "    'original': 'It takes and it takes and it takes',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'And', u'we', u'keep', u'living', u'anyway'],\n",
       "    'original': 'And we keep living anyway',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And', u'we', u'keep', u'living', u'anyway']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'We', u'rise', u'and', u'we', u'fall'],\n",
       "    'original': 'We rise and we fall',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'We', u'rise', u'and', u'we', u'fall']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'And', u'we', u'break'],\n",
       "    'original': 'And we break',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And', u'we', u'break']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'And', u'we', u'make', u'our', u'mistakes'],\n",
       "    'original': 'And we make our mistakes',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And', u'we', u'make', u'our', u'mistakes']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'And',\n",
       "     u'if',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'reason',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'still',\n",
       "     u'aliv'],\n",
       "    'original': 'And if there\\x92s a reason I\\x92m still alive',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And',\n",
       "     u'if',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'reason',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'still',\n",
       "     u'aliv']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'When',\n",
       "     u'everyone',\n",
       "     u'who',\n",
       "     u'loves',\n",
       "     u'me',\n",
       "     u'has',\n",
       "     u'died'],\n",
       "    'original': 'When everyone who loves me has died',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'When',\n",
       "     u'everyone',\n",
       "     u'who',\n",
       "     u'loves',\n",
       "     u'me',\n",
       "     u'has',\n",
       "     u'died']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'I', u'm', u'willing', u'to', u'wait', u'for', u'it'],\n",
       "    'original': 'I\\x92m willing to wait for it',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'm', u'willing', u'to', u'wait', u'for', u'it']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'I', u'm', u'willing', u'to', u'wait', u'for', u'it'],\n",
       "    'original': 'I\\x92m willing to wait for it',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'm', u'willing', u'to', u'wait', u'for', u'it']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'I',\n",
       "     u'am',\n",
       "     u'the',\n",
       "     u'one',\n",
       "     u'thing',\n",
       "     u'in',\n",
       "     u'life',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'control'],\n",
       "    'original': 'I am the one thing in life I can control',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'am',\n",
       "     u'the',\n",
       "     u'one',\n",
       "     u'thing',\n",
       "     u'in',\n",
       "     u'life',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'control']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'I', u'am', u'inimitable'],\n",
       "    'original': 'I am inimitable',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'am', u'inimitable']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'I', u'am', u'an', u'original'],\n",
       "    'original': 'I am an original',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'am', u'an', u'original']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'falling',\n",
       "     u'behind',\n",
       "     u'or',\n",
       "     u'running',\n",
       "     u'late'],\n",
       "    'original': 'I\\x92m not falling behind or running late',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'falling',\n",
       "     u'behind',\n",
       "     u'or',\n",
       "     u'running',\n",
       "     u'late']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'I', u'm', u'not', u'standing', u'still'],\n",
       "    'original': 'I\\x92m not standing still',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'm', u'not', u'standing', u'still']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'I', u'am', u'lying', u'in', u'wait'],\n",
       "    'original': 'I am lying in wait',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'am', u'lying', u'in', u'wait']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Wait'],\n",
       "    'original': 'Wait',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Wait'],\n",
       "    'original': 'Wait',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Wait'],\n",
       "    'original': 'Wait',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'Hamilton',\n",
       "     u'faces',\n",
       "     u'an',\n",
       "     u'endless',\n",
       "     u'uphill',\n",
       "     u'climb'],\n",
       "    'original': 'Hamilton faces an endless uphill climb',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hamilton',\n",
       "     u'faces',\n",
       "     u'an',\n",
       "     u'endless',\n",
       "     u'uphill',\n",
       "     u'climb']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'Climb'],\n",
       "    'original': 'Climb',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Climb']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Climb'],\n",
       "    'original': 'Climb',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Climb']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'Climb'],\n",
       "    'original': 'Climb',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Climb']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'He', u'has', u'something', u'to', u'prove'],\n",
       "    'original': 'He has something to prove',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He', u'has', u'something', u'to', u'prove']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'He', u'has', u'nothing', u'to', u'lose'],\n",
       "    'original': 'He has nothing to lose',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He', u'has', u'nothing', u'to', u'lose']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Lose'],\n",
       "    'original': 'Lose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Lose']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'Lose'],\n",
       "    'original': 'Lose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Lose']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Lose'],\n",
       "    'original': 'Lose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Lose']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Lose'],\n",
       "    'original': 'Lose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Lose']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'Hamilton', u's', u'pace', u'is', u'relentless'],\n",
       "    'original': 'Hamilton\\x92s pace is relentless',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hamilton', u's', u'pace', u'is', u'relentless']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'He', u'wastes', u'no', u'time'],\n",
       "    'original': 'He wastes no time',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He', u'wastes', u'no', u'time']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'What', u'is', u'it', u'like', u'in', u'his', u'shoes'],\n",
       "    'original': 'What is it like in his shoes?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'What', u'is', u'it', u'like', u'in', u'his', u'shoes']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'Hamilton', u'doesn', u't', u'hesitate'],\n",
       "    'original': 'Hamilton doesn\\x92t hesitate',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hamilton', u'doesn', u't', u'hesitate']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'He', u'exhibits', u'no', u'restraint'],\n",
       "    'original': 'He exhibits no restraint',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He', u'exhibits', u'no', u'restraint']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'He',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'he',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'he',\n",
       "     u'takes'],\n",
       "    'original': 'He takes and he takes and he takes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'he',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'he',\n",
       "     u'takes']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'And', u'he', u'keeps', u'winning', u'anyway'],\n",
       "    'original': 'And he keeps winning anyway',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'he', u'keeps', u'winning', u'anyway']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'He', u'changes', u'the', u'game'],\n",
       "    'original': 'He changes the game',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He', u'changes', u'the', u'game']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'He',\n",
       "     u'plays',\n",
       "     u'and',\n",
       "     u'he',\n",
       "     u'raises',\n",
       "     u'the',\n",
       "     u'stakes'],\n",
       "    'original': 'He plays and he raises the stakes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He',\n",
       "     u'plays',\n",
       "     u'and',\n",
       "     u'he',\n",
       "     u'raises',\n",
       "     u'the',\n",
       "     u'stakes']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'And', u'if', u'there', u's', u'a', u'reason'],\n",
       "    'original': 'And if there\\x92s a reason',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'if', u'there', u's', u'a', u'reason']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'He',\n",
       "     u'seems',\n",
       "     u'to',\n",
       "     u'thrive',\n",
       "     u'when',\n",
       "     u'so',\n",
       "     u'few',\n",
       "     u'survive',\n",
       "     u'then',\n",
       "     u'Goddamnit'],\n",
       "    'original': 'He seems to thrive when so few survive, then Goddamnit\\x97',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He',\n",
       "     u'seems',\n",
       "     u'to',\n",
       "     u'thrive',\n",
       "     u'when',\n",
       "     u'so',\n",
       "     u'few',\n",
       "     u'survive',\n",
       "     u'then',\n",
       "     u'Goddamnit']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u\"I'm\", u'willing', u'to', u'wait', u'for', u'it'],\n",
       "    'original': \"I'm willing to wait for it\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u\"I'm\", u'willing', u'to', u'wait', u'for', u'it']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u\"I'm\", u'willing', u'to', u'wait', u'for', u'it'],\n",
       "    'original': \"I'm willing to wait for it...\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u\"I'm\", u'willing', u'to', u'wait', u'for', u'it']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Life', u\"doesn't\", u'discriminate'],\n",
       "    'original': \"Life doesn't discriminate\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Life', u\"doesn't\", u'discriminate']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'Between', u'the', u'sinners', u'and', u'the', u'saints'],\n",
       "    'original': 'Between the sinners and the saints',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Between', u'the', u'sinners', u'and', u'the', u'saints']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes'],\n",
       "    'original': 'It takes and it takes and it takes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'We', u'rise'],\n",
       "    'original': 'We rise',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'We', u'rise']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'We', u'fall'],\n",
       "    'original': 'We fall',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'We', u'fall']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'And',\n",
       "     u'if',\n",
       "     u\"there's\",\n",
       "     u'a',\n",
       "     u'reason',\n",
       "     u\"I'm\",\n",
       "     u'still',\n",
       "     u'alive'],\n",
       "    'original': \"And if there's a reason I'm still alive\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'if',\n",
       "     u\"there's\",\n",
       "     u'a',\n",
       "     u'reason',\n",
       "     u\"I'm\",\n",
       "     u'still',\n",
       "     u'alive']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'When', u'so', u'many', u'have', u'died'],\n",
       "    'original': 'When so many have died',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'When', u'so', u'many', u'have', u'died']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Then', u\"I'm\", u'willin', u'to'],\n",
       "    'original': \"Then I'm willin' to\\x97\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Then', u\"I'm\", u'willin', u'to']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u\"I'm\", u'willing', u'to', u'wait', u'for', u'it'],\n",
       "    'original': \"I'm willing to wait for it\",\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u\"I'm\", u'willing', u'to', u'wait', u'for', u'it']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'Wait', u'for'],\n",
       "    'original': 'Wait for...',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Wait', u'for']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u\"I'm\", u'willing', u'to'],\n",
       "    'original': \"I'm willing to\\x97\",\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u\"I'm\", u'willing', u'to']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'Life', u\"doesn't\", u'discriminate'],\n",
       "    'original': \"Life doesn't discriminate\",\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Life', u\"doesn't\", u'discriminate']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'Between', u'the', u'sinners', u'and', u'the', u'saints'],\n",
       "    'original': 'Between the sinners and the saints',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Between', u'the', u'sinners', u'and', u'the', u'saints']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes'],\n",
       "    'original': 'It takes and it takes and it takes',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'And', u'we', u'keep', u'living', u'anyway'],\n",
       "    'original': 'And we keep living anyway',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'And', u'we', u'keep', u'living', u'anyway']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'We',\n",
       "     u'rise',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'fall',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'break'],\n",
       "    'original': 'We rise and we fall and we break',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'We',\n",
       "     u'rise',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'fall',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'break']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'And', u'we', u'make', u'our', u'mistakes'],\n",
       "    'original': 'And we make our mistakes',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'And', u'we', u'make', u'our', u'mistakes']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'And',\n",
       "     u'if',\n",
       "     u\"there's\",\n",
       "     u'a',\n",
       "     u'reason',\n",
       "     u\"I'm\",\n",
       "     u'still',\n",
       "     u'alive'],\n",
       "    'original': \"And if there's a reason I'm still alive\",\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'And',\n",
       "     u'if',\n",
       "     u\"there's\",\n",
       "     u'a',\n",
       "     u'reason',\n",
       "     u\"I'm\",\n",
       "     u'still',\n",
       "     u'alive']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'When', u'so', u'many', u'have', u'died'],\n",
       "    'original': 'When so many have died',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'When', u'so', u'many', u'have', u'died']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'Then', u\"I'm\", u'willin', u'to'],\n",
       "    'original': \"Then I'm willin' to\\x97\",\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Then', u\"I'm\", u'willin', u'to']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'Wait', u'for', u'it'],\n",
       "    'original': 'Wait for it...',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Wait', u'for', u'it']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'Wait'],\n",
       "    'original': 'Wait...',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Wait']}],\n",
       "  'track': 'Wait For It',\n",
       "  'track#': '13'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Stay', u'alive'],\n",
       "    'original': 'Stay alive\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Stay', u'alive']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Stay', u'alive'],\n",
       "    'original': 'Stay alive\\x85',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'ENSEMBLE WOMEN'],\n",
       "    'tokenized': [u'Stay', u'alive']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'never',\n",
       "     u'seen',\n",
       "     u'the',\n",
       "     u'General',\n",
       "     u'so',\n",
       "     u'despondent'],\n",
       "    'original': 'I have never seen the General so despondent',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'never',\n",
       "     u'seen',\n",
       "     u'the',\n",
       "     u'General',\n",
       "     u'so',\n",
       "     u'despondent']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'taken',\n",
       "     u'over',\n",
       "     u'writing',\n",
       "     u'all',\n",
       "     u'his',\n",
       "     u'correspondence'],\n",
       "    'original': 'I have taken over writing all his correspondence',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'taken',\n",
       "     u'over',\n",
       "     u'writing',\n",
       "     u'all',\n",
       "     u'his',\n",
       "     u'correspondence']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Congress',\n",
       "     u'writes',\n",
       "     u'George',\n",
       "     u'attack',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'forces'],\n",
       "    'original': 'Congress writes, \\x93George, attack the British forces.\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Congress',\n",
       "     u'writes',\n",
       "     u'George',\n",
       "     u'attack',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'forces']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'I',\n",
       "     u'shoot',\n",
       "     u'back',\n",
       "     u'we',\n",
       "     u'have',\n",
       "     u'resorted',\n",
       "     u'to',\n",
       "     u'eating',\n",
       "     u'our',\n",
       "     u'horses'],\n",
       "    'original': 'I shoot back, we have resorted to eating our horses',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'shoot',\n",
       "     u'back',\n",
       "     u'we',\n",
       "     u'have',\n",
       "     u'resorted',\n",
       "     u'to',\n",
       "     u'eating',\n",
       "     u'our',\n",
       "     u'horses']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Local',\n",
       "     u'merchants',\n",
       "     u'deny',\n",
       "     u'us',\n",
       "     u'equipment',\n",
       "     u'assistance'],\n",
       "    'original': 'Local merchants deny us equipment, assistance',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Local',\n",
       "     u'merchants',\n",
       "     u'deny',\n",
       "     u'us',\n",
       "     u'equipment',\n",
       "     u'assistance']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'They',\n",
       "     u'only',\n",
       "     u'take',\n",
       "     u'British',\n",
       "     u'money',\n",
       "     u'so',\n",
       "     u'sing',\n",
       "     u'a',\n",
       "     u'song',\n",
       "     u'of',\n",
       "     u'sixpence'],\n",
       "    'original': 'They only take British money, so sing a song of sixpence',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'They',\n",
       "     u'only',\n",
       "     u'take',\n",
       "     u'British',\n",
       "     u'money',\n",
       "     u'so',\n",
       "     u'sing',\n",
       "     u'a',\n",
       "     u'song',\n",
       "     u'of',\n",
       "     u'sixpence']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'The', u'cavalry', u's', u'not', u'coming'],\n",
       "    'original': 'The cavalry\\x92s not coming',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The', u'cavalry', u's', u'not', u'coming']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'But', u'sir'],\n",
       "    'original': 'But, sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But', u'sir']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Alex',\n",
       "     u'listen',\n",
       "     u'There',\n",
       "     u's',\n",
       "     u'only',\n",
       "     u'one',\n",
       "     u'way',\n",
       "     u'for',\n",
       "     u'us',\n",
       "     u'to',\n",
       "     u'win',\n",
       "     u'this'],\n",
       "    'original': 'Alex, listen. There\\x92s only one way for us to win this',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Alex',\n",
       "     u'listen',\n",
       "     u'There',\n",
       "     u's',\n",
       "     u'only',\n",
       "     u'one',\n",
       "     u'way',\n",
       "     u'for',\n",
       "     u'us',\n",
       "     u'to',\n",
       "     u'win',\n",
       "     u'this']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Provoke', u'outrage', u'outright'],\n",
       "    'original': 'Provoke outrage, outright',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Provoke', u'outrage', u'outright']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'That', u's', u'right'],\n",
       "    'original': 'That\\x92s right',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That', u's', u'right']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Don', u't', u'engage', u'strike', u'by', u'night'],\n",
       "    'original': 'Don\\x92t engage, strike by night',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Don', u't', u'engage', u'strike', u'by', u'night']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Remain',\n",
       "     u'relentless',\n",
       "     u'til',\n",
       "     u'their',\n",
       "     u'troops',\n",
       "     u'take',\n",
       "     u'flight'],\n",
       "    'original': 'Remain relentless \\x91til their troops take flight',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Remain',\n",
       "     u'relentless',\n",
       "     u'til',\n",
       "     u'their',\n",
       "     u'troops',\n",
       "     u'take',\n",
       "     u'flight']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Make',\n",
       "     u'it',\n",
       "     u'impossible',\n",
       "     u'to',\n",
       "     u'justify',\n",
       "     u'the',\n",
       "     u'cost',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'fight'],\n",
       "    'original': 'Make it impossible to justify the cost of the fight',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Make',\n",
       "     u'it',\n",
       "     u'impossible',\n",
       "     u'to',\n",
       "     u'justify',\n",
       "     u'the',\n",
       "     u'cost',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'fight']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Outrun'],\n",
       "    'original': 'Outrun',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Outrun']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Outrun'],\n",
       "    'original': 'Outrun',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Outrun']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Outlast'],\n",
       "    'original': 'Outlast',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Outlast']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Outlast'],\n",
       "    'original': 'Outlast',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Outlast']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Hit', u'em', u'quick', u'get', u'out', u'fast'],\n",
       "    'original': 'Hit \\x91em quick, get out fast',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Hit', u'em', u'quick', u'get', u'out', u'fast']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Chick', u'a', u'plao'],\n",
       "    'original': 'Chick-a-plao!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Chick', u'a', u'plao']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Stay',\n",
       "     u'alive',\n",
       "     u'til',\n",
       "     u'this',\n",
       "     u'horror',\n",
       "     u'show',\n",
       "     u'is',\n",
       "     u'past'],\n",
       "    'original': 'Stay alive \\x91til this horror show is past',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Stay',\n",
       "     u'alive',\n",
       "     u'til',\n",
       "     u'this',\n",
       "     u'horror',\n",
       "     u'show',\n",
       "     u'is',\n",
       "     u'past']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'We',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'fly',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'of',\n",
       "     u'flags',\n",
       "     u'half',\n",
       "     u'mast'],\n",
       "    'original': 'We\\x92re gonna fly a lot of flags half-mast',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'fly',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'of',\n",
       "     u'flags',\n",
       "     u'half',\n",
       "     u'mast']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Raise', u'a', u'glass'],\n",
       "    'original': 'Raise a glass!',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Raise', u'a', u'glass']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'I',\n",
       "     u'go',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'apprenticeship'],\n",
       "    'original': 'I go back to New York and my apprenticeship',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'I',\n",
       "     u'go',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'apprenticeship']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'I',\n",
       "     u'ask',\n",
       "     u'for',\n",
       "     u'French',\n",
       "     u'aid',\n",
       "     u'I',\n",
       "     u'pray',\n",
       "     u'that',\n",
       "     u'France',\n",
       "     u'has',\n",
       "     u'sent',\n",
       "     u'a',\n",
       "     u'ship'],\n",
       "    'original': 'I ask for French aid, I pray that France has sent a ship',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'ask',\n",
       "     u'for',\n",
       "     u'French',\n",
       "     u'aid',\n",
       "     u'I',\n",
       "     u'pray',\n",
       "     u'that',\n",
       "     u'France',\n",
       "     u'has',\n",
       "     u'sent',\n",
       "     u'a',\n",
       "     u'ship']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'I', u'stay', u'at', u'work', u'with', u'Hamilton'],\n",
       "    'original': 'I stay at work with Hamilton',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'I', u'stay', u'at', u'work', u'with', u'Hamilton']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'We', u'write', u'essays', u'against', u'slavery'],\n",
       "    'original': 'We write essays against slavery',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'We', u'write', u'essays', u'against', u'slavery']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'And',\n",
       "     u'every',\n",
       "     u'day',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'test',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'camaraderie'],\n",
       "    'original': 'And every day\\x92s a test of our camaraderie',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'And',\n",
       "     u'every',\n",
       "     u'day',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'test',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'camaraderie']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'And', u'bravery'],\n",
       "    'original': 'And bravery',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'And', u'bravery']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'We',\n",
       "     u'cut',\n",
       "     u'supply',\n",
       "     u'lines',\n",
       "     u'we',\n",
       "     u'steal',\n",
       "     u'contraband'],\n",
       "    'original': 'We cut supply lines, we steal contraband',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'cut',\n",
       "     u'supply',\n",
       "     u'lines',\n",
       "     u'we',\n",
       "     u'steal',\n",
       "     u'contraband']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'We',\n",
       "     u'pick',\n",
       "     u'and',\n",
       "     u'choose',\n",
       "     u'our',\n",
       "     u'battles',\n",
       "     u'and',\n",
       "     u'places',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'stand'],\n",
       "    'original': 'We pick and choose our battles and places to take a stand',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'pick',\n",
       "     u'and',\n",
       "     u'choose',\n",
       "     u'our',\n",
       "     u'battles',\n",
       "     u'and',\n",
       "     u'places',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'stand']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'And', u'ev', u'ry', u'day'],\n",
       "    'original': 'And ev\\x92ry day',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'ev', u'ry', u'day']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Sir', u'entrust', u'me', u'with', u'a', u'command'],\n",
       "    'original': '\\x93Sir, entrust me with a command,\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir', u'entrust', u'me', u'with', u'a', u'command']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'And', u'ev', u'ry', u'day'],\n",
       "    'original': 'And ev\\x92ry day',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'ev', u'ry', u'day']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'He', u'dismisses', u'me', u'out', u'of', u'hand'],\n",
       "    'original': 'He dismisses me out of hand',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'He', u'dismisses', u'me', u'out', u'of', u'hand']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Instead', u'of', u'me'],\n",
       "    'original': 'Instead of me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Instead', u'of', u'me']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'He', u'promotes'],\n",
       "    'original': 'He promotes',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'He', u'promotes']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Charles', u'Lee'],\n",
       "    'original': 'Charles Lee',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Charles', u'Lee']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Makes', u'him', u'second', u'in', u'command'],\n",
       "    'original': 'Makes him second-in-command:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Makes', u'him', u'second', u'in', u'command']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Charles', u'Lee'],\n",
       "    'original': 'Charles Lee.',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Charles', u'Lee']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Stay', u'alive'],\n",
       "    'original': 'Stay alive...',\n",
       "    'speakers': ['ELIZA', 'ANGELICA'],\n",
       "    'tokenized': [u'Stay', u'alive']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'I', u'm', u'a', u'General', u'Whee'],\n",
       "    'original': 'I\\x92m a General. Whee!!!!',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'I', u'm', u'a', u'General', u'Whee']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Yeah',\n",
       "     u'He',\n",
       "     u's',\n",
       "     u'not',\n",
       "     u'the',\n",
       "     u'choice',\n",
       "     u'I',\n",
       "     u'would',\n",
       "     u'have',\n",
       "     u'gone',\n",
       "     u'with'],\n",
       "    'original': 'Yeah. He\\x92s not the choice I would have gone with',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yeah',\n",
       "     u'He',\n",
       "     u's',\n",
       "     u'not',\n",
       "     u'the',\n",
       "     u'choice',\n",
       "     u'I',\n",
       "     u'would',\n",
       "     u'have',\n",
       "     u'gone',\n",
       "     u'with']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'He',\n",
       "     u'shits',\n",
       "     u'the',\n",
       "     u'bed',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'Battle',\n",
       "     u'of',\n",
       "     u'Monmouth'],\n",
       "    'original': 'He shits the bed at the Battle of Monmouth',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'He',\n",
       "     u'shits',\n",
       "     u'the',\n",
       "     u'bed',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'Battle',\n",
       "     u'of',\n",
       "     u'Monmouth']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Ev', u'ryone', u'attack'],\n",
       "    'original': 'Ev\\x92ryone attack!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Ev', u'ryone', u'attack']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Retreat'],\n",
       "    'original': 'Retreat!',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Retreat']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Attack'],\n",
       "    'original': 'Attack!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Attack']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Retreat'],\n",
       "    'original': 'Retreat!',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Retreat']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'What',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'doing',\n",
       "     u'Lee',\n",
       "     u'Get',\n",
       "     u'back',\n",
       "     u'on',\n",
       "     u'your',\n",
       "     u'feet'],\n",
       "    'original': 'What are you doing, Lee? Get back on your feet!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'What',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'doing',\n",
       "     u'Lee',\n",
       "     u'Get',\n",
       "     u'back',\n",
       "     u'on',\n",
       "     u'your',\n",
       "     u'feet']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'But', u'there', u's', u'so', u'many', u'of', u'them'],\n",
       "    'original': 'But there\\x92s so many of them!',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'But', u'there', u's', u'so', u'many', u'of', u'them']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'sorry',\n",
       "     u'is',\n",
       "     u'this',\n",
       "     u'not',\n",
       "     u'your',\n",
       "     u'speed'],\n",
       "    'original': 'I\\x92m sorry, is this not your speed?!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'sorry',\n",
       "     u'is',\n",
       "     u'this',\n",
       "     u'not',\n",
       "     u'your',\n",
       "     u'speed']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Ready', u'sir'],\n",
       "    'original': 'Ready, sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ready', u'sir']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Have', u'Lafayette', u'take', u'the', u'lead'],\n",
       "    'original': 'Have Lafayette take the lead!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Have', u'Lafayette', u'take', u'the', u'lead']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Yes', u'sir'],\n",
       "    'original': 'Yes, sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes', u'sir']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'A',\n",
       "     u'thousand',\n",
       "     u'soldiers',\n",
       "     u'die',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'hundred',\n",
       "     u'degree',\n",
       "     u'heat'],\n",
       "    'original': 'A thousand soldiers die in a hundred degree heat',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'A',\n",
       "     u'thousand',\n",
       "     u'soldiers',\n",
       "     u'die',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'hundred',\n",
       "     u'degree',\n",
       "     u'heat']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'As',\n",
       "     u'we',\n",
       "     u'snatch',\n",
       "     u'a',\n",
       "     u'stalemate',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'jaws',\n",
       "     u'of',\n",
       "     u'defeat'],\n",
       "    'original': 'As we snatch a stalemate from the jaws of defeat',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'As',\n",
       "     u'we',\n",
       "     u'snatch',\n",
       "     u'a',\n",
       "     u'stalemate',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'jaws',\n",
       "     u'of',\n",
       "     u'defeat']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Charles', u'Lee', u'was', u'left', u'behind'],\n",
       "    'original': 'Charles Lee was left behind',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Charles', u'Lee', u'was', u'left', u'behind']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Without', u'a', u'pot', u'to', u'piss', u'in'],\n",
       "    'original': 'Without a pot to piss in',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Without', u'a', u'pot', u'to', u'piss', u'in']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'He',\n",
       "     u'started',\n",
       "     u'sayin',\n",
       "     u'this',\n",
       "     u'to',\n",
       "     u'anybody',\n",
       "     u'who',\n",
       "     u'would',\n",
       "     u'listen'],\n",
       "    'original': 'He started sayin\\x92 this to anybody who would listen:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'He',\n",
       "     u'started',\n",
       "     u'sayin',\n",
       "     u'this',\n",
       "     u'to',\n",
       "     u'anybody',\n",
       "     u'who',\n",
       "     u'would',\n",
       "     u'listen']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Washington',\n",
       "     u'cannot',\n",
       "     u'be',\n",
       "     u'left',\n",
       "     u'alone',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'devices'],\n",
       "    'original': 'Washington cannot be left alone to his devices',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Washington',\n",
       "     u'cannot',\n",
       "     u'be',\n",
       "     u'left',\n",
       "     u'alone',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'devices']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Indecisive', u'from', u'crisis', u'to', u'crisis'],\n",
       "    'original': 'Indecisive, from crisis to crisis',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Indecisive', u'from', u'crisis', u'to', u'crisis']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'The',\n",
       "     u'best',\n",
       "     u'thing',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'do',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'revolution'],\n",
       "    'original': 'The best thing he can do for the revolution',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'The',\n",
       "     u'best',\n",
       "     u'thing',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'do',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'revolution']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Is',\n",
       "     u'turn',\n",
       "     u'n',\n",
       "     u'go',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'plantin',\n",
       "     u'tobacco',\n",
       "     u'in',\n",
       "     u'Mount',\n",
       "     u'Verno'],\n",
       "    'original': 'Is turn n\\x92 go back to plantin\\x92 tobacco in Mount Vernon',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Is',\n",
       "     u'turn',\n",
       "     u'n',\n",
       "     u'go',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'plantin',\n",
       "     u'tobacco',\n",
       "     u'in',\n",
       "     u'Mount',\n",
       "     u'Verno']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'Oo'],\n",
       "    'original': 'Oo!!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Oo']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'Don',\n",
       "     u't',\n",
       "     u'do',\n",
       "     u'a',\n",
       "     u'thing',\n",
       "     u'History',\n",
       "     u'will',\n",
       "     u'prove',\n",
       "     u'him',\n",
       "     u'wrong'],\n",
       "    'original': 'Don\\x92t do a thing. History will prove him wrong',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Don',\n",
       "     u't',\n",
       "     u'do',\n",
       "     u'a',\n",
       "     u'thing',\n",
       "     u'History',\n",
       "     u'will',\n",
       "     u'prove',\n",
       "     u'him',\n",
       "     u'wrong']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'But', u'sir'],\n",
       "    'original': 'But, sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But', u'sir']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'We',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'war',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'let',\n",
       "     u's',\n",
       "     u'move',\n",
       "     u'along'],\n",
       "    'original': 'We have a war to fight, let\\x92s move along',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'war',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'let',\n",
       "     u's',\n",
       "     u'move',\n",
       "     u'along']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'Strong',\n",
       "     u'words',\n",
       "     u'from',\n",
       "     u'Lee',\n",
       "     u'someone',\n",
       "     u'oughta',\n",
       "     u'hold',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'it'],\n",
       "    'original': 'Strong words from Lee, someone oughta hold him to it',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Strong',\n",
       "     u'words',\n",
       "     u'from',\n",
       "     u'Lee',\n",
       "     u'someone',\n",
       "     u'oughta',\n",
       "     u'hold',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'it']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'I', u'can', u't', u'disobey', u'direct', u'orders'],\n",
       "    'original': 'I can\\x92t disobey direct orders',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'can', u't', u'disobey', u'direct', u'orders']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Then', u'I', u'll', u'do', u'it'],\n",
       "    'original': 'Then I\\x92ll do it',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Then', u'I', u'll', u'do', u'it']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'Alexander',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'closest',\n",
       "     u'friend',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'go'],\n",
       "    'original': 'Alexander, you\\x92re the closest friend I\\x92ve got',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Alexander',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'closest',\n",
       "     u'friend',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'go']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Laurens',\n",
       "     u'do',\n",
       "     u'not',\n",
       "     u'throw',\n",
       "     u'away',\n",
       "     u'your',\n",
       "     u'shot'],\n",
       "    'original': 'Laurens, do not throw away your shot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Laurens',\n",
       "     u'do',\n",
       "     u'not',\n",
       "     u'throw',\n",
       "     u'away',\n",
       "     u'your',\n",
       "     u'shot']}],\n",
       "  'track': 'Stay Alive',\n",
       "  'track#': '14'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'One', u'two', u'three', u'four'],\n",
       "    'original': 'One, two, three, four',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'One', u'two', u'three', u'four']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Five', u'six', u'seven', u'eight', u'nine'],\n",
       "    'original': 'Five, six, seven, eight, nine\\x85',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Five', u'six', u'seven', u'eight', u'nine']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'It', u's', u'the', u'Ten', u'Duel', u'Commandments'],\n",
       "    'original': 'It\\x92s the Ten Duel Commandments',\n",
       "    'speakers': ['BURR', 'HAMILTON', 'LAURENS', 'LEE'],\n",
       "    'tokenized': [u'It', u's', u'the', u'Ten', u'Duel', u'Commandments']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'It', u's', u'the', u'Ten', u'Duel', u'Commandments'],\n",
       "    'original': 'It\\x92s the Ten Duel Commandments',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'It', u's', u'the', u'Ten', u'Duel', u'Commandments']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Number', u'one'],\n",
       "    'original': 'Number one!',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Number', u'one']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'The', u'challenge', u'demand', u'satisfaction'],\n",
       "    'original': 'The challenge: demand satisfaction',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'The', u'challenge', u'demand', u'satisfaction']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'If',\n",
       "     u'they',\n",
       "     u'apologize',\n",
       "     u'no',\n",
       "     u'need',\n",
       "     u'for',\n",
       "     u'further',\n",
       "     u'action'],\n",
       "    'original': 'If they apologize, no need for further action',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'If',\n",
       "     u'they',\n",
       "     u'apologize',\n",
       "     u'no',\n",
       "     u'need',\n",
       "     u'for',\n",
       "     u'further',\n",
       "     u'action']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Number', u'two'],\n",
       "    'original': 'Number two!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'two']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'If',\n",
       "     u'they',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'grab',\n",
       "     u'a',\n",
       "     u'friend',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'your',\n",
       "     u'secon'],\n",
       "    'original': 'If they don\\x92t, grab a friend, that\\x92s your second',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'If',\n",
       "     u'they',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'grab',\n",
       "     u'a',\n",
       "     u'friend',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'your',\n",
       "     u'secon']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Your',\n",
       "     u'lieutenant',\n",
       "     u'when',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'reckoning',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'reckoned'],\n",
       "    'original': 'Your lieutenant when there\\x92s reckoning to be reckoned',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Your',\n",
       "     u'lieutenant',\n",
       "     u'when',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'reckoning',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'reckoned']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Number', u'three'],\n",
       "    'original': 'Number three!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'three']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Have',\n",
       "     u'your',\n",
       "     u'seconds',\n",
       "     u'meet',\n",
       "     u'face',\n",
       "     u'to',\n",
       "     u'face'],\n",
       "    'original': 'Have your seconds meet face to face',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Have',\n",
       "     u'your',\n",
       "     u'seconds',\n",
       "     u'meet',\n",
       "     u'face',\n",
       "     u'to',\n",
       "     u'face']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Negotiate', u'a', u'peace'],\n",
       "    'original': 'Negotiate a peace\\x85',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Negotiate', u'a', u'peace']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Or', u'negotiate', u'a', u'time', u'and', u'place'],\n",
       "    'original': 'Or negotiate a time and place',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Or', u'negotiate', u'a', u'time', u'and', u'place']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'This',\n",
       "     u'is',\n",
       "     u'commonplace',\n",
       "     u'specially',\n",
       "     u'tween',\n",
       "     u'recruit'],\n",
       "    'original': 'This is commonplace, \\x91specially \\x91tween recruits',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'This',\n",
       "     u'is',\n",
       "     u'commonplace',\n",
       "     u'specially',\n",
       "     u'tween',\n",
       "     u'recruit']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Most',\n",
       "     u'disputes',\n",
       "     u'die',\n",
       "     u'and',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'shoots'],\n",
       "    'original': 'Most disputes die, and no one shoots',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Most',\n",
       "     u'disputes',\n",
       "     u'die',\n",
       "     u'and',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'shoots']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Number', u'four'],\n",
       "    'original': 'Number four!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'four']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'If',\n",
       "     u'they',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'reach',\n",
       "     u'a',\n",
       "     u'peace',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'alrigh'],\n",
       "    'original': 'If they don\\x92t reach a peace, that\\x92s alright',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'If',\n",
       "     u'they',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'reach',\n",
       "     u'a',\n",
       "     u'peace',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'alrigh']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Time',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'some',\n",
       "     u'pistols',\n",
       "     u'and',\n",
       "     u'a',\n",
       "     u'doctor',\n",
       "     u'on',\n",
       "     u'site'],\n",
       "    'original': 'Time to get some pistols and a doctor on site',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Time',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'some',\n",
       "     u'pistols',\n",
       "     u'and',\n",
       "     u'a',\n",
       "     u'doctor',\n",
       "     u'on',\n",
       "     u'site']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'You',\n",
       "     u'pay',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'advance',\n",
       "     u'you',\n",
       "     u'treat',\n",
       "     u'him',\n",
       "     u'with',\n",
       "     u'civility'],\n",
       "    'original': 'You pay him in advance, you treat him with civility',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'pay',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'advance',\n",
       "     u'you',\n",
       "     u'treat',\n",
       "     u'him',\n",
       "     u'with',\n",
       "     u'civility']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'You',\n",
       "     u'have',\n",
       "     u'him',\n",
       "     u'turn',\n",
       "     u'around',\n",
       "     u'so',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'have',\n",
       "     u'deniability'],\n",
       "    'original': 'You have him turn around so he can have deniability',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u'have',\n",
       "     u'him',\n",
       "     u'turn',\n",
       "     u'around',\n",
       "     u'so',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'have',\n",
       "     u'deniability']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Five'],\n",
       "    'original': 'Five!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Five']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Duel',\n",
       "     u'before',\n",
       "     u'the',\n",
       "     u'sun',\n",
       "     u'is',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'sky'],\n",
       "    'original': 'Duel before the sun is in the sky',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Duel',\n",
       "     u'before',\n",
       "     u'the',\n",
       "     u'sun',\n",
       "     u'is',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'sky']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Pick',\n",
       "     u'a',\n",
       "     u'place',\n",
       "     u'to',\n",
       "     u'die',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'high',\n",
       "     u'and',\n",
       "     u'dry'],\n",
       "    'original': 'Pick a place to die where it\\x92s high and dry',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Pick',\n",
       "     u'a',\n",
       "     u'place',\n",
       "     u'to',\n",
       "     u'die',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'high',\n",
       "     u'and',\n",
       "     u'dry']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Number', u'six'],\n",
       "    'original': 'Number six!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'six']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Leave',\n",
       "     u'a',\n",
       "     u'note',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'next',\n",
       "     u'of',\n",
       "     u'kin'],\n",
       "    'original': 'Leave a note for your next of kin',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Leave',\n",
       "     u'a',\n",
       "     u'note',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'next',\n",
       "     u'of',\n",
       "     u'kin']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Tell',\n",
       "     u'em',\n",
       "     u'where',\n",
       "     u'you',\n",
       "     u'been',\n",
       "     u'Pray',\n",
       "     u'that',\n",
       "     u'hell',\n",
       "     u'or',\n",
       "     u'heaven',\n",
       "     u'lets',\n",
       "     u'you',\n",
       "     u'in'],\n",
       "    'original': 'Tell \\x91em where you been. Pray that hell or heaven lets you in',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Tell',\n",
       "     u'em',\n",
       "     u'where',\n",
       "     u'you',\n",
       "     u'been',\n",
       "     u'Pray',\n",
       "     u'that',\n",
       "     u'hell',\n",
       "     u'or',\n",
       "     u'heaven',\n",
       "     u'lets',\n",
       "     u'you',\n",
       "     u'in']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Seven'],\n",
       "    'original': 'Seven!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Seven']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Confess',\n",
       "     u'your',\n",
       "     u'sins',\n",
       "     u'Ready',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'moment'],\n",
       "    'original': 'Confess your sins. Ready for the moment',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Confess',\n",
       "     u'your',\n",
       "     u'sins',\n",
       "     u'Ready',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'moment']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Of',\n",
       "     u'adrenaline',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'finally',\n",
       "     u'face',\n",
       "     u'your',\n",
       "     u'opponent'],\n",
       "    'original': 'Of adrenaline when you finally face your opponent',\n",
       "    'speakers': ['LEE'],\n",
       "    'tokenized': [u'Of',\n",
       "     u'adrenaline',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'finally',\n",
       "     u'face',\n",
       "     u'your',\n",
       "     u'opponent']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Number', u'eight'],\n",
       "    'original': 'Number eight!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'eight']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Your', u'last', u'chance', u'to', u'negotiate'],\n",
       "    'original': 'Your last chance to negotiate',\n",
       "    'speakers': ['LAURENS', 'LEE', 'HAMILTON', 'BURR'],\n",
       "    'tokenized': [u'Your', u'last', u'chance', u'to', u'negotiate']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Send',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'seconds',\n",
       "     u'see',\n",
       "     u'if',\n",
       "     u'they',\n",
       "     u'can',\n",
       "     u'set',\n",
       "     u'the',\n",
       "     u'record',\n",
       "     u'straight'],\n",
       "    'original': 'Send in your seconds, see if they can set the record straight\\x85',\n",
       "    'speakers': ['LAURENS', 'LEE', 'HAMILTON', 'BURR'],\n",
       "    'tokenized': [u'Send',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'seconds',\n",
       "     u'see',\n",
       "     u'if',\n",
       "     u'they',\n",
       "     u'can',\n",
       "     u'set',\n",
       "     u'the',\n",
       "     u'record',\n",
       "     u'straight']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Alexander'],\n",
       "    'original': 'Alexander',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Alexander']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Aaron', u'Burr', u'sir'],\n",
       "    'original': 'Aaron Burr, sir',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Aaron', u'Burr', u'sir']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Can',\n",
       "     u'we',\n",
       "     u'agree',\n",
       "     u'that',\n",
       "     u'duels',\n",
       "     u'are',\n",
       "     u'dumb',\n",
       "     u'and',\n",
       "     u'immature'],\n",
       "    'original': 'Can we agree that duels are dumb and immature?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Can',\n",
       "     u'we',\n",
       "     u'agree',\n",
       "     u'that',\n",
       "     u'duels',\n",
       "     u'are',\n",
       "     u'dumb',\n",
       "     u'and',\n",
       "     u'immature']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Sure'],\n",
       "    'original': 'Sure',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sure']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'But',\n",
       "     u'your',\n",
       "     u'man',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'answer',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'words',\n",
       "     u'Burr'],\n",
       "    'original': 'But your man has to answer for his words, Burr',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'your',\n",
       "     u'man',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'answer',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'words',\n",
       "     u'Burr']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'With',\n",
       "     u'his',\n",
       "     u'life',\n",
       "     u'We',\n",
       "     u'both',\n",
       "     u'know',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'absurd',\n",
       "     u'sir'],\n",
       "    'original': 'With his life? We both know that\\x92s absurd, sir',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'With',\n",
       "     u'his',\n",
       "     u'life',\n",
       "     u'We',\n",
       "     u'both',\n",
       "     u'know',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'absurd',\n",
       "     u'sir']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Hang',\n",
       "     u'on',\n",
       "     u'how',\n",
       "     u'many',\n",
       "     u'men',\n",
       "     u'died',\n",
       "     u'because',\n",
       "     u'Lee',\n",
       "     u'was',\n",
       "     u'inexperienced',\n",
       "     u'and',\n",
       "     u'ruinous'],\n",
       "    'original': 'Hang on, how many men died because Lee was inexperienced and ruinous?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hang',\n",
       "     u'on',\n",
       "     u'how',\n",
       "     u'many',\n",
       "     u'men',\n",
       "     u'died',\n",
       "     u'because',\n",
       "     u'Lee',\n",
       "     u'was',\n",
       "     u'inexperienced',\n",
       "     u'and',\n",
       "     u'ruinous']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Okay', u'so', u'we', u're', u'doin', u'thi'],\n",
       "    'original': 'Okay, so we\\x92re doin\\x92 this',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Okay', u'so', u'we', u're', u'doin', u'thi']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Number', u'nine'],\n",
       "    'original': 'Number nine!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'nine']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Look',\n",
       "     u'em',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'eye',\n",
       "     u'aim',\n",
       "     u'no',\n",
       "     u'higher'],\n",
       "    'original': 'Look \\x91em in the eye, aim no higher',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'em',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'eye',\n",
       "     u'aim',\n",
       "     u'no',\n",
       "     u'higher']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Summon', u'all', u'the', u'courage', u'you', u'require'],\n",
       "    'original': 'Summon all the courage you require',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Summon', u'all', u'the', u'courage', u'you', u'require']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Then', u'count'],\n",
       "    'original': 'Then count',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Then', u'count']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'One', u'two', u'three', u'four'],\n",
       "    'original': 'One two three four',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'One', u'two', u'three', u'four']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Five', u'six', u'seven', u'eight', u'nine'],\n",
       "    'original': 'Five six seven eight nine',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Five', u'six', u'seven', u'eight', u'nine']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Number'],\n",
       "    'original': 'Number',\n",
       "    'speakers': ['HAMILTON', 'BURR'],\n",
       "    'tokenized': [u'Number']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Ten', u'paces'],\n",
       "    'original': 'Ten paces!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Ten', u'paces']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Fire'],\n",
       "    'original': 'Fire!',\n",
       "    'speakers': ['HAMILTON', 'BURR'],\n",
       "    'tokenized': [u'Fire']}],\n",
       "  'track': 'Ten Duel Commandments',\n",
       "  'track#': '15'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Lee', u'do', u'you', u'yield'],\n",
       "    'original': 'Lee, do you yield?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Lee', u'do', u'you', u'yield']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'You', u'shot', u'him', u'in', u'the', u'side'],\n",
       "    'original': 'You shot him in the side!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You', u'shot', u'him', u'in', u'the', u'side']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Yes', u'he', u'yields'],\n",
       "    'original': 'Yes, he yields!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Yes', u'he', u'yields']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I', u'm', u'satisfied'],\n",
       "    'original': 'I\\x92m satisfied',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'I', u'm', u'satisfied']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Yo', u'we', u'gotta', u'clear', u'the', u'field'],\n",
       "    'original': 'Yo, we gotta clear the field!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Yo', u'we', u'gotta', u'clear', u'the', u'field']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Go', u'We', u'won'],\n",
       "    'original': 'Go! We won',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Go', u'We', u'won']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Here', u'comes', u'the', u'General'],\n",
       "    'original': 'Here comes the General!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Here', u'comes', u'the', u'General']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'This', u'should', u'be', u'fun'],\n",
       "    'original': 'This should be fun',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'This', u'should', u'be', u'fun']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'What',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'meaning',\n",
       "     u'of',\n",
       "     u'this',\n",
       "     u'Mr',\n",
       "     u'Burr',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'medic',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'General'],\n",
       "    'original': 'What is the meaning of this? Mr. Burr, get a medic for the General',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'What',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'meaning',\n",
       "     u'of',\n",
       "     u'this',\n",
       "     u'Mr',\n",
       "     u'Burr',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'medic',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'General']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Yes', u'sir'],\n",
       "    'original': 'Yes, sir',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Yes', u'sir']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Lee',\n",
       "     u'you',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'agree',\n",
       "     u'with',\n",
       "     u'me'],\n",
       "    'original': 'Lee, you will never agree with me',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Lee',\n",
       "     u'you',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'agree',\n",
       "     u'with',\n",
       "     u'me']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'But',\n",
       "     u'believe',\n",
       "     u'me',\n",
       "     u'these',\n",
       "     u'young',\n",
       "     u'men',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'speak',\n",
       "     u'for',\n",
       "     u'me'],\n",
       "    'original': 'But believe me, these young men don\\x92t speak for me',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'believe',\n",
       "     u'me',\n",
       "     u'these',\n",
       "     u'young',\n",
       "     u'men',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'speak',\n",
       "     u'for',\n",
       "     u'me']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Thank', u'you', u'for', u'your', u'service'],\n",
       "    'original': 'Thank you for your service',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Thank', u'you', u'for', u'your', u'service']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Let', u's', u'ride'],\n",
       "    'original': 'Let\\x92s ride!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Let', u's', u'ride']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Meet', u'me', u'inside'],\n",
       "    'original': 'Meet me inside',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Meet', u'me', u'inside']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Meet', u'him', u'inside', u'Meet', u'him', u'inside'],\n",
       "    'original': 'Meet him inside! Meet him inside!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Meet', u'him', u'inside', u'Meet', u'him', u'inside']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Meet',\n",
       "     u'him',\n",
       "     u'inside',\n",
       "     u'meet',\n",
       "     u'him',\n",
       "     u'meet',\n",
       "     u'him',\n",
       "     u'inside'],\n",
       "    'original': 'Meet him inside, meet him, meet him inside!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Meet',\n",
       "     u'him',\n",
       "     u'inside',\n",
       "     u'meet',\n",
       "     u'him',\n",
       "     u'meet',\n",
       "     u'him',\n",
       "     u'inside']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Son'],\n",
       "    'original': 'Son\\x97',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Son']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Don', u't', u'call', u'me', u'son'],\n",
       "    'original': 'Don\\x92t call me son',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Don', u't', u'call', u'me', u'son']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'This', u'war', u'is', u'hard', u'enough'],\n",
       "    'original': 'This war is hard enough',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'This', u'war', u'is', u'hard', u'enough']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Without', u'infighting'],\n",
       "    'original': 'Without infighting\\x97',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Without', u'infighting']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Lee',\n",
       "     u'called',\n",
       "     u'you',\n",
       "     u'out',\n",
       "     u'We',\n",
       "     u'called',\n",
       "     u'his',\n",
       "     u'bluff'],\n",
       "    'original': 'Lee called you out. We called his bluff',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Lee',\n",
       "     u'called',\n",
       "     u'you',\n",
       "     u'out',\n",
       "     u'We',\n",
       "     u'called',\n",
       "     u'his',\n",
       "     u'bluff']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'You',\n",
       "     u'solve',\n",
       "     u'nothing',\n",
       "     u'you',\n",
       "     u'aggravate',\n",
       "     u'our',\n",
       "     u'allies',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'south'],\n",
       "    'original': 'You solve nothing, you aggravate our allies to the south',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'solve',\n",
       "     u'nothing',\n",
       "     u'you',\n",
       "     u'aggravate',\n",
       "     u'our',\n",
       "     u'allies',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'south']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u\"You're\",\n",
       "     u'absolutely',\n",
       "     u'right',\n",
       "     u'John',\n",
       "     u'should',\n",
       "     u'have',\n",
       "     u'shot',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'mouth'],\n",
       "    'original': \"You're absolutely right, John should have shot him in the mouth\",\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u\"You're\",\n",
       "     u'absolutely',\n",
       "     u'right',\n",
       "     u'John',\n",
       "     u'should',\n",
       "     u'have',\n",
       "     u'shot',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'mouth']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'That', u'would', u've', u'shut', u'him', u'up'],\n",
       "    'original': 'That would\\x92ve shut him up',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That', u'would', u've', u'shut', u'him', u'up']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Son'],\n",
       "    'original': 'Son\\x97',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Son']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'I', u'm', u'notcha', u'son'],\n",
       "    'original': 'I\\x92m notcha son\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'm', u'notcha', u'son']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Watch', u'your', u'tone'],\n",
       "    'original': 'Watch your tone',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Watch', u'your', u'tone']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'I',\n",
       "     u'am',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'maiden',\n",
       "     u'in',\n",
       "     u'need',\n",
       "     u'of',\n",
       "     u'defending',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'grown'],\n",
       "    'original': 'I am not a maiden in need of defending, I am grown',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'am',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'maiden',\n",
       "     u'in',\n",
       "     u'need',\n",
       "     u'of',\n",
       "     u'defending',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'grown']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Charles', u'Lee', u'Thomas', u'Conway'],\n",
       "    'original': 'Charles Lee, Thomas Conway',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Charles', u'Lee', u'Thomas', u'Conway']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'These',\n",
       "     u'men',\n",
       "     u'take',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'and',\n",
       "     u'they',\n",
       "     u'rake',\n",
       "     u'it'],\n",
       "    'original': 'These men take your name and they rake it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'These',\n",
       "     u'men',\n",
       "     u'take',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'and',\n",
       "     u'they',\n",
       "     u'rake',\n",
       "     u'it']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Through', u'the', u'mud'],\n",
       "    'original': 'Through the mud',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Through', u'the', u'mud']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'My',\n",
       "     u'name',\n",
       "     u's',\n",
       "     u'been',\n",
       "     u'through',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'take',\n",
       "     u'it'],\n",
       "    'original': 'My name\\x92s been through a lot, I can take it',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'My',\n",
       "     u'name',\n",
       "     u's',\n",
       "     u'been',\n",
       "     u'through',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'take',\n",
       "     u'it']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Well',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'have',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'have',\n",
       "     u'your',\n",
       "     u'title'],\n",
       "    'original': 'Well, I don\\x92t have your name. I don\\x92t have your titles',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'have',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'have',\n",
       "     u'your',\n",
       "     u'title']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'I', u'don', u't', u'have', u'your', u'land'],\n",
       "    'original': 'I don\\x92t have your land',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don', u't', u'have', u'your', u'land']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'But', u'if', u'you'],\n",
       "    'original': 'But, if you\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But', u'if', u'you']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No\\x97',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'gave',\n",
       "     u'me',\n",
       "     u'command',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'battalion',\n",
       "     u'a',\n",
       "     u'group',\n",
       "     u'of',\n",
       "     u'men',\n",
       "     u'to',\n",
       "     u'lead',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'fly',\n",
       "     u'above',\n",
       "     u'my',\n",
       "     u'station',\n",
       "     u'after',\n",
       "     u'the',\n",
       "     u'war'],\n",
       "    'original': 'If you gave me command of a battalion, a group of men to lead, I could fly above my station after the war',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'gave',\n",
       "     u'me',\n",
       "     u'command',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'battalion',\n",
       "     u'a',\n",
       "     u'group',\n",
       "     u'of',\n",
       "     u'men',\n",
       "     u'to',\n",
       "     u'lead',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'fly',\n",
       "     u'above',\n",
       "     u'my',\n",
       "     u'station',\n",
       "     u'after',\n",
       "     u'the',\n",
       "     u'war']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Or',\n",
       "     u'you',\n",
       "     u'could',\n",
       "     u'die',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'need',\n",
       "     u'you',\n",
       "     u'alive'],\n",
       "    'original': 'Or you could die and we need you alive',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Or',\n",
       "     u'you',\n",
       "     u'could',\n",
       "     u'die',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'need',\n",
       "     u'you',\n",
       "     u'alive']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'I', u'm', u'more', u'than', u'willing', u'to', u'die'],\n",
       "    'original': 'I\\x92m more than willing to die\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'm', u'more', u'than', u'willing', u'to', u'die']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Your',\n",
       "     u'wife',\n",
       "     u'needs',\n",
       "     u'you',\n",
       "     u'alive',\n",
       "     u'son',\n",
       "     u'I',\n",
       "     u'need',\n",
       "     u'you',\n",
       "     u'alive'],\n",
       "    'original': 'Your wife needs you alive, son, I need you alive\\x97',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Your',\n",
       "     u'wife',\n",
       "     u'needs',\n",
       "     u'you',\n",
       "     u'alive',\n",
       "     u'son',\n",
       "     u'I',\n",
       "     u'need',\n",
       "     u'you',\n",
       "     u'alive']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Call', u'me', u'son', u'one', u'more', u'time'],\n",
       "    'original': 'Call me son one more time\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Call', u'me', u'son', u'one', u'more', u'time']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Go', u'home', u'Alexander'],\n",
       "    'original': 'Go home, Alexander',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Go', u'home', u'Alexander']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'That',\n",
       "     u's',\n",
       "     u'an',\n",
       "     u'order',\n",
       "     u'from',\n",
       "     u'your',\n",
       "     u'commander'],\n",
       "    'original': 'That\\x92s an order from your commander',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'That',\n",
       "     u's',\n",
       "     u'an',\n",
       "     u'order',\n",
       "     u'from',\n",
       "     u'your',\n",
       "     u'commander']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Go', u'home'],\n",
       "    'original': 'Go home',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Go', u'home']}],\n",
       "  'track': 'Meet Me Inside',\n",
       "  'track#': '16'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'at',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are'],\n",
       "    'original': 'Look around, look around at how lucky we are',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'at',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'To', u'be', u'alive', u'right', u'now'],\n",
       "    'original': 'To be alive right now',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'To', u'be', u'alive', u'right', u'now']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Look', u'around', u'look', u'around'],\n",
       "    'original': 'Look around, look around\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'around', u'look', u'around']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'How', u'long', u'have', u'you', u'known'],\n",
       "    'original': 'How long have you known?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'How', u'long', u'have', u'you', u'known']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'A', u'month', u'or', u'so'],\n",
       "    'original': 'A month or so',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'A', u'month', u'or', u'so']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Eliza', u'you', u'should', u'have', u'told', u'me'],\n",
       "    'original': 'Eliza, you should have told me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Eliza', u'you', u'should', u'have', u'told', u'me']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'I',\n",
       "     u'wrote',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'General',\n",
       "     u'a',\n",
       "     u'month',\n",
       "     u'ago'],\n",
       "    'original': 'I wrote to the General a month ago',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wrote',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'General',\n",
       "     u'a',\n",
       "     u'month',\n",
       "     u'ago']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'I', u'begged', u'him', u'to', u'send', u'you', u'home'],\n",
       "    'original': 'I begged him to send you home',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'begged', u'him', u'to', u'send', u'you', u'home']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'You', u'should', u'have', u'told', u'me'],\n",
       "    'original': 'You should have told me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You', u'should', u'have', u'told', u'me']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'I', u'm', u'not', u'sorry'],\n",
       "    'original': 'I\\x92m not sorry',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'm', u'not', u'sorry']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'I', u'knew', u'you', u'd', u'fight'],\n",
       "    'original': 'I knew you\\x92d fight',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'knew', u'you', u'd', u'fight']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Until', u'the', u'war', u'was', u'won'],\n",
       "    'original': 'Until the war was won',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Until', u'the', u'war', u'was', u'won']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'But',\n",
       "     u'you',\n",
       "     u'deserve',\n",
       "     u'a',\n",
       "     u'chance',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'your',\n",
       "     u'son'],\n",
       "    'original': 'But you deserve a chance to meet your son',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'But',\n",
       "     u'you',\n",
       "     u'deserve',\n",
       "     u'a',\n",
       "     u'chance',\n",
       "     u'to',\n",
       "     u'meet',\n",
       "     u'your',\n",
       "     u'son']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'at',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are'],\n",
       "    'original': 'Look around, look around at how lucky we are',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'at',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'To', u'be', u'alive', u'right', u'now'],\n",
       "    'original': 'To be alive right now.',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'To', u'be', u'alive', u'right', u'now']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'The', u'war', u's', u'not'],\n",
       "    'original': 'The war\\x92s not',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'war', u's', u'not']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Done'],\n",
       "    'original': 'Done.',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Done']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Will',\n",
       "     u'you',\n",
       "     u'relish',\n",
       "     u'being',\n",
       "     u'a',\n",
       "     u'poor',\n",
       "     u'man',\n",
       "     u's',\n",
       "     u'wife'],\n",
       "    'original': 'Will you relish being a poor man\\x92s wife',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Will',\n",
       "     u'you',\n",
       "     u'relish',\n",
       "     u'being',\n",
       "     u'a',\n",
       "     u'poor',\n",
       "     u'man',\n",
       "     u's',\n",
       "     u'wife']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Unable', u'to', u'provide', u'for', u'your', u'life'],\n",
       "    'original': 'Unable to provide for your life?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Unable', u'to', u'provide', u'for', u'your', u'life']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'I', u'relish', u'being', u'your', u'wife'],\n",
       "    'original': 'I relish being your wife',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'relish', u'being', u'your', u'wife']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Look', u'around', u'look', u'around'],\n",
       "    'original': 'Look around, look around\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'around', u'look', u'around']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Look', u'at', u'where', u'you', u'are'],\n",
       "    'original': 'Look at where you are',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'at', u'where', u'you', u'are']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Look', u'at', u'where', u'you', u'started'],\n",
       "    'original': 'Look at where you started',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'at', u'where', u'you', u'started']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'The',\n",
       "     u'fact',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'alive',\n",
       "     u'is',\n",
       "     u'a',\n",
       "     u'miracle'],\n",
       "    'original': 'The fact that you\\x92re alive is a miracle',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'The',\n",
       "     u'fact',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'alive',\n",
       "     u'is',\n",
       "     u'a',\n",
       "     u'miracle']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Just',\n",
       "     u'stay',\n",
       "     u'alive',\n",
       "     u'that',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough'],\n",
       "    'original': 'Just stay alive, that would be enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Just',\n",
       "     u'stay',\n",
       "     u'alive',\n",
       "     u'that',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'And', u'if', u'this', u'child'],\n",
       "    'original': 'And if this child',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'if', u'this', u'child']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Shares', u'a', u'fraction', u'of', u'your', u'smile'],\n",
       "    'original': 'Shares a fraction of your smile',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Shares', u'a', u'fraction', u'of', u'your', u'smile']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Or',\n",
       "     u'a',\n",
       "     u'fragment',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'mind',\n",
       "     u'look',\n",
       "     u'out',\n",
       "     u'world'],\n",
       "    'original': 'Or a fragment of your mind, look out world!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Or',\n",
       "     u'a',\n",
       "     u'fragment',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'mind',\n",
       "     u'look',\n",
       "     u'out',\n",
       "     u'world']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'That', u'would', u'be', u'enough'],\n",
       "    'original': 'That would be enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'That', u'would', u'be', u'enough']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'I', u'don', u't', u'pretend', u'to', u'know'],\n",
       "    'original': 'I don\\x92t pretend to know',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'don', u't', u'pretend', u'to', u'know']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'The', u'challenges', u'you', u're', u'facing'],\n",
       "    'original': 'The challenges you\\x92re facing',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'The', u'challenges', u'you', u're', u'facing']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'The',\n",
       "     u'worlds',\n",
       "     u'you',\n",
       "     u'keep',\n",
       "     u'erasing',\n",
       "     u'and',\n",
       "     u'creating',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'mind'],\n",
       "    'original': 'The worlds you keep erasing and creating in your mind',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'The',\n",
       "     u'worlds',\n",
       "     u'you',\n",
       "     u'keep',\n",
       "     u'erasing',\n",
       "     u'and',\n",
       "     u'creating',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'mind']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'But', u'I', u'm', u'not', u'afraid'],\n",
       "    'original': 'But I\\x92m not afraid',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'But', u'I', u'm', u'not', u'afraid']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'I', u'know', u'who', u'I', u'married'],\n",
       "    'original': 'I know who I married',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'know', u'who', u'I', u'married']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'So',\n",
       "     u'long',\n",
       "     u'as',\n",
       "     u'you',\n",
       "     u'come',\n",
       "     u'home',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'end',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'day'],\n",
       "    'original': 'So long as you come home at the end of the day',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'So',\n",
       "     u'long',\n",
       "     u'as',\n",
       "     u'you',\n",
       "     u'come',\n",
       "     u'home',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'end',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'day']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'That', u'would', u'be', u'enough'],\n",
       "    'original': 'That would be enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'That', u'would', u'be', u'enough']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'We', u'don', u't', u'need', u'a', u'legacy'],\n",
       "    'original': 'We don\\x92t need a legacy',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'We', u'don', u't', u'need', u'a', u'legacy']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'We', u'don', u't', u'need', u'money'],\n",
       "    'original': 'We don\\x92t need money',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'We', u'don', u't', u'need', u'money']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'If',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'grant',\n",
       "     u'you',\n",
       "     u'peace',\n",
       "     u'of',\n",
       "     u'mind'],\n",
       "    'original': 'If I could grant you peace of mind',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'If',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'grant',\n",
       "     u'you',\n",
       "     u'peace',\n",
       "     u'of',\n",
       "     u'mind']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'could',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'inside',\n",
       "     u'your',\n",
       "     u'heart'],\n",
       "    'original': 'If you could let me inside your heart\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'could',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'inside',\n",
       "     u'your',\n",
       "     u'heart']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Oh',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'part',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'narrative'],\n",
       "    'original': 'Oh, let me be a part of the narrative',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Oh',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'part',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'narrative']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'In',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'they',\n",
       "     u'will',\n",
       "     u'write',\n",
       "     u'someday'],\n",
       "    'original': 'In the story they will write someday',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'In',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'they',\n",
       "     u'will',\n",
       "     u'write',\n",
       "     u'someday']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Let',\n",
       "     u'this',\n",
       "     u'moment',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'chapter'],\n",
       "    'original': 'Let this moment be the first chapter:',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Let',\n",
       "     u'this',\n",
       "     u'moment',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'chapter']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Where', u'you', u'decide', u'to', u'stay'],\n",
       "    'original': 'Where you decide to stay',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Where', u'you', u'decide', u'to', u'stay']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'And', u'I', u'could', u'be', u'enough'],\n",
       "    'original': 'And I could be enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'I', u'could', u'be', u'enough']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'And', u'we', u'could', u'be', u'enough'],\n",
       "    'original': 'And we could be enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'we', u'could', u'be', u'enough']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'That', u'would', u'be', u'enough'],\n",
       "    'original': 'That would be enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'That', u'would', u'be', u'enough']}],\n",
       "  'track': 'That Would Be Enough',\n",
       "  'track#': '17'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'How',\n",
       "     u'does',\n",
       "     u'a',\n",
       "     u'ragtag',\n",
       "     u'volunteer',\n",
       "     u'army',\n",
       "     u'in',\n",
       "     u'need',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'shower'],\n",
       "    'original': 'How does a ragtag volunteer army in need of a shower',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How',\n",
       "     u'does',\n",
       "     u'a',\n",
       "     u'ragtag',\n",
       "     u'volunteer',\n",
       "     u'army',\n",
       "     u'in',\n",
       "     u'need',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'shower']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Somehow', u'defeat', u'a', u'global', u'superpower'],\n",
       "    'original': 'Somehow defeat a global superpower?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Somehow', u'defeat', u'a', u'global', u'superpower']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'How',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'emerge',\n",
       "     u'victorious',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'quagmire'],\n",
       "    'original': 'How do we emerge victorious from the quagmire?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'emerge',\n",
       "     u'victorious',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'quagmire']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Leave',\n",
       "     u'the',\n",
       "     u'battlefield',\n",
       "     u'waving',\n",
       "     u'Betsy',\n",
       "     u'Ross',\n",
       "     u'flag',\n",
       "     u'higher'],\n",
       "    'original': 'Leave the battlefield waving Betsy Ross\\x92 flag higher?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Leave',\n",
       "     u'the',\n",
       "     u'battlefield',\n",
       "     u'waving',\n",
       "     u'Betsy',\n",
       "     u'Ross',\n",
       "     u'flag',\n",
       "     u'higher']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Yo',\n",
       "     u'Turns',\n",
       "     u'out',\n",
       "     u'we',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'secret',\n",
       "     u'weapon'],\n",
       "    'original': 'Yo. Turns out we have a secret weapon!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Yo',\n",
       "     u'Turns',\n",
       "     u'out',\n",
       "     u'we',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'secret',\n",
       "     u'weapon']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'An',\n",
       "     u'immigrant',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'and',\n",
       "     u'love',\n",
       "     u'who',\n",
       "     u's',\n",
       "     u'unafraid',\n",
       "     u'to',\n",
       "     u'step',\n",
       "     u'in'],\n",
       "    'original': 'An immigrant you know and love who\\x92s unafraid to step in!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'An',\n",
       "     u'immigrant',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'and',\n",
       "     u'love',\n",
       "     u'who',\n",
       "     u's',\n",
       "     u'unafraid',\n",
       "     u'to',\n",
       "     u'step',\n",
       "     u'in']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'He',\n",
       "     u's',\n",
       "     u'constantly',\n",
       "     u'confusin',\n",
       "     u'confoundin',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'henchm'],\n",
       "    'original': 'He\\x92s constantly confusin\\x92, confoundin\\x92 the British henchmen',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He',\n",
       "     u's',\n",
       "     u'constantly',\n",
       "     u'confusin',\n",
       "     u'confoundin',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'henchm']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Ev',\n",
       "     u'ryone',\n",
       "     u'give',\n",
       "     u'it',\n",
       "     u'up',\n",
       "     u'for',\n",
       "     u'America',\n",
       "     u's',\n",
       "     u'favorite',\n",
       "     u'fighting',\n",
       "     u'Frenchman'],\n",
       "    'original': 'Ev\\x92ryone give it up for America\\x92s favorite fighting Frenchman!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ev',\n",
       "     u'ryone',\n",
       "     u'give',\n",
       "     u'it',\n",
       "     u'up',\n",
       "     u'for',\n",
       "     u'America',\n",
       "     u's',\n",
       "     u'favorite',\n",
       "     u'fighting',\n",
       "     u'Frenchman']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Lafayette'],\n",
       "    'original': 'Lafayette!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Lafayette']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'takin',\n",
       "     u'this',\n",
       "     u'horse',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'reins',\n",
       "     u'makin'],\n",
       "    'original': 'I\\x92m takin this horse by the reins makin\\x92',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'takin',\n",
       "     u'this',\n",
       "     u'horse',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'reins',\n",
       "     u'makin']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Redcoats', u'redder', u'with', u'bloodstains'],\n",
       "    'original': 'Redcoats redder with bloodstains',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Redcoats', u'redder', u'with', u'bloodstains']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Lafayette'],\n",
       "    'original': 'Lafayette!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Lafayette']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'never',\n",
       "     u'gonna',\n",
       "     u'stop',\n",
       "     u'until',\n",
       "     u'I',\n",
       "     u'make',\n",
       "     u'e'],\n",
       "    'original': 'And I\\x92m never gonna stop until I make \\x91em',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'never',\n",
       "     u'gonna',\n",
       "     u'stop',\n",
       "     u'until',\n",
       "     u'I',\n",
       "     u'make',\n",
       "     u'e']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Drop',\n",
       "     u'and',\n",
       "     u'burn',\n",
       "     u'em',\n",
       "     u'up',\n",
       "     u'and',\n",
       "     u'scatter',\n",
       "     u'their',\n",
       "     u'remains',\n",
       "     u'I'],\n",
       "    'original': 'Drop and burn \\x91em up and scatter their remains, I\\x92m',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Drop',\n",
       "     u'and',\n",
       "     u'burn',\n",
       "     u'em',\n",
       "     u'up',\n",
       "     u'and',\n",
       "     u'scatter',\n",
       "     u'their',\n",
       "     u'remains',\n",
       "     u'I']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Lafayette'],\n",
       "    'original': 'Lafayette!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Lafayette']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Watch', u'me', u'engagin', u'em', u'Escapin', u'em'],\n",
       "    'original': 'Watch me engagin\\x92 em! Escapin\\x92 em!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Watch', u'me', u'engagin', u'em', u'Escapin', u'em']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Enragin', u'em', u'I'],\n",
       "    'original': 'Enragin\\x92 em! I\\x92m\\x97',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Enragin', u'em', u'I']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Lafayette'],\n",
       "    'original': 'Lafayette!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Lafayette']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'I', u'go', u'to', u'France', u'for', u'more', u'funds'],\n",
       "    'original': 'I go to France for more funds',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'I', u'go', u'to', u'France', u'for', u'more', u'funds']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Lafayette'],\n",
       "    'original': 'Lafayette!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Lafayette']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'I', u'come', u'back', u'with', u'more'],\n",
       "    'original': 'I come back with more',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'I', u'come', u'back', u'with', u'more']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Guns'],\n",
       "    'original': 'Guns',\n",
       "    'speakers': ['LAFAYETTE', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Guns']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'And', u'ships'],\n",
       "    'original': 'And ships',\n",
       "    'speakers': ['LAFAYETTE', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And', u'ships']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'And', u'so', u'the', u'balance', u'shifts'],\n",
       "    'original': 'And so the balance shifts',\n",
       "    'speakers': ['LAFAYETTE', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And', u'so', u'the', u'balance', u'shifts']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'We',\n",
       "     u'rendezvous',\n",
       "     u'with',\n",
       "     u'Rochambeau',\n",
       "     u'consolidate',\n",
       "     u'their',\n",
       "     u'gifts'],\n",
       "    'original': 'We rendezvous with Rochambeau, consolidate their gifts',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'rendezvous',\n",
       "     u'with',\n",
       "     u'Rochambeau',\n",
       "     u'consolidate',\n",
       "     u'their',\n",
       "     u'gifts']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'We',\n",
       "     u'can',\n",
       "     u'end',\n",
       "     u'this',\n",
       "     u'war',\n",
       "     u'at',\n",
       "     u'Yorktown',\n",
       "     u'cut',\n",
       "     u'them',\n",
       "     u'off',\n",
       "     u'at',\n",
       "     u'sea',\n",
       "     u'but'],\n",
       "    'original': 'We can end this war at Yorktown, cut them off at sea, but',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'We',\n",
       "     u'can',\n",
       "     u'end',\n",
       "     u'this',\n",
       "     u'war',\n",
       "     u'at',\n",
       "     u'Yorktown',\n",
       "     u'cut',\n",
       "     u'them',\n",
       "     u'off',\n",
       "     u'at',\n",
       "     u'sea',\n",
       "     u'but']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'For',\n",
       "     u'this',\n",
       "     u'to',\n",
       "     u'succeed',\n",
       "     u'there',\n",
       "     u'is',\n",
       "     u'someone',\n",
       "     u'else',\n",
       "     u'we',\n",
       "     u'need'],\n",
       "    'original': 'For this to succeed, there is someone else we need:',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'For',\n",
       "     u'this',\n",
       "     u'to',\n",
       "     u'succeed',\n",
       "     u'there',\n",
       "     u'is',\n",
       "     u'someone',\n",
       "     u'else',\n",
       "     u'we',\n",
       "     u'need']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'I', u'know'],\n",
       "    'original': 'I know',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'know']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Sir',\n",
       "     u'he',\n",
       "     u'knows',\n",
       "     u'what',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'trench'],\n",
       "    'original': 'Sir, he knows what to do in a trench',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Sir',\n",
       "     u'he',\n",
       "     u'knows',\n",
       "     u'what',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'trench']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Ingenuitive',\n",
       "     u'and',\n",
       "     u'fluent',\n",
       "     u'in',\n",
       "     u'French',\n",
       "     u'I',\n",
       "     u'mean'],\n",
       "    'original': 'Ingenuitive and fluent in French, I mean\\x97',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Ingenuitive',\n",
       "     u'and',\n",
       "     u'fluent',\n",
       "     u'in',\n",
       "     u'French',\n",
       "     u'I',\n",
       "     u'mean']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Sir',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'use',\n",
       "     u'him',\n",
       "     u'eventually'],\n",
       "    'original': 'Sir, you\\x92re gonna have to use him eventually',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Sir',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'use',\n",
       "     u'him',\n",
       "     u'eventually']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'What',\n",
       "     u's',\n",
       "     u'he',\n",
       "     u'gonna',\n",
       "     u'do',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'bench',\n",
       "     u'I',\n",
       "     u'mean'],\n",
       "    'original': 'What\\x92s he gonna do on the bench? I mean\\x97',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'What',\n",
       "     u's',\n",
       "     u'he',\n",
       "     u'gonna',\n",
       "     u'do',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'bench',\n",
       "     u'I',\n",
       "     u'mean']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'No', u'one', u'has', u'more', u'resilience'],\n",
       "    'original': 'No one has more resilience',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'No', u'one', u'has', u'more', u'resilience']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Or',\n",
       "     u'matches',\n",
       "     u'my',\n",
       "     u'practical',\n",
       "     u'tactical',\n",
       "     u'brilliance'],\n",
       "    'original': 'Or matches my practical tactical brilliance\\x97',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Or',\n",
       "     u'matches',\n",
       "     u'my',\n",
       "     u'practical',\n",
       "     u'tactical',\n",
       "     u'brilliance']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'You',\n",
       "     u'wanna',\n",
       "     u'fight',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'land',\n",
       "     u'back'],\n",
       "    'original': 'You wanna fight for your land back?',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'You',\n",
       "     u'wanna',\n",
       "     u'fight',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'land',\n",
       "     u'back']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'I', u'need', u'my', u'right', u'hand', u'man', u'back'],\n",
       "    'original': 'I need my right hand man back!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'need', u'my', u'right', u'hand', u'man', u'back']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Ah',\n",
       "     u'Uh',\n",
       "     u'get',\n",
       "     u'ya',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man',\n",
       "     u'back'],\n",
       "    'original': 'Ah! Uh, get ya right hand man back',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Ah',\n",
       "     u'Uh',\n",
       "     u'get',\n",
       "     u'ya',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man',\n",
       "     u'back']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'You',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'gotta',\n",
       "     u'get',\n",
       "     u'ya',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man',\n",
       "     u'back'],\n",
       "    'original': 'You know you gotta get ya right hand man back',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'You',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'gotta',\n",
       "     u'get',\n",
       "     u'ya',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man',\n",
       "     u'back']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'I',\n",
       "     u'mean',\n",
       "     u'you',\n",
       "     u'gotta',\n",
       "     u'put',\n",
       "     u'some',\n",
       "     u'thought',\n",
       "     u'into',\n",
       "     u'the',\n",
       "     u'letter',\n",
       "     u'but',\n",
       "     u'the',\n",
       "     u'sooner',\n",
       "     u'the',\n",
       "     u'better'],\n",
       "    'original': 'I mean you gotta put some thought into the letter but the sooner the better',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'mean',\n",
       "     u'you',\n",
       "     u'gotta',\n",
       "     u'put',\n",
       "     u'some',\n",
       "     u'thought',\n",
       "     u'into',\n",
       "     u'the',\n",
       "     u'letter',\n",
       "     u'but',\n",
       "     u'the',\n",
       "     u'sooner',\n",
       "     u'the',\n",
       "     u'better']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'To', u'get', u'your', u'right', u'hand', u'man', u'back'],\n",
       "    'original': 'To get your right hand man back!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'To', u'get', u'your', u'right', u'hand', u'man', u'back']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Hamilton', u'Hamilton'],\n",
       "    'original': 'Hamilton, Hamilton!',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Hamilton', u'Hamilton']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Ha', u'ha'],\n",
       "    'original': 'Ha\\x97 ha\\x97!',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Ha', u'ha']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Get', u'your', u'right', u'hand', u'man', u'back'],\n",
       "    'original': 'Get your right hand man back!',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Get', u'your', u'right', u'hand', u'man', u'back']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Your', u'right', u'hand', u'man', u'back'],\n",
       "    'original': 'Your right hand man back!',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Your', u'right', u'hand', u'man', u'back']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Ha'],\n",
       "    'original': 'Ha\\x97',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Ha']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Ha'],\n",
       "    'original': 'Ha\\x97',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Ha']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Hamilton', u'Hamilton'],\n",
       "    'original': 'Hamilton, Hamilton!',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Hamilton', u'Hamilton']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Ha', u'ha'],\n",
       "    'original': 'Ha\\x97 ha\\x97!',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Ha', u'ha']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Troops',\n",
       "     u'are',\n",
       "     u'waiting',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'field',\n",
       "     u'for',\n",
       "     u'you'],\n",
       "    'original': 'Troops are waiting in the field for you',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Troops',\n",
       "     u'are',\n",
       "     u'waiting',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'field',\n",
       "     u'for',\n",
       "     u'you']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'join',\n",
       "     u'us',\n",
       "     u'right',\n",
       "     u'now',\n",
       "     u'together',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'turn',\n",
       "     u'the',\n",
       "     u'tide'],\n",
       "    'original': 'If you join us right now, together we can turn the tide',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'join',\n",
       "     u'us',\n",
       "     u'right',\n",
       "     u'now',\n",
       "     u'together',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'turn',\n",
       "     u'the',\n",
       "     u'tide']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Oh', u'Alexander', u'Hamilton'],\n",
       "    'original': 'Oh, Alexander Hamilton',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Oh', u'Alexander', u'Hamilton']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'soldiers',\n",
       "     u'that',\n",
       "     u'will',\n",
       "     u'yield',\n",
       "     u'for',\n",
       "     u'you'],\n",
       "    'original': 'I have soldiers that will yield for you',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'soldiers',\n",
       "     u'that',\n",
       "     u'will',\n",
       "     u'yield',\n",
       "     u'for',\n",
       "     u'you']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'If', u'we', u'manage', u'to', u'get', u'this', u'right'],\n",
       "    'original': 'If we manage to get this right',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'If', u'we', u'manage', u'to', u'get', u'this', u'right']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'They', u'll', u'surrender', u'by', u'early', u'light'],\n",
       "    'original': 'They\\x92ll surrender by early light',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'They', u'll', u'surrender', u'by', u'early', u'light']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'The',\n",
       "     u'world',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'Alexander'],\n",
       "    'original': 'The world will never be the same, Alexander\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'world',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'Alexander']}],\n",
       "  'track': 'Guns And Ships',\n",
       "  'track#': '18'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'I', u'was', u'younger', u'than', u'you', u'are', u'now'],\n",
       "    'original': 'I was younger than you are now',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'was', u'younger', u'than', u'you', u'are', u'now']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'When',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'given',\n",
       "     u'my',\n",
       "     u'first',\n",
       "     u'command'],\n",
       "    'original': 'When I was given my first command',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'When',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'given',\n",
       "     u'my',\n",
       "     u'first',\n",
       "     u'command']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'I',\n",
       "     u'led',\n",
       "     u'my',\n",
       "     u'men',\n",
       "     u'straight',\n",
       "     u'into',\n",
       "     u'a',\n",
       "     u'massacre'],\n",
       "    'original': 'I led my men straight into a massacre',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'led',\n",
       "     u'my',\n",
       "     u'men',\n",
       "     u'straight',\n",
       "     u'into',\n",
       "     u'a',\n",
       "     u'massacre']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I', u'witnessed', u'their', u'deaths', u'firsthand'],\n",
       "    'original': 'I witnessed their deaths firsthand',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'witnessed', u'their', u'deaths', u'firsthand']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'I', u'made', u'every', u'mistake'],\n",
       "    'original': 'I made every mistake',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'made', u'every', u'mistake']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'And', u'felt', u'the', u'shame', u'rise', u'in', u'me'],\n",
       "    'original': 'And felt the shame rise in me',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'And', u'felt', u'the', u'shame', u'rise', u'in', u'me']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'And', u'even', u'now', u'I', u'lie', u'awake'],\n",
       "    'original': 'And even now I lie awake',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'And', u'even', u'now', u'I', u'lie', u'awake']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Knowing',\n",
       "     u'history',\n",
       "     u'has',\n",
       "     u'its',\n",
       "     u'eyes',\n",
       "     u'on',\n",
       "     u'me'],\n",
       "    'original': 'Knowing history has its eyes on me',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Knowing',\n",
       "     u'history',\n",
       "     u'has',\n",
       "     u'its',\n",
       "     u'eyes',\n",
       "     u'on',\n",
       "     u'me']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'History', u'has', u'its', u'eyes', u'on', u'me'],\n",
       "    'original': 'History has its eyes on me.',\n",
       "    'speakers': ['HAMILTON', 'WASHINGTON'],\n",
       "    'tokenized': [u'History', u'has', u'its', u'eyes', u'on', u'me']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa\\x85',\n",
       "    'speakers': ['LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa\\x85',\n",
       "    'speakers': ['LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa\\x85',\n",
       "    'speakers': ['LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Yeah'],\n",
       "    'original': 'Yeah',\n",
       "    'speakers': ['LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Yeah']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa\\x85',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa\\x85',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa\\x85',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Yeah'],\n",
       "    'original': 'Yeah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Yeah']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Let',\n",
       "     u'me',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'wish',\n",
       "     u'I',\n",
       "     u'd',\n",
       "     u'known'],\n",
       "    'original': 'Let me tell you what I wish I\\x92d known',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Let',\n",
       "     u'me',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'wish',\n",
       "     u'I',\n",
       "     u'd',\n",
       "     u'known']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'When',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'young',\n",
       "     u'and',\n",
       "     u'dreamed',\n",
       "     u'of',\n",
       "     u'glory'],\n",
       "    'original': 'When I was young and dreamed of glory:',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'When',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'young',\n",
       "     u'and',\n",
       "     u'dreamed',\n",
       "     u'of',\n",
       "     u'glory']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'You', u'have', u'no', u'control'],\n",
       "    'original': 'You have no control:',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You', u'have', u'no', u'control']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Who',\n",
       "     u'lives',\n",
       "     u'who',\n",
       "     u'dies',\n",
       "     u'who',\n",
       "     u'tells',\n",
       "     u'your',\n",
       "     u'story'],\n",
       "    'original': 'Who lives, who dies, who tells your story',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who',\n",
       "     u'lives',\n",
       "     u'who',\n",
       "     u'dies',\n",
       "     u'who',\n",
       "     u'tells',\n",
       "     u'your',\n",
       "     u'story']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'I', u'know', u'that', u'we', u'can', u'win'],\n",
       "    'original': 'I know that we can win',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'know', u'that', u'we', u'can', u'win']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'that',\n",
       "     u'greatness',\n",
       "     u'lies',\n",
       "     u'in',\n",
       "     u'you'],\n",
       "    'original': 'I know that greatness lies in you',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'that',\n",
       "     u'greatness',\n",
       "     u'lies',\n",
       "     u'in',\n",
       "     u'you']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'But', u'remember', u'from', u'here', u'on', u'in'],\n",
       "    'original': 'But remember from here on in',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'But', u'remember', u'from', u'here', u'on', u'in']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'History', u'has', u'its'],\n",
       "    'original': 'History has its',\n",
       "    'speakers': ['WASHINGTON', 'HAMILTON', 'MEN'],\n",
       "    'tokenized': [u'History', u'has', u'its']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Eyes', u'on', u'you'],\n",
       "    'original': 'Eyes on you.',\n",
       "    'speakers': ['WASHINGTON', 'HAMILTON', 'MEN'],\n",
       "    'tokenized': [u'Eyes', u'on', u'you']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa\\x85',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa\\x85',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa\\x85',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'History', u'has', u'its', u'eyes', u'on', u'you'],\n",
       "    'original': 'History has its eyes on you',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'History', u'has', u'its', u'eyes', u'on', u'you']}],\n",
       "  'track': 'History Has Its Eyes On You',\n",
       "  'track#': '19'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'How',\n",
       "     u'does',\n",
       "     u'a',\n",
       "     u'bastard',\n",
       "     u'orphan',\n",
       "     u'son',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'whore',\n",
       "     u'and',\n",
       "     u'a'],\n",
       "    'original': 'How does a bastard, orphan, son of a whore and a',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How',\n",
       "     u'does',\n",
       "     u'a',\n",
       "     u'bastard',\n",
       "     u'orphan',\n",
       "     u'son',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'whore',\n",
       "     u'and',\n",
       "     u'a']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Scotsman',\n",
       "     u'dropped',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'middle',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'forgotten'],\n",
       "    'original': 'Scotsman, dropped in the middle of a forgotten',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Scotsman',\n",
       "     u'dropped',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'middle',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'forgotten']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Spot',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'Caribbean',\n",
       "     u'by',\n",
       "     u'providence',\n",
       "     u'impoverished',\n",
       "     u'in',\n",
       "     u'squalor'],\n",
       "    'original': 'Spot in the Caribbean by providence, impoverished, in squalor',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Spot',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'Caribbean',\n",
       "     u'by',\n",
       "     u'providence',\n",
       "     u'impoverished',\n",
       "     u'in',\n",
       "     u'squalor']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Grow',\n",
       "     u'up',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'hero',\n",
       "     u'and',\n",
       "     u'a',\n",
       "     u'scholar'],\n",
       "    'original': 'Grow up to be a hero and a scholar?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Grow',\n",
       "     u'up',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'hero',\n",
       "     u'and',\n",
       "     u'a',\n",
       "     u'scholar']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'The',\n",
       "     u'ten',\n",
       "     u'dollar',\n",
       "     u'Founding',\n",
       "     u'Father',\n",
       "     u'without',\n",
       "     u'a',\n",
       "     u'father'],\n",
       "    'original': 'The ten-dollar Founding Father without a father',\n",
       "    'speakers': ['JOHN LAURENS'],\n",
       "    'tokenized': [u'The',\n",
       "     u'ten',\n",
       "     u'dollar',\n",
       "     u'Founding',\n",
       "     u'Father',\n",
       "     u'without',\n",
       "     u'a',\n",
       "     u'father']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Got',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'farther',\n",
       "     u'by',\n",
       "     u'working',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'harder'],\n",
       "    'original': 'Got a lot farther by working a lot harder',\n",
       "    'speakers': ['JOHN LAURENS'],\n",
       "    'tokenized': [u'Got',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'farther',\n",
       "     u'by',\n",
       "     u'working',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'harder']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'By', u'being', u'a', u'lot', u'smarter'],\n",
       "    'original': 'By being a lot smarter',\n",
       "    'speakers': ['JOHN LAURENS'],\n",
       "    'tokenized': [u'By', u'being', u'a', u'lot', u'smarter']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'By', u'being', u'a', u'self', u'starter'],\n",
       "    'original': 'By being a self-starter',\n",
       "    'speakers': ['JOHN LAURENS'],\n",
       "    'tokenized': [u'By', u'being', u'a', u'self', u'starter']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'By',\n",
       "     u'fourteen',\n",
       "     u'they',\n",
       "     u'placed',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'charge',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'trading',\n",
       "     u'charter'],\n",
       "    'original': 'By fourteen, they placed him in charge of a trading charter',\n",
       "    'speakers': ['JOHN LAURENS'],\n",
       "    'tokenized': [u'By',\n",
       "     u'fourteen',\n",
       "     u'they',\n",
       "     u'placed',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'charge',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'trading',\n",
       "     u'charter']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'And',\n",
       "     u'every',\n",
       "     u'day',\n",
       "     u'while',\n",
       "     u'slaves',\n",
       "     u'were',\n",
       "     u'being',\n",
       "     u'slaughtered',\n",
       "     u'and',\n",
       "     u'carted'],\n",
       "    'original': 'And every day while slaves were being slaughtered and carted',\n",
       "    'speakers': ['THOMAS JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'every',\n",
       "     u'day',\n",
       "     u'while',\n",
       "     u'slaves',\n",
       "     u'were',\n",
       "     u'being',\n",
       "     u'slaughtered',\n",
       "     u'and',\n",
       "     u'carted']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Away',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'waves',\n",
       "     u'he',\n",
       "     u'struggled',\n",
       "     u'and',\n",
       "     u'kept',\n",
       "     u'his',\n",
       "     u'guard',\n",
       "     u'up'],\n",
       "    'original': 'Away across the waves, he struggled and kept his guard up',\n",
       "    'speakers': ['THOMAS JEFFERSON'],\n",
       "    'tokenized': [u'Away',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'waves',\n",
       "     u'he',\n",
       "     u'struggled',\n",
       "     u'and',\n",
       "     u'kept',\n",
       "     u'his',\n",
       "     u'guard',\n",
       "     u'up']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Inside',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'longing',\n",
       "     u'for',\n",
       "     u'something',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'part',\n",
       "     u'of'],\n",
       "    'original': 'Inside, he was longing for something to be a part of',\n",
       "    'speakers': ['THOMAS JEFFERSON'],\n",
       "    'tokenized': [u'Inside',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'longing',\n",
       "     u'for',\n",
       "     u'something',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'part',\n",
       "     u'of']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'The',\n",
       "     u'brother',\n",
       "     u'was',\n",
       "     u'ready',\n",
       "     u'to',\n",
       "     u'beg',\n",
       "     u'steal',\n",
       "     u'borrow',\n",
       "     u'or',\n",
       "     u'barter'],\n",
       "    'original': 'The brother was ready to beg, steal, borrow, or barter',\n",
       "    'speakers': ['THOMAS JEFFERSON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'brother',\n",
       "     u'was',\n",
       "     u'ready',\n",
       "     u'to',\n",
       "     u'beg',\n",
       "     u'steal',\n",
       "     u'borrow',\n",
       "     u'or',\n",
       "     u'barter']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Then',\n",
       "     u'a',\n",
       "     u'hurricane',\n",
       "     u'came',\n",
       "     u'and',\n",
       "     u'devastation',\n",
       "     u'reigned'],\n",
       "    'original': 'Then a hurricane came, and devastation reigned',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'a',\n",
       "     u'hurricane',\n",
       "     u'came',\n",
       "     u'and',\n",
       "     u'devastation',\n",
       "     u'reigned']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Our',\n",
       "     u'man',\n",
       "     u'saw',\n",
       "     u'his',\n",
       "     u'future',\n",
       "     u'drip',\n",
       "     u'dripping',\n",
       "     u'down',\n",
       "     u'the',\n",
       "     u'drain'],\n",
       "    'original': 'Our man saw his future drip, dripping down the drain',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Our',\n",
       "     u'man',\n",
       "     u'saw',\n",
       "     u'his',\n",
       "     u'future',\n",
       "     u'drip',\n",
       "     u'dripping',\n",
       "     u'down',\n",
       "     u'the',\n",
       "     u'drain']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Put',\n",
       "     u'a',\n",
       "     u'pencil',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'temple',\n",
       "     u'connected',\n",
       "     u'it',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'brain'],\n",
       "    'original': 'Put a pencil to his temple, connected it to his brain',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Put',\n",
       "     u'a',\n",
       "     u'pencil',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'temple',\n",
       "     u'connected',\n",
       "     u'it',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'brain']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'And',\n",
       "     u'he',\n",
       "     u'wrote',\n",
       "     u'his',\n",
       "     u'first',\n",
       "     u'refrain',\n",
       "     u'a',\n",
       "     u'testament',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'pain'],\n",
       "    'original': 'And he wrote his first refrain, a testament to his pain',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'he',\n",
       "     u'wrote',\n",
       "     u'his',\n",
       "     u'first',\n",
       "     u'refrain',\n",
       "     u'a',\n",
       "     u'testament',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'pain']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Well',\n",
       "     u'the',\n",
       "     u'word',\n",
       "     u'got',\n",
       "     u'around',\n",
       "     u'they',\n",
       "     u'said',\n",
       "     u'This',\n",
       "     u'kid',\n",
       "     u'is',\n",
       "     u'insane',\n",
       "     u'man'],\n",
       "    'original': 'Well, the word got around, they said, \\x93This kid is insane, man\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'the',\n",
       "     u'word',\n",
       "     u'got',\n",
       "     u'around',\n",
       "     u'they',\n",
       "     u'said',\n",
       "     u'This',\n",
       "     u'kid',\n",
       "     u'is',\n",
       "     u'insane',\n",
       "     u'man']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Took',\n",
       "     u'up',\n",
       "     u'a',\n",
       "     u'collection',\n",
       "     u'just',\n",
       "     u'to',\n",
       "     u'send',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'mainland'],\n",
       "    'original': 'Took up a collection just to send him to the mainland',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Took',\n",
       "     u'up',\n",
       "     u'a',\n",
       "     u'collection',\n",
       "     u'just',\n",
       "     u'to',\n",
       "     u'send',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'mainland']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Get',\n",
       "     u'your',\n",
       "     u'education',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'forget',\n",
       "     u'from',\n",
       "     u'whence',\n",
       "     u'you',\n",
       "     u'came',\n",
       "     u'an'],\n",
       "    'original': '\\x93Get your education, don\\x92t forget from whence you came, and',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Get',\n",
       "     u'your',\n",
       "     u'education',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'forget',\n",
       "     u'from',\n",
       "     u'whence',\n",
       "     u'you',\n",
       "     u'came',\n",
       "     u'an']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'The',\n",
       "     u\"world's\",\n",
       "     u'gonna',\n",
       "     u'know',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'What',\n",
       "     u's',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'man'],\n",
       "    'original': \"The world's gonna know your name. What\\x92s your name, man?\\x94\",\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The',\n",
       "     u\"world's\",\n",
       "     u'gonna',\n",
       "     u'know',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'What',\n",
       "     u's',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'man']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'My', u'name', u'is', u'Alexander', u'Hamilton'],\n",
       "    'original': 'My name is Alexander Hamilton',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'name', u'is', u'Alexander', u'Hamilton']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'And',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'million',\n",
       "     u'things',\n",
       "     u'I',\n",
       "     u'haven',\n",
       "     u't',\n",
       "     u'don'],\n",
       "    'original': 'And there\\x92s a million things I haven\\x92t done',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'million',\n",
       "     u'things',\n",
       "     u'I',\n",
       "     u'haven',\n",
       "     u't',\n",
       "     u'don']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'But', u'just', u'you', u'wait', u'just', u'you', u'wait'],\n",
       "    'original': 'But just you wait, just you wait...',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But', u'just', u'you', u'wait', u'just', u'you', u'wait']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'When',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'ten',\n",
       "     u'his',\n",
       "     u'father',\n",
       "     u'split',\n",
       "     u'full',\n",
       "     u'of',\n",
       "     u'it',\n",
       "     u'debt',\n",
       "     u'ridden'],\n",
       "    'original': 'When he was ten his father split, full of it, debt-ridden',\n",
       "    'speakers': ['ELIZA HAMILTON'],\n",
       "    'tokenized': [u'When',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'ten',\n",
       "     u'his',\n",
       "     u'father',\n",
       "     u'split',\n",
       "     u'full',\n",
       "     u'of',\n",
       "     u'it',\n",
       "     u'debt',\n",
       "     u'ridden']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Two',\n",
       "     u'years',\n",
       "     u'later',\n",
       "     u'see',\n",
       "     u'Alex',\n",
       "     u'and',\n",
       "     u'his',\n",
       "     u'mother',\n",
       "     u'bed',\n",
       "     u'ridden'],\n",
       "    'original': 'Two years later, see Alex and his mother bed-ridden',\n",
       "    'speakers': ['ELIZA HAMILTON'],\n",
       "    'tokenized': [u'Two',\n",
       "     u'years',\n",
       "     u'later',\n",
       "     u'see',\n",
       "     u'Alex',\n",
       "     u'and',\n",
       "     u'his',\n",
       "     u'mother',\n",
       "     u'bed',\n",
       "     u'ridden']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Half',\n",
       "     u'dead',\n",
       "     u'sittin',\n",
       "     u'in',\n",
       "     u'their',\n",
       "     u'own',\n",
       "     u'sick',\n",
       "     u'the',\n",
       "     u'scent',\n",
       "     u'thick'],\n",
       "    'original': \"Half-dead sittin' in their own sick, the scent thick\",\n",
       "    'speakers': ['ELIZA HAMILTON'],\n",
       "    'tokenized': [u'Half',\n",
       "     u'dead',\n",
       "     u'sittin',\n",
       "     u'in',\n",
       "     u'their',\n",
       "     u'own',\n",
       "     u'sick',\n",
       "     u'the',\n",
       "     u'scent',\n",
       "     u'thick']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'And',\n",
       "     u'Alex',\n",
       "     u'got',\n",
       "     u'better',\n",
       "     u'but',\n",
       "     u'his',\n",
       "     u'mother',\n",
       "     u'went',\n",
       "     u'quick'],\n",
       "    'original': 'And Alex got better but his mother went quick',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'And',\n",
       "     u'Alex',\n",
       "     u'got',\n",
       "     u'better',\n",
       "     u'but',\n",
       "     u'his',\n",
       "     u'mother',\n",
       "     u'went',\n",
       "     u'quick']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Moved',\n",
       "     u'in',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'cousin',\n",
       "     u'the',\n",
       "     u'cousin',\n",
       "     u'committed',\n",
       "     u'suicide'],\n",
       "    'original': 'Moved in with a cousin, the cousin committed suicide',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Moved',\n",
       "     u'in',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'cousin',\n",
       "     u'the',\n",
       "     u'cousin',\n",
       "     u'committed',\n",
       "     u'suicide']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Left',\n",
       "     u'him',\n",
       "     u'with',\n",
       "     u'nothin',\n",
       "     u'but',\n",
       "     u'ruined',\n",
       "     u'pride',\n",
       "     u'something',\n",
       "     u'new',\n",
       "     u'inside'],\n",
       "    'original': 'Left him with nothin\\x92 but ruined pride, something new inside',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Left',\n",
       "     u'him',\n",
       "     u'with',\n",
       "     u'nothin',\n",
       "     u'but',\n",
       "     u'ruined',\n",
       "     u'pride',\n",
       "     u'something',\n",
       "     u'new',\n",
       "     u'inside']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'A', u'voice', u'saying'],\n",
       "    'original': 'A voice saying',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'A', u'voice', u'saying']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'You', u'gotta', u'fend', u'for', u'yourself'],\n",
       "    'original': '\\x93You gotta fend for yourself.\\x94',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You', u'gotta', u'fend', u'for', u'yourself']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Alex', u'you', u'gotta', u'fend', u'for', u'yourself'],\n",
       "    'original': '\\x93Alex, you gotta fend for yourself.\\x94',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Alex', u'you', u'gotta', u'fend', u'for', u'yourself']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'He',\n",
       "     u'started',\n",
       "     u'retreatin',\n",
       "     u'and',\n",
       "     u'readin',\n",
       "     u'every',\n",
       "     u'treatise',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'shel'],\n",
       "    'original': 'He started retreatin\\x92 and readin\\x92 every treatise on the shelf',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'He',\n",
       "     u'started',\n",
       "     u'retreatin',\n",
       "     u'and',\n",
       "     u'readin',\n",
       "     u'every',\n",
       "     u'treatise',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'shel']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'There',\n",
       "     u'would',\n",
       "     u'have',\n",
       "     u'been',\n",
       "     u'nothin',\n",
       "     u'left',\n",
       "     u'to',\n",
       "     u'do'],\n",
       "    'original': 'There would have been nothin\\x92 left to do',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'There',\n",
       "     u'would',\n",
       "     u'have',\n",
       "     u'been',\n",
       "     u'nothin',\n",
       "     u'left',\n",
       "     u'to',\n",
       "     u'do']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'For', u'someone', u'less', u'astute'],\n",
       "    'original': 'For someone less astute',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'For', u'someone', u'less', u'astute']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'He', u'woulda', u'been', u'dead', u'or', u'destitute'],\n",
       "    'original': 'He woulda been dead or destitute',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He', u'woulda', u'been', u'dead', u'or', u'destitute']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Without', u'a', u'cent', u'of', u'restitution'],\n",
       "    'original': 'Without a cent of restitution',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Without', u'a', u'cent', u'of', u'restitution']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Started',\n",
       "     u'workin',\n",
       "     u'clerkin',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'late',\n",
       "     u'mother',\n",
       "     u's',\n",
       "     u'landlo'],\n",
       "    'original': 'Started workin\\x92, clerkin\\x92 for his late mother\\x92s landlord',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Started',\n",
       "     u'workin',\n",
       "     u'clerkin',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'late',\n",
       "     u'mother',\n",
       "     u's',\n",
       "     u'landlo']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Tradin',\n",
       "     u'sugar',\n",
       "     u'cane',\n",
       "     u'and',\n",
       "     u'rum',\n",
       "     u'and',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'things',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'affor'],\n",
       "    'original': 'Tradin\\x92 sugar cane and rum and all the things he can\\x92t afford',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Tradin',\n",
       "     u'sugar',\n",
       "     u'cane',\n",
       "     u'and',\n",
       "     u'rum',\n",
       "     u'and',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'things',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'affor']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Scammin',\n",
       "     u'for',\n",
       "     u'every',\n",
       "     u'book',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'get',\n",
       "     u'his',\n",
       "     u'hands',\n",
       "     u'on'],\n",
       "    'original': 'Scammin\\x92 for every book he can get his hands on',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Scammin',\n",
       "     u'for',\n",
       "     u'every',\n",
       "     u'book',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'get',\n",
       "     u'his',\n",
       "     u'hands',\n",
       "     u'on']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Plannin',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'future',\n",
       "     u'see',\n",
       "     u'him',\n",
       "     u'now',\n",
       "     u'as',\n",
       "     u'he',\n",
       "     u'stands',\n",
       "     u'on'],\n",
       "    'original': 'Plannin\\x92 for the future see him now as he stands on',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Plannin',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'future',\n",
       "     u'see',\n",
       "     u'him',\n",
       "     u'now',\n",
       "     u'as',\n",
       "     u'he',\n",
       "     u'stands',\n",
       "     u'on']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'The',\n",
       "     u'bow',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'ship',\n",
       "     u'headed',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'land'],\n",
       "    'original': 'The bow of a ship headed for a new land',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The',\n",
       "     u'bow',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'ship',\n",
       "     u'headed',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'land']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man'],\n",
       "    'original': 'In New York you can be a new man',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Scammin'],\n",
       "    'original': 'Scammin\\x92',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Scammin']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Plannin'],\n",
       "    'original': 'Plannin\\x92',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Plannin']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Oooh'],\n",
       "    'original': 'Oooh...',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Oooh']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'In', u'New', u'York', u'you', u'can'],\n",
       "    'original': 'In New York you can',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'In', u'New', u'York', u'you', u'can']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Be', u'a', u'new', u'man'],\n",
       "    'original': 'Be a new man\\x97',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Be', u'a', u'new', u'man']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'In', u'New', u'York', u'you', u'can'],\n",
       "    'original': 'In New York you can',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'In', u'New', u'York', u'you', u'can']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Be', u'a', u'new', u'man'],\n",
       "    'original': 'Be a new man\\x97',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Be', u'a', u'new', u'man']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Just', u'you', u'wait'],\n",
       "    'original': 'Just you wait!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Just', u'you', u'wait']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Just', u'you', u'wait'],\n",
       "    'original': 'Just you wait!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Just', u'you', u'wait']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man'],\n",
       "    'original': 'In New York you can be a new man\\x97',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'In',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'man']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'In', u'New', u'York'],\n",
       "    'original': 'In New York\\x97',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'In', u'New', u'York']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'New', u'York'],\n",
       "    'original': 'New York\\x97',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'New', u'York']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Just', u'you', u'wait'],\n",
       "    'original': 'Just you wait!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Just', u'you', u'wait']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'We',\n",
       "     u'are',\n",
       "     u'waiting',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'wings',\n",
       "     u'for',\n",
       "     u'you'],\n",
       "    'original': 'We are waiting in the wings for you',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'We',\n",
       "     u'are',\n",
       "     u'waiting',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'wings',\n",
       "     u'for',\n",
       "     u'you']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'You', u'could', u'never', u'back', u'down'],\n",
       "    'original': 'You could never back down',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'You', u'could', u'never', u'back', u'down']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'You',\n",
       "     u'never',\n",
       "     u'learned',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'your',\n",
       "     u'time'],\n",
       "    'original': 'You never learned to take your time!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'You',\n",
       "     u'never',\n",
       "     u'learned',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'your',\n",
       "     u'time']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Oh', u'Alexander', u'Hamilton'],\n",
       "    'original': 'Oh, Alexander Hamilton',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Oh', u'Alexander', u'Hamilton']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'When', u'America', u'sings', u'for', u'you'],\n",
       "    'original': 'When America sings for you',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'When', u'America', u'sings', u'for', u'you']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Will', u'they', u'know', u'what', u'you', u'overcame'],\n",
       "    'original': 'Will they know what you overcame?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Will', u'they', u'know', u'what', u'you', u'overcame']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Will',\n",
       "     u'they',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'rewrote',\n",
       "     u'the',\n",
       "     u'game'],\n",
       "    'original': 'Will they know you rewrote the game?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Will',\n",
       "     u'they',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'rewrote',\n",
       "     u'the',\n",
       "     u'game']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'The',\n",
       "     u'world',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'oh'],\n",
       "    'original': 'The world will never be the same, oh',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The',\n",
       "     u'world',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'oh']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'The', u'ship', u'is', u'in', u'the', u'harbor', u'now'],\n",
       "    'original': 'The ship is in the harbor now',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'ship', u'is', u'in', u'the', u'harbor', u'now']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'See', u'if', u'you', u'can', u'spot', u'him'],\n",
       "    'original': 'See if you can spot him',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'See', u'if', u'you', u'can', u'spot', u'him']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Another', u'immigrant'],\n",
       "    'original': 'Another immigrant',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Another', u'immigrant']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'Comin', u'up', u'from', u'the', u'bottom'],\n",
       "    'original': 'Comin\\x92 up from the bottom',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Comin', u'up', u'from', u'the', u'bottom']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'His', u'enemies', u'destroyed', u'his', u'rep'],\n",
       "    'original': 'His enemies destroyed his rep',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'His', u'enemies', u'destroyed', u'his', u'rep']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'America', u'forgot', u'him'],\n",
       "    'original': 'America forgot him',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'America', u'forgot', u'him']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'Waiting', u'in', u'the', u'wings', u'for', u'you'],\n",
       "    'original': 'Waiting in the wings for you',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Waiting', u'in', u'the', u'wings', u'for', u'you']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'You',\n",
       "     u'never',\n",
       "     u'learned',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'your',\n",
       "     u'time'],\n",
       "    'original': 'You never learned to take your time!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'You',\n",
       "     u'never',\n",
       "     u'learned',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'your',\n",
       "     u'time']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Oh', u'Alexander', u'Hamilton'],\n",
       "    'original': 'Oh, Alexander Hamilton',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Oh', u'Alexander', u'Hamilton']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton\\x85',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'America', u'sings', u'for', u'you'],\n",
       "    'original': 'America sings for you',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'America', u'sings', u'for', u'you']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Will', u'they', u'know', u'what', u'you', u'overcame'],\n",
       "    'original': 'Will they know what you overcame?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Will', u'they', u'know', u'what', u'you', u'overcame']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Will',\n",
       "     u'they',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'rewrote',\n",
       "     u'the',\n",
       "     u'game'],\n",
       "    'original': 'Will they know you rewrote the game?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Will',\n",
       "     u'they',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'rewrote',\n",
       "     u'the',\n",
       "     u'game']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'The',\n",
       "     u'world',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'oh'],\n",
       "    'original': 'The world will never be the same, oh',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The',\n",
       "     u'world',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'oh']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'Just', u'you', u'wait'],\n",
       "    'original': 'Just you wait',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Just', u'you', u'wait']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'Just', u'you', u'wait'],\n",
       "    'original': 'Just you wait',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Just', u'you', u'wait']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'We', u'fought', u'with', u'him'],\n",
       "    'original': 'We fought with him',\n",
       "    'speakers': ['MULLIGAN', 'MADISON', 'LAFAYETTE', 'JEFFERSON'],\n",
       "    'tokenized': [u'We', u'fought', u'with', u'him']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'Me', u'I', u'died', u'for', u'him'],\n",
       "    'original': 'Me? I died for him',\n",
       "    'speakers': ['LAURENS', 'PHILIP'],\n",
       "    'tokenized': [u'Me', u'I', u'died', u'for', u'him']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'Me', u'I', u'trusted', u'him'],\n",
       "    'original': 'Me? I trusted him',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Me', u'I', u'trusted', u'him']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Me', u'I', u'loved', u'him'],\n",
       "    'original': 'Me? I loved him',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY', 'MARIA'],\n",
       "    'tokenized': [u'Me', u'I', u'loved', u'him']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'And',\n",
       "     u'me',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'the',\n",
       "     u'damn',\n",
       "     u'fool',\n",
       "     u'that',\n",
       "     u'shot',\n",
       "     u'him'],\n",
       "    'original': 'And me? I\\x92m the damn fool that shot him',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'me',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'the',\n",
       "     u'damn',\n",
       "     u'fool',\n",
       "     u'that',\n",
       "     u'shot',\n",
       "     u'him']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'There',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'million',\n",
       "     u'things',\n",
       "     u'I',\n",
       "     u'haven',\n",
       "     u't',\n",
       "     u'don'],\n",
       "    'original': 'There\\x92s a million things I haven\\x92t done',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'There',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'million',\n",
       "     u'things',\n",
       "     u'I',\n",
       "     u'haven',\n",
       "     u't',\n",
       "     u'don']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'But', u'just', u'you', u'wait'],\n",
       "    'original': 'But just you wait!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'But', u'just', u'you', u'wait']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'What', u's', u'your', u'name', u'man'],\n",
       "    'original': 'What\\x92s your name, man?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'What', u's', u'your', u'name', u'man']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']}],\n",
       "  'track': 'Alexander Hamilton',\n",
       "  'track#': '1'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'The', u'battle', u'of', u'Yorktown', u'1781'],\n",
       "    'original': 'The battle of Yorktown. 1781',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'battle', u'of', u'Yorktown', u'1781']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Monsieur', u'Hamilton'],\n",
       "    'original': 'Monsieur Hamilton',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Monsieur', u'Hamilton']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Monsieur', u'Lafayette'],\n",
       "    'original': 'Monsieur Lafayette',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Monsieur', u'Lafayette']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'In', u'command', u'where', u'you', u'belong'],\n",
       "    'original': 'In command where you belong',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'In', u'command', u'where', u'you', u'belong']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'How', u'you', u'say', u'no', u'sweat'],\n",
       "    'original': 'How you say, no sweat',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'How', u'you', u'say', u'no', u'sweat']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u\"We're\",\n",
       "     u'finally',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'field',\n",
       "     u'We',\n",
       "     u've',\n",
       "     u'had',\n",
       "     u'quite',\n",
       "     u'a',\n",
       "     u'run'],\n",
       "    'original': \"We're finally on the field. We\\x92ve had quite a run\",\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u\"We're\",\n",
       "     u'finally',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'field',\n",
       "     u'We',\n",
       "     u've',\n",
       "     u'had',\n",
       "     u'quite',\n",
       "     u'a',\n",
       "     u'run']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Immigrants'],\n",
       "    'original': 'Immigrants:',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Immigrants']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'We', u'get', u'the', u'job', u'done'],\n",
       "    'original': 'We get the job done',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE'],\n",
       "    'tokenized': [u'We', u'get', u'the', u'job', u'done']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'So', u'what', u'happens', u'if', u'we', u'win'],\n",
       "    'original': 'So what happens if we win?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'So', u'what', u'happens', u'if', u'we', u'win']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'I', u'go', u'back', u'to', u'France'],\n",
       "    'original': 'I go back to France',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'I', u'go', u'back', u'to', u'France']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'I',\n",
       "     u'bring',\n",
       "     u'freedom',\n",
       "     u'to',\n",
       "     u'my',\n",
       "     u'people',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'given',\n",
       "     u'the',\n",
       "     u'chance'],\n",
       "    'original': 'I bring freedom to my people if I\\x92m given the chance',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'bring',\n",
       "     u'freedom',\n",
       "     u'to',\n",
       "     u'my',\n",
       "     u'people',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'given',\n",
       "     u'the',\n",
       "     u'chance']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'We',\n",
       "     u'll',\n",
       "     u'be',\n",
       "     u'with',\n",
       "     u'you',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'do'],\n",
       "    'original': 'We\\x92ll be with you when you do',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'll',\n",
       "     u'be',\n",
       "     u'with',\n",
       "     u'you',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'do']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Go', u'lead', u'your', u'men'],\n",
       "    'original': 'Go lead your men',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Go', u'lead', u'your', u'men']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'See', u'you', u'on', u'the', u'other', u'side'],\n",
       "    'original': 'See you on the other side',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'See', u'you', u'on', u'the', u'other', u'side']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Til', u'we', u'meet', u'again', u'let', u's', u'go'],\n",
       "    'original': '\\x91Til we meet again, let\\x92s go!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Til', u'we', u'meet', u'again', u'let', u's', u'go']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwin\\x92 away my shot!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwin\\x92 away my shot!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'youn'],\n",
       "    'original': 'Hey yo, I\\x92m just like my country, I\\x92m young',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'youn']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Scrappy', u'and', u'hungry'],\n",
       "    'original': 'Scrappy and hungry',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Scrappy', u'and', u'hungry']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwin',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot'],\n",
       "    'original': 'And I\\x92m not throwin\\x92 away my shot!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwin',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwin\\x92 away my shot!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Til', u'the', u'world', u'turns', u'upside', u'down'],\n",
       "    'original': '\\x91Til the world turns upside down\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Til', u'the', u'world', u'turns', u'upside', u'down']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Til', u'the', u'world', u'turns', u'upside', u'down'],\n",
       "    'original': '\\x91Til the world turns upside down!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Til', u'the', u'world', u'turns', u'upside', u'down']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'I',\n",
       "     u'imagine',\n",
       "     u'death',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'it',\n",
       "     u'feels',\n",
       "     u'more',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'memory'],\n",
       "    'original': 'I imagine death so much it feels more like a memory',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'imagine',\n",
       "     u'death',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'it',\n",
       "     u'feels',\n",
       "     u'more',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'memory']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'This',\n",
       "     u'is',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'gets',\n",
       "     u'me',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'feet'],\n",
       "    'original': 'This is where it gets me: on my feet',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'is',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'gets',\n",
       "     u'me',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'feet']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'The', u'enemy', u'ahead', u'of', u'me'],\n",
       "    'original': 'The enemy ahead of me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'enemy', u'ahead', u'of', u'me']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'If',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'end',\n",
       "     u'of',\n",
       "     u'me',\n",
       "     u'at',\n",
       "     u'least',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'friend',\n",
       "     u'with',\n",
       "     u'me'],\n",
       "    'original': 'If this is the end of me, at least I have a friend with me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'end',\n",
       "     u'of',\n",
       "     u'me',\n",
       "     u'at',\n",
       "     u'least',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'friend',\n",
       "     u'with',\n",
       "     u'me']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Weapon',\n",
       "     u'in',\n",
       "     u'my',\n",
       "     u'hand',\n",
       "     u'a',\n",
       "     u'command',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'men',\n",
       "     u'with',\n",
       "     u'me'],\n",
       "    'original': 'Weapon in my hand, a command, and my men with me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Weapon',\n",
       "     u'in',\n",
       "     u'my',\n",
       "     u'hand',\n",
       "     u'a',\n",
       "     u'command',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'men',\n",
       "     u'with',\n",
       "     u'me']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Then',\n",
       "     u'I',\n",
       "     u'remember',\n",
       "     u'my',\n",
       "     u'Eliza',\n",
       "     u's',\n",
       "     u'expecting',\n",
       "     u'me'],\n",
       "    'original': 'Then I remember my Eliza\\x92s expecting me...',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'I',\n",
       "     u'remember',\n",
       "     u'my',\n",
       "     u'Eliza',\n",
       "     u's',\n",
       "     u'expecting',\n",
       "     u'me']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Not',\n",
       "     u'only',\n",
       "     u'that',\n",
       "     u'my',\n",
       "     u'Eliza',\n",
       "     u's',\n",
       "     u'expecting'],\n",
       "    'original': 'Not only that, my Eliza\\x92s expecting',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Not',\n",
       "     u'only',\n",
       "     u'that',\n",
       "     u'my',\n",
       "     u'Eliza',\n",
       "     u's',\n",
       "     u'expecting']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'We',\n",
       "     u'gotta',\n",
       "     u'go',\n",
       "     u'gotta',\n",
       "     u'get',\n",
       "     u'the',\n",
       "     u'job',\n",
       "     u'done'],\n",
       "    'original': 'We gotta go, gotta get the job done',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'gotta',\n",
       "     u'go',\n",
       "     u'gotta',\n",
       "     u'get',\n",
       "     u'the',\n",
       "     u'job',\n",
       "     u'done']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Gotta',\n",
       "     u'start',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'nation',\n",
       "     u'gotta',\n",
       "     u'meet',\n",
       "     u'my',\n",
       "     u'son'],\n",
       "    'original': 'Gotta start a new nation, gotta meet my son!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Gotta',\n",
       "     u'start',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'nation',\n",
       "     u'gotta',\n",
       "     u'meet',\n",
       "     u'my',\n",
       "     u'son']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Take', u'the', u'bullets', u'out', u'your', u'gun'],\n",
       "    'original': 'Take the bullets out your gun!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Take', u'the', u'bullets', u'out', u'your', u'gun']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'The', u'bullets', u'out', u'your', u'gun'],\n",
       "    'original': 'The bullets out your gun!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'bullets', u'out', u'your', u'gun']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'We',\n",
       "     u'move',\n",
       "     u'under',\n",
       "     u'cover',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'move',\n",
       "     u'as',\n",
       "     u'one'],\n",
       "    'original': 'We move under cover and we move as one',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'move',\n",
       "     u'under',\n",
       "     u'cover',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'move',\n",
       "     u'as',\n",
       "     u'one']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Through',\n",
       "     u'the',\n",
       "     u'night',\n",
       "     u'we',\n",
       "     u'have',\n",
       "     u'one',\n",
       "     u'shot',\n",
       "     u'to',\n",
       "     u'live',\n",
       "     u'another',\n",
       "     u'day'],\n",
       "    'original': 'Through the night, we have one shot to live another day',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Through',\n",
       "     u'the',\n",
       "     u'night',\n",
       "     u'we',\n",
       "     u'have',\n",
       "     u'one',\n",
       "     u'shot',\n",
       "     u'to',\n",
       "     u'live',\n",
       "     u'another',\n",
       "     u'day']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'We',\n",
       "     u'cannot',\n",
       "     u'let',\n",
       "     u'a',\n",
       "     u'stray',\n",
       "     u'gunshot',\n",
       "     u'give',\n",
       "     u'us',\n",
       "     u'away'],\n",
       "    'original': 'We cannot let a stray gunshot give us away',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'cannot',\n",
       "     u'let',\n",
       "     u'a',\n",
       "     u'stray',\n",
       "     u'gunshot',\n",
       "     u'give',\n",
       "     u'us',\n",
       "     u'away']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'We',\n",
       "     u'will',\n",
       "     u'fight',\n",
       "     u'up',\n",
       "     u'close',\n",
       "     u'seize',\n",
       "     u'the',\n",
       "     u'moment',\n",
       "     u'and',\n",
       "     u'stay',\n",
       "     u'in',\n",
       "     u'it'],\n",
       "    'original': 'We will fight up close, seize the moment and stay in it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'will',\n",
       "     u'fight',\n",
       "     u'up',\n",
       "     u'close',\n",
       "     u'seize',\n",
       "     u'the',\n",
       "     u'moment',\n",
       "     u'and',\n",
       "     u'stay',\n",
       "     u'in',\n",
       "     u'it']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'It',\n",
       "     u's',\n",
       "     u'either',\n",
       "     u'that',\n",
       "     u'or',\n",
       "     u'meet',\n",
       "     u'the',\n",
       "     u'business',\n",
       "     u'end',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'bayonet'],\n",
       "    'original': 'It\\x92s either that or meet the business end of a bayonet',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'It',\n",
       "     u's',\n",
       "     u'either',\n",
       "     u'that',\n",
       "     u'or',\n",
       "     u'meet',\n",
       "     u'the',\n",
       "     u'business',\n",
       "     u'end',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'bayonet']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'The',\n",
       "     u'code',\n",
       "     u'word',\n",
       "     u'is',\n",
       "     u'Rochambeau',\n",
       "     u'dig',\n",
       "     u'me'],\n",
       "    'original': 'The code word is \\x91Rochambeau,\\x92 dig me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'code',\n",
       "     u'word',\n",
       "     u'is',\n",
       "     u'Rochambeau',\n",
       "     u'dig',\n",
       "     u'me']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Rochambeau'],\n",
       "    'original': 'Rochambeau!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Rochambeau']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'You',\n",
       "     u'have',\n",
       "     u'your',\n",
       "     u'orders',\n",
       "     u'now',\n",
       "     u'go',\n",
       "     u'man',\n",
       "     u'go'],\n",
       "    'original': 'You have your orders now, go, man, go!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'have',\n",
       "     u'your',\n",
       "     u'orders',\n",
       "     u'now',\n",
       "     u'go',\n",
       "     u'man',\n",
       "     u'go']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'And',\n",
       "     u'so',\n",
       "     u'the',\n",
       "     u'American',\n",
       "     u'experiment',\n",
       "     u'begins'],\n",
       "    'original': 'And so the American experiment begins',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'so',\n",
       "     u'the',\n",
       "     u'American',\n",
       "     u'experiment',\n",
       "     u'begins']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'With',\n",
       "     u'my',\n",
       "     u'friends',\n",
       "     u'all',\n",
       "     u'scattered',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'winds'],\n",
       "    'original': 'With my friends all scattered to the winds',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'With',\n",
       "     u'my',\n",
       "     u'friends',\n",
       "     u'all',\n",
       "     u'scattered',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'winds']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Laurens',\n",
       "     u'is',\n",
       "     u'in',\n",
       "     u'South',\n",
       "     u'Carolina',\n",
       "     u'redefining',\n",
       "     u'brav',\n",
       "     u'ry'],\n",
       "    'original': 'Laurens is in South Carolina, redefining brav\\x92ry',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Laurens',\n",
       "     u'is',\n",
       "     u'in',\n",
       "     u'South',\n",
       "     u'Carolina',\n",
       "     u'redefining',\n",
       "     u'brav',\n",
       "     u'ry']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'We',\n",
       "     u'll',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'free',\n",
       "     u'until',\n",
       "     u'we',\n",
       "     u'end',\n",
       "     u'slavery'],\n",
       "    'original': 'We\\x92ll never be free until we end slavery!',\n",
       "    'speakers': ['HAMILTON', 'LAURENS'],\n",
       "    'tokenized': [u'We',\n",
       "     u'll',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'free',\n",
       "     u'until',\n",
       "     u'we',\n",
       "     u'end',\n",
       "     u'slavery']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'When',\n",
       "     u'we',\n",
       "     u'finally',\n",
       "     u'drive',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'away'],\n",
       "    'original': 'When we finally drive the British away',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'When',\n",
       "     u'we',\n",
       "     u'finally',\n",
       "     u'drive',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'away']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Lafayette', u'is', u'there', u'waiting'],\n",
       "    'original': 'Lafayette is there waiting\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Lafayette', u'is', u'there', u'waiting']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'In', u'Chesapeake', u'Bay'],\n",
       "    'original': 'In Chesapeake Bay!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE'],\n",
       "    'tokenized': [u'In', u'Chesapeake', u'Bay']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'How',\n",
       "     u'did',\n",
       "     u'we',\n",
       "     u'know',\n",
       "     u'that',\n",
       "     u'this',\n",
       "     u'plan',\n",
       "     u'would',\n",
       "     u'work'],\n",
       "    'original': 'How did we know that this plan would work?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'How',\n",
       "     u'did',\n",
       "     u'we',\n",
       "     u'know',\n",
       "     u'that',\n",
       "     u'this',\n",
       "     u'plan',\n",
       "     u'would',\n",
       "     u'work']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'We',\n",
       "     u'had',\n",
       "     u'a',\n",
       "     u'spy',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'inside',\n",
       "     u'That',\n",
       "     u's',\n",
       "     u'right'],\n",
       "    'original': 'We had a spy on the inside. That\\x92s right',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'had',\n",
       "     u'a',\n",
       "     u'spy',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'inside',\n",
       "     u'That',\n",
       "     u's',\n",
       "     u'right']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Hercules', u'Mulligan'],\n",
       "    'original': 'Hercules Mulligan!',\n",
       "    'speakers': ['HAMILTON', 'COMPANY'],\n",
       "    'tokenized': [u'Hercules', u'Mulligan']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'A',\n",
       "     u'tailor',\n",
       "     u'spyin',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'government'],\n",
       "    'original': 'A tailor spyin\\x92 on the British government!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'A',\n",
       "     u'tailor',\n",
       "     u'spyin',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'government']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'I',\n",
       "     u'take',\n",
       "     u'their',\n",
       "     u'measurements',\n",
       "     u'information',\n",
       "     u'and',\n",
       "     u'then',\n",
       "     u'I',\n",
       "     u'smuggle',\n",
       "     u'it'],\n",
       "    'original': 'I take their measurements, information and then I smuggle it',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'I',\n",
       "     u'take',\n",
       "     u'their',\n",
       "     u'measurements',\n",
       "     u'information',\n",
       "     u'and',\n",
       "     u'then',\n",
       "     u'I',\n",
       "     u'smuggle',\n",
       "     u'it']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Up'],\n",
       "    'original': 'Up',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Up']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'To', u'my', u\"brother's\", u'revolutionary', u'covenant'],\n",
       "    'original': \"To my brother's revolutionary covenant\",\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'To', u'my', u\"brother's\", u'revolutionary', u'covenant']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'runnin',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'Sons',\n",
       "     u'of',\n",
       "     u'Liberty',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'lovin',\n",
       "     u'i'],\n",
       "    'original': 'I\\x92m runnin\\x92 with the Sons of Liberty and I am lovin\\x92 it!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'runnin',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'Sons',\n",
       "     u'of',\n",
       "     u'Liberty',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'lovin',\n",
       "     u'i']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'See',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'what',\n",
       "     u'happens',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'up',\n",
       "     u'against',\n",
       "     u'the',\n",
       "     u'ruffians'],\n",
       "    'original': 'See, that\\x92s what happens when you up against the ruffians',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'See',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'what',\n",
       "     u'happens',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'up',\n",
       "     u'against',\n",
       "     u'the',\n",
       "     u'ruffians']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'We',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'shit',\n",
       "     u'now',\n",
       "     u'somebody',\n",
       "     u'gotta',\n",
       "     u'shovel',\n",
       "     u'it'],\n",
       "    'original': 'We in the shit now, somebody gotta shovel it!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'We',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'shit',\n",
       "     u'now',\n",
       "     u'somebody',\n",
       "     u'gotta',\n",
       "     u'shovel',\n",
       "     u'it']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Hercules',\n",
       "     u'Mulligan',\n",
       "     u'I',\n",
       "     u'need',\n",
       "     u'no',\n",
       "     u'introduction'],\n",
       "    'original': 'Hercules Mulligan, I need no introduction',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Hercules',\n",
       "     u'Mulligan',\n",
       "     u'I',\n",
       "     u'need',\n",
       "     u'no',\n",
       "     u'introduction']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'When',\n",
       "     u'you',\n",
       "     u'knock',\n",
       "     u'me',\n",
       "     u'down',\n",
       "     u'I',\n",
       "     u'get',\n",
       "     u'the',\n",
       "     u'fuck',\n",
       "     u'back',\n",
       "     u'up',\n",
       "     u'again'],\n",
       "    'original': 'When you knock me down I get the fuck back up again!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'When',\n",
       "     u'you',\n",
       "     u'knock',\n",
       "     u'me',\n",
       "     u'down',\n",
       "     u'I',\n",
       "     u'get',\n",
       "     u'the',\n",
       "     u'fuck',\n",
       "     u'back',\n",
       "     u'up',\n",
       "     u'again']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Left', u'Right', u'Hold'],\n",
       "    'original': 'Left! Right! Hold!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Left', u'Right', u'Hold']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Go'],\n",
       "    'original': 'Go!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Go']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'What', u'What', u'What'],\n",
       "    'original': 'What! What! What!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'What', u'What', u'What']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'After',\n",
       "     u'a',\n",
       "     u'week',\n",
       "     u'of',\n",
       "     u'fighting',\n",
       "     u'a',\n",
       "     u'young',\n",
       "     u'man',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'red',\n",
       "     u'coat',\n",
       "     u'stands',\n",
       "     u'on',\n",
       "     u'a',\n",
       "     u'parapet'],\n",
       "    'original': 'After a week of fighting, a young man in a red coat stands on a parapet',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'After',\n",
       "     u'a',\n",
       "     u'week',\n",
       "     u'of',\n",
       "     u'fighting',\n",
       "     u'a',\n",
       "     u'young',\n",
       "     u'man',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'red',\n",
       "     u'coat',\n",
       "     u'stands',\n",
       "     u'on',\n",
       "     u'a',\n",
       "     u'parapet']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'We',\n",
       "     u'lower',\n",
       "     u'our',\n",
       "     u'guns',\n",
       "     u'as',\n",
       "     u'he',\n",
       "     u'frantically',\n",
       "     u'waves',\n",
       "     u'a',\n",
       "     u'white',\n",
       "     u'handkerchief'],\n",
       "    'original': 'We lower our guns as he frantically waves a white handkerchief',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'We',\n",
       "     u'lower',\n",
       "     u'our',\n",
       "     u'guns',\n",
       "     u'as',\n",
       "     u'he',\n",
       "     u'frantically',\n",
       "     u'waves',\n",
       "     u'a',\n",
       "     u'white',\n",
       "     u'handkerchief']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'And',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'that',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'over',\n",
       "     u'We',\n",
       "     u'tend',\n",
       "     u'to',\n",
       "     u'our',\n",
       "     u'wounded',\n",
       "     u'we',\n",
       "     u'count',\n",
       "     u'our',\n",
       "     u'dead'],\n",
       "    'original': 'And just like that, it\\x92s over. We tend to our wounded, we count our dead',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'And',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'that',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'over',\n",
       "     u'We',\n",
       "     u'tend',\n",
       "     u'to',\n",
       "     u'our',\n",
       "     u'wounded',\n",
       "     u'we',\n",
       "     u'count',\n",
       "     u'our',\n",
       "     u'dead']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Black',\n",
       "     u'and',\n",
       "     u'white',\n",
       "     u'soldiers',\n",
       "     u'wonder',\n",
       "     u'alike',\n",
       "     u'if',\n",
       "     u'this',\n",
       "     u'really',\n",
       "     u'means',\n",
       "     u'freedom'],\n",
       "    'original': 'Black and white soldiers wonder alike if this really means freedom',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Black',\n",
       "     u'and',\n",
       "     u'white',\n",
       "     u'soldiers',\n",
       "     u'wonder',\n",
       "     u'alike',\n",
       "     u'if',\n",
       "     u'this',\n",
       "     u'really',\n",
       "     u'means',\n",
       "     u'freedom']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'Not', u'Yet'],\n",
       "    'original': 'Not. Yet',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Not', u'Yet']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'We', u'negotiate', u'the', u'terms', u'of', u'surrender'],\n",
       "    'original': 'We negotiate the terms of surrender',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We', u'negotiate', u'the', u'terms', u'of', u'surrender']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'I', u'see', u'George', u'Washington', u'smile'],\n",
       "    'original': 'I see George Washington smile',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'see', u'George', u'Washington', u'smile']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'We',\n",
       "     u'escort',\n",
       "     u'their',\n",
       "     u'men',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'Yorktown'],\n",
       "    'original': 'We escort their men out of Yorktown',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'escort',\n",
       "     u'their',\n",
       "     u'men',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'Yorktown']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'They', u'stagger', u'home', u'single', u'file'],\n",
       "    'original': 'They stagger home single file',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'They', u'stagger', u'home', u'single', u'file']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Tens',\n",
       "     u'of',\n",
       "     u'thousands',\n",
       "     u'of',\n",
       "     u'people',\n",
       "     u'flood',\n",
       "     u'the',\n",
       "     u'streets'],\n",
       "    'original': 'Tens of thousands of people flood the streets',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Tens',\n",
       "     u'of',\n",
       "     u'thousands',\n",
       "     u'of',\n",
       "     u'people',\n",
       "     u'flood',\n",
       "     u'the',\n",
       "     u'streets']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'There',\n",
       "     u'are',\n",
       "     u'screams',\n",
       "     u'and',\n",
       "     u'church',\n",
       "     u'bells',\n",
       "     u'ringing'],\n",
       "    'original': 'There are screams and church bells ringing',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'There',\n",
       "     u'are',\n",
       "     u'screams',\n",
       "     u'and',\n",
       "     u'church',\n",
       "     u'bells',\n",
       "     u'ringing']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'And', u'as', u'our', u'fallen', u'foes', u'retreat'],\n",
       "    'original': 'And as our fallen foes retreat',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'as', u'our', u'fallen', u'foes', u'retreat']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'I',\n",
       "     u'hear',\n",
       "     u'the',\n",
       "     u'drinking',\n",
       "     u'song',\n",
       "     u'they',\n",
       "     u're',\n",
       "     u'singing'],\n",
       "    'original': 'I hear the drinking song they\\x92re singing\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'hear',\n",
       "     u'the',\n",
       "     u'drinking',\n",
       "     u'song',\n",
       "     u'they',\n",
       "     u're',\n",
       "     u'singing']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'The', u'world', u'turned', u'upside', u'down'],\n",
       "    'original': 'The world turned upside down',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'The', u'world', u'turned', u'upside', u'down']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'The', u'world', u'turned', u'upside', u'down'],\n",
       "    'original': 'The world turned upside down',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'The', u'world', u'turned', u'upside', u'down']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'The', u'world', u'turned', u'upside', u'down'],\n",
       "    'original': 'The world turned upside down',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'The', u'world', u'turned', u'upside', u'down']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'The', u'world', u'turned', u'upside', u'down'],\n",
       "    'original': 'The world turned upside down',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'The', u'world', u'turned', u'upside', u'down']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'Down'],\n",
       "    'original': 'Down',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Down']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'Down', u'down', u'down'],\n",
       "    'original': 'Down, down, down',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Down', u'down', u'down']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'Freedom',\n",
       "     u'for',\n",
       "     u'America',\n",
       "     u'freedom',\n",
       "     u'for',\n",
       "     u'France'],\n",
       "    'original': 'Freedom for America, freedom for France!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Freedom',\n",
       "     u'for',\n",
       "     u'America',\n",
       "     u'freedom',\n",
       "     u'for',\n",
       "     u'France']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'Down', u'down', u'down'],\n",
       "    'original': 'Down, down, down',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Down', u'down', u'down']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Gotta', u'start', u'a', u'new', u'nation'],\n",
       "    'original': 'Gotta start a new nation',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Gotta', u'start', u'a', u'new', u'nation']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'Gotta', u'meet', u'my', u'son'],\n",
       "    'original': 'Gotta meet my son',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Gotta', u'meet', u'my', u'son']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'Down', u'down', u'down'],\n",
       "    'original': 'Down, down, down',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Down', u'down', u'down']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'We', u'won'],\n",
       "    'original': 'We won!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'We', u'won']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'We', u'won'],\n",
       "    'original': 'We won!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'We', u'won']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'We', u'won'],\n",
       "    'original': 'We won!',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'LAURENS'],\n",
       "    'tokenized': [u'We', u'won']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'We', u'won'],\n",
       "    'original': 'We won!',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'LAURENS', 'HAMILTON', 'WASHINGTON'],\n",
       "    'tokenized': [u'We', u'won']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'The', u'world', u'turned', u'upside', u'down'],\n",
       "    'original': 'The world turned upside down!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'world', u'turned', u'upside', u'down']}],\n",
       "  'track': 'Yorktown (The World Turned Upside Down)',\n",
       "  'track#': '20'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'They', u'say'],\n",
       "    'original': 'They say',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'They', u'say']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'The',\n",
       "     u'price',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'war',\n",
       "     u's',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'price',\n",
       "     u'that',\n",
       "     u'they',\n",
       "     u're',\n",
       "     u'willing',\n",
       "     u'to',\n",
       "     u'pa'],\n",
       "    'original': 'The price of my war\\x92s not a price that they\\x92re willing to pay',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'The',\n",
       "     u'price',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'war',\n",
       "     u's',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'price',\n",
       "     u'that',\n",
       "     u'they',\n",
       "     u're',\n",
       "     u'willing',\n",
       "     u'to',\n",
       "     u'pa']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Insane'],\n",
       "    'original': 'Insane',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Insane']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'You',\n",
       "     u'cheat',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'French',\n",
       "     u'now',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'fighting',\n",
       "     u'with',\n",
       "     u'France',\n",
       "     u'and',\n",
       "     u'with',\n",
       "     u'Spain'],\n",
       "    'original': 'You cheat with the French, now I\\x92m fighting with France and with Spain',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You',\n",
       "     u'cheat',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'French',\n",
       "     u'now',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'fighting',\n",
       "     u'with',\n",
       "     u'France',\n",
       "     u'and',\n",
       "     u'with',\n",
       "     u'Spain']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'I', u'm', u'so', u'blue'],\n",
       "    'original': 'I\\x92m so blue',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'I', u'm', u'so', u'blue']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'I',\n",
       "     u'thought',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u'd',\n",
       "     u'made',\n",
       "     u'an',\n",
       "     u'arrangement'],\n",
       "    'original': 'I thought that we\\x92d made an arrangement',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'thought',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u'd',\n",
       "     u'made',\n",
       "     u'an',\n",
       "     u'arrangement']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'When', u'you', u'went', u'away'],\n",
       "    'original': 'When you went away',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'When', u'you', u'went', u'away']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'You', u'were', u'mine', u'to', u'subdue'],\n",
       "    'original': 'You were mine to subdue',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You', u'were', u'mine', u'to', u'subdue']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Well',\n",
       "     u'even',\n",
       "     u'despite',\n",
       "     u'our',\n",
       "     u'estrangement',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'got'],\n",
       "    'original': 'Well, even despite our estrangement, I\\x92ve got',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'even',\n",
       "     u'despite',\n",
       "     u'our',\n",
       "     u'estrangement',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'got']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'A', u'small', u'query', u'for', u'you'],\n",
       "    'original': 'A small query for you:',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'A', u'small', u'query', u'for', u'you']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'What', u'comes', u'next'],\n",
       "    'original': 'What comes next?',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'What', u'comes', u'next']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'You', u've', u'been', u'freed'],\n",
       "    'original': 'You\\x92ve been freed',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You', u've', u'been', u'freed']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Do',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'how',\n",
       "     u'hard',\n",
       "     u'it',\n",
       "     u'is',\n",
       "     u'to',\n",
       "     u'lead'],\n",
       "    'original': 'Do you know how hard it is to lead?',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Do',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'how',\n",
       "     u'hard',\n",
       "     u'it',\n",
       "     u'is',\n",
       "     u'to',\n",
       "     u'lead']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'You', u're', u'on', u'your', u'own'],\n",
       "    'original': 'You\\x92re on your own',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You', u're', u'on', u'your', u'own']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Awesome', u'Wow'],\n",
       "    'original': 'Awesome. Wow',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Awesome', u'Wow']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Do',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'clue',\n",
       "     u'what',\n",
       "     u'happens',\n",
       "     u'now'],\n",
       "    'original': 'Do you have a clue what happens now?',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Do',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'clue',\n",
       "     u'what',\n",
       "     u'happens',\n",
       "     u'now']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Oceans', u'rise'],\n",
       "    'original': 'Oceans rise',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Oceans', u'rise']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Empires', u'fall'],\n",
       "    'original': 'Empires fall',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Empires', u'fall']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'It',\n",
       "     u's',\n",
       "     u'much',\n",
       "     u'harder',\n",
       "     u'when',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'all',\n",
       "     u'your',\n",
       "     u'cal'],\n",
       "    'original': 'It\\x92s much harder when it\\x92s all your call',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'It',\n",
       "     u's',\n",
       "     u'much',\n",
       "     u'harder',\n",
       "     u'when',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'all',\n",
       "     u'your',\n",
       "     u'cal']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'All', u'alone', u'across', u'the', u'sea'],\n",
       "    'original': 'All alone, across the sea',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'All', u'alone', u'across', u'the', u'sea']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'When',\n",
       "     u'your',\n",
       "     u'people',\n",
       "     u'say',\n",
       "     u'they',\n",
       "     u'hate',\n",
       "     u'you'],\n",
       "    'original': 'When your people say they hate you',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'When',\n",
       "     u'your',\n",
       "     u'people',\n",
       "     u'say',\n",
       "     u'they',\n",
       "     u'hate',\n",
       "     u'you']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Don', u't', u'come', u'crawling', u'back', u'to', u'me'],\n",
       "    'original': 'Don\\x92t come crawling back to me',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Don', u't', u'come', u'crawling', u'back', u'to', u'me']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'You', u're', u'on', u'your', u'ow'],\n",
       "    'original': 'You\\x92re on your own\\x85',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You', u're', u'on', u'your', u'ow']}],\n",
       "  'track': 'What Comes Next',\n",
       "  'track#': '21'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Dear',\n",
       "     u'Theodosia',\n",
       "     u'what',\n",
       "     u'to',\n",
       "     u'say',\n",
       "     u'to',\n",
       "     u'you'],\n",
       "    'original': 'Dear Theodosia, what to say to you?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Dear',\n",
       "     u'Theodosia',\n",
       "     u'what',\n",
       "     u'to',\n",
       "     u'say',\n",
       "     u'to',\n",
       "     u'you']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'You',\n",
       "     u'have',\n",
       "     u'my',\n",
       "     u'eyes',\n",
       "     u'You',\n",
       "     u'have',\n",
       "     u'your',\n",
       "     u'mother',\n",
       "     u's',\n",
       "     u'name'],\n",
       "    'original': 'You have my eyes. You have your mother\\x92s name',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u'have',\n",
       "     u'my',\n",
       "     u'eyes',\n",
       "     u'You',\n",
       "     u'have',\n",
       "     u'your',\n",
       "     u'mother',\n",
       "     u's',\n",
       "     u'name']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'When',\n",
       "     u'you',\n",
       "     u'came',\n",
       "     u'into',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'you',\n",
       "     u'cried',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'broke',\n",
       "     u'my',\n",
       "     u'heart'],\n",
       "    'original': 'When you came into the world, you cried and it broke my heart',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'When',\n",
       "     u'you',\n",
       "     u'came',\n",
       "     u'into',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'you',\n",
       "     u'cried',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'broke',\n",
       "     u'my',\n",
       "     u'heart']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I', u'm', u'dedicating', u'every', u'day', u'to', u'you'],\n",
       "    'original': 'I\\x92m dedicating every day to you',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'm', u'dedicating', u'every', u'day', u'to', u'you']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Domestic',\n",
       "     u'life',\n",
       "     u'was',\n",
       "     u'never',\n",
       "     u'quite',\n",
       "     u'my',\n",
       "     u'style'],\n",
       "    'original': 'Domestic life was never quite my style',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Domestic',\n",
       "     u'life',\n",
       "     u'was',\n",
       "     u'never',\n",
       "     u'quite',\n",
       "     u'my',\n",
       "     u'style']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'When',\n",
       "     u'you',\n",
       "     u'smile',\n",
       "     u'you',\n",
       "     u'knock',\n",
       "     u'me',\n",
       "     u'out',\n",
       "     u'I',\n",
       "     u'fall',\n",
       "     u'apart'],\n",
       "    'original': 'When you smile, you knock me out, I fall apart',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'When',\n",
       "     u'you',\n",
       "     u'smile',\n",
       "     u'you',\n",
       "     u'knock',\n",
       "     u'me',\n",
       "     u'out',\n",
       "     u'I',\n",
       "     u'fall',\n",
       "     u'apart']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'And', u'I', u'thought', u'I', u'was', u'so', u'smart'],\n",
       "    'original': 'And I thought I was so smart',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'I', u'thought', u'I', u'was', u'so', u'smart']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'You',\n",
       "     u'will',\n",
       "     u'come',\n",
       "     u'of',\n",
       "     u'age',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'young',\n",
       "     u'nation'],\n",
       "    'original': 'You will come of age with our young nation',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u'will',\n",
       "     u'come',\n",
       "     u'of',\n",
       "     u'age',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'young',\n",
       "     u'nation']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'We',\n",
       "     u'll',\n",
       "     u'bleed',\n",
       "     u'and',\n",
       "     u'fight',\n",
       "     u'for',\n",
       "     u'you',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'make',\n",
       "     u'it',\n",
       "     u'right',\n",
       "     u'for',\n",
       "     u'yo'],\n",
       "    'original': 'We\\x92ll bleed and fight for you, we\\x92ll make it right for you',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'We',\n",
       "     u'll',\n",
       "     u'bleed',\n",
       "     u'and',\n",
       "     u'fight',\n",
       "     u'for',\n",
       "     u'you',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'make',\n",
       "     u'it',\n",
       "     u'right',\n",
       "     u'for',\n",
       "     u'yo']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'If',\n",
       "     u'we',\n",
       "     u'lay',\n",
       "     u'a',\n",
       "     u'strong',\n",
       "     u'enough',\n",
       "     u'foundation'],\n",
       "    'original': 'If we lay a strong enough foundation',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'If',\n",
       "     u'we',\n",
       "     u'lay',\n",
       "     u'a',\n",
       "     u'strong',\n",
       "     u'enough',\n",
       "     u'foundation']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'We',\n",
       "     u'll',\n",
       "     u'pass',\n",
       "     u'it',\n",
       "     u'on',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'give',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'to',\n",
       "     u'yo'],\n",
       "    'original': 'We\\x92ll pass it on to you, we\\x92ll give the world to you',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'We',\n",
       "     u'll',\n",
       "     u'pass',\n",
       "     u'it',\n",
       "     u'on',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'give',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'to',\n",
       "     u'yo']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'And', u'you', u'll', u'blow', u'us', u'all', u'away'],\n",
       "    'original': 'And you\\x92ll blow us all away\\x85',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'you', u'll', u'blow', u'us', u'all', u'away']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Someday', u'someday'],\n",
       "    'original': 'Someday, someday',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Someday', u'someday']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Yeah', u'you', u'll', u'blow', u'us', u'all', u'away'],\n",
       "    'original': 'Yeah, you\\x92ll blow us all away',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Yeah', u'you', u'll', u'blow', u'us', u'all', u'away']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Someday', u'someday'],\n",
       "    'original': 'Someday, someday',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Someday', u'someday']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Oh',\n",
       "     u'Philip',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'smile',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'undone'],\n",
       "    'original': 'Oh Philip, when you smile I am undone',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Oh',\n",
       "     u'Philip',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'smile',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'undone']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'My', u'son'],\n",
       "    'original': 'My son',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'son']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Look',\n",
       "     u'at',\n",
       "     u'my',\n",
       "     u'son',\n",
       "     u'Pride',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'the',\n",
       "     u'word',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'looking',\n",
       "     u'for'],\n",
       "    'original': 'Look at my son. Pride is not the word I\\x92m looking for',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'at',\n",
       "     u'my',\n",
       "     u'son',\n",
       "     u'Pride',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'the',\n",
       "     u'word',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'looking',\n",
       "     u'for']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'There',\n",
       "     u'is',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'more',\n",
       "     u'inside',\n",
       "     u'me',\n",
       "     u'now'],\n",
       "    'original': 'There is so much more inside me now',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'There',\n",
       "     u'is',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'more',\n",
       "     u'inside',\n",
       "     u'me',\n",
       "     u'now']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Oh',\n",
       "     u'Philip',\n",
       "     u'you',\n",
       "     u'outshine',\n",
       "     u'the',\n",
       "     u'morning',\n",
       "     u'sun'],\n",
       "    'original': 'Oh Philip, you outshine the morning sun',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Oh',\n",
       "     u'Philip',\n",
       "     u'you',\n",
       "     u'outshine',\n",
       "     u'the',\n",
       "     u'morning',\n",
       "     u'sun']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'My', u'son'],\n",
       "    'original': 'My son',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'son']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'When', u'you', u'smile', u'I', u'fall', u'apart'],\n",
       "    'original': 'When you smile, I fall apart',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'When', u'you', u'smile', u'I', u'fall', u'apart']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'And', u'I', u'thought', u'I', u'was', u'so', u'smart'],\n",
       "    'original': 'And I thought I was so smart',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'I', u'thought', u'I', u'was', u'so', u'smart']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'My', u'father', u'wasn', u't', u'around'],\n",
       "    'original': 'My father wasn\\x92t around',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'father', u'wasn', u't', u'around']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'My', u'father', u'wasn', u't', u'around'],\n",
       "    'original': 'My father wasn\\x92t around',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'My', u'father', u'wasn', u't', u'around']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'I', u'swear', u'that'],\n",
       "    'original': 'I swear that',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'swear', u'that']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'I', u'll', u'be', u'around', u'for', u'you'],\n",
       "    'original': 'I\\x92ll be around for you.',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'll', u'be', u'around', u'for', u'you']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'I', u'll', u'be', u'around', u'for', u'you'],\n",
       "    'original': 'I\\x92ll be around for you.',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'll', u'be', u'around', u'for', u'you']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'I', u'll', u'do', u'whatever', u'it', u'takes'],\n",
       "    'original': 'I\\x92ll do whatever it takes',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'll', u'do', u'whatever', u'it', u'takes']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'I', u'll', u'make', u'a', u'million', u'mistakes'],\n",
       "    'original': 'I\\x92ll make a million mistakes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'll', u'make', u'a', u'million', u'mistakes']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'I',\n",
       "     u'll',\n",
       "     u'make',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'safe',\n",
       "     u'and',\n",
       "     u'sound',\n",
       "     u'for',\n",
       "     u'you'],\n",
       "    'original': 'I\\x92ll make the world safe and sound for you\\x85',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'll',\n",
       "     u'make',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'safe',\n",
       "     u'and',\n",
       "     u'sound',\n",
       "     u'for',\n",
       "     u'you']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'will',\n",
       "     u'come',\n",
       "     u'of',\n",
       "     u'age',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'young',\n",
       "     u'nation'],\n",
       "    'original': '\\x85will come of age with our young nation',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'will',\n",
       "     u'come',\n",
       "     u'of',\n",
       "     u'age',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'young',\n",
       "     u'nation']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'We',\n",
       "     u'll',\n",
       "     u'bleed',\n",
       "     u'and',\n",
       "     u'fight',\n",
       "     u'for',\n",
       "     u'you',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'make',\n",
       "     u'it',\n",
       "     u'right',\n",
       "     u'for',\n",
       "     u'yo'],\n",
       "    'original': 'We\\x92ll bleed and fight for you, we\\x92ll make it right for you',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'll',\n",
       "     u'bleed',\n",
       "     u'and',\n",
       "     u'fight',\n",
       "     u'for',\n",
       "     u'you',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'make',\n",
       "     u'it',\n",
       "     u'right',\n",
       "     u'for',\n",
       "     u'yo']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'If',\n",
       "     u'we',\n",
       "     u'lay',\n",
       "     u'a',\n",
       "     u'strong',\n",
       "     u'enough',\n",
       "     u'foundation'],\n",
       "    'original': 'If we lay a strong enough foundation',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'we',\n",
       "     u'lay',\n",
       "     u'a',\n",
       "     u'strong',\n",
       "     u'enough',\n",
       "     u'foundation']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'We',\n",
       "     u'll',\n",
       "     u'pass',\n",
       "     u'it',\n",
       "     u'on',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'give',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'to',\n",
       "     u'yo'],\n",
       "    'original': 'We\\x92ll pass it on to you, we\\x92ll give the world to you',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'll',\n",
       "     u'pass',\n",
       "     u'it',\n",
       "     u'on',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'we',\n",
       "     u'll',\n",
       "     u'give',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'to',\n",
       "     u'yo']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'And', u'you', u'll', u'blow', u'us', u'all', u'away'],\n",
       "    'original': 'And you\\x92ll blow us all away...',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'And', u'you', u'll', u'blow', u'us', u'all', u'away']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Someday', u'someday'],\n",
       "    'original': 'Someday, someday',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'Someday', u'someday']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Yeah', u'you', u'll', u'blow', u'us', u'all', u'away'],\n",
       "    'original': 'Yeah, you\\x92ll blow us all away',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'Yeah', u'you', u'll', u'blow', u'us', u'all', u'away']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Someday', u'someday'],\n",
       "    'original': 'Someday, someday',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'Someday', u'someday']}],\n",
       "  'track': 'Dear Theodosia',\n",
       "  'track#': '22'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'After',\n",
       "     u'the',\n",
       "     u'war',\n",
       "     u'I',\n",
       "     u'went',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'New',\n",
       "     u'York'],\n",
       "    'original': 'After the war I went back to New York',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'After',\n",
       "     u'the',\n",
       "     u'war',\n",
       "     u'I',\n",
       "     u'went',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'New',\n",
       "     u'York']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'A',\n",
       "     u'After',\n",
       "     u'the',\n",
       "     u'war',\n",
       "     u'I',\n",
       "     u'went',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'New',\n",
       "     u'York'],\n",
       "    'original': 'A-After the war I went back to New York',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'After',\n",
       "     u'the',\n",
       "     u'war',\n",
       "     u'I',\n",
       "     u'went',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'New',\n",
       "     u'York']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'I',\n",
       "     u'finished',\n",
       "     u'up',\n",
       "     u'my',\n",
       "     u'studies',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'practiced',\n",
       "     u'law'],\n",
       "    'original': 'I finished up my studies and I practiced law',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'finished',\n",
       "     u'up',\n",
       "     u'my',\n",
       "     u'studies',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'practiced',\n",
       "     u'law']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I',\n",
       "     u'practiced',\n",
       "     u'law',\n",
       "     u'Burr',\n",
       "     u'worked',\n",
       "     u'next',\n",
       "     u'door'],\n",
       "    'original': 'I practiced law, Burr worked next door',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'practiced',\n",
       "     u'law',\n",
       "     u'Burr',\n",
       "     u'worked',\n",
       "     u'next',\n",
       "     u'door']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Even',\n",
       "     u'though',\n",
       "     u'we',\n",
       "     u'started',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'very',\n",
       "     u'same',\n",
       "     u'time'],\n",
       "    'original': 'Even though we started at the very same time',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Even',\n",
       "     u'though',\n",
       "     u'we',\n",
       "     u'started',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'very',\n",
       "     u'same',\n",
       "     u'time']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Alexander', u'Hamilton', u'began', u'to', u'climb'],\n",
       "    'original': 'Alexander Hamilton began to climb',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton', u'began', u'to', u'climb']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'How',\n",
       "     u'to',\n",
       "     u'account',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'rise',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'top'],\n",
       "    'original': 'How to account for his rise to the top?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How',\n",
       "     u'to',\n",
       "     u'account',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'rise',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'top']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Maaaaan', u'the', u'man', u'is'],\n",
       "    'original': 'Maaaaan, the man is',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Maaaaan', u'the', u'man', u'is']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Non', u'stop'],\n",
       "    'original': 'Non-stop!',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Non', u'stop']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Gentlemen',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'jury',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'curious',\n",
       "     u'bear',\n",
       "     u'with',\n",
       "     u'me'],\n",
       "    'original': 'Gentlemen of the jury, I\\x92m curious, bear with me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Gentlemen',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'jury',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'curious',\n",
       "     u'bear',\n",
       "     u'with',\n",
       "     u'me']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Are',\n",
       "     u'you',\n",
       "     u'aware',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'making',\n",
       "     u'hist',\n",
       "     u'ry'],\n",
       "    'original': 'Are you aware that we\\x92re making hist\\x92ry?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Are',\n",
       "     u'you',\n",
       "     u'aware',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'making',\n",
       "     u'hist',\n",
       "     u'ry']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'This',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'murder',\n",
       "     u'trial',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'brand',\n",
       "     u'new',\n",
       "     u'nation'],\n",
       "    'original': 'This is the first murder trial of our brand-new nation',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'murder',\n",
       "     u'trial',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'brand',\n",
       "     u'new',\n",
       "     u'nation']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'The', u'liberty', u'behind'],\n",
       "    'original': 'The liberty behind',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'liberty', u'behind']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Deliberation'],\n",
       "    'original': 'Deliberation\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Deliberation']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Non', u'stop'],\n",
       "    'original': 'Non-stop!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Non', u'stop']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I',\n",
       "     u'intend',\n",
       "     u'to',\n",
       "     u'prove',\n",
       "     u'beyond',\n",
       "     u'a',\n",
       "     u'shadow',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'doubt'],\n",
       "    'original': 'I intend to prove beyond a shadow of a doubt',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'intend',\n",
       "     u'to',\n",
       "     u'prove',\n",
       "     u'beyond',\n",
       "     u'a',\n",
       "     u'shadow',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'doubt']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'With', u'my', u'assistant', u'counsel'],\n",
       "    'original': 'With my assistant counsel\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'With', u'my', u'assistant', u'counsel']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Co', u'counsel'],\n",
       "    'original': 'Co-counsel',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Co', u'counsel']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Hamilton', u'sit', u'down'],\n",
       "    'original': 'Hamilton, sit down',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hamilton', u'sit', u'down']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Our',\n",
       "     u'client',\n",
       "     u'Levi',\n",
       "     u'Weeks',\n",
       "     u'is',\n",
       "     u'innocent',\n",
       "     u'Call',\n",
       "     u'your',\n",
       "     u'first',\n",
       "     u'witness'],\n",
       "    'original': 'Our client Levi Weeks is innocent. Call your first witness',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Our',\n",
       "     u'client',\n",
       "     u'Levi',\n",
       "     u'Weeks',\n",
       "     u'is',\n",
       "     u'innocent',\n",
       "     u'Call',\n",
       "     u'your',\n",
       "     u'first',\n",
       "     u'witness']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'That', u's', u'all', u'you', u'had', u'to', u'say'],\n",
       "    'original': 'That\\x92s all you had to say!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'That', u's', u'all', u'you', u'had', u'to', u'say']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Okay'],\n",
       "    'original': 'Okay!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Okay']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'One', u'more', u'thing'],\n",
       "    'original': 'One more thing\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'One', u'more', u'thing']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room'],\n",
       "    'original': 'Why do you assume you\\x92re the smartest in the room?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room'],\n",
       "    'original': 'Why do you assume you\\x92re the smartest in the room?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room'],\n",
       "    'original': 'Why do you assume you\\x92re the smartest in the room?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Soon',\n",
       "     u'that',\n",
       "     u'attitude',\n",
       "     u'may',\n",
       "     u'be',\n",
       "     u'your',\n",
       "     u'doom'],\n",
       "    'original': 'Soon that attitude may be your doom!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Soon',\n",
       "     u'that',\n",
       "     u'attitude',\n",
       "     u'may',\n",
       "     u'be',\n",
       "     u'your',\n",
       "     u'doom']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Awwww'],\n",
       "    'original': 'Awwww!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Awwww']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time'],\n",
       "    'original': 'Why do you write like you\\x92re running out of time?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Write',\n",
       "     u'day',\n",
       "     u'and',\n",
       "     u'night',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time'],\n",
       "    'original': 'Write day and night like you\\x92re running out of time?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Write',\n",
       "     u'day',\n",
       "     u'and',\n",
       "     u'night',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'day',\n",
       "     u'you',\n",
       "     u'fight',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'tim'],\n",
       "    'original': 'Ev\\x92ry day you fight, like you\\x92re running out of time',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'day',\n",
       "     u'you',\n",
       "     u'fight',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'tim']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Keep', u'on', u'fighting', u'In', u'the', u'meantime'],\n",
       "    'original': 'Keep on fighting. In the meantime\\x97',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Keep', u'on', u'fighting', u'In', u'the', u'meantime']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time'],\n",
       "    'original': 'Why do you write like you\\x92re running out of time?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'day',\n",
       "     u'you',\n",
       "     u'fight',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'tim'],\n",
       "    'original': 'Ev\\x92ry day you fight, like you\\x92re running out of time',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'day',\n",
       "     u'you',\n",
       "     u'fight',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'tim']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Non', u'stop'],\n",
       "    'original': 'Non-stop!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Non', u'stop']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Corruption',\n",
       "     u's',\n",
       "     u'such',\n",
       "     u'an',\n",
       "     u'old',\n",
       "     u'song',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'sing',\n",
       "     u'along',\n",
       "     u'in',\n",
       "     u'harmony'],\n",
       "    'original': 'Corruption\\x92s such an old song that we can sing along in harmony',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Corruption',\n",
       "     u's',\n",
       "     u'such',\n",
       "     u'an',\n",
       "     u'old',\n",
       "     u'song',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'sing',\n",
       "     u'along',\n",
       "     u'in',\n",
       "     u'harmony']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'And',\n",
       "     u'nowhere',\n",
       "     u'is',\n",
       "     u'it',\n",
       "     u'stronger',\n",
       "     u'than',\n",
       "     u'in',\n",
       "     u'Albany'],\n",
       "    'original': 'And nowhere is it stronger than in Albany',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'nowhere',\n",
       "     u'is',\n",
       "     u'it',\n",
       "     u'stronger',\n",
       "     u'than',\n",
       "     u'in',\n",
       "     u'Albany']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'This',\n",
       "     u'colony',\n",
       "     u's',\n",
       "     u'economy',\n",
       "     u's',\n",
       "     u'increasingly',\n",
       "     u'stalling',\n",
       "     u'an'],\n",
       "    'original': 'This colony\\x92s economy\\x92s increasingly stalling and',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'colony',\n",
       "     u's',\n",
       "     u'economy',\n",
       "     u's',\n",
       "     u'increasingly',\n",
       "     u'stalling',\n",
       "     u'an']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Honestly', u'that', u's', u'why', u'public', u'service'],\n",
       "    'original': 'Honestly, that\\x92s why public service',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Honestly', u'that', u's', u'why', u'public', u'service']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Seems', u'to', u'be', u'calling', u'me'],\n",
       "    'original': 'Seems to be calling me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Seems', u'to', u'be', u'calling', u'me']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'He', u's', u'just'],\n",
       "    'original': 'He\\x92s just',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'He', u's', u'just']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Non', u'stop'],\n",
       "    'original': 'Non-stop!',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Non', u'stop']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'I',\n",
       "     u'practiced',\n",
       "     u'the',\n",
       "     u'law',\n",
       "     u'I',\n",
       "     u'practic',\n",
       "     u'ly',\n",
       "     u'perfected',\n",
       "     u'it'],\n",
       "    'original': 'I practiced the law, I practic\\x92ly perfected it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'practiced',\n",
       "     u'the',\n",
       "     u'law',\n",
       "     u'I',\n",
       "     u'practic',\n",
       "     u'ly',\n",
       "     u'perfected',\n",
       "     u'it']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'I',\n",
       "     u've',\n",
       "     u'seen',\n",
       "     u'injustice',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'corrected',\n",
       "     u'i'],\n",
       "    'original': 'I\\x92ve seen injustice in the world and I\\x92ve corrected it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u've',\n",
       "     u'seen',\n",
       "     u'injustice',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'corrected',\n",
       "     u'i']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Now', u'for', u'a', u'strong', u'central', u'democracy'],\n",
       "    'original': 'Now for a strong central democracy',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Now', u'for', u'a', u'strong', u'central', u'democracy']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'If', u'not', u'then', u'I', u'll', u'be', u'Socrates'],\n",
       "    'original': 'If not, then I\\x92ll be Socrates',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If', u'not', u'then', u'I', u'll', u'be', u'Socrates']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Throwing',\n",
       "     u'verbal',\n",
       "     u'rocks',\n",
       "     u'at',\n",
       "     u'these',\n",
       "     u'mediocrities'],\n",
       "    'original': 'Throwing verbal rocks at these mediocrities',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Throwing',\n",
       "     u'verbal',\n",
       "     u'rocks',\n",
       "     u'at',\n",
       "     u'these',\n",
       "     u'mediocrities']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Awww'],\n",
       "    'original': 'Awww!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Awww']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Hamilton',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'Constitutional',\n",
       "     u'Convention'],\n",
       "    'original': 'Hamilton, at the Constitutional Convention:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hamilton',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'Constitutional',\n",
       "     u'Convention']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'I',\n",
       "     u'was',\n",
       "     u'chosen',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'Constitutional',\n",
       "     u'Convention'],\n",
       "    'original': 'I was chosen for the Constitutional Convention!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'was',\n",
       "     u'chosen',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'Constitutional',\n",
       "     u'Convention']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'There',\n",
       "     u'as',\n",
       "     u'a',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'junior',\n",
       "     u'delegate'],\n",
       "    'original': 'There as a New York junior delegate:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'There',\n",
       "     u'as',\n",
       "     u'a',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'junior',\n",
       "     u'delegate']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Now',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'going',\n",
       "     u'to',\n",
       "     u'say',\n",
       "     u'may',\n",
       "     u'sound',\n",
       "     u'indelicate'],\n",
       "    'original': 'Now what I\\x92m going to say may sound indelicate\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'going',\n",
       "     u'to',\n",
       "     u'say',\n",
       "     u'may',\n",
       "     u'sound',\n",
       "     u'indelicate']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Goes',\n",
       "     u'and',\n",
       "     u'proposes',\n",
       "     u'his',\n",
       "     u'own',\n",
       "     u'form',\n",
       "     u'of',\n",
       "     u'government'],\n",
       "    'original': 'Goes and proposes his own form of government!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Goes',\n",
       "     u'and',\n",
       "     u'proposes',\n",
       "     u'his',\n",
       "     u'own',\n",
       "     u'form',\n",
       "     u'of',\n",
       "     u'government']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'His',\n",
       "     u'own',\n",
       "     u'plan',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'form',\n",
       "     u'of',\n",
       "     u'government'],\n",
       "    'original': 'His own plan for a new form of government!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'His',\n",
       "     u'own',\n",
       "     u'plan',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'new',\n",
       "     u'form',\n",
       "     u'of',\n",
       "     u'government']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Awwww'],\n",
       "    'original': 'Awwww!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Awwww']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Talks',\n",
       "     u'for',\n",
       "     u'six',\n",
       "     u'hours',\n",
       "     u'The',\n",
       "     u'convention',\n",
       "     u'is',\n",
       "     u'listless'],\n",
       "    'original': 'Talks for six hours! The convention is listless!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Talks',\n",
       "     u'for',\n",
       "     u'six',\n",
       "     u'hours',\n",
       "     u'The',\n",
       "     u'convention',\n",
       "     u'is',\n",
       "     u'listless']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Bright', u'young', u'man'],\n",
       "    'original': 'Bright young man\\x85',\n",
       "    'speakers': ['ENSEMBLE MAN'],\n",
       "    'tokenized': [u'Bright', u'young', u'man']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Yo', u'who', u'the', u'f', u'is', u'this'],\n",
       "    'original': 'Yo, who the f is this?',\n",
       "    'speakers': ['ANOTHER ENSEMBLE MAN'],\n",
       "    'tokenized': [u'Yo', u'who', u'the', u'f', u'is', u'this']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'always',\n",
       "     u'say',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'believe'],\n",
       "    'original': 'Why do you always say what you believe?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'always',\n",
       "     u'say',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'believe']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'always',\n",
       "     u'say',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'believe'],\n",
       "    'original': 'Why do you always say what you believe?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'always',\n",
       "     u'say',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'believe']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'proclamation',\n",
       "     u'guarantees',\n",
       "     u'free',\n",
       "     u'ammunition',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'enemies'],\n",
       "    'original': 'Ev\\x92ry proclamation guarantees free ammunition for your enemies!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'proclamation',\n",
       "     u'guarantees',\n",
       "     u'free',\n",
       "     u'ammunition',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'enemies']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Why', u'do', u'you', u'write', u'like', u'it', u's'],\n",
       "    'original': 'Why do you write like it\\x92s',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Why', u'do', u'you', u'write', u'like', u'it', u's']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Going', u'out', u'of', u'style'],\n",
       "    'original': 'Going out of style?',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Going', u'out', u'of', u'style']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Write', u'day', u'and', u'night', u'like', u'it', u's'],\n",
       "    'original': 'Write day and night like it\\x92s',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Write', u'day', u'and', u'night', u'like', u'it', u's']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Going', u'out', u'of', u'style'],\n",
       "    'original': 'Going out of style?',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Going', u'out', u'of', u'style']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'always',\n",
       "     u'say',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'believe'],\n",
       "    'original': 'Why do you always say what you believe?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'always',\n",
       "     u'say',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'believe']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'Awww'],\n",
       "    'original': 'Awww!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Awww']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Going', u'out', u'of', u'style', u'hey'],\n",
       "    'original': 'Going out of style, hey!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Going', u'out', u'of', u'style', u'hey']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'Going', u'out', u'of', u'style', u'hey'],\n",
       "    'original': 'Going out of style, hey!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Going', u'out', u'of', u'style', u'hey']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'Ev', u'ry', u'day', u'you', u'fight', u'like', u'it'],\n",
       "    'original': 'Ev\\x92ry day you fight like it\\x92s',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Ev', u'ry', u'day', u'you', u'fight', u'like', u'it']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Going', u'out', u'of', u'style'],\n",
       "    'original': 'Going out of style',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Going', u'out', u'of', u'style']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Do', u'what', u'you', u'do'],\n",
       "    'original': 'Do what you do',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Do', u'what', u'you', u'do']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'Alexander'],\n",
       "    'original': 'Alexander?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Alexander']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Aaron', u'Burr', u'sir'],\n",
       "    'original': 'Aaron Burr, sir',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Aaron', u'Burr', u'sir']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'It', u's', u'the', u'middle', u'of', u'the', u'night'],\n",
       "    'original': 'It\\x92s the middle of the night',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It', u's', u'the', u'middle', u'of', u'the', u'night']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'Can', u'we', u'confer', u'sir'],\n",
       "    'original': 'Can we confer, sir?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Can', u'we', u'confer', u'sir']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'Is', u'this', u'a', u'legal', u'matter'],\n",
       "    'original': 'Is this a legal matter?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Is', u'this', u'a', u'legal', u'matter']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Yes', u'and', u'it', u's', u'important', u'to', u'me'],\n",
       "    'original': 'Yes, and it\\x92s important to me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes', u'and', u'it', u's', u'important', u'to', u'me']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'What', u'do', u'you', u'need'],\n",
       "    'original': 'What do you need?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'need']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'Burr',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'a',\n",
       "     u'better',\n",
       "     u'lawyer',\n",
       "     u'than',\n",
       "     u'me'],\n",
       "    'original': 'Burr, you\\x92re a better lawyer than me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'a',\n",
       "     u'better',\n",
       "     u'lawyer',\n",
       "     u'than',\n",
       "     u'me']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'Okay'],\n",
       "    'original': 'Okay',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Okay']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'talk',\n",
       "     u'too',\n",
       "     u'much',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'abrasive'],\n",
       "    'original': 'I know I talk too much, I\\x92m abrasive',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'talk',\n",
       "     u'too',\n",
       "     u'much',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'abrasive']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'You',\n",
       "     u're',\n",
       "     u'incredible',\n",
       "     u'in',\n",
       "     u'court',\n",
       "     u'You',\n",
       "     u're',\n",
       "     u'succinct',\n",
       "     u'persuasiv'],\n",
       "    'original': 'You\\x92re incredible in court. You\\x92re succinct, persuasive',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u're',\n",
       "     u'incredible',\n",
       "     u'in',\n",
       "     u'court',\n",
       "     u'You',\n",
       "     u're',\n",
       "     u'succinct',\n",
       "     u'persuasiv']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'My',\n",
       "     u'client',\n",
       "     u'needs',\n",
       "     u'a',\n",
       "     u'strong',\n",
       "     u'defense',\n",
       "     u'You',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'solution'],\n",
       "    'original': 'My client needs a strong defense. You\\x92re the solution',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My',\n",
       "     u'client',\n",
       "     u'needs',\n",
       "     u'a',\n",
       "     u'strong',\n",
       "     u'defense',\n",
       "     u'You',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'solution']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'Who', u's', u'your', u'client'],\n",
       "    'original': 'Who\\x92s your client?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Who', u's', u'your', u'client']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'The', u'new', u'U.S', u'Constitution'],\n",
       "    'original': 'The new U.S. Constitution?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'new', u'U.S', u'Constitution']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'Hear', u'me', u'out'],\n",
       "    'original': 'Hear me out',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hear', u'me', u'out']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'No', u'way'],\n",
       "    'original': 'No way!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'way']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'A',\n",
       "     u'series',\n",
       "     u'of',\n",
       "     u'essays',\n",
       "     u'anonymously',\n",
       "     u'published'],\n",
       "    'original': 'A series of essays, anonymously published',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'series',\n",
       "     u'of',\n",
       "     u'essays',\n",
       "     u'anonymously',\n",
       "     u'published']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'Defending',\n",
       "     u'the',\n",
       "     u'document',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'public'],\n",
       "    'original': 'Defending the document to the public',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Defending',\n",
       "     u'the',\n",
       "     u'document',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'public']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'No', u'one', u'will', u'read', u'it'],\n",
       "    'original': 'No one will read it',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'one', u'will', u'read', u'it']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'I', u'disagree'],\n",
       "    'original': 'I disagree',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'disagree']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'And', u'if', u'it', u'fails'],\n",
       "    'original': 'And if it fails?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'if', u'it', u'fails']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'Burr', u'that', u's', u'why', u'we', u'need', u'it'],\n",
       "    'original': 'Burr, that\\x92s why we need it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr', u'that', u's', u'why', u'we', u'need', u'it']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'The', u'constitution', u's', u'a', u'mess'],\n",
       "    'original': 'The constitution\\x92s a mess',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'constitution', u's', u'a', u'mess']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'So', u'it', u'needs', u'amendments'],\n",
       "    'original': 'So it needs amendments',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'So', u'it', u'needs', u'amendments']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'It', u's', u'full', u'of', u'contradictions'],\n",
       "    'original': 'It\\x92s full of contradictions',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It', u's', u'full', u'of', u'contradictions']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'So', u'is', u'independence'],\n",
       "    'original': 'So is independence',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'So', u'is', u'independence']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'We', u'have', u'to', u'start', u'somewhere'],\n",
       "    'original': 'We have to start somewhere',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We', u'have', u'to', u'start', u'somewhere']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'No', u'No', u'way'],\n",
       "    'original': 'No. No way',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'No', u'way']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'You', u're', u'making', u'a', u'mistake'],\n",
       "    'original': 'You\\x92re making a mistake',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You', u're', u'making', u'a', u'mistake']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'Good', u'night'],\n",
       "    'original': 'Good night',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Good', u'night']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'What', u'are', u'you', u'waiting', u'for'],\n",
       "    'original': 'What are you waiting for?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What', u'are', u'you', u'waiting', u'for']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'What', u'do', u'you', u'stall', u'for'],\n",
       "    'original': 'What do you stall for?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'stall', u'for']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'We', u'won', u'the', u'war'],\n",
       "    'original': 'We won the war',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We', u'won', u'the', u'war']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'What', u'was', u'it', u'all', u'for'],\n",
       "    'original': 'What was it all for?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What', u'was', u'it', u'all', u'for']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'Do', u'you', u'support', u'this', u'constitution'],\n",
       "    'original': 'Do you support this constitution?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Do', u'you', u'support', u'this', u'constitution']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'Of', u'course'],\n",
       "    'original': 'Of course',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Of', u'course']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'Then', u'defend', u'it'],\n",
       "    'original': 'Then defend it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Then', u'defend', u'it']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'And',\n",
       "     u'what',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'backing',\n",
       "     u'the',\n",
       "     u'wrong',\n",
       "     u'horse'],\n",
       "    'original': 'And what if you\\x92re backing the wrong horse?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'what',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'backing',\n",
       "     u'the',\n",
       "     u'wrong',\n",
       "     u'horse']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'Burr',\n",
       "     u'we',\n",
       "     u'studied',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'fought',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'killed'],\n",
       "    'original': 'Burr, we studied and we fought and we killed',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr',\n",
       "     u'we',\n",
       "     u'studied',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'fought',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'killed']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'For',\n",
       "     u'the',\n",
       "     u'notion',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'nation',\n",
       "     u'we',\n",
       "     u'now',\n",
       "     u'get',\n",
       "     u'to',\n",
       "     u'build'],\n",
       "    'original': 'For the notion of a nation we now get to build',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'For',\n",
       "     u'the',\n",
       "     u'notion',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'nation',\n",
       "     u'we',\n",
       "     u'now',\n",
       "     u'get',\n",
       "     u'to',\n",
       "     u'build']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'For',\n",
       "     u'once',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'life',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'stand',\n",
       "     u'with',\n",
       "     u'pride'],\n",
       "    'original': 'For once in your life, take a stand with pride',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'For',\n",
       "     u'once',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'life',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'stand',\n",
       "     u'with',\n",
       "     u'pride']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'understand',\n",
       "     u'how',\n",
       "     u'you',\n",
       "     u'stand',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'side'],\n",
       "    'original': 'I don\\x92t understand how you stand to the side',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'understand',\n",
       "     u'how',\n",
       "     u'you',\n",
       "     u'stand',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'side']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'I', u'll', u'keep', u'all', u'my', u'plans'],\n",
       "    'original': 'I\\x92ll keep all my plans',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'll', u'keep', u'all', u'my', u'plans']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'Close', u'to', u'my', u'chest'],\n",
       "    'original': 'Close to my chest',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Close', u'to', u'my', u'chest']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'I', u'll', u'wait', u'here', u'and', u'see'],\n",
       "    'original': 'I\\x92ll wait here and see',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'll', u'wait', u'here', u'and', u'see']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'Which', u'way', u'the', u'wind'],\n",
       "    'original': 'Which way the wind',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Which', u'way', u'the', u'wind']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'Will', u'blow'],\n",
       "    'original': 'Will blow',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Will', u'blow']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'I', u'm', u'taking', u'my', u'time'],\n",
       "    'original': 'I\\x92m taking my time',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'm', u'taking', u'my', u'time']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'Watching', u'the'],\n",
       "    'original': 'Watching the',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Watching', u'the']},\n",
       "   {'line#': 126,\n",
       "    'normalized': [u'Afterbirth', u'of', u'a', u'nation'],\n",
       "    'original': 'Afterbirth of a nation',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Afterbirth', u'of', u'a', u'nation']},\n",
       "   {'line#': 127,\n",
       "    'normalized': [u'Watching', u'the', u'tension', u'grow'],\n",
       "    'original': 'Watching the tension grow',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Watching', u'the', u'tension', u'grow']},\n",
       "   {'line#': 128,\n",
       "    'normalized': [u'Wait', u'for', u'it', u'wait', u'for'],\n",
       "    'original': 'Wait for it, wait for',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wait', u'for', u'it', u'wait', u'for']},\n",
       "   {'line#': 129,\n",
       "    'normalized': [u'It', u'wait'],\n",
       "    'original': 'It, wait\\x85',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'It', u'wait']},\n",
       "   {'line#': 130,\n",
       "    'normalized': [u'Which', u'way', u'the', u'wind'],\n",
       "    'original': 'Which way the wind',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Which', u'way', u'the', u'wind']},\n",
       "   {'line#': 131,\n",
       "    'normalized': [u'Will', u'blow'],\n",
       "    'original': 'Will blow',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Will', u'blow']},\n",
       "   {'line#': 132,\n",
       "    'normalized': [u'I', u'm', u'taking', u'my', u'time'],\n",
       "    'original': 'I\\x92m taking my time',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'm', u'taking', u'my', u'time']},\n",
       "   {'line#': 133,\n",
       "    'normalized': [u'Watching', u'the'],\n",
       "    'original': 'Watching the',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Watching', u'the']},\n",
       "   {'line#': 134,\n",
       "    'normalized': [u'Afterbirth', u'of', u'a', u'nation'],\n",
       "    'original': 'Afterbirth of a nation',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Afterbirth', u'of', u'a', u'nation']},\n",
       "   {'line#': 135,\n",
       "    'normalized': [u'Watching', u'the', u'tension', u'grow'],\n",
       "    'original': 'Watching the tension grow',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Watching', u'the', u'tension', u'grow']},\n",
       "   {'line#': 136,\n",
       "    'normalized': [u'I', u'am', u'sailing', u'off', u'to', u'London'],\n",
       "    'original': 'I am sailing off to London',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'am', u'sailing', u'off', u'to', u'London']},\n",
       "   {'line#': 137,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'accompanied',\n",
       "     u'by',\n",
       "     u'someone',\n",
       "     u'who',\n",
       "     u'always',\n",
       "     u'pays'],\n",
       "    'original': 'I\\x92m accompanied by someone who always pays',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'accompanied',\n",
       "     u'by',\n",
       "     u'someone',\n",
       "     u'who',\n",
       "     u'always',\n",
       "     u'pays']},\n",
       "   {'line#': 138,\n",
       "    'normalized': [u'I', u'have', u'found', u'a', u'wealthy', u'husband'],\n",
       "    'original': 'I have found a wealthy husband',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'have', u'found', u'a', u'wealthy', u'husband']},\n",
       "   {'line#': 139,\n",
       "    'normalized': [u'Who',\n",
       "     u'will',\n",
       "     u'keep',\n",
       "     u'me',\n",
       "     u'in',\n",
       "     u'comfort',\n",
       "     u'for',\n",
       "     u'all',\n",
       "     u'my',\n",
       "     u'days'],\n",
       "    'original': 'Who will keep me in comfort for all my days',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Who',\n",
       "     u'will',\n",
       "     u'keep',\n",
       "     u'me',\n",
       "     u'in',\n",
       "     u'comfort',\n",
       "     u'for',\n",
       "     u'all',\n",
       "     u'my',\n",
       "     u'days']},\n",
       "   {'line#': 140,\n",
       "    'normalized': [u'He',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'of',\n",
       "     u'fun',\n",
       "     u'but',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'no',\n",
       "     u'one'],\n",
       "    'original': 'He is not a lot of fun, but there\\x92s no one',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'He',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'of',\n",
       "     u'fun',\n",
       "     u'but',\n",
       "     u'there',\n",
       "     u's',\n",
       "     u'no',\n",
       "     u'one']},\n",
       "   {'line#': 141,\n",
       "    'normalized': [u'Who',\n",
       "     u'can',\n",
       "     u'match',\n",
       "     u'you',\n",
       "     u'for',\n",
       "     u'turn',\n",
       "     u'of',\n",
       "     u'phrase'],\n",
       "    'original': 'Who can match you for turn of phrase',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Who',\n",
       "     u'can',\n",
       "     u'match',\n",
       "     u'you',\n",
       "     u'for',\n",
       "     u'turn',\n",
       "     u'of',\n",
       "     u'phrase']},\n",
       "   {'line#': 142,\n",
       "    'normalized': [u'My', u'Alexander'],\n",
       "    'original': 'My Alexander',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'My', u'Alexander']},\n",
       "   {'line#': 143,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 144,\n",
       "    'normalized': [u'Don', u't', u'forget', u'to', u'write'],\n",
       "    'original': 'Don\\x92t forget to write',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Don', u't', u'forget', u'to', u'write']},\n",
       "   {'line#': 145,\n",
       "    'normalized': [u'Look', u'at', u'where', u'you', u'are'],\n",
       "    'original': 'Look at where you are',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'at', u'where', u'you', u'are']},\n",
       "   {'line#': 146,\n",
       "    'normalized': [u'Look', u'at', u'where', u'you', u'started'],\n",
       "    'original': 'Look at where you started',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'at', u'where', u'you', u'started']},\n",
       "   {'line#': 147,\n",
       "    'normalized': [u'The',\n",
       "     u'fact',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'alive',\n",
       "     u'is',\n",
       "     u'a',\n",
       "     u'miracle'],\n",
       "    'original': 'The fact that you\\x92re alive is a miracle',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'The',\n",
       "     u'fact',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'alive',\n",
       "     u'is',\n",
       "     u'a',\n",
       "     u'miracle']},\n",
       "   {'line#': 148,\n",
       "    'normalized': [u'Just',\n",
       "     u'stay',\n",
       "     u'alive',\n",
       "     u'that',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough'],\n",
       "    'original': 'Just stay alive, that would be enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Just',\n",
       "     u'stay',\n",
       "     u'alive',\n",
       "     u'that',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough']},\n",
       "   {'line#': 149,\n",
       "    'normalized': [u'And',\n",
       "     u'if',\n",
       "     u'your',\n",
       "     u'wife',\n",
       "     u'could',\n",
       "     u'share',\n",
       "     u'a',\n",
       "     u'fraction',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'time'],\n",
       "    'original': 'And if your wife could share a fraction of your time',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And',\n",
       "     u'if',\n",
       "     u'your',\n",
       "     u'wife',\n",
       "     u'could',\n",
       "     u'share',\n",
       "     u'a',\n",
       "     u'fraction',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'time']},\n",
       "   {'line#': 150,\n",
       "    'normalized': [u'If',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'grant',\n",
       "     u'you',\n",
       "     u'peace',\n",
       "     u'of',\n",
       "     u'mind'],\n",
       "    'original': 'If I could grant you peace of mind',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'If',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'grant',\n",
       "     u'you',\n",
       "     u'peace',\n",
       "     u'of',\n",
       "     u'mind']},\n",
       "   {'line#': 151,\n",
       "    'normalized': [u'Would', u'that', u'be', u'enough'],\n",
       "    'original': 'Would that be enough?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Would', u'that', u'be', u'enough']},\n",
       "   {'line#': 152,\n",
       "    'normalized': [u'Alexander',\n",
       "     u'joins',\n",
       "     u'forces',\n",
       "     u'with',\n",
       "     u'James',\n",
       "     u'Madison',\n",
       "     u'and',\n",
       "     u'John',\n",
       "     u'Jay',\n",
       "     u'to',\n",
       "     u'write',\n",
       "     u'a',\n",
       "     u'series',\n",
       "     u'of',\n",
       "     u'essays',\n",
       "     u'defending',\n",
       "     u'the',\n",
       "     u'new',\n",
       "     u'United',\n",
       "     u'States',\n",
       "     u'Constitution',\n",
       "     u'entitled',\n",
       "     u'The',\n",
       "     u'Federalist',\n",
       "     u'Papers',\n",
       "     u'The',\n",
       "     u'plan',\n",
       "     u'was',\n",
       "     u'to',\n",
       "     u'write',\n",
       "     u'a',\n",
       "     u'total',\n",
       "     u'of',\n",
       "     u'twenty',\n",
       "     u'five',\n",
       "     u'essays',\n",
       "     u'the',\n",
       "     u'work',\n",
       "     u'divided',\n",
       "     u'evenly',\n",
       "     u'among',\n",
       "     u'the',\n",
       "     u'three',\n",
       "     u'men',\n",
       "     u'In',\n",
       "     u'the',\n",
       "     u'end',\n",
       "     u'they',\n",
       "     u'wrote',\n",
       "     u'eighty',\n",
       "     u'five',\n",
       "     u'essays',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'span',\n",
       "     u'of',\n",
       "     u'six',\n",
       "     u'months',\n",
       "     u'John',\n",
       "     u'Jay',\n",
       "     u'got',\n",
       "     u'sick',\n",
       "     u'after',\n",
       "     u'writing',\n",
       "     u'five',\n",
       "     u'James',\n",
       "     u'Madison',\n",
       "     u'wrote',\n",
       "     u'twenty',\n",
       "     u'nine',\n",
       "     u'Hamilton',\n",
       "     u'wrote',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'fifty',\n",
       "     u'one'],\n",
       "    'original': 'Alexander joins forces with James Madison and John Jay to write a series of essays defending the new United States Constitution, entitled The Federalist Papers. The plan was to write a total of twenty-five essays, the work divided evenly among the three men. In the end, they wrote eighty-five essays, in the span of six months. John Jay got sick after writing five. James Madison wrote twenty-nine. Hamilton wrote the other fifty-one!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Alexander',\n",
       "     u'joins',\n",
       "     u'forces',\n",
       "     u'with',\n",
       "     u'James',\n",
       "     u'Madison',\n",
       "     u'and',\n",
       "     u'John',\n",
       "     u'Jay',\n",
       "     u'to',\n",
       "     u'write',\n",
       "     u'a',\n",
       "     u'series',\n",
       "     u'of',\n",
       "     u'essays',\n",
       "     u'defending',\n",
       "     u'the',\n",
       "     u'new',\n",
       "     u'United',\n",
       "     u'States',\n",
       "     u'Constitution',\n",
       "     u'entitled',\n",
       "     u'The',\n",
       "     u'Federalist',\n",
       "     u'Papers',\n",
       "     u'The',\n",
       "     u'plan',\n",
       "     u'was',\n",
       "     u'to',\n",
       "     u'write',\n",
       "     u'a',\n",
       "     u'total',\n",
       "     u'of',\n",
       "     u'twenty',\n",
       "     u'five',\n",
       "     u'essays',\n",
       "     u'the',\n",
       "     u'work',\n",
       "     u'divided',\n",
       "     u'evenly',\n",
       "     u'among',\n",
       "     u'the',\n",
       "     u'three',\n",
       "     u'men',\n",
       "     u'In',\n",
       "     u'the',\n",
       "     u'end',\n",
       "     u'they',\n",
       "     u'wrote',\n",
       "     u'eighty',\n",
       "     u'five',\n",
       "     u'essays',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'span',\n",
       "     u'of',\n",
       "     u'six',\n",
       "     u'months',\n",
       "     u'John',\n",
       "     u'Jay',\n",
       "     u'got',\n",
       "     u'sick',\n",
       "     u'after',\n",
       "     u'writing',\n",
       "     u'five',\n",
       "     u'James',\n",
       "     u'Madison',\n",
       "     u'wrote',\n",
       "     u'twenty',\n",
       "     u'nine',\n",
       "     u'Hamilton',\n",
       "     u'wrote',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'fifty',\n",
       "     u'one']},\n",
       "   {'line#': 153,\n",
       "    'normalized': [u'How', u'do', u'you', u'write', u'like', u'you', u're'],\n",
       "    'original': 'How do you write like you\\x92re',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How', u'do', u'you', u'write', u'like', u'you', u're']},\n",
       "   {'line#': 154,\n",
       "    'normalized': [u'Running', u'out', u'of', u'time'],\n",
       "    'original': 'Running out of time?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Running', u'out', u'of', u'time']},\n",
       "   {'line#': 155,\n",
       "    'normalized': [u'Write', u'day', u'and', u'night', u'like', u'you', u're'],\n",
       "    'original': 'Write day and night like you\\x92re',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Write', u'day', u'and', u'night', u'like', u'you', u're']},\n",
       "   {'line#': 156,\n",
       "    'normalized': [u'Running', u'out', u'of', u'time'],\n",
       "    'original': 'Running out of time?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Running', u'out', u'of', u'time']},\n",
       "   {'line#': 157,\n",
       "    'normalized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'day',\n",
       "     u'you',\n",
       "     u'fight',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u'r'],\n",
       "    'original': 'Ev\\x92ry day you fight like you\\x92re',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'day',\n",
       "     u'you',\n",
       "     u'fight',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u'r']},\n",
       "   {'line#': 158,\n",
       "    'normalized': [u'Running', u'out', u'of', u'time', u'like', u'you', u're'],\n",
       "    'original': 'Running out of time like you\\x92re',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Running', u'out', u'of', u'time', u'like', u'you', u're']},\n",
       "   {'line#': 159,\n",
       "    'normalized': [u'Running', u'out', u'of', u'time'],\n",
       "    'original': 'Running out of time',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Running', u'out', u'of', u'time']},\n",
       "   {'line#': 160,\n",
       "    'normalized': [u'Are', u'you', u'running', u'out', u'of', u'time'],\n",
       "    'original': 'Are you running out of time?',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Are', u'you', u'running', u'out', u'of', u'time']},\n",
       "   {'line#': 161,\n",
       "    'normalized': [u'Running', u'out', u'of', u'time'],\n",
       "    'original': 'Running out of time?',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Running', u'out', u'of', u'time']},\n",
       "   {'line#': 162,\n",
       "    'normalized': [u'Running', u'out', u'of', u'time'],\n",
       "    'original': 'Running out of time?',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Running', u'out', u'of', u'time']},\n",
       "   {'line#': 163,\n",
       "    'normalized': [u'Running', u'out', u'of', u'time'],\n",
       "    'original': 'Running out of time',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Running', u'out', u'of', u'time']},\n",
       "   {'line#': 164,\n",
       "    'normalized': [u'Running', u'out', u'of', u'time'],\n",
       "    'original': 'Running out of time',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Running', u'out', u'of', u'time']},\n",
       "   {'line#': 165,\n",
       "    'normalized': [u'Awwww'],\n",
       "    'original': 'Awwww!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'Awwww']},\n",
       "   {'line#': 166,\n",
       "    'normalized': [u'How',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'tomorrow',\n",
       "     u'won',\n",
       "     u't',\n",
       "     u'arrive'],\n",
       "    'original': 'How do you write like tomorrow won\\x92t arrive?',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'How',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'tomorrow',\n",
       "     u'won',\n",
       "     u't',\n",
       "     u'arrive']},\n",
       "   {'line#': 167,\n",
       "    'normalized': [u'How',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u'need',\n",
       "     u'it',\n",
       "     u'to',\n",
       "     u'survive'],\n",
       "    'original': 'How do you write like you need it to survive?',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'How',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u'need',\n",
       "     u'it',\n",
       "     u'to',\n",
       "     u'survive']},\n",
       "   {'line#': 168,\n",
       "    'normalized': [u'How',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'ev',\n",
       "     u'ry',\n",
       "     u'second',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'alive'],\n",
       "    'original': 'How do you write ev\\x92ry second you\\x92re alive?',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'How',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'ev',\n",
       "     u'ry',\n",
       "     u'second',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'alive']},\n",
       "   {'line#': 169,\n",
       "    'normalized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'second',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'alive',\n",
       "     u'Ev',\n",
       "     u'ry',\n",
       "     u'second',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'ali'],\n",
       "    'original': 'Ev\\x92ry second you\\x92re alive? Ev\\x92ry second you\\x92re alive?',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Ev',\n",
       "     u'ry',\n",
       "     u'second',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'alive',\n",
       "     u'Ev',\n",
       "     u'ry',\n",
       "     u'second',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'ali']},\n",
       "   {'line#': 170,\n",
       "    'normalized': [u'They', u'are', u'asking', u'me', u'to', u'lead'],\n",
       "    'original': 'They are asking me to lead',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'They', u'are', u'asking', u'me', u'to', u'lead']},\n",
       "   {'line#': 171,\n",
       "    'normalized': [u'I', u'am', u'doing', u'the', u'best', u'I', u'can'],\n",
       "    'original': 'I am doing the best I can',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'am', u'doing', u'the', u'best', u'I', u'can']},\n",
       "   {'line#': 172,\n",
       "    'normalized': [u'To', u'get', u'the', u'people', u'that', u'I', u'need'],\n",
       "    'original': 'To get the people that I need',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'To', u'get', u'the', u'people', u'that', u'I', u'need']},\n",
       "   {'line#': 173,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'asking',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'my',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man'],\n",
       "    'original': 'I\\x92m asking you to be my right hand man',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'asking',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'my',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man']},\n",
       "   {'line#': 174,\n",
       "    'normalized': [u'Treasury', u'or', u'State'],\n",
       "    'original': 'Treasury or State?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Treasury', u'or', u'State']},\n",
       "   {'line#': 175,\n",
       "    'normalized': [u'I', u'know', u'it', u's', u'a', u'lot', u'to', u'ask'],\n",
       "    'original': 'I know it\\x92s a lot to ask',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'know', u'it', u's', u'a', u'lot', u'to', u'ask']},\n",
       "   {'line#': 176,\n",
       "    'normalized': [u'Treasury', u'or', u'State'],\n",
       "    'original': 'Treasury or State?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Treasury', u'or', u'State']},\n",
       "   {'line#': 177,\n",
       "    'normalized': [u'To',\n",
       "     u'leave',\n",
       "     u'behind',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'you',\n",
       "     u'know'],\n",
       "    'original': 'To leave behind the world you know\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'To',\n",
       "     u'leave',\n",
       "     u'behind',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'you',\n",
       "     u'know']},\n",
       "   {'line#': 178,\n",
       "    'normalized': [u'Sir',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'want',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'run',\n",
       "     u'the',\n",
       "     u'Treasury',\n",
       "     u'or',\n",
       "     u'State',\n",
       "     u'department'],\n",
       "    'original': 'Sir, do you want me to run the Treasury or State department?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'want',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'run',\n",
       "     u'the',\n",
       "     u'Treasury',\n",
       "     u'or',\n",
       "     u'State',\n",
       "     u'department']},\n",
       "   {'line#': 179,\n",
       "    'normalized': [u'Treasury'],\n",
       "    'original': 'Treasury',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Treasury']},\n",
       "   {'line#': 180,\n",
       "    'normalized': [u'Let', u's', u'go'],\n",
       "    'original': 'Let\\x92s go',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Let', u's', u'go']},\n",
       "   {'line#': 181,\n",
       "    'normalized': [u'Alexander'],\n",
       "    'original': 'Alexander\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Alexander']},\n",
       "   {'line#': 182,\n",
       "    'normalized': [u'I', u'have', u'to', u'leave'],\n",
       "    'original': 'I have to leave',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'have', u'to', u'leave']},\n",
       "   {'line#': 183,\n",
       "    'normalized': [u'Alexander'],\n",
       "    'original': 'Alexander\\x97',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Alexander']},\n",
       "   {'line#': 184,\n",
       "    'normalized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'at',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now'],\n",
       "    'original': 'Look around, look around at how lucky we are to be alive right now',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'at',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now']},\n",
       "   {'line#': 185,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 186,\n",
       "    'normalized': [u'They', u'are', u'asking', u'me', u'to', u'lead'],\n",
       "    'original': 'They are asking me to lead',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'They', u'are', u'asking', u'me', u'to', u'lead']},\n",
       "   {'line#': 187,\n",
       "    'normalized': [u'Look', u'around', u'isn', u't', u'this', u'enough'],\n",
       "    'original': 'Look around, isn\\x92t this enough?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'around', u'isn', u't', u'this', u'enough']},\n",
       "   {'line#': 188,\n",
       "    'normalized': [u'He', u'will', u'never', u'be', u'satisfied'],\n",
       "    'original': 'He will never be satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'He', u'will', u'never', u'be', u'satisfied']},\n",
       "   {'line#': 189,\n",
       "    'normalized': [u'He', u'will', u'never', u'be', u'satisfied'],\n",
       "    'original': 'He will never be satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'He', u'will', u'never', u'be', u'satisfied']},\n",
       "   {'line#': 190,\n",
       "    'normalized': [u'Satisfied'],\n",
       "    'original': 'Satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Satisfied']},\n",
       "   {'line#': 191,\n",
       "    'normalized': [u'Satisfied'],\n",
       "    'original': 'Satisfied\\x85',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Satisfied']},\n",
       "   {'line#': 192,\n",
       "    'normalized': [u'He', u'will', u'never', u'be', u'satisfied'],\n",
       "    'original': 'He will never be satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'He', u'will', u'never', u'be', u'satisfied']},\n",
       "   {'line#': 193,\n",
       "    'normalized': [u'Satisfied'],\n",
       "    'original': 'Satisfied\\x85',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Satisfied']},\n",
       "   {'line#': 194,\n",
       "    'normalized': [u'Satisfied'],\n",
       "    'original': 'Satisfied...',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Satisfied']},\n",
       "   {'line#': 195,\n",
       "    'normalized': [u'Why', u'do', u'you', u'fight', u'like'],\n",
       "    'original': 'Why do you fight like',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Why', u'do', u'you', u'fight', u'like']},\n",
       "   {'line#': 196,\n",
       "    'normalized': [u'What', u'would', u'be', u'enough'],\n",
       "    'original': 'What would be enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'What', u'would', u'be', u'enough']},\n",
       "   {'line#': 197,\n",
       "    'normalized': [u'To'],\n",
       "    'original': 'To',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'To']},\n",
       "   {'line#': 198,\n",
       "    'normalized': [u'Be', u'satisfied'],\n",
       "    'original': 'Be satisfied',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Be', u'satisfied']},\n",
       "   {'line#': 199,\n",
       "    'normalized': [u'Satisfied'],\n",
       "    'original': 'Satisfied',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Satisfied']},\n",
       "   {'line#': 200,\n",
       "    'normalized': [u'Satisfied'],\n",
       "    'original': 'Satisfied\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Satisfied']},\n",
       "   {'line#': 201,\n",
       "    'normalized': [u'Look', u'around'],\n",
       "    'original': 'Look around',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'around']},\n",
       "   {'line#': 202,\n",
       "    'normalized': [u'Look', u'around'],\n",
       "    'original': 'Look around!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'around']},\n",
       "   {'line#': 203,\n",
       "    'normalized': [u'Isn', u't', u'this', u'enough'],\n",
       "    'original': 'Isn\\x92t this enough?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Isn', u't', u'this', u'enough']},\n",
       "   {'line#': 204,\n",
       "    'normalized': [u'What', u'would', u'be', u'enough'],\n",
       "    'original': 'What would be enough?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'What', u'would', u'be', u'enough']},\n",
       "   {'line#': 205,\n",
       "    'normalized': [u'Why', u'do', u'you', u'fight', u'like'],\n",
       "    'original': 'Why do you fight like',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Why', u'do', u'you', u'fight', u'like']},\n",
       "   {'line#': 206,\n",
       "    'normalized': [u'History', u'has', u'its', u'eyes'],\n",
       "    'original': 'History has its eyes\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'History', u'has', u'its', u'eyes']},\n",
       "   {'line#': 207,\n",
       "    'normalized': [u'On'],\n",
       "    'original': 'On\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'On']},\n",
       "   {'line#': 208,\n",
       "    'normalized': [u'You'],\n",
       "    'original': 'You!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You']},\n",
       "   {'line#': 209,\n",
       "    'normalized': [u'History', u'has', u'its', u'eyes'],\n",
       "    'original': 'History has its eyes\\x85',\n",
       "    'speakers': ['WASHINGTON', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'History', u'has', u'its', u'eyes']},\n",
       "   {'line#': 210,\n",
       "    'normalized': [u'On'],\n",
       "    'original': 'On\\x85',\n",
       "    'speakers': ['WASHINGTON', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'On']},\n",
       "   {'line#': 211,\n",
       "    'normalized': [u'You'],\n",
       "    'original': 'You...',\n",
       "    'speakers': ['WASHINGTON', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'You']},\n",
       "   {'line#': 212,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'roo'],\n",
       "    'original': 'Why do you assume you\\x92re the smartest in the room? Why do you assume you\\x92re the smartest in the room? Why do you assume you\\x92re the smartest in the room?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'assume',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'the',\n",
       "     u'smartest',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'roo']},\n",
       "   {'line#': 213,\n",
       "    'normalized': [u'Soon',\n",
       "     u'that',\n",
       "     u'attitude',\n",
       "     u's',\n",
       "     u'gonna',\n",
       "     u'be',\n",
       "     u'your',\n",
       "     u'doom'],\n",
       "    'original': 'Soon that attitude\\x92s gonna be your doom!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Soon',\n",
       "     u'that',\n",
       "     u'attitude',\n",
       "     u's',\n",
       "     u'gonna',\n",
       "     u'be',\n",
       "     u'your',\n",
       "     u'doom']},\n",
       "   {'line#': 214,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'fight',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time'],\n",
       "    'original': 'Why do you fight like you\\x92re running out of time?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'fight',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time']},\n",
       "   {'line#': 215,\n",
       "    'normalized': [u'Why', u'do', u'you', u'fight', u'like'],\n",
       "    'original': 'Why do you fight like',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why', u'do', u'you', u'fight', u'like']},\n",
       "   {'line#': 216,\n",
       "    'normalized': [u'Non', u'stop'],\n",
       "    'original': 'Non-stop!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Non', u'stop']},\n",
       "   {'line#': 217,\n",
       "    'normalized': [u'Non', u'stop'],\n",
       "    'original': 'Non-stop!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Non', u'stop']},\n",
       "   {'line#': 218,\n",
       "    'normalized': [u'Non', u'stop'],\n",
       "    'original': 'Non-stop!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Non', u'stop']},\n",
       "   {'line#': 219,\n",
       "    'normalized': [u'Non', u'stop'],\n",
       "    'original': 'Non-stop!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Non', u'stop']},\n",
       "   {'line#': 220,\n",
       "    'normalized': [u'History', u'has', u'its', u'eyes', u'on', u'you'],\n",
       "    'original': 'History has its eyes on you',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'History', u'has', u'its', u'eyes', u'on', u'you']},\n",
       "   {'line#': 221,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwin\\x92 away my shot!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot']},\n",
       "   {'line#': 222,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwin\\x92 away my shot!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot']},\n",
       "   {'line#': 223,\n",
       "    'normalized': [u'I', u'am'],\n",
       "    'original': 'I am',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am']},\n",
       "   {'line#': 224,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 225,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwin\\x92 away my shot!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot']},\n",
       "   {'line#': 226,\n",
       "    'normalized': [u'Just', u'you', u'wait'],\n",
       "    'original': 'Just you wait!',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Just', u'you', u'wait']},\n",
       "   {'line#': 227,\n",
       "    'normalized': [u'Just', u'you', u'wait'],\n",
       "    'original': 'Just you wait!',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Just', u'you', u'wait']},\n",
       "   {'line#': 228,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 229,\n",
       "    'normalized': [u'Hamilton', u'just', u'you', u'wait'],\n",
       "    'original': 'Hamilton, just you wait!',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Hamilton', u'just', u'you', u'wait']}],\n",
       "  'track': 'Non-Stop',\n",
       "  'track#': '23'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'1776', u'New', u'York', u'City'],\n",
       "    'original': '1776. New York City',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'1776', u'New', u'York', u'City']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Pardon',\n",
       "     u'me',\n",
       "     u'Are',\n",
       "     u'you',\n",
       "     u'Aaron',\n",
       "     u'Burr',\n",
       "     u'sir'],\n",
       "    'original': 'Pardon me. Are you Aaron Burr, sir?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Pardon',\n",
       "     u'me',\n",
       "     u'Are',\n",
       "     u'you',\n",
       "     u'Aaron',\n",
       "     u'Burr',\n",
       "     u'sir']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'That', u'depends', u'Who', u's', u'asking'],\n",
       "    'original': 'That depends. Who\\x92s asking?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'That', u'depends', u'Who', u's', u'asking']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Oh', u'well', u'sure', u'sir'],\n",
       "    'original': 'Oh, well, sure, sir',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Oh', u'well', u'sure', u'sir']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'Alexander',\n",
       "     u'Hamilton',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'at',\n",
       "     u'your',\n",
       "     u'service',\n",
       "     u'si'],\n",
       "    'original': 'I\\x92m Alexander Hamilton, I\\x92m at your service, sir',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'Alexander',\n",
       "     u'Hamilton',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'at',\n",
       "     u'your',\n",
       "     u'service',\n",
       "     u'si']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'I', u'have', u'been', u'looking', u'for', u'you'],\n",
       "    'original': 'I have been looking for you',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'have', u'been', u'looking', u'for', u'you']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'I', u'm', u'getting', u'nervous'],\n",
       "    'original': 'I\\x92m getting nervous',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'm', u'getting', u'nervous']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'I',\n",
       "     u'heard',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'at',\n",
       "     u'Princeton',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'seeking',\n",
       "     u'an',\n",
       "     u'accelerated',\n",
       "     u'course',\n",
       "     u'of',\n",
       "     u'study',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'sort',\n",
       "     u'of',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'sorts',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'buddy',\n",
       "     u'of',\n",
       "     u'yours',\n",
       "     u'I',\n",
       "     u'may',\n",
       "     u'have',\n",
       "     u'punched',\n",
       "     u'him',\n",
       "     u'It',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'blur',\n",
       "     u'sir',\n",
       "     u'He',\n",
       "     u'handles',\n",
       "     u'the',\n",
       "     u'financials'],\n",
       "    'original': 'I heard your name at Princeton. I was seeking an accelerated course of study when I got sort of out of sorts with a buddy of yours. I may have punched him. It\\x92s a blur, sir. He handles the financials?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'heard',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'at',\n",
       "     u'Princeton',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'seeking',\n",
       "     u'an',\n",
       "     u'accelerated',\n",
       "     u'course',\n",
       "     u'of',\n",
       "     u'study',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'sort',\n",
       "     u'of',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'sorts',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'buddy',\n",
       "     u'of',\n",
       "     u'yours',\n",
       "     u'I',\n",
       "     u'may',\n",
       "     u'have',\n",
       "     u'punched',\n",
       "     u'him',\n",
       "     u'It',\n",
       "     u's',\n",
       "     u'a',\n",
       "     u'blur',\n",
       "     u'sir',\n",
       "     u'He',\n",
       "     u'handles',\n",
       "     u'the',\n",
       "     u'financials']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'You', u'punched', u'the', u'bursar'],\n",
       "    'original': 'You punched the bursar',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You', u'punched', u'the', u'bursar']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'I',\n",
       "     u'wanted',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'did',\n",
       "     u'Graduate',\n",
       "     u'in',\n",
       "     u'two',\n",
       "     u'then',\n",
       "     u'join',\n",
       "     u'the',\n",
       "     u'revolution',\n",
       "     u'He',\n",
       "     u'looked',\n",
       "     u'at',\n",
       "     u'me',\n",
       "     u'like',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'stupid',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'stupid'],\n",
       "    'original': 'I wanted to do what you did. Graduate in two, then join the revolution. He looked at me like I was stupid, I\\x92m not stupid',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wanted',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'did',\n",
       "     u'Graduate',\n",
       "     u'in',\n",
       "     u'two',\n",
       "     u'then',\n",
       "     u'join',\n",
       "     u'the',\n",
       "     u'revolution',\n",
       "     u'He',\n",
       "     u'looked',\n",
       "     u'at',\n",
       "     u'me',\n",
       "     u'like',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'stupid',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'stupid']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'So',\n",
       "     u'how',\n",
       "     u'd',\n",
       "     u'you',\n",
       "     u'do',\n",
       "     u'it',\n",
       "     u'How',\n",
       "     u'd',\n",
       "     u'you',\n",
       "     u'graduate',\n",
       "     u'so',\n",
       "     u'fast'],\n",
       "    'original': 'So how\\x92d you do it? How\\x92d you graduate so fast?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'So',\n",
       "     u'how',\n",
       "     u'd',\n",
       "     u'you',\n",
       "     u'do',\n",
       "     u'it',\n",
       "     u'How',\n",
       "     u'd',\n",
       "     u'you',\n",
       "     u'graduate',\n",
       "     u'so',\n",
       "     u'fast']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'It',\n",
       "     u'was',\n",
       "     u'my',\n",
       "     u'parents',\n",
       "     u'dying',\n",
       "     u'wish',\n",
       "     u'before',\n",
       "     u'they',\n",
       "     u'passed'],\n",
       "    'original': 'It was my parents\\x92 dying wish before they passed',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'was',\n",
       "     u'my',\n",
       "     u'parents',\n",
       "     u'dying',\n",
       "     u'wish',\n",
       "     u'before',\n",
       "     u'they',\n",
       "     u'passed']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'You',\n",
       "     u're',\n",
       "     u'an',\n",
       "     u'orphan',\n",
       "     u'Of',\n",
       "     u'course',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'an',\n",
       "     u'orpha'],\n",
       "    'original': 'You\\x92re an orphan. Of course! I\\x92m an orphan',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u're',\n",
       "     u'an',\n",
       "     u'orphan',\n",
       "     u'Of',\n",
       "     u'course',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'an',\n",
       "     u'orpha']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'God', u'I', u'wish', u'there', u'was', u'a', u'war'],\n",
       "    'original': 'God, I wish there was a war!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'God', u'I', u'wish', u'there', u'was', u'a', u'war']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Then',\n",
       "     u'we',\n",
       "     u'could',\n",
       "     u'prove',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'worth',\n",
       "     u'more'],\n",
       "    'original': 'Then we could prove that we\\x92re worth more',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'we',\n",
       "     u'could',\n",
       "     u'prove',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'worth',\n",
       "     u'more']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Than', u'anyone', u'bargained', u'for'],\n",
       "    'original': 'Than anyone bargained for\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Than', u'anyone', u'bargained', u'for']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Can', u'I', u'buy', u'you', u'a', u'drink'],\n",
       "    'original': 'Can I buy you a drink?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Can', u'I', u'buy', u'you', u'a', u'drink']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'That', u'would', u'be', u'nice'],\n",
       "    'original': 'That would be nice',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That', u'would', u'be', u'nice']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'While',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'talking',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'offer',\n",
       "     u'you',\n",
       "     u'some',\n",
       "     u'free',\n",
       "     u'advice'],\n",
       "    'original': 'While we\\x92re talking, let me offer you some free advice',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'While',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'talking',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'offer',\n",
       "     u'you',\n",
       "     u'some',\n",
       "     u'free',\n",
       "     u'advice']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Talk', u'less'],\n",
       "    'original': 'Talk less',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Talk', u'less']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Smile', u'more'],\n",
       "    'original': 'Smile more',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Smile', u'more']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Ha'],\n",
       "    'original': 'Ha',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ha']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Don',\n",
       "     u't',\n",
       "     u'let',\n",
       "     u'them',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'against',\n",
       "     u'or',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'f'],\n",
       "    'original': 'Don\\x92t let them know what you\\x92re against or what you\\x92re for',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Don',\n",
       "     u't',\n",
       "     u'let',\n",
       "     u'them',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'against',\n",
       "     u'or',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'f']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'You', u'can', u't', u'be', u'serious'],\n",
       "    'original': 'You can\\x92t be serious',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You', u'can', u't', u'be', u'serious']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'You', u'wanna', u'get', u'ahead'],\n",
       "    'original': 'You wanna get ahead?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You', u'wanna', u'get', u'ahead']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Fools',\n",
       "     u'who',\n",
       "     u'run',\n",
       "     u'their',\n",
       "     u'mouths',\n",
       "     u'off',\n",
       "     u'wind',\n",
       "     u'up',\n",
       "     u'dead'],\n",
       "    'original': 'Fools who run their mouths off wind up dead',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Fools',\n",
       "     u'who',\n",
       "     u'run',\n",
       "     u'their',\n",
       "     u'mouths',\n",
       "     u'off',\n",
       "     u'wind',\n",
       "     u'up',\n",
       "     u'dead']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Yo', u'yo', u'yo', u'yo', u'yo'],\n",
       "    'original': 'Yo yo yo yo yo!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Yo', u'yo', u'yo', u'yo', u'yo']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'What', u'time', u'is', u'it'],\n",
       "    'original': 'What time is it?',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'What', u'time', u'is', u'it']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Show', u'time'],\n",
       "    'original': 'Show time!',\n",
       "    'speakers': ['LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'Show', u'time']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Like', u'I', u'said'],\n",
       "    'original': 'Like I said\\x85',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Like', u'I', u'said']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Show', u'time', u'Show', u'time', u'Yo'],\n",
       "    'original': 'Show time! Show time! Yo!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Show', u'time', u'Show', u'time', u'Yo']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'John',\n",
       "     u'Laurens',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'place',\n",
       "     u'to',\n",
       "     u'be'],\n",
       "    'original': 'I\\x92m John Laurens in the place to be!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'John',\n",
       "     u'Laurens',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'place',\n",
       "     u'to',\n",
       "     u'be']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Two',\n",
       "     u'pints',\n",
       "     u'o',\n",
       "     u'Sam',\n",
       "     u'Adams',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'workin',\n",
       "     u'on',\n",
       "     u'three',\n",
       "     u'u'],\n",
       "    'original': 'Two pints o\\x92 Sam Adams, but I\\x92m workin\\x92 on three, uh!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Two',\n",
       "     u'pints',\n",
       "     u'o',\n",
       "     u'Sam',\n",
       "     u'Adams',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'workin',\n",
       "     u'on',\n",
       "     u'three',\n",
       "     u'u']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Those',\n",
       "     u'redcoats',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'want',\n",
       "     u'it',\n",
       "     u'with',\n",
       "     u'me'],\n",
       "    'original': 'Those redcoats don\\x92t want it with me!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Those',\n",
       "     u'redcoats',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'want',\n",
       "     u'it',\n",
       "     u'with',\n",
       "     u'me']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Cuz',\n",
       "     u'I',\n",
       "     u'will',\n",
       "     u'pop',\n",
       "     u'chick',\n",
       "     u'a',\n",
       "     u'pop',\n",
       "     u'these',\n",
       "     u'cops',\n",
       "     u'till',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'free'],\n",
       "    'original': 'Cuz I will pop chick-a pop these cops till I\\x92m free!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Cuz',\n",
       "     u'I',\n",
       "     u'will',\n",
       "     u'pop',\n",
       "     u'chick',\n",
       "     u'a',\n",
       "     u'pop',\n",
       "     u'these',\n",
       "     u'cops',\n",
       "     u'till',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'free']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Oui',\n",
       "     u'oui',\n",
       "     u'mon',\n",
       "     u'ami',\n",
       "     u'je',\n",
       "     u'm',\n",
       "     u'appelle',\n",
       "     u'Lafayette'],\n",
       "    'original': 'Oui oui, mon ami, je m\\x92appelle Lafayette!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Oui',\n",
       "     u'oui',\n",
       "     u'mon',\n",
       "     u'ami',\n",
       "     u'je',\n",
       "     u'm',\n",
       "     u'appelle',\n",
       "     u'Lafayette']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'The',\n",
       "     u'Lancelot',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'revolutionary',\n",
       "     u'set'],\n",
       "    'original': 'The Lancelot of the revolutionary set!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'The',\n",
       "     u'Lancelot',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'revolutionary',\n",
       "     u'set']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'I',\n",
       "     u'came',\n",
       "     u'from',\n",
       "     u'afar',\n",
       "     u'just',\n",
       "     u'to',\n",
       "     u'say',\n",
       "     u'Bonsoir'],\n",
       "    'original': 'I came from afar just to say \\x93Bonsoir!\\x94',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'came',\n",
       "     u'from',\n",
       "     u'afar',\n",
       "     u'just',\n",
       "     u'to',\n",
       "     u'say',\n",
       "     u'Bonsoir']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Tell',\n",
       "     u'the',\n",
       "     u'King',\n",
       "     u'Casse',\n",
       "     u'toi',\n",
       "     u'Who',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'bes'],\n",
       "    'original': 'Tell the King \\x93Casse toi!\\x94 Who\\x92s the best?',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Tell',\n",
       "     u'the',\n",
       "     u'King',\n",
       "     u'Casse',\n",
       "     u'toi',\n",
       "     u'Who',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'bes']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'C', u'est', u'moi'],\n",
       "    'original': 'C\\x92est moi!',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'C', u'est', u'moi']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Brrrah',\n",
       "     u'brraaah',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'Hercules',\n",
       "     u'Mulligan'],\n",
       "    'original': 'Brrrah brraaah! I am Hercules Mulligan',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Brrrah',\n",
       "     u'brraaah',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'Hercules',\n",
       "     u'Mulligan']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Up',\n",
       "     u'in',\n",
       "     u'it',\n",
       "     u'lovin',\n",
       "     u'it',\n",
       "     u'yes',\n",
       "     u'I',\n",
       "     u'heard',\n",
       "     u'ya',\n",
       "     u'mother',\n",
       "     u'said',\n",
       "     u'Come',\n",
       "     u'again'],\n",
       "    'original': 'Up in it, lovin\\x92 it, yes I heard ya mother said \\x93Come again?\\x94',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Up',\n",
       "     u'in',\n",
       "     u'it',\n",
       "     u'lovin',\n",
       "     u'it',\n",
       "     u'yes',\n",
       "     u'I',\n",
       "     u'heard',\n",
       "     u'ya',\n",
       "     u'mother',\n",
       "     u'said',\n",
       "     u'Come',\n",
       "     u'again']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Ayyyyy'],\n",
       "    'original': 'Ayyyyy',\n",
       "    'speakers': ['LAFAYETTE', 'LAURENS'],\n",
       "    'tokenized': [u'Ayyyyy']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Lock',\n",
       "     u'up',\n",
       "     u'ya',\n",
       "     u'daughters',\n",
       "     u'and',\n",
       "     u'horses',\n",
       "     u'of',\n",
       "     u'course'],\n",
       "    'original': 'Lock up ya daughters and horses, of course',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Lock',\n",
       "     u'up',\n",
       "     u'ya',\n",
       "     u'daughters',\n",
       "     u'and',\n",
       "     u'horses',\n",
       "     u'of',\n",
       "     u'course']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'It',\n",
       "     u's',\n",
       "     u'hard',\n",
       "     u'to',\n",
       "     u'have',\n",
       "     u'intercourse',\n",
       "     u'over',\n",
       "     u'four',\n",
       "     u'sets',\n",
       "     u'of',\n",
       "     u'corsets'],\n",
       "    'original': 'It\\x92s hard to have intercourse over four sets of corsets\\x85',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'It',\n",
       "     u's',\n",
       "     u'hard',\n",
       "     u'to',\n",
       "     u'have',\n",
       "     u'intercourse',\n",
       "     u'over',\n",
       "     u'four',\n",
       "     u'sets',\n",
       "     u'of',\n",
       "     u'corsets']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Wow'],\n",
       "    'original': 'Wow',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Wow']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'No',\n",
       "     u'more',\n",
       "     u'sex',\n",
       "     u'pour',\n",
       "     u'me',\n",
       "     u'another',\n",
       "     u'brew',\n",
       "     u'son'],\n",
       "    'original': 'No more sex, pour me another brew, son!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'No',\n",
       "     u'more',\n",
       "     u'sex',\n",
       "     u'pour',\n",
       "     u'me',\n",
       "     u'another',\n",
       "     u'brew',\n",
       "     u'son']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Let', u's', u'raise', u'a', u'couple', u'more'],\n",
       "    'original': 'Let\\x92s raise a couple more\\x85',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Let', u's', u'raise', u'a', u'couple', u'more']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'To', u'the', u'revolution'],\n",
       "    'original': 'To the revolution!',\n",
       "    'speakers': ['LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'To', u'the', u'revolution']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Well',\n",
       "     u'if',\n",
       "     u'it',\n",
       "     u'ain',\n",
       "     u't',\n",
       "     u'the',\n",
       "     u'prodigy',\n",
       "     u'of',\n",
       "     u'Princeton',\n",
       "     u'college'],\n",
       "    'original': 'Well, if it ain\\x92t the prodigy of Princeton college!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'if',\n",
       "     u'it',\n",
       "     u'ain',\n",
       "     u't',\n",
       "     u'the',\n",
       "     u'prodigy',\n",
       "     u'of',\n",
       "     u'Princeton',\n",
       "     u'college']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Aaron', u'Burr'],\n",
       "    'original': 'Aaron Burr!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Aaron', u'Burr']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Give',\n",
       "     u'us',\n",
       "     u'a',\n",
       "     u'verse',\n",
       "     u'drop',\n",
       "     u'some',\n",
       "     u'knowledge'],\n",
       "    'original': 'Give us a verse, drop some knowledge!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Give',\n",
       "     u'us',\n",
       "     u'a',\n",
       "     u'verse',\n",
       "     u'drop',\n",
       "     u'some',\n",
       "     u'knowledge']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Good',\n",
       "     u'luck',\n",
       "     u'with',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'takin',\n",
       "     u'a',\n",
       "     u'stan'],\n",
       "    'original': 'Good luck with that: you\\x92re takin\\x92 a stand',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Good',\n",
       "     u'luck',\n",
       "     u'with',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'takin',\n",
       "     u'a',\n",
       "     u'stan']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'You',\n",
       "     u'spit',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'sit',\n",
       "     u'We',\n",
       "     u'll',\n",
       "     u'see',\n",
       "     u'where',\n",
       "     u'we',\n",
       "     u'la'],\n",
       "    'original': 'You spit. I\\x92m \\x91a sit. We\\x92ll see where we land',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u'spit',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'sit',\n",
       "     u'We',\n",
       "     u'll',\n",
       "     u'see',\n",
       "     u'where',\n",
       "     u'we',\n",
       "     u'la']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Boooo'],\n",
       "    'original': 'Boooo!',\n",
       "    'speakers': ['LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'Boooo']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Burr',\n",
       "     u'the',\n",
       "     u'revolution',\n",
       "     u's',\n",
       "     u'imminent',\n",
       "     u'What',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'stall',\n",
       "     u'for'],\n",
       "    'original': 'Burr, the revolution\\x92s imminent. What do you stall for?',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Burr',\n",
       "     u'the',\n",
       "     u'revolution',\n",
       "     u's',\n",
       "     u'imminent',\n",
       "     u'What',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'stall',\n",
       "     u'for']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'stand',\n",
       "     u'for',\n",
       "     u'nothing',\n",
       "     u'Burr',\n",
       "     u'what',\n",
       "     u'll',\n",
       "     u'you',\n",
       "     u'fall',\n",
       "     u'for'],\n",
       "    'original': 'If you stand for nothing, Burr, what\\x92ll you fall for?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'stand',\n",
       "     u'for',\n",
       "     u'nothing',\n",
       "     u'Burr',\n",
       "     u'what',\n",
       "     u'll',\n",
       "     u'you',\n",
       "     u'fall',\n",
       "     u'for']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Ooh'],\n",
       "    'original': 'Ooh',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'LAURENS'],\n",
       "    'tokenized': [u'Ooh']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Who', u'you'],\n",
       "    'original': 'Who you?',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'LAURENS'],\n",
       "    'tokenized': [u'Who', u'you']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Who', u'you'],\n",
       "    'original': 'Who you?',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'LAURENS'],\n",
       "    'tokenized': [u'Who', u'you']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Who', u'are', u'you'],\n",
       "    'original': 'Who are you?',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'LAURENS'],\n",
       "    'tokenized': [u'Who', u'are', u'you']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Ooh',\n",
       "     u'who',\n",
       "     u'is',\n",
       "     u'this',\n",
       "     u'kid',\n",
       "     u'What',\n",
       "     u's',\n",
       "     u'he',\n",
       "     u'gonna',\n",
       "     u'do'],\n",
       "    'original': 'Ooh, who is this kid? What\\x92s he gonna do?',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'LAURENS'],\n",
       "    'tokenized': [u'Ooh',\n",
       "     u'who',\n",
       "     u'is',\n",
       "     u'this',\n",
       "     u'kid',\n",
       "     u'What',\n",
       "     u's',\n",
       "     u'he',\n",
       "     u'gonna',\n",
       "     u'do']}],\n",
       "  'track': 'Aaron Burr, Sir',\n",
       "  'track#': '2'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country'],\n",
       "    'original': 'Hey yo, I\\x92m just like my country',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry'],\n",
       "    'original': 'I\\x92m young, scrappy and hungry',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot'],\n",
       "    'original': 'And I\\x92m not throwing away my shot!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'scholarship',\n",
       "     u'to',\n",
       "     u'King',\n",
       "     u's',\n",
       "     u'Colle'],\n",
       "    'original': 'I\\x92m \\x91a get a scholarship to King\\x92s College',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'scholarship',\n",
       "     u'to',\n",
       "     u'King',\n",
       "     u's',\n",
       "     u'Colle']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'I',\n",
       "     u'prob',\n",
       "     u'ly',\n",
       "     u'shouldn',\n",
       "     u't',\n",
       "     u'brag',\n",
       "     u'but',\n",
       "     u'dag',\n",
       "     u'I',\n",
       "     u'amaze',\n",
       "     u'and',\n",
       "     u'astonis'],\n",
       "    'original': 'I prob\\x92ly shouldn\\x92t brag, but dag, I amaze and astonish',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'prob',\n",
       "     u'ly',\n",
       "     u'shouldn',\n",
       "     u't',\n",
       "     u'brag',\n",
       "     u'but',\n",
       "     u'dag',\n",
       "     u'I',\n",
       "     u'amaze',\n",
       "     u'and',\n",
       "     u'astonis']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'The',\n",
       "     u'problem',\n",
       "     u'is',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'of',\n",
       "     u'brains',\n",
       "     u'but',\n",
       "     u'no',\n",
       "     u'polish'],\n",
       "    'original': 'The problem is I got a lot of brains but no polish',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'problem',\n",
       "     u'is',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'of',\n",
       "     u'brains',\n",
       "     u'but',\n",
       "     u'no',\n",
       "     u'polish']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'I', u'gotta', u'holler', u'just', u'to', u'be', u'heard'],\n",
       "    'original': 'I gotta holler just to be heard',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'gotta', u'holler', u'just', u'to', u'be', u'heard']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'With', u'every', u'word', u'I', u'drop', u'knowledge'],\n",
       "    'original': 'With every word, I drop knowledge!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'With', u'every', u'word', u'I', u'drop', u'knowledge']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'diamond',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'rough',\n",
       "     u'a',\n",
       "     u'shiny',\n",
       "     u'piece',\n",
       "     u'of',\n",
       "     u'coal'],\n",
       "    'original': 'I\\x92m a diamond in the rough, a shiny piece of coal',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'diamond',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'rough',\n",
       "     u'a',\n",
       "     u'shiny',\n",
       "     u'piece',\n",
       "     u'of',\n",
       "     u'coal']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Tryin',\n",
       "     u'to',\n",
       "     u'reach',\n",
       "     u'my',\n",
       "     u'goal',\n",
       "     u'My',\n",
       "     u'power',\n",
       "     u'of',\n",
       "     u'speech',\n",
       "     u'unimpeachable'],\n",
       "    'original': 'Tryin\\x92 to reach my goal. My power of speech: unimpeachable',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Tryin',\n",
       "     u'to',\n",
       "     u'reach',\n",
       "     u'my',\n",
       "     u'goal',\n",
       "     u'My',\n",
       "     u'power',\n",
       "     u'of',\n",
       "     u'speech',\n",
       "     u'unimpeachable']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Only',\n",
       "     u'nineteen',\n",
       "     u'but',\n",
       "     u'my',\n",
       "     u'mind',\n",
       "     u'is',\n",
       "     u'older'],\n",
       "    'original': 'Only nineteen but my mind is older',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Only',\n",
       "     u'nineteen',\n",
       "     u'but',\n",
       "     u'my',\n",
       "     u'mind',\n",
       "     u'is',\n",
       "     u'older']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'These',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'City',\n",
       "     u'streets',\n",
       "     u'get',\n",
       "     u'colder',\n",
       "     u'I',\n",
       "     u'shoulder'],\n",
       "    'original': 'These New York City streets get colder, I shoulder',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'These',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'City',\n",
       "     u'streets',\n",
       "     u'get',\n",
       "     u'colder',\n",
       "     u'I',\n",
       "     u'shoulder']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Ev', u'ry', u'burden', u'ev', u'ry', u'disadvantag'],\n",
       "    'original': 'Ev\\x92ry burden, ev\\x92ry disadvantage',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ev', u'ry', u'burden', u'ev', u'ry', u'disadvantag']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'learned',\n",
       "     u'to',\n",
       "     u'manage',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'gun',\n",
       "     u'to',\n",
       "     u'brandish'],\n",
       "    'original': 'I have learned to manage, I don\\x92t have a gun to brandish',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'learned',\n",
       "     u'to',\n",
       "     u'manage',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'gun',\n",
       "     u'to',\n",
       "     u'brandish']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'I', u'walk', u'these', u'streets', u'famished'],\n",
       "    'original': 'I walk these streets famished',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'walk', u'these', u'streets', u'famished']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'The',\n",
       "     u'plan',\n",
       "     u'is',\n",
       "     u'to',\n",
       "     u'fan',\n",
       "     u'this',\n",
       "     u'spark',\n",
       "     u'into',\n",
       "     u'a',\n",
       "     u'flame'],\n",
       "    'original': 'The plan is to fan this spark into a flame',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'plan',\n",
       "     u'is',\n",
       "     u'to',\n",
       "     u'fan',\n",
       "     u'this',\n",
       "     u'spark',\n",
       "     u'into',\n",
       "     u'a',\n",
       "     u'flame']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'But',\n",
       "     u'damn',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'getting',\n",
       "     u'dark',\n",
       "     u'so',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'spell',\n",
       "     u'out',\n",
       "     u'the',\n",
       "     u'name'],\n",
       "    'original': 'But damn, it\\x92s getting dark, so let me spell out the name',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'damn',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'getting',\n",
       "     u'dark',\n",
       "     u'so',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'spell',\n",
       "     u'out',\n",
       "     u'the',\n",
       "     u'name']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'I', u'am', u'the'],\n",
       "    'original': 'I am the\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'the']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'A', u'L', u'E', u'X', u'A', u'N', u'D'],\n",
       "    'original': 'A-L-E-X-A-N-D',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'MULLIGAN', 'LAURENS'],\n",
       "    'tokenized': [u'A', u'L', u'E', u'X', u'A', u'N', u'D']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'E', u'R', u'we', u'are', u'meant', u'to', u'b'],\n",
       "    'original': 'E-R\\x97we are\\x97meant to be\\x85',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'MULLIGAN', 'LAURENS'],\n",
       "    'tokenized': [u'E', u'R', u'we', u'are', u'meant', u'to', u'b']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'A', u'colony', u'that', u'runs', u'independently'],\n",
       "    'original': 'A colony that runs independently',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A', u'colony', u'that', u'runs', u'independently']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Meanwhile',\n",
       "     u'Britain',\n",
       "     u'keeps',\n",
       "     u'shittin',\n",
       "     u'on',\n",
       "     u'us',\n",
       "     u'endlessly'],\n",
       "    'original': 'Meanwhile, Britain keeps shittin\\x92 on us endlessly',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Meanwhile',\n",
       "     u'Britain',\n",
       "     u'keeps',\n",
       "     u'shittin',\n",
       "     u'on',\n",
       "     u'us',\n",
       "     u'endlessly']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Essentially', u'they', u'tax', u'us', u'relentlessly'],\n",
       "    'original': 'Essentially, they tax us relentlessly',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Essentially', u'they', u'tax', u'us', u'relentlessly']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Then',\n",
       "     u'King',\n",
       "     u'George',\n",
       "     u'turns',\n",
       "     u'around',\n",
       "     u'runs',\n",
       "     u'a',\n",
       "     u'spending',\n",
       "     u'spree'],\n",
       "    'original': 'Then King George turns around, runs a spending spree',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'King',\n",
       "     u'George',\n",
       "     u'turns',\n",
       "     u'around',\n",
       "     u'runs',\n",
       "     u'a',\n",
       "     u'spending',\n",
       "     u'spree']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'He',\n",
       "     u'ain',\n",
       "     u't',\n",
       "     u'ever',\n",
       "     u'gonna',\n",
       "     u'set',\n",
       "     u'his',\n",
       "     u'descendants',\n",
       "     u'free'],\n",
       "    'original': 'He ain\\x92t ever gonna set his descendants free',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'He',\n",
       "     u'ain',\n",
       "     u't',\n",
       "     u'ever',\n",
       "     u'gonna',\n",
       "     u'set',\n",
       "     u'his',\n",
       "     u'descendants',\n",
       "     u'free']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'So',\n",
       "     u'there',\n",
       "     u'will',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'revolution',\n",
       "     u'in',\n",
       "     u'this',\n",
       "     u'century'],\n",
       "    'original': 'So there will be a revolution in this century',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'So',\n",
       "     u'there',\n",
       "     u'will',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'revolution',\n",
       "     u'in',\n",
       "     u'this',\n",
       "     u'century']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Enter', u'me'],\n",
       "    'original': 'Enter me!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Enter', u'me']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'He', u'says', u'in', u'parentheses'],\n",
       "    'original': '(He says in parentheses)',\n",
       "    'speakers': ['LAFAYETTE', 'MULLIGAN', 'LAURENS'],\n",
       "    'tokenized': [u'He', u'says', u'in', u'parentheses']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Don',\n",
       "     u't',\n",
       "     u'be',\n",
       "     u'shocked',\n",
       "     u'when',\n",
       "     u'your',\n",
       "     u'hist',\n",
       "     u'ry',\n",
       "     u'book',\n",
       "     u'mentions',\n",
       "     u'm'],\n",
       "    'original': 'Don\\x92t be shocked when your hist\\x92ry book mentions me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Don',\n",
       "     u't',\n",
       "     u'be',\n",
       "     u'shocked',\n",
       "     u'when',\n",
       "     u'your',\n",
       "     u'hist',\n",
       "     u'ry',\n",
       "     u'book',\n",
       "     u'mentions',\n",
       "     u'm']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'I',\n",
       "     u'will',\n",
       "     u'lay',\n",
       "     u'down',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'if',\n",
       "     u'it',\n",
       "     u'sets',\n",
       "     u'us',\n",
       "     u'free'],\n",
       "    'original': 'I will lay down my life if it sets us free',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'will',\n",
       "     u'lay',\n",
       "     u'down',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'if',\n",
       "     u'it',\n",
       "     u'sets',\n",
       "     u'us',\n",
       "     u'free']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Eventually', u'you', u'll', u'see', u'my', u'ascendancy'],\n",
       "    'original': 'Eventually, you\\x92ll see my ascendancy',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Eventually', u'you', u'll', u'see', u'my', u'ascendancy']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'And', u'I', u'am', u'not', u'throwing', u'away'],\n",
       "    'original': 'And I am not throwing away',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'I', u'am', u'not', u'throwing', u'away']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'My', u'shot'],\n",
       "    'original': 'My shot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'shot']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away'],\n",
       "    'original': 'I am not throwing away',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'My', u'shot'],\n",
       "    'original': 'My shot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'shot']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country'],\n",
       "    'original': 'Hey yo, I\\x92m just like my country',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry'],\n",
       "    'original': 'I\\x92m young, scrappy and hungry',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot'],\n",
       "    'original': 'And I\\x92m not throwing away my shot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'My', u'shot'],\n",
       "    'original': 'My shot!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'My', u'shot']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'My', u'shot'],\n",
       "    'original': 'My shot!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'My', u'shot']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot'],\n",
       "    'original': 'And I\\x92m not throwing away my shot.',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country'],\n",
       "    'original': 'Hey yo, I\\x92m just like my country',\n",
       "    'speakers': ['HAMILTON', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry'],\n",
       "    'original': 'I\\x92m young, scrappy and hungry',\n",
       "    'speakers': ['HAMILTON', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot'],\n",
       "    'original': 'And I\\x92m not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'It', u's', u'time', u'to', u'take', u'a', u'shot'],\n",
       "    'original': 'It\\x92s time to take a shot!',\n",
       "    'speakers': ['HAMILTON', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'It', u's', u'time', u'to', u'take', u'a', u'shot']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'I',\n",
       "     u'dream',\n",
       "     u'of',\n",
       "     u'life',\n",
       "     u'without',\n",
       "     u'a',\n",
       "     u'monarchy'],\n",
       "    'original': 'I dream of life without a monarchy',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'dream',\n",
       "     u'of',\n",
       "     u'life',\n",
       "     u'without',\n",
       "     u'a',\n",
       "     u'monarchy']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'The',\n",
       "     u'unrest',\n",
       "     u'in',\n",
       "     u'France',\n",
       "     u'will',\n",
       "     u'lead',\n",
       "     u'to',\n",
       "     u'onarchy'],\n",
       "    'original': 'The unrest in France will lead to \\x91onarchy?',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'The',\n",
       "     u'unrest',\n",
       "     u'in',\n",
       "     u'France',\n",
       "     u'will',\n",
       "     u'lead',\n",
       "     u'to',\n",
       "     u'onarchy']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Onarchy',\n",
       "     u'How',\n",
       "     u'you',\n",
       "     u'say',\n",
       "     u'how',\n",
       "     u'you',\n",
       "     u'say',\n",
       "     u'anarchy'],\n",
       "    'original': '\\x91Onarchy? How you say, how you say, \\x91anarchy?\\x92',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Onarchy',\n",
       "     u'How',\n",
       "     u'you',\n",
       "     u'say',\n",
       "     u'how',\n",
       "     u'you',\n",
       "     u'say',\n",
       "     u'anarchy']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'When',\n",
       "     u'I',\n",
       "     u'fight',\n",
       "     u'I',\n",
       "     u'make',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side',\n",
       "     u'panicky'],\n",
       "    'original': 'When I fight, I make the other side panicky',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'When',\n",
       "     u'I',\n",
       "     u'fight',\n",
       "     u'I',\n",
       "     u'make',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side',\n",
       "     u'panicky']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'With', u'my'],\n",
       "    'original': 'With my\\x97',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'With', u'my']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Shot'],\n",
       "    'original': 'Shot!',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'Shot']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Yo', u'I', u'm', u'a', u'tailor', u's', u'apprentic'],\n",
       "    'original': 'Yo, I\\x92m a tailor\\x92s apprentice',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Yo', u'I', u'm', u'a', u'tailor', u's', u'apprentic']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'y',\n",
       "     u'all',\n",
       "     u'knuckleheads',\n",
       "     u'in',\n",
       "     u'loco',\n",
       "     u'parentis'],\n",
       "    'original': 'And I got y\\x92all knuckleheads in loco parentis',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'y',\n",
       "     u'all',\n",
       "     u'knuckleheads',\n",
       "     u'in',\n",
       "     u'loco',\n",
       "     u'parentis']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'joining',\n",
       "     u'the',\n",
       "     u'rebellion',\n",
       "     u'cuz',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'my',\n",
       "     u'chanc'],\n",
       "    'original': 'I\\x92m joining the rebellion cuz I know it\\x92s my chance',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'joining',\n",
       "     u'the',\n",
       "     u'rebellion',\n",
       "     u'cuz',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'my',\n",
       "     u'chanc']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'To',\n",
       "     u'socially',\n",
       "     u'advance',\n",
       "     u'instead',\n",
       "     u'of',\n",
       "     u'sewin',\n",
       "     u'some',\n",
       "     u'pants'],\n",
       "    'original': 'To socially advance, instead of sewin\\x92 some pants!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'To',\n",
       "     u'socially',\n",
       "     u'advance',\n",
       "     u'instead',\n",
       "     u'of',\n",
       "     u'sewin',\n",
       "     u'some',\n",
       "     u'pants']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'I', u'm', u'gonna', u'take', u'a'],\n",
       "    'original': 'I\\x92m gonna take a\\x97',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'I', u'm', u'gonna', u'take', u'a']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Shot'],\n",
       "    'original': 'Shot!',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'Shot']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'But', u'we', u'll', u'never', u'be', u'truly', u'free'],\n",
       "    'original': 'But we\\x92ll never be truly free',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'But', u'we', u'll', u'never', u'be', u'truly', u'free']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Until',\n",
       "     u'those',\n",
       "     u'in',\n",
       "     u'bondage',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'rights',\n",
       "     u'as',\n",
       "     u'you',\n",
       "     u'and',\n",
       "     u'me'],\n",
       "    'original': 'Until those in bondage have the same rights as you and me',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Until',\n",
       "     u'those',\n",
       "     u'in',\n",
       "     u'bondage',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'rights',\n",
       "     u'as',\n",
       "     u'you',\n",
       "     u'and',\n",
       "     u'me']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'You',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'Do',\n",
       "     u'or',\n",
       "     u'die',\n",
       "     u'Wait',\n",
       "     u'till',\n",
       "     u'I',\n",
       "     u'sally',\n",
       "     u'in'],\n",
       "    'original': 'You and I. Do or die. Wait till I sally in',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'You',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'Do',\n",
       "     u'or',\n",
       "     u'die',\n",
       "     u'Wait',\n",
       "     u'till',\n",
       "     u'I',\n",
       "     u'sally',\n",
       "     u'in']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'On',\n",
       "     u'a',\n",
       "     u'stallion',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'black',\n",
       "     u'battalion'],\n",
       "    'original': 'On a stallion with the first black battalion',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'On',\n",
       "     u'a',\n",
       "     u'stallion',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'black',\n",
       "     u'battalion']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Have', u'another'],\n",
       "    'original': 'Have another\\x97',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Have', u'another']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Shot'],\n",
       "    'original': 'Shot!',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'Shot']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'Geniuses', u'lower', u'your', u'voices'],\n",
       "    'original': 'Geniuses, lower your voices',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Geniuses', u'lower', u'your', u'voices']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'You',\n",
       "     u'keep',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'trouble',\n",
       "     u'and',\n",
       "     u'you',\n",
       "     u'double',\n",
       "     u'your',\n",
       "     u'choices'],\n",
       "    'original': 'You keep out of trouble and you double your choices',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u'keep',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'trouble',\n",
       "     u'and',\n",
       "     u'you',\n",
       "     u'double',\n",
       "     u'your',\n",
       "     u'choices']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'with',\n",
       "     u'you',\n",
       "     u'but',\n",
       "     u'the',\n",
       "     u'situation',\n",
       "     u'is',\n",
       "     u'fraught'],\n",
       "    'original': 'I\\x92m with you, but the situation is fraught',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'with',\n",
       "     u'you',\n",
       "     u'but',\n",
       "     u'the',\n",
       "     u'situation',\n",
       "     u'is',\n",
       "     u'fraught']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'You',\n",
       "     u've',\n",
       "     u'got',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'carefully',\n",
       "     u'taught'],\n",
       "    'original': 'You\\x92ve got to be carefully taught:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u've',\n",
       "     u'got',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'carefully',\n",
       "     u'taught']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'talk',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'get',\n",
       "     u'shot'],\n",
       "    'original': 'If you talk, you\\x92re gonna get shot!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'talk',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'get',\n",
       "     u'shot']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Burr', u'check', u'what', u'we', u'got'],\n",
       "    'original': 'Burr, check what we got',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr', u'check', u'what', u'we', u'got']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Mister',\n",
       "     u'Lafayette',\n",
       "     u'hard',\n",
       "     u'rock',\n",
       "     u'like',\n",
       "     u'Lancelot'],\n",
       "    'original': 'Mister Lafayette, hard rock like Lancelot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Mister',\n",
       "     u'Lafayette',\n",
       "     u'hard',\n",
       "     u'rock',\n",
       "     u'like',\n",
       "     u'Lancelot']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'I', u'think', u'your', u'pants', u'look', u'hot'],\n",
       "    'original': 'I think your pants look hot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'think', u'your', u'pants', u'look', u'hot']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Laurens', u'I', u'like', u'you', u'a', u'lot'],\n",
       "    'original': 'Laurens, I like you a lot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Laurens', u'I', u'like', u'you', u'a', u'lot']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Let',\n",
       "     u's',\n",
       "     u'hatch',\n",
       "     u'a',\n",
       "     u'plot',\n",
       "     u'blacker',\n",
       "     u'than',\n",
       "     u'the',\n",
       "     u'kettle',\n",
       "     u'callin',\n",
       "     u'the',\n",
       "     u'pot'],\n",
       "    'original': 'Let\\x92s hatch a plot blacker than the kettle callin\\x92 the pot...',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Let',\n",
       "     u's',\n",
       "     u'hatch',\n",
       "     u'a',\n",
       "     u'plot',\n",
       "     u'blacker',\n",
       "     u'than',\n",
       "     u'the',\n",
       "     u'kettle',\n",
       "     u'callin',\n",
       "     u'the',\n",
       "     u'pot']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'What',\n",
       "     u'are',\n",
       "     u'the',\n",
       "     u'odds',\n",
       "     u'the',\n",
       "     u'gods',\n",
       "     u'would',\n",
       "     u'put',\n",
       "     u'us',\n",
       "     u'all',\n",
       "     u'in',\n",
       "     u'one',\n",
       "     u'spot'],\n",
       "    'original': 'What are the odds the gods would put us all in one spot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What',\n",
       "     u'are',\n",
       "     u'the',\n",
       "     u'odds',\n",
       "     u'the',\n",
       "     u'gods',\n",
       "     u'would',\n",
       "     u'put',\n",
       "     u'us',\n",
       "     u'all',\n",
       "     u'in',\n",
       "     u'one',\n",
       "     u'spot']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'Poppin',\n",
       "     u'a',\n",
       "     u'squat',\n",
       "     u'on',\n",
       "     u'conventional',\n",
       "     u'wisdom',\n",
       "     u'like',\n",
       "     u'it',\n",
       "     u'or',\n",
       "     u'not'],\n",
       "    'original': 'Poppin\\x92 a squat on conventional wisdom, like it or not',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Poppin',\n",
       "     u'a',\n",
       "     u'squat',\n",
       "     u'on',\n",
       "     u'conventional',\n",
       "     u'wisdom',\n",
       "     u'like',\n",
       "     u'it',\n",
       "     u'or',\n",
       "     u'not']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'A',\n",
       "     u'bunch',\n",
       "     u'of',\n",
       "     u'revolutionary',\n",
       "     u'manumission',\n",
       "     u'abolitionists'],\n",
       "    'original': 'A bunch of revolutionary manumission abolitionists?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'bunch',\n",
       "     u'of',\n",
       "     u'revolutionary',\n",
       "     u'manumission',\n",
       "     u'abolitionists']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Give',\n",
       "     u'me',\n",
       "     u'a',\n",
       "     u'position',\n",
       "     u'show',\n",
       "     u'me',\n",
       "     u'where',\n",
       "     u'the',\n",
       "     u'ammunition',\n",
       "     u'is'],\n",
       "    'original': 'Give me a position, show me where the ammunition is!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Give',\n",
       "     u'me',\n",
       "     u'a',\n",
       "     u'position',\n",
       "     u'show',\n",
       "     u'me',\n",
       "     u'where',\n",
       "     u'the',\n",
       "     u'ammunition',\n",
       "     u'is']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'Oh', u'am', u'I', u'talkin', u'too', u'loud'],\n",
       "    'original': 'Oh, am I talkin\\x92 too loud?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Oh', u'am', u'I', u'talkin', u'too', u'loud']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'Sometimes',\n",
       "     u'I',\n",
       "     u'get',\n",
       "     u'over',\n",
       "     u'excited',\n",
       "     u'shoot',\n",
       "     u'off',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'mouth'],\n",
       "    'original': 'Sometimes I get over excited, shoot off at the mouth',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sometimes',\n",
       "     u'I',\n",
       "     u'get',\n",
       "     u'over',\n",
       "     u'excited',\n",
       "     u'shoot',\n",
       "     u'off',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'mouth']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'I',\n",
       "     u'never',\n",
       "     u'had',\n",
       "     u'a',\n",
       "     u'group',\n",
       "     u'of',\n",
       "     u'friends',\n",
       "     u'before'],\n",
       "    'original': 'I never had a group of friends before',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'never',\n",
       "     u'had',\n",
       "     u'a',\n",
       "     u'group',\n",
       "     u'of',\n",
       "     u'friends',\n",
       "     u'before']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'I',\n",
       "     u'promise',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'll',\n",
       "     u'make',\n",
       "     u'y',\n",
       "     u'all',\n",
       "     u'prou'],\n",
       "    'original': 'I promise that I\\x92ll make y\\x92all proud',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'promise',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'll',\n",
       "     u'make',\n",
       "     u'y',\n",
       "     u'all',\n",
       "     u'prou']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'Let',\n",
       "     u's',\n",
       "     u'get',\n",
       "     u'this',\n",
       "     u'guy',\n",
       "     u'in',\n",
       "     u'front',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'crowd'],\n",
       "    'original': 'Let\\x92s get this guy in front of a crowd',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Let',\n",
       "     u's',\n",
       "     u'get',\n",
       "     u'this',\n",
       "     u'guy',\n",
       "     u'in',\n",
       "     u'front',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'crowd']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country'],\n",
       "    'original': 'Hey yo, I\\x92m just like my country',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry'],\n",
       "    'original': 'I\\x92m young, scrappy and hungry',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot'],\n",
       "    'original': 'And I\\x92m not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country'],\n",
       "    'original': 'Hey yo, I\\x92m just like my country',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry'],\n",
       "    'original': 'I\\x92m young, scrappy and hungry',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot'],\n",
       "    'original': 'And I\\x92m not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'Ev', u'rybody', u'sing'],\n",
       "    'original': 'Ev\\x92rybody sing:',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Ev', u'rybody', u'sing']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'Whoa', u'whoa', u'whoa'],\n",
       "    'original': 'Whoa, whoa, whoa',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Whoa', u'whoa', u'whoa']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Wooh'],\n",
       "    'original': 'Wooh!!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Wooh']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'Ay', u'let', u'em', u'hear', u'ya'],\n",
       "    'original': 'Ay, let \\x91em hear ya!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Ay', u'let', u'em', u'hear', u'ya']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'Let', u's', u'go'],\n",
       "    'original': 'Let\\x92s go!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Let', u's', u'go']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'I', u'said', u'shout', u'it', u'to', u'the', u'rooftops'],\n",
       "    'original': 'I said shout it to the rooftops!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'I', u'said', u'shout', u'it', u'to', u'the', u'rooftops']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'Said', u'to', u'the', u'rooftops'],\n",
       "    'original': 'Said, to the rooftops!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Said', u'to', u'the', u'rooftops']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'Come', u'on'],\n",
       "    'original': 'Come on!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Come', u'on']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'Come', u'on', u'let', u's', u'go'],\n",
       "    'original': 'Come on, let\\x92s go!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Come', u'on', u'let', u's', u'go']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'Whoa', u'Whoa', u'Whoa'],\n",
       "    'original': 'Whoa! Whoa! Whoa!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'Whoa', u'Whoa', u'Whoa']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'Yea'],\n",
       "    'original': 'Yea!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'Yea']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'Whoa', u'Whoa', u'Whoa'],\n",
       "    'original': 'Whoa! Whoa! Whoa!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa', u'Whoa', u'Whoa']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'Yea'],\n",
       "    'original': 'Yea!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Yea']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'When',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'living',\n",
       "     u'on',\n",
       "     u'your',\n",
       "     u'knees',\n",
       "     u'you',\n",
       "     u'rise',\n",
       "     u'up'],\n",
       "    'original': 'When you\\x92re living on your knees, you rise up',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'When',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'living',\n",
       "     u'on',\n",
       "     u'your',\n",
       "     u'knees',\n",
       "     u'you',\n",
       "     u'rise',\n",
       "     u'up']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'Tell',\n",
       "     u'your',\n",
       "     u'brother',\n",
       "     u'that',\n",
       "     u'he',\n",
       "     u's',\n",
       "     u'gotta',\n",
       "     u'rise',\n",
       "     u'up'],\n",
       "    'original': 'Tell your brother that he\\x92s gotta rise up',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Tell',\n",
       "     u'your',\n",
       "     u'brother',\n",
       "     u'that',\n",
       "     u'he',\n",
       "     u's',\n",
       "     u'gotta',\n",
       "     u'rise',\n",
       "     u'up']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'Tell',\n",
       "     u'your',\n",
       "     u'sister',\n",
       "     u'that',\n",
       "     u\"she's\",\n",
       "     u'gotta',\n",
       "     u'rise',\n",
       "     u'up'],\n",
       "    'original': \"Tell your sister that she's gotta rise up\",\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Tell',\n",
       "     u'your',\n",
       "     u'sister',\n",
       "     u'that',\n",
       "     u\"she's\",\n",
       "     u'gotta',\n",
       "     u'rise',\n",
       "     u'up']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'When',\n",
       "     u'are',\n",
       "     u'these',\n",
       "     u'colonies',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up'],\n",
       "    'original': 'When are these colonies gonna rise up?',\n",
       "    'speakers': ['LAURENS', 'ENSEMBLE'],\n",
       "    'tokenized': [u'When',\n",
       "     u'are',\n",
       "     u'these',\n",
       "     u'colonies',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'When',\n",
       "     u'are',\n",
       "     u'these',\n",
       "     u'colonies',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up'],\n",
       "    'original': 'When are these colonies gonna rise up?',\n",
       "    'speakers': ['LAURENS', 'ENSEMBLE'],\n",
       "    'tokenized': [u'When',\n",
       "     u'are',\n",
       "     u'these',\n",
       "     u'colonies',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'When',\n",
       "     u'are',\n",
       "     u'these',\n",
       "     u'colonies',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up'],\n",
       "    'original': 'When are these colonies gonna rise up?',\n",
       "    'speakers': ['LAURENS', 'ENSEMBLE'],\n",
       "    'tokenized': [u'When',\n",
       "     u'are',\n",
       "     u'these',\n",
       "     u'colonies',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'When',\n",
       "     u'are',\n",
       "     u'these',\n",
       "     u'colonies',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up'],\n",
       "    'original': 'When are these colonies gonna rise up?',\n",
       "    'speakers': ['LAURENS', 'ENSEMBLE'],\n",
       "    'tokenized': [u'When',\n",
       "     u'are',\n",
       "     u'these',\n",
       "     u'colonies',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['LAURENS', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'Whoa', u'Whoa'],\n",
       "    'original': 'Whoa! Whoa!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa', u'Whoa']},\n",
       "   {'line#': 126,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 127,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 128,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 129,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 130,\n",
       "    'normalized': [u'I',\n",
       "     u'imagine',\n",
       "     u'death',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'it',\n",
       "     u'feels',\n",
       "     u'more',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'memory'],\n",
       "    'original': 'I imagine death so much it feels more like a memory',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'imagine',\n",
       "     u'death',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'it',\n",
       "     u'feels',\n",
       "     u'more',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'memory']},\n",
       "   {'line#': 131,\n",
       "    'normalized': [u'When', u's', u'it', u'gonna', u'get', u'me'],\n",
       "    'original': 'When\\x92s it gonna get me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'When', u's', u'it', u'gonna', u'get', u'me']},\n",
       "   {'line#': 132,\n",
       "    'normalized': [u'In',\n",
       "     u'my',\n",
       "     u'sleep',\n",
       "     u'Seven',\n",
       "     u'feet',\n",
       "     u'ahead',\n",
       "     u'of',\n",
       "     u'me'],\n",
       "    'original': 'In my sleep? Seven feet ahead of me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'In',\n",
       "     u'my',\n",
       "     u'sleep',\n",
       "     u'Seven',\n",
       "     u'feet',\n",
       "     u'ahead',\n",
       "     u'of',\n",
       "     u'me']},\n",
       "   {'line#': 133,\n",
       "    'normalized': [u'If',\n",
       "     u'I',\n",
       "     u'see',\n",
       "     u'it',\n",
       "     u'comin',\n",
       "     u'do',\n",
       "     u'I',\n",
       "     u'run',\n",
       "     u'or',\n",
       "     u'do',\n",
       "     u'I',\n",
       "     u'let',\n",
       "     u'it',\n",
       "     u'be'],\n",
       "    'original': 'If I see it comin\\x92, do I run or do I let it be?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'I',\n",
       "     u'see',\n",
       "     u'it',\n",
       "     u'comin',\n",
       "     u'do',\n",
       "     u'I',\n",
       "     u'run',\n",
       "     u'or',\n",
       "     u'do',\n",
       "     u'I',\n",
       "     u'let',\n",
       "     u'it',\n",
       "     u'be']},\n",
       "   {'line#': 134,\n",
       "    'normalized': [u'Is',\n",
       "     u'it',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'beat',\n",
       "     u'without',\n",
       "     u'a',\n",
       "     u'melody'],\n",
       "    'original': 'Is it like a beat without a melody?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is',\n",
       "     u'it',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'beat',\n",
       "     u'without',\n",
       "     u'a',\n",
       "     u'melody']},\n",
       "   {'line#': 135,\n",
       "    'normalized': [u'See',\n",
       "     u'I',\n",
       "     u'never',\n",
       "     u'thought',\n",
       "     u'I',\n",
       "     u'd',\n",
       "     u'live',\n",
       "     u'past',\n",
       "     u'twenty'],\n",
       "    'original': 'See, I never thought I\\x92d live past twenty',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'See',\n",
       "     u'I',\n",
       "     u'never',\n",
       "     u'thought',\n",
       "     u'I',\n",
       "     u'd',\n",
       "     u'live',\n",
       "     u'past',\n",
       "     u'twenty']},\n",
       "   {'line#': 136,\n",
       "    'normalized': [u'Where',\n",
       "     u'I',\n",
       "     u'come',\n",
       "     u'from',\n",
       "     u'some',\n",
       "     u'get',\n",
       "     u'half',\n",
       "     u'as',\n",
       "     u'many'],\n",
       "    'original': 'Where I come from some get half as many',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Where',\n",
       "     u'I',\n",
       "     u'come',\n",
       "     u'from',\n",
       "     u'some',\n",
       "     u'get',\n",
       "     u'half',\n",
       "     u'as',\n",
       "     u'many']},\n",
       "   {'line#': 137,\n",
       "    'normalized': [u'Ask',\n",
       "     u'anybody',\n",
       "     u'why',\n",
       "     u'we',\n",
       "     u'livin',\n",
       "     u'fast',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'laugh',\n",
       "     u'reach',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'flask'],\n",
       "    'original': 'Ask anybody why we livin\\x92 fast and we laugh, reach for a flask',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ask',\n",
       "     u'anybody',\n",
       "     u'why',\n",
       "     u'we',\n",
       "     u'livin',\n",
       "     u'fast',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'laugh',\n",
       "     u'reach',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'flask']},\n",
       "   {'line#': 138,\n",
       "    'normalized': [u'We',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'make',\n",
       "     u'this',\n",
       "     u'moment',\n",
       "     u'last',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'plenty'],\n",
       "    'original': 'We have to make this moment last, that\\x92s plenty',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'make',\n",
       "     u'this',\n",
       "     u'moment',\n",
       "     u'last',\n",
       "     u'that',\n",
       "     u's',\n",
       "     u'plenty']},\n",
       "   {'line#': 139,\n",
       "    'normalized': [u'Scratch', u'that'],\n",
       "    'original': 'Scratch that',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Scratch', u'that']},\n",
       "   {'line#': 140,\n",
       "    'normalized': [u'This',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'moment',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'movement'],\n",
       "    'original': 'This is not a moment, it\\x92s the movement',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'moment',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'movement']},\n",
       "   {'line#': 141,\n",
       "    'normalized': [u'Where',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'hungriest',\n",
       "     u'brothers',\n",
       "     u'with'],\n",
       "    'original': 'Where all the hungriest brothers with',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Where',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'hungriest',\n",
       "     u'brothers',\n",
       "     u'with']},\n",
       "   {'line#': 142,\n",
       "    'normalized': [u'Something', u'to', u'prove', u'went'],\n",
       "    'original': 'Something to prove went?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Something', u'to', u'prove', u'went']},\n",
       "   {'line#': 143,\n",
       "    'normalized': [u'Foes',\n",
       "     u'oppose',\n",
       "     u'us',\n",
       "     u'we',\n",
       "     u'take',\n",
       "     u'an',\n",
       "     u'honest',\n",
       "     u'stand'],\n",
       "    'original': 'Foes oppose us, we take an honest stand',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Foes',\n",
       "     u'oppose',\n",
       "     u'us',\n",
       "     u'we',\n",
       "     u'take',\n",
       "     u'an',\n",
       "     u'honest',\n",
       "     u'stand']},\n",
       "   {'line#': 144,\n",
       "    'normalized': [u'We',\n",
       "     u'roll',\n",
       "     u'like',\n",
       "     u'Moses',\n",
       "     u'claimin',\n",
       "     u'our',\n",
       "     u'promised',\n",
       "     u'land'],\n",
       "    'original': 'We roll like Moses, claimin\\x92 our promised land',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'roll',\n",
       "     u'like',\n",
       "     u'Moses',\n",
       "     u'claimin',\n",
       "     u'our',\n",
       "     u'promised',\n",
       "     u'land']},\n",
       "   {'line#': 145,\n",
       "    'normalized': [u'And', u'If', u'we', u'win', u'our', u'independence'],\n",
       "    'original': 'And? If we win our independence?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'If', u'we', u'win', u'our', u'independence']},\n",
       "   {'line#': 146,\n",
       "    'normalized': [u'Is',\n",
       "     u'that',\n",
       "     u'a',\n",
       "     u'guarantee',\n",
       "     u'of',\n",
       "     u'freedom',\n",
       "     u'for',\n",
       "     u'our',\n",
       "     u'descendants'],\n",
       "    'original': 'Is that a guarantee of freedom for our descendants?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is',\n",
       "     u'that',\n",
       "     u'a',\n",
       "     u'guarantee',\n",
       "     u'of',\n",
       "     u'freedom',\n",
       "     u'for',\n",
       "     u'our',\n",
       "     u'descendants']},\n",
       "   {'line#': 147,\n",
       "    'normalized': [u'Or',\n",
       "     u'will',\n",
       "     u'the',\n",
       "     u'blood',\n",
       "     u'we',\n",
       "     u'shed',\n",
       "     u'begin',\n",
       "     u'an',\n",
       "     u'endless'],\n",
       "    'original': 'Or will the blood we shed begin an endless',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Or',\n",
       "     u'will',\n",
       "     u'the',\n",
       "     u'blood',\n",
       "     u'we',\n",
       "     u'shed',\n",
       "     u'begin',\n",
       "     u'an',\n",
       "     u'endless']},\n",
       "   {'line#': 148,\n",
       "    'normalized': [u'Cycle',\n",
       "     u'of',\n",
       "     u'vengeance',\n",
       "     u'and',\n",
       "     u'death',\n",
       "     u'with',\n",
       "     u'no',\n",
       "     u'defendants'],\n",
       "    'original': 'Cycle of vengeance and death with no defendants?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Cycle',\n",
       "     u'of',\n",
       "     u'vengeance',\n",
       "     u'and',\n",
       "     u'death',\n",
       "     u'with',\n",
       "     u'no',\n",
       "     u'defendants']},\n",
       "   {'line#': 149,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'the',\n",
       "     u'action',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'street',\n",
       "     u'is',\n",
       "     u'excitin'],\n",
       "    'original': 'I know the action in the street is excitin\\x92',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'the',\n",
       "     u'action',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'street',\n",
       "     u'is',\n",
       "     u'excitin']},\n",
       "   {'line#': 150,\n",
       "    'normalized': [u'But',\n",
       "     u'Jesus',\n",
       "     u'between',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'bleedin',\n",
       "     u'n',\n",
       "     u'fighti'],\n",
       "    'original': 'But Jesus, between all the bleedin\\x92 \\x91n fightin\\x92',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'Jesus',\n",
       "     u'between',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'bleedin',\n",
       "     u'n',\n",
       "     u'fighti']},\n",
       "   {'line#': 151,\n",
       "    'normalized': [u'I', u've', u'been', u'readin', u'n', u'writ'],\n",
       "    'original': 'I\\x92ve been readin\\x92 \\x91n writin\\x92',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u've', u'been', u'readin', u'n', u'writ']},\n",
       "   {'line#': 152,\n",
       "    'normalized': [u'We',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'handle',\n",
       "     u'our',\n",
       "     u'financial',\n",
       "     u'situation'],\n",
       "    'original': 'We need to handle our financial situation',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'handle',\n",
       "     u'our',\n",
       "     u'financial',\n",
       "     u'situation']},\n",
       "   {'line#': 153,\n",
       "    'normalized': [u'Are',\n",
       "     u'we',\n",
       "     u'a',\n",
       "     u'nation',\n",
       "     u'of',\n",
       "     u'states',\n",
       "     u'What',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'state',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'nation'],\n",
       "    'original': 'Are we a nation of states? What\\x92s the state of our nation?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Are',\n",
       "     u'we',\n",
       "     u'a',\n",
       "     u'nation',\n",
       "     u'of',\n",
       "     u'states',\n",
       "     u'What',\n",
       "     u's',\n",
       "     u'the',\n",
       "     u'state',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'nation']},\n",
       "   {'line#': 154,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'past',\n",
       "     u'patiently',\n",
       "     u'waitin',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'passionate'],\n",
       "    'original': 'I\\x92m past patiently waitin\\x92. I\\x92m passionately',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'past',\n",
       "     u'patiently',\n",
       "     u'waitin',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'passionate']},\n",
       "   {'line#': 155,\n",
       "    'normalized': [u'Smashin', u'every', u'expectation'],\n",
       "    'original': 'Smashin\\x92 every expectation',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Smashin', u'every', u'expectation']},\n",
       "   {'line#': 156,\n",
       "    'normalized': [u'Every',\n",
       "     u'action',\n",
       "     u's',\n",
       "     u'an',\n",
       "     u'act',\n",
       "     u'of',\n",
       "     u'creation'],\n",
       "    'original': 'Every action\\x92s an act of creation!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Every',\n",
       "     u'action',\n",
       "     u's',\n",
       "     u'an',\n",
       "     u'act',\n",
       "     u'of',\n",
       "     u'creation']},\n",
       "   {'line#': 157,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'laughin',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'face',\n",
       "     u'of',\n",
       "     u'casualties',\n",
       "     u'and',\n",
       "     u'sorro'],\n",
       "    'original': 'I\\x92m laughin\\x92 in the face of casualties and sorrow',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'laughin',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'face',\n",
       "     u'of',\n",
       "     u'casualties',\n",
       "     u'and',\n",
       "     u'sorro']},\n",
       "   {'line#': 158,\n",
       "    'normalized': [u'For',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'time',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'thinkin',\n",
       "     u'past',\n",
       "     u'tomorro'],\n",
       "    'original': 'For the first time, I\\x92m thinkin\\x92 past tomorrow',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'For',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'time',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'thinkin',\n",
       "     u'past',\n",
       "     u'tomorro']},\n",
       "   {'line#': 159,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot'],\n",
       "    'original': 'And I am not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'COMPANY'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot']},\n",
       "   {'line#': 160,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'COMPANY'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 161,\n",
       "    'normalized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country'],\n",
       "    'original': 'Hey yo, I\\x92m just like my country',\n",
       "    'speakers': ['HAMILTON', 'COMPANY'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'yo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country']},\n",
       "   {'line#': 162,\n",
       "    'normalized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry'],\n",
       "    'original': 'I\\x92m young, scrappy and hungry',\n",
       "    'speakers': ['HAMILTON', 'COMPANY'],\n",
       "    'tokenized': [u'I', u'm', u'young', u'scrappy', u'and', u'hungry']},\n",
       "   {'line#': 163,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot'],\n",
       "    'original': 'And I\\x92m not throwing away my shot',\n",
       "    'speakers': ['HAMILTON', 'COMPANY'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'not',\n",
       "     u'throwing',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot']},\n",
       "   {'line#': 164,\n",
       "    'normalized': [u'We',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up',\n",
       "     u'Time',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'shot'],\n",
       "    'original': 'We\\x92re gonna rise up! Time to take a shot!',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'We',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up',\n",
       "     u'Time',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'shot']},\n",
       "   {'line#': 165,\n",
       "    'normalized': [u'We',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up',\n",
       "     u'Time',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'shot'],\n",
       "    'original': 'We\\x92re gonna rise up! Time to take a shot!',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'We',\n",
       "     u're',\n",
       "     u'gonna',\n",
       "     u'rise',\n",
       "     u'up',\n",
       "     u'Time',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'shot']},\n",
       "   {'line#': 166,\n",
       "    'normalized': [u'We', u're', u'gonna'],\n",
       "    'original': 'We\\x92re gonna',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'We', u're', u'gonna']},\n",
       "   {'line#': 167,\n",
       "    'normalized': [u'Time', u'to', u'take', u'a', u'shot'],\n",
       "    'original': 'Time to take a shot!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Time', u'to', u'take', u'a', u'shot']},\n",
       "   {'line#': 168,\n",
       "    'normalized': [u'Time', u'to', u'take', u'a', u'shot'],\n",
       "    'original': 'Time to take a shot!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Time', u'to', u'take', u'a', u'shot']},\n",
       "   {'line#': 169,\n",
       "    'normalized': [u'Time', u'to', u'take', u'a', u'shot'],\n",
       "    'original': 'Time to take a shot!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Time', u'to', u'take', u'a', u'shot']},\n",
       "   {'line#': 170,\n",
       "    'normalized': [u'Take', u'a', u'shot'],\n",
       "    'original': 'Take a shot!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Take', u'a', u'shot']},\n",
       "   {'line#': 171,\n",
       "    'normalized': [u'Shot'],\n",
       "    'original': 'Shot!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Shot']},\n",
       "   {'line#': 172,\n",
       "    'normalized': [u'Shot'],\n",
       "    'original': 'Shot!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Shot']},\n",
       "   {'line#': 173,\n",
       "    'normalized': [u'A', u'yo', u'it', u's'],\n",
       "    'original': 'A-yo it\\x92s',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'A', u'yo', u'it', u's']},\n",
       "   {'line#': 174,\n",
       "    'normalized': [u'Time', u'to', u'take', u'a', u'shot'],\n",
       "    'original': 'Time to take a shot!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Time', u'to', u'take', u'a', u'shot']},\n",
       "   {'line#': 175,\n",
       "    'normalized': [u'Time', u'to', u'take', u'a', u'shot'],\n",
       "    'original': 'Time to take a shot!',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Time', u'to', u'take', u'a', u'shot']},\n",
       "   {'line#': 176,\n",
       "    'normalized': [u'And', u'I', u'am'],\n",
       "    'original': 'And I am\\x97',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'And', u'I', u'am']},\n",
       "   {'line#': 177,\n",
       "    'normalized': [u'Not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'Not throwing away my shot',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 178,\n",
       "    'normalized': [u'Not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'Not throwing away my shot',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 179,\n",
       "    'normalized': [u'We', u're', u'gonna'],\n",
       "    'original': 'We\\x92re gonna',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'We', u're', u'gonna']},\n",
       "   {'line#': 180,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 181,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 182,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 183,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 184,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 185,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 186,\n",
       "    'normalized': [u'Ri', u'ri', u'r'],\n",
       "    'original': 'Ri\\x97 ri\\x97 ri\\x97',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Ri', u'ri', u'r']},\n",
       "   {'line#': 187,\n",
       "    'normalized': [u'Time', u'to', u'take', u'a', u'shot'],\n",
       "    'original': 'Time to take a shot!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Time', u'to', u'take', u'a', u'shot']},\n",
       "   {'line#': 188,\n",
       "    'normalized': [u'Time', u'to', u'take', u'a', u'shot'],\n",
       "    'original': 'Time to take a shot!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Time', u'to', u'take', u'a', u'shot']},\n",
       "   {'line#': 189,\n",
       "    'normalized': [u'And', u'I', u'am'],\n",
       "    'original': 'And I am\\x97',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'And', u'I', u'am']},\n",
       "   {'line#': 190,\n",
       "    'normalized': [u'Not', u'throwin', u'away', u'my'],\n",
       "    'original': 'Not throwin\\x92 away my\\x97',\n",
       "    'speakers': ['HAMILTON', 'LAFAYETTE', 'MULLIGAN', 'LAURENS'],\n",
       "    'tokenized': [u'Not', u'throwin', u'away', u'my']},\n",
       "   {'line#': 191,\n",
       "    'normalized': [u'Not', u'throwin', u'away', u'my', u'shot'],\n",
       "    'original': 'Not throwin\\x92 away my shot!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Not', u'throwin', u'away', u'my', u'shot']}],\n",
       "  'track': 'My Shot',\n",
       "  'track#': '3'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'I',\n",
       "     u'may',\n",
       "     u'not',\n",
       "     u'live',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'our',\n",
       "     u'glory'],\n",
       "    'original': 'I may not live to see our glory!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'may',\n",
       "     u'not',\n",
       "     u'live',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'our',\n",
       "     u'glory']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'I',\n",
       "     u'may',\n",
       "     u'not',\n",
       "     u'live',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'our',\n",
       "     u'glory'],\n",
       "    'original': 'I may not live to see our glory!',\n",
       "    'speakers': ['LAFAYETTE', 'MULLIGAN', 'LAURENS'],\n",
       "    'tokenized': [u'I',\n",
       "     u'may',\n",
       "     u'not',\n",
       "     u'live',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'our',\n",
       "     u'glory']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'But',\n",
       "     u'I',\n",
       "     u'will',\n",
       "     u'gladly',\n",
       "     u'join',\n",
       "     u'the',\n",
       "     u'fight'],\n",
       "    'original': 'But I will gladly join the fight!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'I',\n",
       "     u'will',\n",
       "     u'gladly',\n",
       "     u'join',\n",
       "     u'the',\n",
       "     u'fight']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'But',\n",
       "     u'I',\n",
       "     u'will',\n",
       "     u'gladly',\n",
       "     u'join',\n",
       "     u'the',\n",
       "     u'fight'],\n",
       "    'original': 'But I will gladly join the fight!',\n",
       "    'speakers': ['LAFAYETTE', 'MULLIGAN', 'LAURENS'],\n",
       "    'tokenized': [u'But',\n",
       "     u'I',\n",
       "     u'will',\n",
       "     u'gladly',\n",
       "     u'join',\n",
       "     u'the',\n",
       "     u'fight']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'And',\n",
       "     u'when',\n",
       "     u'our',\n",
       "     u'children',\n",
       "     u'tell',\n",
       "     u'our',\n",
       "     u'story'],\n",
       "    'original': 'And when our children tell our story\\x85',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'when',\n",
       "     u'our',\n",
       "     u'children',\n",
       "     u'tell',\n",
       "     u'our',\n",
       "     u'story']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'And',\n",
       "     u'when',\n",
       "     u'our',\n",
       "     u'children',\n",
       "     u'tell',\n",
       "     u'our',\n",
       "     u'story'],\n",
       "    'original': 'And when our children tell our story\\x85',\n",
       "    'speakers': ['LAFAYETTE', 'MULLIGAN', 'LAURENS'],\n",
       "    'tokenized': [u'And',\n",
       "     u'when',\n",
       "     u'our',\n",
       "     u'children',\n",
       "     u'tell',\n",
       "     u'our',\n",
       "     u'story']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight'],\n",
       "    'original': 'They\\x92ll tell the story of tonight',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Let', u's', u'have', u'another', u'round', u'tonight'],\n",
       "    'original': 'Let\\x92s have another round tonight',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Let', u's', u'have', u'another', u'round', u'tonight']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Let', u's', u'have', u'another', u'round', u'tonight'],\n",
       "    'original': 'Let\\x92s have another round tonight',\n",
       "    'speakers': ['LAFAYETTE'],\n",
       "    'tokenized': [u'Let', u's', u'have', u'another', u'round', u'tonight']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Let', u's', u'have', u'another', u'round', u'tonight'],\n",
       "    'original': 'Let\\x92s have another round tonight',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Let', u's', u'have', u'another', u'round', u'tonight']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Raise', u'a', u'glass', u'to', u'freedom'],\n",
       "    'original': 'Raise a glass to freedom',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Raise', u'a', u'glass', u'to', u'freedom']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Something', u'they', u'can', u'never', u'take', u'away'],\n",
       "    'original': 'Something they can never take away',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Something', u'they', u'can', u'never', u'take', u'away']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'No', u'matter', u'what', u'they', u'tell', u'you'],\n",
       "    'original': 'No matter what they tell you',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'No', u'matter', u'what', u'they', u'tell', u'you']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Raise',\n",
       "     u'a',\n",
       "     u'glass',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'four',\n",
       "     u'of',\n",
       "     u'us'],\n",
       "    'original': 'Raise a glass to the four of us',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Raise',\n",
       "     u'a',\n",
       "     u'glass',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'four',\n",
       "     u'of',\n",
       "     u'us']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Tomorrow', u'there', u'll', u'be', u'more', u'of', u'us'],\n",
       "    'original': 'Tomorrow there\\x92ll be more of us',\n",
       "    'speakers': ['LAURENS', 'MULLIGAN'],\n",
       "    'tokenized': [u'Tomorrow', u'there', u'll', u'be', u'more', u'of', u'us']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Telling', u'the', u'story', u'of', u'tonight'],\n",
       "    'original': 'Telling the story of tonight',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'LAURENS'],\n",
       "    'tokenized': [u'Telling', u'the', u'story', u'of', u'tonight']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight'],\n",
       "    'original': 'They\\x92ll tell the story of tonight',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Raise', u'a', u'glass', u'to', u'freedom'],\n",
       "    'original': 'Raise a glass to freedom',\n",
       "    'speakers': ['LAURENS', 'MULLIGAN', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Raise', u'a', u'glass', u'to', u'freedom']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Something', u'they', u'can', u'never', u'take', u'away'],\n",
       "    'original': 'Something they can never take away',\n",
       "    'speakers': ['LAURENS', 'MULLIGAN', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Something', u'they', u'can', u'never', u'take', u'away']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'No', u'matter', u'what', u'they', u'tell', u'you'],\n",
       "    'original': 'No matter what they tell you',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No', u'matter', u'what', u'they', u'tell', u'you']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Let', u's', u'have', u'another', u'round', u'tonight'],\n",
       "    'original': 'Let\\x92s have another round tonight',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Let', u's', u'have', u'another', u'round', u'tonight']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Raise',\n",
       "     u'a',\n",
       "     u'glass',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'four',\n",
       "     u'of',\n",
       "     u'us'],\n",
       "    'original': 'Raise a glass to the four of us',\n",
       "    'speakers': ['LAURENS'],\n",
       "    'tokenized': [u'Raise',\n",
       "     u'a',\n",
       "     u'glass',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'four',\n",
       "     u'of',\n",
       "     u'us']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Tomorrow', u'there', u'll', u'be', u'more', u'of', u'us'],\n",
       "    'original': 'Tomorrow there\\x92ll be more of us',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'MULLIGAN', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Tomorrow', u'there', u'll', u'be', u'more', u'of', u'us']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Telling', u'the', u'story', u'of', u'tonight'],\n",
       "    'original': 'Telling the story of tonight',\n",
       "    'speakers': ['HAMILTON', 'LAURENS'],\n",
       "    'tokenized': [u'Telling', u'the', u'story', u'of', u'tonight']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Let', u's', u'have', u'another', u'round', u'tonight'],\n",
       "    'original': 'Let\\x92s have another round tonight',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Let', u's', u'have', u'another', u'round', u'tonight']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight'],\n",
       "    'original': 'They\\x92ll tell the story of tonight',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'ENSEMBLE'],\n",
       "    'tokenized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight'],\n",
       "    'original': 'They\\x92ll tell the story of tonight',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'ENSEMBLE'],\n",
       "    'tokenized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight'],\n",
       "    'original': 'They\\x92ll tell the story of tonight',\n",
       "    'speakers': ['HAMILTON', 'LAURENS', 'ENSEMBLE'],\n",
       "    'tokenized': [u'They',\n",
       "     u'll',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'story',\n",
       "     u'of',\n",
       "     u'tonight']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Raise', u'a', u'glass', u'to', u'freedom'],\n",
       "    'original': 'Raise a glass to freedom',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Raise', u'a', u'glass', u'to', u'freedom']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Raise', u'a', u'glass', u'to', u'freedom'],\n",
       "    'original': 'Raise a glass to freedom',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Raise', u'a', u'glass', u'to', u'freedom']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'They', u'll', u'tell', u'the', u'story', u'of'],\n",
       "    'original': 'They\\x92ll tell the story of\\x97',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'ENSEMBLE'],\n",
       "    'tokenized': [u'They', u'll', u'tell', u'the', u'story', u'of']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Tonight'],\n",
       "    'original': 'Tonight',\n",
       "    'speakers': ['FULL ENSEMBLE'],\n",
       "    'tokenized': [u'Tonight']}],\n",
       "  'track': 'The Story Of Tonight',\n",
       "  'track#': '4'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'There',\n",
       "     u's',\n",
       "     u'nothing',\n",
       "     u'rich',\n",
       "     u'folks',\n",
       "     u'love',\n",
       "     u'more'],\n",
       "    'original': 'There\\x92s nothing rich folks love more',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'There',\n",
       "     u's',\n",
       "     u'nothing',\n",
       "     u'rich',\n",
       "     u'folks',\n",
       "     u'love',\n",
       "     u'more']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Than',\n",
       "     u'going',\n",
       "     u'downtown',\n",
       "     u'and',\n",
       "     u'slummin',\n",
       "     u'it',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'poor'],\n",
       "    'original': 'Than going downtown and slummin\\x92 it with the poor',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Than',\n",
       "     u'going',\n",
       "     u'downtown',\n",
       "     u'and',\n",
       "     u'slummin',\n",
       "     u'it',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'poor']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'They',\n",
       "     u'pull',\n",
       "     u'up',\n",
       "     u'in',\n",
       "     u'their',\n",
       "     u'carriages',\n",
       "     u'and',\n",
       "     u'gawk'],\n",
       "    'original': 'They pull up in their carriages and gawk',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'They',\n",
       "     u'pull',\n",
       "     u'up',\n",
       "     u'in',\n",
       "     u'their',\n",
       "     u'carriages',\n",
       "     u'and',\n",
       "     u'gawk']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'At', u'the', u'students', u'in', u'the', u'common'],\n",
       "    'original': 'At the students in the common',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'At', u'the', u'students', u'in', u'the', u'common']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Just', u'to', u'watch', u'them', u'talk'],\n",
       "    'original': 'Just to watch them talk',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Just', u'to', u'watch', u'them', u'talk']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Take',\n",
       "     u'Philip',\n",
       "     u'Schuyler',\n",
       "     u'the',\n",
       "     u'man',\n",
       "     u'is',\n",
       "     u'loaded'],\n",
       "    'original': 'Take Philip Schuyler: the man is loaded',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Take',\n",
       "     u'Philip',\n",
       "     u'Schuyler',\n",
       "     u'the',\n",
       "     u'man',\n",
       "     u'is',\n",
       "     u'loaded']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Uh',\n",
       "     u'oh',\n",
       "     u'but',\n",
       "     u'little',\n",
       "     u'does',\n",
       "     u'he',\n",
       "     u'know',\n",
       "     u'that'],\n",
       "    'original': 'Uh-oh, but little does he know that',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Uh',\n",
       "     u'oh',\n",
       "     u'but',\n",
       "     u'little',\n",
       "     u'does',\n",
       "     u'he',\n",
       "     u'know',\n",
       "     u'that']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'His', u'daughters', u'Peggy', u'Angelica', u'Eliza'],\n",
       "    'original': 'His daughters, Peggy, Angelica, Eliza',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'His', u'daughters', u'Peggy', u'Angelica', u'Eliza']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Sneak',\n",
       "     u'into',\n",
       "     u'the',\n",
       "     u'city',\n",
       "     u'just',\n",
       "     u'to',\n",
       "     u'watch',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'guys',\n",
       "     u'at'],\n",
       "    'original': 'Sneak into the city just to watch all the guys at\\x97',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Sneak',\n",
       "     u'into',\n",
       "     u'the',\n",
       "     u'city',\n",
       "     u'just',\n",
       "     u'to',\n",
       "     u'watch',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'guys',\n",
       "     u'at']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'And', u'Peggy'],\n",
       "    'original': 'And Peggy!',\n",
       "    'speakers': ['PEGGY'],\n",
       "    'tokenized': [u'And', u'Peggy']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'The', u'Schuyler', u'sisters'],\n",
       "    'original': 'The Schuyler sisters!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'Schuyler', u'sisters']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Peggy'],\n",
       "    'original': 'Peggy!',\n",
       "    'speakers': ['PEGGY'],\n",
       "    'tokenized': [u'Peggy']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Work'],\n",
       "    'original': 'Work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Daddy',\n",
       "     u'said',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'home',\n",
       "     u'by',\n",
       "     u'sundown'],\n",
       "    'original': 'Daddy said to be home by sundown',\n",
       "    'speakers': ['PEGGY'],\n",
       "    'tokenized': [u'Daddy',\n",
       "     u'said',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'home',\n",
       "     u'by',\n",
       "     u'sundown']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Daddy', u'doesn', u't', u'need', u'to', u'know'],\n",
       "    'original': 'Daddy doesn\\x92t need to know',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Daddy', u'doesn', u't', u'need', u'to', u'know']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Daddy', u'said', u'not', u'to', u'go', u'downtown'],\n",
       "    'original': 'Daddy said not to go downtown',\n",
       "    'speakers': ['PEGGY'],\n",
       "    'tokenized': [u'Daddy', u'said', u'not', u'to', u'go', u'downtown']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Like',\n",
       "     u'I',\n",
       "     u'said',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'free',\n",
       "     u'to',\n",
       "     u'go'],\n",
       "    'original': 'Like I said, you\\x92re free to go',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Like',\n",
       "     u'I',\n",
       "     u'said',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'free',\n",
       "     u'to',\n",
       "     u'go']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'But', u'look', u'around', u'look', u'around', u'the'],\n",
       "    'original': 'But\\x97look around, look around, the',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'But', u'look', u'around', u'look', u'around', u'the']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Revolution', u's', u'happening', u'in', u'New', u'York'],\n",
       "    'original': 'Revolution\\x92s happening in New York',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Revolution', u's', u'happening', u'in', u'New', u'York']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'New', u'York'],\n",
       "    'original': 'New York',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'New', u'York']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Work'],\n",
       "    'original': 'Work!',\n",
       "    'speakers': ['SCHUYLER SISTERS', 'COMPANY'],\n",
       "    'tokenized': [u'Work']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'It',\n",
       "     u's',\n",
       "     u'bad',\n",
       "     u'enough',\n",
       "     u'daddy',\n",
       "     u'wants',\n",
       "     u'to',\n",
       "     u'go',\n",
       "     u'to',\n",
       "     u'war'],\n",
       "    'original': 'It\\x92s bad enough daddy wants to go to war',\n",
       "    'speakers': ['PEGGY'],\n",
       "    'tokenized': [u'It',\n",
       "     u's',\n",
       "     u'bad',\n",
       "     u'enough',\n",
       "     u'daddy',\n",
       "     u'wants',\n",
       "     u'to',\n",
       "     u'go',\n",
       "     u'to',\n",
       "     u'war']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'People', u'shouting', u'in', u'the', u'square'],\n",
       "    'original': 'People shouting in the square',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'People', u'shouting', u'in', u'the', u'square']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'It',\n",
       "     u's',\n",
       "     u'bad',\n",
       "     u'enough',\n",
       "     u'there',\n",
       "     u'll',\n",
       "     u'be',\n",
       "     u'violence',\n",
       "     u'on',\n",
       "     u'our',\n",
       "     u'shor'],\n",
       "    'original': 'It\\x92s bad enough there\\x92ll be violence on our shore',\n",
       "    'speakers': ['PEGGY'],\n",
       "    'tokenized': [u'It',\n",
       "     u's',\n",
       "     u'bad',\n",
       "     u'enough',\n",
       "     u'there',\n",
       "     u'll',\n",
       "     u'be',\n",
       "     u'violence',\n",
       "     u'on',\n",
       "     u'our',\n",
       "     u'shor']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'New', u'ideas', u'in', u'the', u'air'],\n",
       "    'original': 'New ideas in the air',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'New', u'ideas', u'in', u'the', u'air']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Look', u'around', u'look', u'around'],\n",
       "    'original': 'Look around, look around\\x97',\n",
       "    'speakers': ['ANGELICA', 'MALE ENSEMBLE'],\n",
       "    'tokenized': [u'Look', u'around', u'look', u'around']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Angelica',\n",
       "     u'remind',\n",
       "     u'me',\n",
       "     u'what',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'looking',\n",
       "     u'for'],\n",
       "    'original': 'Angelica, remind me what we\\x92re looking for\\x85',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Angelica',\n",
       "     u'remind',\n",
       "     u'me',\n",
       "     u'what',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'looking',\n",
       "     u'for']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'She', u's', u'lookin', u'for', u'me'],\n",
       "    'original': 'She\\x92s lookin\\x92 for me!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'She', u's', u'lookin', u'for', u'me']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Eliza',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'lookin',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'mind',\n",
       "     u'at',\n",
       "     u'wor'],\n",
       "    'original': 'Eliza, I\\x92m lookin\\x92 for a mind at work',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Eliza',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'lookin',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'mind',\n",
       "     u'at',\n",
       "     u'wor']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'lookin',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'mind',\n",
       "     u'at',\n",
       "     u'work'],\n",
       "    'original': 'I\\x92m lookin\\x92 for a mind at work!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'lookin',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'mind',\n",
       "     u'at',\n",
       "     u'work']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'lookin',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'mind',\n",
       "     u'at',\n",
       "     u'work'],\n",
       "    'original': 'I\\x92m lookin\\x92 for a mind at work!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'lookin',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'mind',\n",
       "     u'at',\n",
       "     u'work']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Whooaaaaa'],\n",
       "    'original': 'Whooaaaaa!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Whooaaaaa']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Whooaaaaa'],\n",
       "    'original': 'Whooaaaaa!',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY'],\n",
       "    'tokenized': [u'Whooaaaaa']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Work'],\n",
       "    'original': 'Work!',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY'],\n",
       "    'tokenized': [u'Work']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Work'],\n",
       "    'original': 'Work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Wooh',\n",
       "     u'There',\n",
       "     u's',\n",
       "     u'nothin',\n",
       "     u'like',\n",
       "     u'summer',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'cit'],\n",
       "    'original': 'Wooh! There\\x92s nothin\\x92 like summer in the city',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Wooh',\n",
       "     u'There',\n",
       "     u's',\n",
       "     u'nothin',\n",
       "     u'like',\n",
       "     u'summer',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'cit']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Someone',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'rush',\n",
       "     u'next',\n",
       "     u'to',\n",
       "     u'someone',\n",
       "     u'lookin',\n",
       "     u'pretty'],\n",
       "    'original': 'Someone in a rush next to someone lookin\\x92 pretty',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Someone',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'rush',\n",
       "     u'next',\n",
       "     u'to',\n",
       "     u'someone',\n",
       "     u'lookin',\n",
       "     u'pretty']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Excuse',\n",
       "     u'me',\n",
       "     u'miss',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'not',\n",
       "     u'funny'],\n",
       "    'original': 'Excuse me, miss, I know it\\x92s not funny',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Excuse',\n",
       "     u'me',\n",
       "     u'miss',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'it',\n",
       "     u's',\n",
       "     u'not',\n",
       "     u'funny']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'But',\n",
       "     u'your',\n",
       "     u'perfume',\n",
       "     u'smells',\n",
       "     u'like',\n",
       "     u'your',\n",
       "     u'daddy',\n",
       "     u's',\n",
       "     u'got',\n",
       "     u'money'],\n",
       "    'original': 'But your perfume smells like your daddy\\x92s got money',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But',\n",
       "     u'your',\n",
       "     u'perfume',\n",
       "     u'smells',\n",
       "     u'like',\n",
       "     u'your',\n",
       "     u'daddy',\n",
       "     u's',\n",
       "     u'got',\n",
       "     u'money']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Why',\n",
       "     u'you',\n",
       "     u'slummin',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'fancy',\n",
       "     u'heels'],\n",
       "    'original': 'Why you slummin\\x92 in the city in your fancy heels',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'you',\n",
       "     u'slummin',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'fancy',\n",
       "     u'heels']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'You',\n",
       "     u'searchin',\n",
       "     u'for',\n",
       "     u'an',\n",
       "     u'urchin',\n",
       "     u'who',\n",
       "     u'can',\n",
       "     u'give',\n",
       "     u'you',\n",
       "     u'ideals'],\n",
       "    'original': 'You searchin for an urchin who can give you ideals?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u'searchin',\n",
       "     u'for',\n",
       "     u'an',\n",
       "     u'urchin',\n",
       "     u'who',\n",
       "     u'can',\n",
       "     u'give',\n",
       "     u'you',\n",
       "     u'ideals']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Burr', u'you', u'disgust', u'me'],\n",
       "    'original': 'Burr, you disgust me',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Burr', u'you', u'disgust', u'me']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Ah', u'so', u'you', u've', u'discussed', u'me'],\n",
       "    'original': 'Ah, so you\\x92ve discussed me',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ah', u'so', u'you', u've', u'discussed', u'me']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'trust',\n",
       "     u'fund',\n",
       "     u'baby',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'trust',\n",
       "     u'me'],\n",
       "    'original': 'I\\x92m a trust fund, baby, you can trust me!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'trust',\n",
       "     u'fund',\n",
       "     u'baby',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'trust',\n",
       "     u'me']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'I',\n",
       "     u've',\n",
       "     u'been',\n",
       "     u'reading',\n",
       "     u'Common',\n",
       "     u'Sense',\n",
       "     u'by',\n",
       "     u'Thomas',\n",
       "     u'Paine'],\n",
       "    'original': 'I\\x92ve been reading Common Sense by Thomas Paine',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u've',\n",
       "     u'been',\n",
       "     u'reading',\n",
       "     u'Common',\n",
       "     u'Sense',\n",
       "     u'by',\n",
       "     u'Thomas',\n",
       "     u'Paine']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'So',\n",
       "     u'men',\n",
       "     u'say',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'intense',\n",
       "     u'or',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'insan'],\n",
       "    'original': 'So men say that I\\x92m intense or I\\x92m insane',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'So',\n",
       "     u'men',\n",
       "     u'say',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'intense',\n",
       "     u'or',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'insan']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'You',\n",
       "     u'want',\n",
       "     u'a',\n",
       "     u'revolution',\n",
       "     u'I',\n",
       "     u'want',\n",
       "     u'a',\n",
       "     u'revelation'],\n",
       "    'original': 'You want a revolution? I want a revelation',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'want',\n",
       "     u'a',\n",
       "     u'revolution',\n",
       "     u'I',\n",
       "     u'want',\n",
       "     u'a',\n",
       "     u'revelation']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'So', u'listen', u'to', u'my', u'declaration'],\n",
       "    'original': 'So listen to my declaration:',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'So', u'listen', u'to', u'my', u'declaration']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'We',\n",
       "     u'hold',\n",
       "     u'these',\n",
       "     u'truths',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'self',\n",
       "     u'evident'],\n",
       "    'original': '\\x93We hold these truths to be self-evident',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY'],\n",
       "    'tokenized': [u'We',\n",
       "     u'hold',\n",
       "     u'these',\n",
       "     u'truths',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'self',\n",
       "     u'evident']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'That', u'all', u'men', u'are', u'created', u'equal'],\n",
       "    'original': 'That all men are created equal\\x94',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY'],\n",
       "    'tokenized': [u'That', u'all', u'men', u'are', u'created', u'equal']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'And', u'when', u'I', u'meet', u'Thomas', u'Jefferson'],\n",
       "    'original': 'And when I meet Thomas Jefferson',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'when', u'I', u'meet', u'Thomas', u'Jefferson']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Unh'],\n",
       "    'original': 'Unh!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Unh']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'compel',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'include',\n",
       "     u'women',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'sequel'],\n",
       "    'original': 'I\\x92m \\x91a compel him to include women in the sequel!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'a',\n",
       "     u'compel',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'include',\n",
       "     u'women',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'sequel']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Work'],\n",
       "    'original': 'Work!',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Work']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Look', u'around', u'look', u'around', u'at', u'how'],\n",
       "    'original': 'Look around, look around at how',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'around', u'look', u'around', u'at', u'how']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now'],\n",
       "    'original': 'Lucky we are to be alive right now!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'Look', u'around', u'look', u'around', u'at', u'how'],\n",
       "    'original': 'Look around, look around at how',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'Look', u'around', u'look', u'around', u'at', u'how']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'Lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now'],\n",
       "    'original': 'Lucky we are to be alive right now!',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'Lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'History',\n",
       "     u'is',\n",
       "     u'happening',\n",
       "     u'in',\n",
       "     u'Manhattan',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'just',\n",
       "     u'happen',\n",
       "     u'to',\n",
       "     u'be'],\n",
       "    'original': 'History is happening in Manhattan and we just happen to be',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY'],\n",
       "    'tokenized': [u'History',\n",
       "     u'is',\n",
       "     u'happening',\n",
       "     u'in',\n",
       "     u'Manhattan',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'just',\n",
       "     u'happen',\n",
       "     u'to',\n",
       "     u'be']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world'],\n",
       "    'original': 'In the greatest city in the world!',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY'],\n",
       "    'tokenized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world'],\n",
       "    'original': 'In the greatest city in the world!',\n",
       "    'speakers': ['SCHUYLER SISTERS', 'COMPANY'],\n",
       "    'tokenized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Cuz',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'been',\n",
       "     u'reading',\n",
       "     u'Common',\n",
       "     u'Sense',\n",
       "     u'by',\n",
       "     u'Thomas',\n",
       "     u'Paine'],\n",
       "    'original': 'Cuz I\\x92ve been reading Common Sense by Thomas Paine',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Cuz',\n",
       "     u'I',\n",
       "     u've',\n",
       "     u'been',\n",
       "     u'reading',\n",
       "     u'Common',\n",
       "     u'Sense',\n",
       "     u'by',\n",
       "     u'Thomas',\n",
       "     u'Paine']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'So',\n",
       "     u'men',\n",
       "     u'say',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'intense',\n",
       "     u'or',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'insan'],\n",
       "    'original': 'So men say that I\\x92m intense or I\\x92m insane',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'So',\n",
       "     u'men',\n",
       "     u'say',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'intense',\n",
       "     u'or',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'insan']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'You', u'want', u'a', u'revolution'],\n",
       "    'original': 'You want a revolution?',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'You', u'want', u'a', u'revolution']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'I', u'want', u'a', u'revelation'],\n",
       "    'original': 'I want a revelation',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'want', u'a', u'revelation']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'So', u'listen', u'to', u'my', u'declaration'],\n",
       "    'original': 'So listen to my declaration:',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'So', u'listen', u'to', u'my', u'declaration']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'We',\n",
       "     u'hold',\n",
       "     u'these',\n",
       "     u'truths',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'self',\n",
       "     u'evident',\n",
       "     u'that',\n",
       "     u'all',\n",
       "     u'men',\n",
       "     u'are',\n",
       "     u'created',\n",
       "     u'equal'],\n",
       "    'original': 'We hold these truths to be self evident that all men are created equal',\n",
       "    'speakers': ['ANGELICA', 'ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'We',\n",
       "     u'hold',\n",
       "     u'these',\n",
       "     u'truths',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'self',\n",
       "     u'evident',\n",
       "     u'that',\n",
       "     u'all',\n",
       "     u'men',\n",
       "     u'are',\n",
       "     u'created',\n",
       "     u'equal']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'Whoo'],\n",
       "    'original': 'Whoo!',\n",
       "    'speakers': ['ANGELICA', 'ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'Whoo']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Look', u'around', u'look', u'around'],\n",
       "    'original': 'Look around, look around',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'Look', u'around', u'look', u'around']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'The', u'revolution', u's', u'happening', u'in'],\n",
       "    'original': 'The revolution\\x92s happening in\\x97',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'The', u'revolution', u's', u'happening', u'in']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'New', u'York'],\n",
       "    'original': 'New York!',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'New', u'York']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'In', u'New', u'York'],\n",
       "    'original': 'In New York!',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'In', u'New', u'York']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'Look', u'around'],\n",
       "    'original': 'Look around',\n",
       "    'speakers': ['FEMALE ENSEMBLE'],\n",
       "    'tokenized': [u'Look', u'around']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'Look', u'around'],\n",
       "    'original': 'Look around',\n",
       "    'speakers': ['FEMALE ENSEMBLE'],\n",
       "    'tokenized': [u'Look', u'around']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'At',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now'],\n",
       "    'original': 'At how lucky we are to be alive right now',\n",
       "    'speakers': ['FEMALE ENSEMBLE'],\n",
       "    'tokenized': [u'At',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'Hey', u'Hey', u'Hey', u'Hey'],\n",
       "    'original': 'Hey! Hey! Hey! Hey!',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Hey', u'Hey', u'Hey', u'Hey']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Hey', u'Hey', u'Hey', u'Hey'],\n",
       "    'original': 'Hey! Hey! Hey! Hey!',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Hey', u'Hey', u'Hey', u'Hey']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'the',\n",
       "     u'revolution',\n",
       "     u's',\n",
       "     u'happening'],\n",
       "    'original': 'Look around, look around the revolution\\x92s happening',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'the',\n",
       "     u'revolution',\n",
       "     u's',\n",
       "     u'happening']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'Hey', u'Hey'],\n",
       "    'original': 'Hey! Hey!',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Hey', u'Hey']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'Hey', u'Hey'],\n",
       "    'original': 'Hey! Hey!',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Hey', u'Hey']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'Hey', u'Hey'],\n",
       "    'original': 'Hey! Hey!',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Hey', u'Hey']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'Hey', u'Hey'],\n",
       "    'original': 'Hey! Hey!',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Hey', u'Hey']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'at',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now'],\n",
       "    'original': 'Look around, look around at how lucky we are to be alive right now!',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'around',\n",
       "     u'look',\n",
       "     u'around',\n",
       "     u'at',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'History',\n",
       "     u'is',\n",
       "     u'happening',\n",
       "     u'in',\n",
       "     u'Manhattan',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'just',\n",
       "     u'happen',\n",
       "     u'to',\n",
       "     u'be'],\n",
       "    'original': 'History is happening in Manhattan and we just happen to be',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'History',\n",
       "     u'is',\n",
       "     u'happening',\n",
       "     u'in',\n",
       "     u'Manhattan',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'just',\n",
       "     u'happen',\n",
       "     u'to',\n",
       "     u'be']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world'],\n",
       "    'original': 'In the greatest city in the world',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'In', u'the', u'greatest', u'city'],\n",
       "    'original': 'In the greatest city\\x97',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'In', u'the', u'greatest', u'city']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world'],\n",
       "    'original': 'In the greatest city in the world!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'Work', u'work'],\n",
       "    'original': 'Work, work!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Work', u'work']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'And', u'Peggy'],\n",
       "    'original': 'And Peggy!',\n",
       "    'speakers': ['PEGGY'],\n",
       "    'tokenized': [u'And', u'Peggy']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'The', u'Schuyler', u'sisters'],\n",
       "    'original': 'The Schuyler sisters!',\n",
       "    'speakers': ['ANGELICA', 'ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'The', u'Schuyler', u'sisters']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'We',\n",
       "     u're',\n",
       "     u'looking',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'mind',\n",
       "     u'at',\n",
       "     u'work'],\n",
       "    'original': 'We\\x92re looking for a mind at work!',\n",
       "    'speakers': ['ANGELICA', 'ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'We',\n",
       "     u're',\n",
       "     u'looking',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'mind',\n",
       "     u'at',\n",
       "     u'work']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey!',\n",
       "    'speakers': ['ANGELICA', 'ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey!',\n",
       "    'speakers': ['ANGELICA', 'ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'In', u'the', u'greatest'],\n",
       "    'original': 'In the greatest',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'In', u'the', u'greatest']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'City', u'in', u'the', u'world'],\n",
       "    'original': 'City in the world',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'City', u'in', u'the', u'world']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'Hey', u'Hey', u'Hey', u'Hey', u'Hey'],\n",
       "    'original': 'Hey! Hey! Hey! Hey! Hey!',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'Hey', u'Hey', u'Hey', u'Hey', u'Hey']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'In', u'the', u'greatest'],\n",
       "    'original': 'In the greatest',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'In', u'the', u'greatest']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'City', u'in', u'the', u'world'],\n",
       "    'original': 'City in the world',\n",
       "    'speakers': ['ELIZA', 'PEGGY'],\n",
       "    'tokenized': [u'City', u'in', u'the', u'world']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world'],\n",
       "    'original': 'In the greatest city in the world!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'In',\n",
       "     u'the',\n",
       "     u'greatest',\n",
       "     u'city',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world']}],\n",
       "  'track': 'The Schuyler Sisters',\n",
       "  'track#': '5'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Hear',\n",
       "     u'ye',\n",
       "     u'hear',\n",
       "     u'ye',\n",
       "     u'My',\n",
       "     u'name',\n",
       "     u'is',\n",
       "     u'Samuel',\n",
       "     u'Seabury'],\n",
       "    'original': 'Hear ye, hear ye! My name is Samuel Seabury',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Hear',\n",
       "     u'ye',\n",
       "     u'hear',\n",
       "     u'ye',\n",
       "     u'My',\n",
       "     u'name',\n",
       "     u'is',\n",
       "     u'Samuel',\n",
       "     u'Seabury']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'present',\n",
       "     u'Free',\n",
       "     u'Thoughts',\n",
       "     u'on',\n",
       "     u'the'],\n",
       "    'original': 'And I present \\x93Free Thoughts on the',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'present',\n",
       "     u'Free',\n",
       "     u'Thoughts',\n",
       "     u'on',\n",
       "     u'the']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Proceedings', u'of', u'the', u'Continental', u'Congress'],\n",
       "    'original': 'Proceedings of the Continental Congress!\\x94',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Proceedings', u'of', u'the', u'Continental', u'Congress']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Heed',\n",
       "     u'not',\n",
       "     u'the',\n",
       "     u'rabble',\n",
       "     u'who',\n",
       "     u'scream',\n",
       "     u'revolution'],\n",
       "    'original': 'Heed not the rabble who scream revolution',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Heed',\n",
       "     u'not',\n",
       "     u'the',\n",
       "     u'rabble',\n",
       "     u'who',\n",
       "     u'scream',\n",
       "     u'revolution']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'They',\n",
       "     u'have',\n",
       "     u'not',\n",
       "     u'your',\n",
       "     u'interests',\n",
       "     u'at',\n",
       "     u'heart'],\n",
       "    'original': 'They have not your interests at heart',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'They',\n",
       "     u'have',\n",
       "     u'not',\n",
       "     u'your',\n",
       "     u'interests',\n",
       "     u'at',\n",
       "     u'heart']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Oh', u'my', u'God', u'Tear', u'this', u'dude', u'apart'],\n",
       "    'original': 'Oh my God. Tear this dude apart',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Oh', u'my', u'God', u'Tear', u'this', u'dude', u'apart']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Chaos',\n",
       "     u'and',\n",
       "     u'bloodshed',\n",
       "     u'are',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'solution'],\n",
       "    'original': 'Chaos and bloodshed are not a solution',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Chaos',\n",
       "     u'and',\n",
       "     u'bloodshed',\n",
       "     u'are',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'solution']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Don', u't', u'let', u'them', u'lead', u'you', u'astray'],\n",
       "    'original': 'Don\\x92t let them lead you astray',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Don', u't', u'let', u'them', u'lead', u'you', u'astray']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'This',\n",
       "     u'Congress',\n",
       "     u'does',\n",
       "     u'not',\n",
       "     u'speak',\n",
       "     u'for',\n",
       "     u'me'],\n",
       "    'original': 'This Congress does not speak for me',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'This',\n",
       "     u'Congress',\n",
       "     u'does',\n",
       "     u'not',\n",
       "     u'speak',\n",
       "     u'for',\n",
       "     u'me']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Let', u'him', u'be'],\n",
       "    'original': 'Let him be',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Let', u'him', u'be']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'They', u're', u'playing', u'a', u'dangerous', u'game'],\n",
       "    'original': 'They\\x92re playing a dangerous game',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'They', u're', u'playing', u'a', u'dangerous', u'game']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'I',\n",
       "     u'pray',\n",
       "     u'the',\n",
       "     u'king',\n",
       "     u'shows',\n",
       "     u'you',\n",
       "     u'his',\n",
       "     u'mercy'],\n",
       "    'original': 'I pray the king shows you his mercy',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'I',\n",
       "     u'pray',\n",
       "     u'the',\n",
       "     u'king',\n",
       "     u'shows',\n",
       "     u'you',\n",
       "     u'his',\n",
       "     u'mercy']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'For', u'shame', u'for', u'shame'],\n",
       "    'original': 'For shame, for shame\\x85',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'For', u'shame', u'for', u'shame']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Yo'],\n",
       "    'original': 'Yo!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yo']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'He',\n",
       "     u'd',\n",
       "     u'have',\n",
       "     u'you',\n",
       "     u'all',\n",
       "     u'unravel',\n",
       "     u'at',\n",
       "     u'the'],\n",
       "    'original': 'He\\x92d have you all unravel at the',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'He',\n",
       "     u'd',\n",
       "     u'have',\n",
       "     u'you',\n",
       "     u'all',\n",
       "     u'unravel',\n",
       "     u'at',\n",
       "     u'the']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Sound', u'of', u'screams', u'but', u'the'],\n",
       "    'original': 'Sound of screams but the',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sound', u'of', u'screams', u'but', u'the']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Revolution', u'is', u'comin'],\n",
       "    'original': 'Revolution is comin\\x92',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Revolution', u'is', u'comin']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'The', u'have', u'nots', u'are', u'gonna'],\n",
       "    'original': 'The have-nots are gonna',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'have', u'nots', u'are', u'gonna']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Win', u'this'],\n",
       "    'original': 'Win this',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Win', u'this']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'It',\n",
       "     u's',\n",
       "     u'hard',\n",
       "     u'to',\n",
       "     u'listen',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'straight',\n",
       "     u'face'],\n",
       "    'original': 'It\\x92s hard to listen to you with a straight face',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'It',\n",
       "     u's',\n",
       "     u'hard',\n",
       "     u'to',\n",
       "     u'listen',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'straight',\n",
       "     u'face']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Chaos',\n",
       "     u'and',\n",
       "     u'bloodshed',\n",
       "     u'already',\n",
       "     u'haunt',\n",
       "     u'us',\n",
       "     u'honestly',\n",
       "     u'you',\n",
       "     u'shouldn',\n",
       "     u't',\n",
       "     u'even',\n",
       "     u'talk',\n",
       "     u'And',\n",
       "     u'what',\n",
       "     u'about',\n",
       "     u'Boston',\n",
       "     u'Look',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'cost',\n",
       "     u'n',\n",
       "     u'all',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u've',\n",
       "     u'lost',\n",
       "     u'n',\n",
       "     u'you',\n",
       "     u't'],\n",
       "    'original': 'Chaos and bloodshed already haunt us, honestly you shouldn\\x92t even talk. And what about Boston? Look at the cost, n\\x92 all that we\\x92ve lost n\\x92 you talk',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Chaos',\n",
       "     u'and',\n",
       "     u'bloodshed',\n",
       "     u'already',\n",
       "     u'haunt',\n",
       "     u'us',\n",
       "     u'honestly',\n",
       "     u'you',\n",
       "     u'shouldn',\n",
       "     u't',\n",
       "     u'even',\n",
       "     u'talk',\n",
       "     u'And',\n",
       "     u'what',\n",
       "     u'about',\n",
       "     u'Boston',\n",
       "     u'Look',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'cost',\n",
       "     u'n',\n",
       "     u'all',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u've',\n",
       "     u'lost',\n",
       "     u'n',\n",
       "     u'you',\n",
       "     u't']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'About', u'Congress'],\n",
       "    'original': 'About Congress?!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'About', u'Congress']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'My',\n",
       "     u'dog',\n",
       "     u'speaks',\n",
       "     u'more',\n",
       "     u'eloquently',\n",
       "     u'than',\n",
       "     u'thee'],\n",
       "    'original': 'My dog speaks more eloquently than thee!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My',\n",
       "     u'dog',\n",
       "     u'speaks',\n",
       "     u'more',\n",
       "     u'eloquently',\n",
       "     u'than',\n",
       "     u'thee']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'But',\n",
       "     u'strangely',\n",
       "     u'your',\n",
       "     u'mange',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'same'],\n",
       "    'original': 'But strangely, your mange is the same',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'strangely',\n",
       "     u'your',\n",
       "     u'mange',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'same']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Is', u'he', u'in', u'Jersey'],\n",
       "    'original': 'Is he in Jersey?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is', u'he', u'in', u'Jersey']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'For', u'the', u'revolution'],\n",
       "    'original': 'For the revolution!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'For', u'the', u'revolution']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Heed', u'not', u'the', u'rabble'],\n",
       "    'original': 'Heed not the rabble',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Heed', u'not', u'the', u'rabble']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Who', u'scream'],\n",
       "    'original': 'Who scream',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Who', u'scream']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Revolution', u'they'],\n",
       "    'original': 'Revolution, they',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Revolution', u'they']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Have', u'not', u'your'],\n",
       "    'original': 'Have not your',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Have', u'not', u'your']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Interests'],\n",
       "    'original': 'Interests',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Interests']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'At', u'heart'],\n",
       "    'original': 'At heart',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'At', u'heart']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Chaos', u'and', u'bloodshed', u'are'],\n",
       "    'original': 'Chaos and bloodshed are',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Chaos', u'and', u'bloodshed', u'are']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Not', u'a'],\n",
       "    'original': 'Not a',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Not', u'a']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Solution', u'Don', u't'],\n",
       "    'original': 'Solution. Don\\x92t',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Solution', u'Don', u't']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Let', u'them', u'lead', u'you'],\n",
       "    'original': 'Let them lead you',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Let', u'them', u'lead', u'you']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Astray'],\n",
       "    'original': 'Astray',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Astray']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'This', u'Congress', u'does', u'not'],\n",
       "    'original': 'This Congress does not',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'This', u'Congress', u'does', u'not']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Speak', u'for', u'me'],\n",
       "    'original': 'Speak for me',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Speak', u'for', u'me']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'They', u're', u'playing', u'a', u'dangerous', u'game'],\n",
       "    'original': 'They\\x92re playing a dangerous game',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'They', u're', u'playing', u'a', u'dangerous', u'game']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'I',\n",
       "     u'pray',\n",
       "     u'the',\n",
       "     u'king',\n",
       "     u'shows',\n",
       "     u'you',\n",
       "     u'his',\n",
       "     u'mercy'],\n",
       "    'original': 'I pray the king shows you his mercy',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'I',\n",
       "     u'pray',\n",
       "     u'the',\n",
       "     u'king',\n",
       "     u'shows',\n",
       "     u'you',\n",
       "     u'his',\n",
       "     u'mercy']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'For', u'shame'],\n",
       "    'original': 'For shame',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'For', u'shame']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'For', u'shame'],\n",
       "    'original': 'For shame!',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'For', u'shame']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'For', u'the', u'revolution'],\n",
       "    'original': 'For the revolution!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'For', u'the', u'revolution']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Heed'],\n",
       "    'original': 'Heed\\x97',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Heed']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'repeat',\n",
       "     u'yourself',\n",
       "     u'again',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'gonna'],\n",
       "    'original': 'If you repeat yourself again I\\x92m gonna\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'repeat',\n",
       "     u'yourself',\n",
       "     u'again',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'gonna']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Scream'],\n",
       "    'original': 'Scream\\x97',\n",
       "    'speakers': ['SEABURY', 'HAMILTON'],\n",
       "    'tokenized': [u'Scream']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Honestly',\n",
       "     u'look',\n",
       "     u'at',\n",
       "     u'me',\n",
       "     u'please',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'read'],\n",
       "    'original': 'Honestly, look at me, please don\\x92t read!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Honestly',\n",
       "     u'look',\n",
       "     u'at',\n",
       "     u'me',\n",
       "     u'please',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'read']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Not', u'your', u'interests'],\n",
       "    'original': 'Not your interests\\x97',\n",
       "    'speakers': ['SEABURY'],\n",
       "    'tokenized': [u'Not', u'your', u'interests']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Don',\n",
       "     u't',\n",
       "     u'modulate',\n",
       "     u'the',\n",
       "     u'key',\n",
       "     u'then',\n",
       "     u'not',\n",
       "     u'debate',\n",
       "     u'with',\n",
       "     u'me'],\n",
       "    'original': 'Don\\x92t modulate the key then not debate with me!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Don',\n",
       "     u't',\n",
       "     u'modulate',\n",
       "     u'the',\n",
       "     u'key',\n",
       "     u'then',\n",
       "     u'not',\n",
       "     u'debate',\n",
       "     u'with',\n",
       "     u'me']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Why',\n",
       "     u'should',\n",
       "     u'a',\n",
       "     u'tiny',\n",
       "     u'island',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'sea',\n",
       "     u'regulate',\n",
       "     u'the',\n",
       "     u'price',\n",
       "     u'of',\n",
       "     u'tea'],\n",
       "    'original': 'Why should a tiny island across the sea regulate the price of tea?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'should',\n",
       "     u'a',\n",
       "     u'tiny',\n",
       "     u'island',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'sea',\n",
       "     u'regulate',\n",
       "     u'the',\n",
       "     u'price',\n",
       "     u'of',\n",
       "     u'tea']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Alexander', u'please'],\n",
       "    'original': 'Alexander, please!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Alexander', u'please']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Burr',\n",
       "     u'I',\n",
       "     u'd',\n",
       "     u'rather',\n",
       "     u'be',\n",
       "     u'divisive',\n",
       "     u'than',\n",
       "     u'indecisive',\n",
       "     u'drop',\n",
       "     u'the',\n",
       "     u'niceties'],\n",
       "    'original': 'Burr, I\\x92d rather be divisive than indecisive, drop the niceties',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr',\n",
       "     u'I',\n",
       "     u'd',\n",
       "     u'rather',\n",
       "     u'be',\n",
       "     u'divisive',\n",
       "     u'than',\n",
       "     u'indecisive',\n",
       "     u'drop',\n",
       "     u'the',\n",
       "     u'niceties']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Silence', u'A', u'message', u'from', u'the', u'King'],\n",
       "    'original': 'Silence! A message from the King!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Silence', u'A', u'message', u'from', u'the', u'King']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'A', u'message', u'from', u'the', u'King'],\n",
       "    'original': 'A message from the King!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'A', u'message', u'from', u'the', u'King']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'A', u'message', u'from', u'the', u'King'],\n",
       "    'original': 'A message from the King!',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'A', u'message', u'from', u'the', u'King']}],\n",
       "  'track': 'Farmer Refuted',\n",
       "  'track#': '6'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'You', u'say'],\n",
       "    'original': 'You say',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You', u'say']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'The',\n",
       "     u'price',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'love',\n",
       "     u's',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'price',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'willing',\n",
       "     u'to',\n",
       "     u'pa'],\n",
       "    'original': 'The price of my love\\x92s not a price that you\\x92re willing to pay',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'The',\n",
       "     u'price',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'love',\n",
       "     u's',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'price',\n",
       "     u'that',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'willing',\n",
       "     u'to',\n",
       "     u'pa']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'You', u'cry'],\n",
       "    'original': 'You cry',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You', u'cry']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'In',\n",
       "     u'your',\n",
       "     u'tea',\n",
       "     u'which',\n",
       "     u'you',\n",
       "     u'hurl',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'sea',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'me',\n",
       "     u'go',\n",
       "     u'by'],\n",
       "    'original': 'In your tea which you hurl in the sea when you see me go by',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'In',\n",
       "     u'your',\n",
       "     u'tea',\n",
       "     u'which',\n",
       "     u'you',\n",
       "     u'hurl',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'sea',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'me',\n",
       "     u'go',\n",
       "     u'by']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Why', u'so', u'sad'],\n",
       "    'original': 'Why so sad',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Why', u'so', u'sad']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Remember',\n",
       "     u'we',\n",
       "     u'made',\n",
       "     u'an',\n",
       "     u'arrangement',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'went',\n",
       "     u'away'],\n",
       "    'original': 'Remember we made an arrangement when you went away',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Remember',\n",
       "     u'we',\n",
       "     u'made',\n",
       "     u'an',\n",
       "     u'arrangement',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'went',\n",
       "     u'away']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Now', u'you', u're', u'making', u'me', u'mad'],\n",
       "    'original': 'Now you\\x92re making me mad',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Now', u'you', u're', u'making', u'me', u'mad']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Remember',\n",
       "     u'despite',\n",
       "     u'our',\n",
       "     u'estrangement',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'your',\n",
       "     u'man'],\n",
       "    'original': 'Remember, despite our estrangement, I\\x92m your man',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Remember',\n",
       "     u'despite',\n",
       "     u'our',\n",
       "     u'estrangement',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'your',\n",
       "     u'man']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'You',\n",
       "     u'll',\n",
       "     u'be',\n",
       "     u'back',\n",
       "     u'soon',\n",
       "     u'you',\n",
       "     u'll',\n",
       "     u'se'],\n",
       "    'original': 'You\\x92ll be back, soon you\\x92ll see',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You',\n",
       "     u'll',\n",
       "     u'be',\n",
       "     u'back',\n",
       "     u'soon',\n",
       "     u'you',\n",
       "     u'll',\n",
       "     u'se']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'You',\n",
       "     u'll',\n",
       "     u'remember',\n",
       "     u'you',\n",
       "     u'belong',\n",
       "     u'to',\n",
       "     u'me'],\n",
       "    'original': 'You\\x92ll remember you belong to me',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You',\n",
       "     u'll',\n",
       "     u'remember',\n",
       "     u'you',\n",
       "     u'belong',\n",
       "     u'to',\n",
       "     u'me']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'You', u'll', u'be', u'back', u'time', u'will', u'tell'],\n",
       "    'original': 'You\\x92ll be back, time will tell',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You', u'll', u'be', u'back', u'time', u'will', u'tell']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'You',\n",
       "     u'll',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'served',\n",
       "     u'you',\n",
       "     u'well'],\n",
       "    'original': 'You\\x92ll remember that I served you well',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You',\n",
       "     u'll',\n",
       "     u'remember',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'served',\n",
       "     u'you',\n",
       "     u'well']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Oceans', u'rise', u'empires', u'fall'],\n",
       "    'original': 'Oceans rise, empires fall',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Oceans', u'rise', u'empires', u'fall']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'We',\n",
       "     u'have',\n",
       "     u'seen',\n",
       "     u'each',\n",
       "     u'other',\n",
       "     u'through',\n",
       "     u'it',\n",
       "     u'all'],\n",
       "    'original': 'We have seen each other through it all',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'We',\n",
       "     u'have',\n",
       "     u'seen',\n",
       "     u'each',\n",
       "     u'other',\n",
       "     u'through',\n",
       "     u'it',\n",
       "     u'all']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'And', u'when', u'push', u'comes', u'to', u'shove'],\n",
       "    'original': 'And when push comes to shove',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'And', u'when', u'push', u'comes', u'to', u'shove']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I',\n",
       "     u'will',\n",
       "     u'send',\n",
       "     u'a',\n",
       "     u'fully',\n",
       "     u'armed',\n",
       "     u'battalion',\n",
       "     u'to',\n",
       "     u'remind',\n",
       "     u'you',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'love'],\n",
       "    'original': 'I will send a fully armed battalion to remind you of my love!',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'will',\n",
       "     u'send',\n",
       "     u'a',\n",
       "     u'fully',\n",
       "     u'armed',\n",
       "     u'battalion',\n",
       "     u'to',\n",
       "     u'remind',\n",
       "     u'you',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'love']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da'],\n",
       "    'original': 'Da da da dat da dat da da da da ya da',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Da', u'da', u'dat', u'dat', u'da', u'ya', u'da'],\n",
       "    'original': 'Da da dat dat da ya da!',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da', u'da', u'dat', u'dat', u'da', u'ya', u'da']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da'],\n",
       "    'original': 'Da da da dat da dat da da da da ya da',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Da', u'da', u'dat', u'dat', u'da'],\n",
       "    'original': 'Da da dat dat da\\x85',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da', u'da', u'dat', u'dat', u'da']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'You',\n",
       "     u'say',\n",
       "     u'our',\n",
       "     u'love',\n",
       "     u'is',\n",
       "     u'draining',\n",
       "     u'and',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'go',\n",
       "     u'on'],\n",
       "    'original': 'You say our love is draining and you can\\x92t go on',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You',\n",
       "     u'say',\n",
       "     u'our',\n",
       "     u'love',\n",
       "     u'is',\n",
       "     u'draining',\n",
       "     u'and',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'go',\n",
       "     u'on']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'You',\n",
       "     u'll',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'one',\n",
       "     u'complaining',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'gone'],\n",
       "    'original': 'You\\x92ll be the one complaining when I am gone...',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You',\n",
       "     u'll',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'one',\n",
       "     u'complaining',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'gone']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'And', u'no', u'don', u't', u'change', u'the', u'subject'],\n",
       "    'original': 'And no, don\\x92t change the subject',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'And', u'no', u'don', u't', u'change', u'the', u'subject']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Cuz', u'you', u're', u'my', u'favorite', u'subject'],\n",
       "    'original': 'Cuz you\\x92re my favorite subject',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Cuz', u'you', u're', u'my', u'favorite', u'subject']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'My', u'sweet', u'submissive', u'subject'],\n",
       "    'original': 'My sweet, submissive subject',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'My', u'sweet', u'submissive', u'subject']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'My', u'loyal', u'royal', u'subject'],\n",
       "    'original': 'My loyal, royal subject',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'My', u'loyal', u'royal', u'subject']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Forever',\n",
       "     u'and',\n",
       "     u'ever',\n",
       "     u'and',\n",
       "     u'ever',\n",
       "     u'and',\n",
       "     u'ever',\n",
       "     u'and',\n",
       "     u'ever'],\n",
       "    'original': 'Forever and ever and ever and ever and ever\\x85',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Forever',\n",
       "     u'and',\n",
       "     u'ever',\n",
       "     u'and',\n",
       "     u'ever',\n",
       "     u'and',\n",
       "     u'ever',\n",
       "     u'and',\n",
       "     u'ever']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'You', u'll', u'be', u'back', u'like', u'before'],\n",
       "    'original': 'You\\x92ll be back like before',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'You', u'll', u'be', u'back', u'like', u'before']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'I',\n",
       "     u'will',\n",
       "     u'fight',\n",
       "     u'the',\n",
       "     u'fight',\n",
       "     u'and',\n",
       "     u'win',\n",
       "     u'the',\n",
       "     u'war'],\n",
       "    'original': 'I will fight the fight and win the war',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'will',\n",
       "     u'fight',\n",
       "     u'the',\n",
       "     u'fight',\n",
       "     u'and',\n",
       "     u'win',\n",
       "     u'the',\n",
       "     u'war']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'For', u'your', u'love', u'for', u'your', u'praise'],\n",
       "    'original': 'For your love, for your praise',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'For', u'your', u'love', u'for', u'your', u'praise']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'And',\n",
       "     u'I',\n",
       "     u'll',\n",
       "     u'love',\n",
       "     u'you',\n",
       "     u'till',\n",
       "     u'my',\n",
       "     u'dying',\n",
       "     u'days'],\n",
       "    'original': 'And I\\x92ll love you till my dying days',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'And',\n",
       "     u'I',\n",
       "     u'll',\n",
       "     u'love',\n",
       "     u'you',\n",
       "     u'till',\n",
       "     u'my',\n",
       "     u'dying',\n",
       "     u'days']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'When', u'you', u're', u'gone', u'I', u'll', u'go', u'ma'],\n",
       "    'original': 'When you\\x92re gone, I\\x92ll go mad',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'When', u'you', u're', u'gone', u'I', u'll', u'go', u'ma']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'So',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'throw',\n",
       "     u'away',\n",
       "     u'this',\n",
       "     u'thing',\n",
       "     u'we',\n",
       "     u'had'],\n",
       "    'original': 'So don\\x92t throw away this thing we had',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'So',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'throw',\n",
       "     u'away',\n",
       "     u'this',\n",
       "     u'thing',\n",
       "     u'we',\n",
       "     u'had']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Cuz', u'when', u'push', u'comes', u'to', u'shove'],\n",
       "    'original': 'Cuz when push comes to shove',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Cuz', u'when', u'push', u'comes', u'to', u'shove']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'I',\n",
       "     u'will',\n",
       "     u'kill',\n",
       "     u'your',\n",
       "     u'friends',\n",
       "     u'and',\n",
       "     u'family',\n",
       "     u'to',\n",
       "     u'remind',\n",
       "     u'you',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'love'],\n",
       "    'original': 'I will kill your friends and family to remind you of my love',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'will',\n",
       "     u'kill',\n",
       "     u'your',\n",
       "     u'friends',\n",
       "     u'and',\n",
       "     u'family',\n",
       "     u'to',\n",
       "     u'remind',\n",
       "     u'you',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'love']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da'],\n",
       "    'original': 'Da da da dat da dat da da da da ya da',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Da', u'da', u'dat', u'dat', u'da', u'ya', u'da'],\n",
       "    'original': 'Da da dat dat da ya da!',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da', u'da', u'dat', u'dat', u'da', u'ya', u'da']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da'],\n",
       "    'original': 'Da da da dat da dat da da da da ya da',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Da', u'da', u'dat'],\n",
       "    'original': 'Da da dat\\x97',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da', u'da', u'dat']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Everybody'],\n",
       "    'original': 'Everybody!',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Everybody']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da'],\n",
       "    'original': 'Da da da dat da dat da da da da ya da',\n",
       "    'speakers': ['FULL ENSEMBLE'],\n",
       "    'tokenized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Da', u'da', u'dat', u'dat', u'da', u'ya', u'da'],\n",
       "    'original': 'Da da dat dat da ya da!',\n",
       "    'speakers': ['FULL ENSEMBLE'],\n",
       "    'tokenized': [u'Da', u'da', u'dat', u'dat', u'da', u'ya', u'da']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da'],\n",
       "    'original': 'Da da da dat da dat da da da da ya da da da da',\n",
       "    'speakers': ['FULL ENSEMBLE'],\n",
       "    'tokenized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Dat', u'dat', u'da', u'ya', u'da'],\n",
       "    'original': 'Dat dat da ya da!',\n",
       "    'speakers': ['FULL ENSEMBLE'],\n",
       "    'tokenized': [u'Dat', u'dat', u'da', u'ya', u'da']}],\n",
       "  'track': \"You'll Be Back\",\n",
       "  'track#': '7'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'British',\n",
       "     u'Admiral',\n",
       "     u'Howe',\n",
       "     u's',\n",
       "     u'got',\n",
       "     u'troops',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'water'],\n",
       "    'original': 'British Admiral Howe\\x92s got troops on the water',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'British',\n",
       "     u'Admiral',\n",
       "     u'Howe',\n",
       "     u's',\n",
       "     u'got',\n",
       "     u'troops',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'water']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Thirty',\n",
       "     u'two',\n",
       "     u'thousand',\n",
       "     u'troops',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'harbor'],\n",
       "    'original': 'Thirty-two thousand troops in New York harbor',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Thirty',\n",
       "     u'two',\n",
       "     u'thousand',\n",
       "     u'troops',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'harbor']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Thirty',\n",
       "     u'two',\n",
       "     u'thousand',\n",
       "     u'troops',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'harbor'],\n",
       "    'original': 'Thirty-two thousand troops in New York harbor',\n",
       "    'speakers': ['ENSEMBLE 1'],\n",
       "    'tokenized': [u'Thirty',\n",
       "     u'two',\n",
       "     u'thousand',\n",
       "     u'troops',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'harbor']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'When', u'they', u'surround', u'our', u'troops'],\n",
       "    'original': 'When they surround our troops!',\n",
       "    'speakers': ['ENSEMBLE 1'],\n",
       "    'tokenized': [u'When', u'they', u'surround', u'our', u'troops']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'They', u'surround', u'our', u'troops'],\n",
       "    'original': 'They surround our troops!',\n",
       "    'speakers': ['ENSEMBLE 1'],\n",
       "    'tokenized': [u'They', u'surround', u'our', u'troops']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'When', u'they', u'surround', u'our', u'troops'],\n",
       "    'original': 'When they surround our troops!',\n",
       "    'speakers': ['ENSEMBLE 1'],\n",
       "    'tokenized': [u'When', u'they', u'surround', u'our', u'troops']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Thirty',\n",
       "     u'two',\n",
       "     u'thousand',\n",
       "     u'troops',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'harbor'],\n",
       "    'original': 'Thirty-two thousand troops in New York harbor',\n",
       "    'speakers': ['ENSEMBLE 2'],\n",
       "    'tokenized': [u'Thirty',\n",
       "     u'two',\n",
       "     u'thousand',\n",
       "     u'troops',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'harbor']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'They', u'surround', u'our', u'troops'],\n",
       "    'original': 'They surround our troops!',\n",
       "    'speakers': ['ENSEMBLE 2'],\n",
       "    'tokenized': [u'They', u'surround', u'our', u'troops']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'They', u'surround', u'our', u'troops'],\n",
       "    'original': 'They surround our troops!',\n",
       "    'speakers': ['ENSEMBLE 2'],\n",
       "    'tokenized': [u'They', u'surround', u'our', u'troops']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'As',\n",
       "     u'a',\n",
       "     u'kid',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'Caribbean',\n",
       "     u'I',\n",
       "     u'wished',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'war'],\n",
       "    'original': 'As a kid in the Caribbean I wished for a war',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'As',\n",
       "     u'a',\n",
       "     u'kid',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'Caribbean',\n",
       "     u'I',\n",
       "     u'wished',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'war']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'I', u'knew', u'that', u'I', u'was', u'poor'],\n",
       "    'original': 'I knew that I was poor',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'knew', u'that', u'I', u'was', u'poor']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'I',\n",
       "     u'knew',\n",
       "     u'it',\n",
       "     u'was',\n",
       "     u'the',\n",
       "     u'only',\n",
       "     u'way',\n",
       "     u'to'],\n",
       "    'original': 'I knew it was the only way to\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'knew',\n",
       "     u'it',\n",
       "     u'was',\n",
       "     u'the',\n",
       "     u'only',\n",
       "     u'way',\n",
       "     u'to']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['HAMILTON', 'BURR', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'If', u'they', u'tell', u'my', u'story'],\n",
       "    'original': 'If they tell my story',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If', u'they', u'tell', u'my', u'story']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'I',\n",
       "     u'am',\n",
       "     u'either',\n",
       "     u'gonna',\n",
       "     u'die',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'battlefield',\n",
       "     u'in',\n",
       "     u'glory',\n",
       "     u'or'],\n",
       "    'original': 'I am either gonna die on the battlefield in glory or\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'am',\n",
       "     u'either',\n",
       "     u'gonna',\n",
       "     u'die',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'battlefield',\n",
       "     u'in',\n",
       "     u'glory',\n",
       "     u'or']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['HAMILTON', 'BURR', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'I', u'will', u'fight', u'for', u'this', u'land'],\n",
       "    'original': 'I will fight for this land',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'will', u'fight', u'for', u'this', u'land']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'But', u'there', u's', u'only', u'one', u'man'],\n",
       "    'original': 'But there\\x92s only one man',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But', u'there', u's', u'only', u'one', u'man']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Who',\n",
       "     u'can',\n",
       "     u'give',\n",
       "     u'us',\n",
       "     u'a',\n",
       "     u'command',\n",
       "     u'so',\n",
       "     u'we',\n",
       "     u'can'],\n",
       "    'original': 'Who can give us a command so we can\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Who',\n",
       "     u'can',\n",
       "     u'give',\n",
       "     u'us',\n",
       "     u'a',\n",
       "     u'command',\n",
       "     u'so',\n",
       "     u'we',\n",
       "     u'can']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['HAMILTON', 'BURR', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Understand', u'It', u's', u'the', u'only', u'way', u'to'],\n",
       "    'original': 'Understand? It\\x92s the only way to\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Understand', u'It', u's', u'the', u'only', u'way', u'to']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Rise', u'up', u'Rise', u'up'],\n",
       "    'original': 'Rise up! Rise up!',\n",
       "    'speakers': ['HAMILTON', 'BURR', 'MULLIGAN', 'LAURENS', 'LAFAYETTE'],\n",
       "    'tokenized': [u'Rise', u'up', u'Rise', u'up']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Here', u'he', u'comes'],\n",
       "    'original': 'Here he comes!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Here', u'he', u'comes']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'George',\n",
       "     u'Washington',\n",
       "     u'enters',\n",
       "     u'heralded',\n",
       "     u'by',\n",
       "     u'soldiers'],\n",
       "    'original': '(George Washington enters, heralded by soldiers.)',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'George',\n",
       "     u'Washington',\n",
       "     u'enters',\n",
       "     u'heralded',\n",
       "     u'by',\n",
       "     u'soldiers']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Here', u'comes', u'the', u'General'],\n",
       "    'original': 'Here comes the General!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Here', u'comes', u'the', u'General']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Ladies', u'and', u'gentlemen'],\n",
       "    'original': 'Ladies and gentlemen!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ladies', u'and', u'gentlemen']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Here', u'comes', u'the', u'General'],\n",
       "    'original': 'Here comes the General!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Here', u'comes', u'the', u'General']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'The',\n",
       "     u'moment',\n",
       "     u'you',\n",
       "     u've',\n",
       "     u'been',\n",
       "     u'waiting',\n",
       "     u'for'],\n",
       "    'original': 'The moment you\\x92ve been waiting for!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The',\n",
       "     u'moment',\n",
       "     u'you',\n",
       "     u've',\n",
       "     u'been',\n",
       "     u'waiting',\n",
       "     u'for']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Here', u'comes', u'the', u'General'],\n",
       "    'original': 'Here comes the General!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Here', u'comes', u'the', u'General']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'The', u'pride', u'of', u'Mount', u'Vernon'],\n",
       "    'original': 'The pride of Mount Vernon!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'pride', u'of', u'Mount', u'Vernon']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Here', u'comes', u'the', u'General'],\n",
       "    'original': 'Here comes the General!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Here', u'comes', u'the', u'General']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'George', u'Washington'],\n",
       "    'original': 'George Washington!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'George', u'Washington']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'We', u'are', u'outgunned'],\n",
       "    'original': 'We are outgunned',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We', u'are', u'outgunned']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Outmanned'],\n",
       "    'original': 'Outmanned',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Outmanned']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Outnumbered'],\n",
       "    'original': 'Outnumbered',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Outnumbered']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Outplanned'],\n",
       "    'original': 'Outplanned',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Outplanned']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'We', u'gotta', u'make', u'an', u'all', u'out', u'stand'],\n",
       "    'original': 'We gotta make an all out stand',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We', u'gotta', u'make', u'an', u'all', u'out', u'stand']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Ayo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'gonna',\n",
       "     u'need',\n",
       "     u'a',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man'],\n",
       "    'original': 'Ayo, I\\x92m gonna need a right-hand man.',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Ayo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'gonna',\n",
       "     u'need',\n",
       "     u'a',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Buck', u'buck', u'buck', u'buck', u'buck'],\n",
       "    'original': 'Buck, buck, buck, buck, buck!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Buck', u'buck', u'buck', u'buck', u'buck']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Buck', u'buck', u'buck', u'buck', u'buck'],\n",
       "    'original': 'Buck, buck, buck, buck, buck!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Buck', u'buck', u'buck', u'buck', u'buck']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Check', u'it'],\n",
       "    'original': 'Check it\\x97',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Check', u'it']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Can', u'I', u'be', u'real', u'a', u'second'],\n",
       "    'original': 'Can I be real a second?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Can', u'I', u'be', u'real', u'a', u'second']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'For', u'just', u'a', u'millisecond'],\n",
       "    'original': 'For just a millisecond?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'For', u'just', u'a', u'millisecond']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Let',\n",
       "     u'down',\n",
       "     u'my',\n",
       "     u'guard',\n",
       "     u'and',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'people',\n",
       "     u'how',\n",
       "     u'I',\n",
       "     u'feel',\n",
       "     u'a',\n",
       "     u'second'],\n",
       "    'original': 'Let down my guard and tell the people how I feel a second?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Let',\n",
       "     u'down',\n",
       "     u'my',\n",
       "     u'guard',\n",
       "     u'and',\n",
       "     u'tell',\n",
       "     u'the',\n",
       "     u'people',\n",
       "     u'how',\n",
       "     u'I',\n",
       "     u'feel',\n",
       "     u'a',\n",
       "     u'second']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Now',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'the',\n",
       "     u'model',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'modern',\n",
       "     u'major',\n",
       "     u'general'],\n",
       "    'original': 'Now I\\x92m the model of a modern major general',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'the',\n",
       "     u'model',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'modern',\n",
       "     u'major',\n",
       "     u'general']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'The',\n",
       "     u'venerated',\n",
       "     u'Virginian',\n",
       "     u'veteran',\n",
       "     u'whose',\n",
       "     u'men',\n",
       "     u'are',\n",
       "     u'all'],\n",
       "    'original': 'The venerated Virginian veteran whose men are all',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'venerated',\n",
       "     u'Virginian',\n",
       "     u'veteran',\n",
       "     u'whose',\n",
       "     u'men',\n",
       "     u'are',\n",
       "     u'all']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Lining',\n",
       "     u'up',\n",
       "     u'to',\n",
       "     u'put',\n",
       "     u'me',\n",
       "     u'up',\n",
       "     u'on',\n",
       "     u'a',\n",
       "     u'pedestal'],\n",
       "    'original': 'Lining up, to put me up on a pedestal',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Lining',\n",
       "     u'up',\n",
       "     u'to',\n",
       "     u'put',\n",
       "     u'me',\n",
       "     u'up',\n",
       "     u'on',\n",
       "     u'a',\n",
       "     u'pedestal']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Writin', u'letters', u'to', u'relatives'],\n",
       "    'original': 'Writin\\x92 letters to relatives',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Writin', u'letters', u'to', u'relatives']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Embellishin', u'my', u'elegance', u'and', u'eloquence'],\n",
       "    'original': 'Embellishin\\x92 my elegance and eloquence',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Embellishin', u'my', u'elegance', u'and', u'eloquence']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'But', u'the', u'elephant', u'is', u'in', u'the', u'room'],\n",
       "    'original': 'But the elephant is in the room',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'But', u'the', u'elephant', u'is', u'in', u'the', u'room']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'The',\n",
       "     u'truth',\n",
       "     u'is',\n",
       "     u'in',\n",
       "     u'ya',\n",
       "     u'face',\n",
       "     u'when',\n",
       "     u'ya',\n",
       "     u'hear',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'cannons',\n",
       "     u'go'],\n",
       "    'original': 'The truth is in ya face when ya hear the British cannons go\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'truth',\n",
       "     u'is',\n",
       "     u'in',\n",
       "     u'ya',\n",
       "     u'face',\n",
       "     u'when',\n",
       "     u'ya',\n",
       "     u'hear',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'cannons',\n",
       "     u'go']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Boom'],\n",
       "    'original': 'Boom!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Boom']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Any', u'hope', u'of', u'success', u'is', u'fleeting'],\n",
       "    'original': 'Any hope of success is fleeting',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Any', u'hope', u'of', u'success', u'is', u'fleeting']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'How',\n",
       "     u'can',\n",
       "     u'I',\n",
       "     u'keep',\n",
       "     u'leading',\n",
       "     u'when',\n",
       "     u'the',\n",
       "     u'people',\n",
       "     u'I',\n",
       "     u'm'],\n",
       "    'original': 'How can I keep leading when the people I\\x92m',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'How',\n",
       "     u'can',\n",
       "     u'I',\n",
       "     u'keep',\n",
       "     u'leading',\n",
       "     u'when',\n",
       "     u'the',\n",
       "     u'people',\n",
       "     u'I',\n",
       "     u'm']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Leading', u'keep', u'retreating'],\n",
       "    'original': 'Leading keep retreating?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Leading', u'keep', u'retreating']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'We',\n",
       "     u'put',\n",
       "     u'a',\n",
       "     u'stop',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'bleeding',\n",
       "     u'as',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'take',\n",
       "     u'Brooklyn'],\n",
       "    'original': 'We put a stop to the bleeding as the British take Brooklyn',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'put',\n",
       "     u'a',\n",
       "     u'stop',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'bleeding',\n",
       "     u'as',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'take',\n",
       "     u'Brooklyn']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Knight', u'takes', u'rook', u'but', u'look'],\n",
       "    'original': 'Knight takes rook, but look',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Knight', u'takes', u'rook', u'but', u'look']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'We', u'are', u'outgunned'],\n",
       "    'original': 'We are outgunned',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We', u'are', u'outgunned']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Outmanned'],\n",
       "    'original': 'Outmanned',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Outmanned']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Outnumbered'],\n",
       "    'original': 'Outnumbered',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Outnumbered']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Outplanned'],\n",
       "    'original': 'Outplanned',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Outplanned']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'We', u'gotta', u'make', u'an', u'all', u'out', u'stand'],\n",
       "    'original': 'We gotta make an all out stand',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We', u'gotta', u'make', u'an', u'all', u'out', u'stand']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Ayo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'gonna',\n",
       "     u'need',\n",
       "     u'a',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man'],\n",
       "    'original': 'Ayo, I\\x92m gonna need a right-hand man',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Ayo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'gonna',\n",
       "     u'need',\n",
       "     u'a',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'man']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Incoming'],\n",
       "    'original': 'Incoming!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Incoming']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'Buck', u'buck', u'buck', u'buck', u'buck'],\n",
       "    'original': 'Buck, buck, buck, buck, buck!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Buck', u'buck', u'buck', u'buck', u'buck']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Buck', u'buck', u'buck', u'buck', u'buck'],\n",
       "    'original': 'Buck, buck, buck, buck, buck!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Buck', u'buck', u'buck', u'buck', u'buck']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'They',\n",
       "     u're',\n",
       "     u'battering',\n",
       "     u'down',\n",
       "     u'the',\n",
       "     u'Battery',\n",
       "     u'check',\n",
       "     u'the',\n",
       "     u'damages'],\n",
       "    'original': 'They\\x92re battering down the Battery check the damages',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'They',\n",
       "     u're',\n",
       "     u'battering',\n",
       "     u'down',\n",
       "     u'the',\n",
       "     u'Battery',\n",
       "     u'check',\n",
       "     u'the',\n",
       "     u'damages']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'Rah'],\n",
       "    'original': 'Rah!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Rah']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'We',\n",
       "     u'gotta',\n",
       "     u'stop',\n",
       "     u'em',\n",
       "     u'and',\n",
       "     u'rob',\n",
       "     u'em',\n",
       "     u'of',\n",
       "     u'their',\n",
       "     u'advantage'],\n",
       "    'original': 'We gotta stop \\x91em and rob \\x91em of their advantages',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'gotta',\n",
       "     u'stop',\n",
       "     u'em',\n",
       "     u'and',\n",
       "     u'rob',\n",
       "     u'em',\n",
       "     u'of',\n",
       "     u'their',\n",
       "     u'advantage']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Rah'],\n",
       "    'original': 'Rah!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Rah']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'Let',\n",
       "     u's',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'stand',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'stamina',\n",
       "     u'God',\n",
       "     u'has',\n",
       "     u'granted',\n",
       "     u'us'],\n",
       "    'original': 'Let\\x92s take a stand with the stamina God has granted us',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Let',\n",
       "     u's',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'stand',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'stamina',\n",
       "     u'God',\n",
       "     u'has',\n",
       "     u'granted',\n",
       "     u'us']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Hamilton', u'won', u't', u'abandon', u'ship'],\n",
       "    'original': 'Hamilton won\\x92t abandon ship',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hamilton', u'won', u't', u'abandon', u'ship']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Yo', u'let', u's', u'steal', u'their', u'cannons'],\n",
       "    'original': 'Yo, let\\x92s steal their cannons\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yo', u'let', u's', u'steal', u'their', u'cannons']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'Shh', u'boom'],\n",
       "    'original': 'Shh-boom!',\n",
       "    'speakers': ['MULLIGAN'],\n",
       "    'tokenized': [u'Shh', u'boom']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'Boom'],\n",
       "    'original': 'Boom!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Boom']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Goes',\n",
       "     u'the',\n",
       "     u'cannon',\n",
       "     u'watch',\n",
       "     u'the',\n",
       "     u'blood',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'shit',\n",
       "     u'spray',\n",
       "     u'and'],\n",
       "    'original': 'Goes the cannon, watch the blood and the shit spray and\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Goes',\n",
       "     u'the',\n",
       "     u'cannon',\n",
       "     u'watch',\n",
       "     u'the',\n",
       "     u'blood',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'shit',\n",
       "     u'spray',\n",
       "     u'and']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Boom'],\n",
       "    'original': 'Boom!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Boom']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'Goes',\n",
       "     u'the',\n",
       "     u'cannon',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'abandonin',\n",
       "     u'Kips',\n",
       "     u'Bay',\n",
       "     u'an'],\n",
       "    'original': 'Goes the cannon, we\\x92re abandonin\\x92 Kips Bay and\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Goes',\n",
       "     u'the',\n",
       "     u'cannon',\n",
       "     u'we',\n",
       "     u're',\n",
       "     u'abandonin',\n",
       "     u'Kips',\n",
       "     u'Bay',\n",
       "     u'an']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'Boom'],\n",
       "    'original': 'Boom!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Boom']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'There', u's', u'another', u'ship', u'and'],\n",
       "    'original': 'There\\x92s another ship and\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'There', u's', u'another', u'ship', u'and']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'Boom'],\n",
       "    'original': 'Boom!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Boom']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'We',\n",
       "     u'just',\n",
       "     u'lost',\n",
       "     u'the',\n",
       "     u'southern',\n",
       "     u'tip',\n",
       "     u'and'],\n",
       "    'original': 'We just lost the southern tip and\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'just',\n",
       "     u'lost',\n",
       "     u'the',\n",
       "     u'southern',\n",
       "     u'tip',\n",
       "     u'and']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'Boom'],\n",
       "    'original': 'Boom!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Boom']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'We',\n",
       "     u'gotta',\n",
       "     u'run',\n",
       "     u'to',\n",
       "     u'Harlem',\n",
       "     u'quick',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'afford',\n",
       "     u'another',\n",
       "     u'slip'],\n",
       "    'original': 'We gotta run to Harlem quick, we can\\x92t afford another slip',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'gotta',\n",
       "     u'run',\n",
       "     u'to',\n",
       "     u'Harlem',\n",
       "     u'quick',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u't',\n",
       "     u'afford',\n",
       "     u'another',\n",
       "     u'slip']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'Guns', u'and', u'horses', u'giddyup'],\n",
       "    'original': 'Guns and horses giddyup',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Guns', u'and', u'horses', u'giddyup']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'I', u'decide', u'to', u'divvy', u'up'],\n",
       "    'original': 'I decide to divvy up',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'decide', u'to', u'divvy', u'up']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'My',\n",
       "     u'forces',\n",
       "     u'they',\n",
       "     u're',\n",
       "     u'skittish',\n",
       "     u'as',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'cut',\n",
       "     u'the',\n",
       "     u'city',\n",
       "     u'up'],\n",
       "    'original': 'My forces, they\\x92re skittish as the British cut the city up',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'My',\n",
       "     u'forces',\n",
       "     u'they',\n",
       "     u're',\n",
       "     u'skittish',\n",
       "     u'as',\n",
       "     u'the',\n",
       "     u'British',\n",
       "     u'cut',\n",
       "     u'the',\n",
       "     u'city',\n",
       "     u'up']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'This',\n",
       "     u'close',\n",
       "     u'to',\n",
       "     u'giving',\n",
       "     u'up',\n",
       "     u'facing',\n",
       "     u'mad',\n",
       "     u'scrutiny'],\n",
       "    'original': 'This close to giving up, facing mad scrutiny',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'close',\n",
       "     u'to',\n",
       "     u'giving',\n",
       "     u'up',\n",
       "     u'facing',\n",
       "     u'mad',\n",
       "     u'scrutiny']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'I',\n",
       "     u'scream',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'face',\n",
       "     u'of',\n",
       "     u'this',\n",
       "     u'mass',\n",
       "     u'mutiny'],\n",
       "    'original': 'I scream in the face of this mass mutiny:',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'scream',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'face',\n",
       "     u'of',\n",
       "     u'this',\n",
       "     u'mass',\n",
       "     u'mutiny']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Are',\n",
       "     u'these',\n",
       "     u'the',\n",
       "     u'men',\n",
       "     u'with',\n",
       "     u'which',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'to',\n",
       "     u'defend',\n",
       "     u'America'],\n",
       "    'original': 'Are these the men with which I am to defend America?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Are',\n",
       "     u'these',\n",
       "     u'the',\n",
       "     u'men',\n",
       "     u'with',\n",
       "     u'which',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'to',\n",
       "     u'defend',\n",
       "     u'America']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'We',\n",
       "     u'ride',\n",
       "     u'at',\n",
       "     u'midnight',\n",
       "     u'Manhattan',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'distance'],\n",
       "    'original': 'We ride at midnight, Manhattan in the distance',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'ride',\n",
       "     u'at',\n",
       "     u'midnight',\n",
       "     u'Manhattan',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'distance']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'I',\n",
       "     u'cannot',\n",
       "     u'be',\n",
       "     u'everywhere',\n",
       "     u'at',\n",
       "     u'once',\n",
       "     u'people'],\n",
       "    'original': 'I cannot be everywhere at once, people',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'cannot',\n",
       "     u'be',\n",
       "     u'everywhere',\n",
       "     u'at',\n",
       "     u'once',\n",
       "     u'people']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'I', u'm', u'in', u'dire', u'need', u'of', u'assistance'],\n",
       "    'original': 'I\\x92m in dire need of assistance\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'm', u'in', u'dire', u'need', u'of', u'assistance']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u\"Washington's\", u'tent', u'Burr', u'enters'],\n",
       "    'original': \"(Washington's tent. Burr enters.)\",\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u\"Washington's\", u'tent', u'Burr', u'enters']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'Your', u'excellency', u'sir'],\n",
       "    'original': 'Your excellency, sir!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Your', u'excellency', u'sir']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'Who', u'are', u'you'],\n",
       "    'original': 'Who are you?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Who', u'are', u'you']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Aaron', u'Burr', u'Sir'],\n",
       "    'original': 'Aaron Burr, Sir?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Aaron', u'Burr', u'Sir']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'Permission', u'to', u'state', u'my', u'case'],\n",
       "    'original': 'Permission to state my case?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Permission', u'to', u'state', u'my', u'case']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'As', u'you', u'were'],\n",
       "    'original': 'As you were',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'As', u'you', u'were']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'I',\n",
       "     u'was',\n",
       "     u'a',\n",
       "     u'captain',\n",
       "     u'under',\n",
       "     u'General',\n",
       "     u'Montgomery'],\n",
       "    'original': 'I was a captain under General Montgomery',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'was',\n",
       "     u'a',\n",
       "     u'captain',\n",
       "     u'under',\n",
       "     u'General',\n",
       "     u'Montgomery']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'Until',\n",
       "     u'he',\n",
       "     u'caught',\n",
       "     u'a',\n",
       "     u'bullet',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'neck',\n",
       "     u'in',\n",
       "     u'Quebec'],\n",
       "    'original': 'Until he caught a bullet in the neck in Quebec',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Until',\n",
       "     u'he',\n",
       "     u'caught',\n",
       "     u'a',\n",
       "     u'bullet',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'neck',\n",
       "     u'in',\n",
       "     u'Quebec']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'And', u'well', u'in', u'summary'],\n",
       "    'original': 'And well, in summary',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'well', u'in', u'summary']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'I',\n",
       "     u'think',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'be',\n",
       "     u'of',\n",
       "     u'some',\n",
       "     u'assistance'],\n",
       "    'original': 'I think that I could be of some assistance',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'think',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'be',\n",
       "     u'of',\n",
       "     u'some',\n",
       "     u'assistance']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'I',\n",
       "     u'admire',\n",
       "     u'how',\n",
       "     u'you',\n",
       "     u'keep',\n",
       "     u'firing',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'British'],\n",
       "    'original': 'I admire how you keep firing on the British',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'admire',\n",
       "     u'how',\n",
       "     u'you',\n",
       "     u'keep',\n",
       "     u'firing',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'British']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'From', u'a', u'distance'],\n",
       "    'original': 'From a distance',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'From', u'a', u'distance']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'Huh'],\n",
       "    'original': 'Huh',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Huh']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'some',\n",
       "     u'questions',\n",
       "     u'a',\n",
       "     u'couple',\n",
       "     u'of',\n",
       "     u'suggestions',\n",
       "     u'on',\n",
       "     u'how',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'instead',\n",
       "     u'of',\n",
       "     u'fleeing',\n",
       "     u'west'],\n",
       "    'original': 'I have some questions, a couple of suggestions on how to fight instead of fleeing west',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'some',\n",
       "     u'questions',\n",
       "     u'a',\n",
       "     u'couple',\n",
       "     u'of',\n",
       "     u'suggestions',\n",
       "     u'on',\n",
       "     u'how',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'instead',\n",
       "     u'of',\n",
       "     u'fleeing',\n",
       "     u'west']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'Well'],\n",
       "    'original': 'Well\\x97',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Well']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'Your',\n",
       "     u'excellency',\n",
       "     u'you',\n",
       "     u'wanted',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'me'],\n",
       "    'original': 'Your excellency, you wanted to see me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Your',\n",
       "     u'excellency',\n",
       "     u'you',\n",
       "     u'wanted',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'me']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'Hamilton',\n",
       "     u'come',\n",
       "     u'in',\n",
       "     u'have',\n",
       "     u'you',\n",
       "     u'met',\n",
       "     u'Burr'],\n",
       "    'original': 'Hamilton, come in, have you met Burr?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Hamilton',\n",
       "     u'come',\n",
       "     u'in',\n",
       "     u'have',\n",
       "     u'you',\n",
       "     u'met',\n",
       "     u'Burr']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'Yes', u'sir'],\n",
       "    'original': 'Yes, sir',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes', u'sir']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'We', u'keep', u'meeting'],\n",
       "    'original': 'We keep meeting',\n",
       "    'speakers': ['HAMILTON', 'BURR'],\n",
       "    'tokenized': [u'We', u'keep', u'meeting']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'As',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'saying',\n",
       "     u'sir',\n",
       "     u'I',\n",
       "     u'look',\n",
       "     u'forward',\n",
       "     u'to',\n",
       "     u'seeing',\n",
       "     u'your',\n",
       "     u'strategy',\n",
       "     u'play',\n",
       "     u'out'],\n",
       "    'original': 'As I was saying, sir, I look forward to seeing your strategy play out',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'As',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'saying',\n",
       "     u'sir',\n",
       "     u'I',\n",
       "     u'look',\n",
       "     u'forward',\n",
       "     u'to',\n",
       "     u'seeing',\n",
       "     u'your',\n",
       "     u'strategy',\n",
       "     u'play',\n",
       "     u'out']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'Close', u'the', u'door', u'on', u'your', u'way', u'out'],\n",
       "    'original': 'Close the door on your way out',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Close', u'the', u'door', u'on', u'your', u'way', u'out']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'Burr', u'exits'],\n",
       "    'original': '(Burr exits.)',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Burr', u'exits']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'Have', u'I', u'done', u'something', u'wrong', u'sir'],\n",
       "    'original': 'Have I done something wrong, sir?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Have', u'I', u'done', u'something', u'wrong', u'sir']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'On', u'the', u'contrary'],\n",
       "    'original': 'On the contrary',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'On', u'the', u'contrary']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'I',\n",
       "     u'called',\n",
       "     u'you',\n",
       "     u'here',\n",
       "     u'because',\n",
       "     u'our',\n",
       "     u'odds',\n",
       "     u'are',\n",
       "     u'beyond',\n",
       "     u'scary'],\n",
       "    'original': 'I called you here because our odds are beyond scary',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'called',\n",
       "     u'you',\n",
       "     u'here',\n",
       "     u'because',\n",
       "     u'our',\n",
       "     u'odds',\n",
       "     u'are',\n",
       "     u'beyond',\n",
       "     u'scary']},\n",
       "   {'line#': 126,\n",
       "    'normalized': [u'Your',\n",
       "     u'reputation',\n",
       "     u'precedes',\n",
       "     u'you',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'laugh'],\n",
       "    'original': 'Your reputation precedes you, but I have to laugh',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Your',\n",
       "     u'reputation',\n",
       "     u'precedes',\n",
       "     u'you',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'laugh']},\n",
       "   {'line#': 127,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 128,\n",
       "    'normalized': [u'Hamilton',\n",
       "     u'how',\n",
       "     u'come',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'can',\n",
       "     u'get',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'their',\n",
       "     u'staff'],\n",
       "    'original': 'Hamilton, how come no one can get you on their staff?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Hamilton',\n",
       "     u'how',\n",
       "     u'come',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'can',\n",
       "     u'get',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'their',\n",
       "     u'staff']},\n",
       "   {'line#': 129,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 130,\n",
       "    'normalized': [u'Don',\n",
       "     u't',\n",
       "     u'get',\n",
       "     u'me',\n",
       "     u'wrong',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'a',\n",
       "     u'young',\n",
       "     u'man',\n",
       "     u'of',\n",
       "     u'great',\n",
       "     u'renow'],\n",
       "    'original': 'Don\\x92t get me wrong, you\\x92re a young man of great renown',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Don',\n",
       "     u't',\n",
       "     u'get',\n",
       "     u'me',\n",
       "     u'wrong',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'a',\n",
       "     u'young',\n",
       "     u'man',\n",
       "     u'of',\n",
       "     u'great',\n",
       "     u'renow']},\n",
       "   {'line#': 131,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'stole',\n",
       "     u'British',\n",
       "     u'cannons',\n",
       "     u'when',\n",
       "     u'we',\n",
       "     u'were',\n",
       "     u'still',\n",
       "     u'downtown'],\n",
       "    'original': 'I know you stole British cannons when we were still downtown',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'stole',\n",
       "     u'British',\n",
       "     u'cannons',\n",
       "     u'when',\n",
       "     u'we',\n",
       "     u'were',\n",
       "     u'still',\n",
       "     u'downtown']},\n",
       "   {'line#': 132,\n",
       "    'normalized': [u'Nathaniel',\n",
       "     u'Green',\n",
       "     u'and',\n",
       "     u'Henry',\n",
       "     u'Knox',\n",
       "     u'wanted',\n",
       "     u'to',\n",
       "     u'hire',\n",
       "     u'you'],\n",
       "    'original': 'Nathaniel Green and Henry Knox wanted to hire you\\x85',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Nathaniel',\n",
       "     u'Green',\n",
       "     u'and',\n",
       "     u'Henry',\n",
       "     u'Knox',\n",
       "     u'wanted',\n",
       "     u'to',\n",
       "     u'hire',\n",
       "     u'you']},\n",
       "   {'line#': 133,\n",
       "    'normalized': [u'To',\n",
       "     u'be',\n",
       "     u'their',\n",
       "     u'Secretary',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'think',\n",
       "     u'so'],\n",
       "    'original': 'To be their Secretary? I don\\x92t think so',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'To',\n",
       "     u'be',\n",
       "     u'their',\n",
       "     u'Secretary',\n",
       "     u'I',\n",
       "     u'don',\n",
       "     u't',\n",
       "     u'think',\n",
       "     u'so']},\n",
       "   {'line#': 134,\n",
       "    'normalized': [u'Why', u're', u'you', u'upset'],\n",
       "    'original': 'Why\\x92re you upset?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Why', u're', u'you', u'upset']},\n",
       "   {'line#': 135,\n",
       "    'normalized': [u'I', u'm', u'not'],\n",
       "    'original': 'I\\x92m not\\x97',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'm', u'not']},\n",
       "   {'line#': 136,\n",
       "    'normalized': [u'It',\n",
       "     u's',\n",
       "     u'alright',\n",
       "     u'you',\n",
       "     u'want',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'you',\n",
       "     u've',\n",
       "     u'got',\n",
       "     u'a',\n",
       "     u'hunge'],\n",
       "    'original': 'It\\x92s alright, you want to fight, you\\x92ve got a hunger',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'It',\n",
       "     u's',\n",
       "     u'alright',\n",
       "     u'you',\n",
       "     u'want',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'you',\n",
       "     u've',\n",
       "     u'got',\n",
       "     u'a',\n",
       "     u'hunge']},\n",
       "   {'line#': 137,\n",
       "    'normalized': [u'I',\n",
       "     u'was',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'younger'],\n",
       "    'original': 'I was just like you when I was younger',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'was',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'younger']},\n",
       "   {'line#': 138,\n",
       "    'normalized': [u'Head',\n",
       "     u'full',\n",
       "     u'of',\n",
       "     u'fantasies',\n",
       "     u'of',\n",
       "     u'dyin',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'martyr'],\n",
       "    'original': 'Head full of fantasies of dyin\\x92 like a martyr?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Head',\n",
       "     u'full',\n",
       "     u'of',\n",
       "     u'fantasies',\n",
       "     u'of',\n",
       "     u'dyin',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'martyr']},\n",
       "   {'line#': 139,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 140,\n",
       "    'normalized': [u'Dying',\n",
       "     u'is',\n",
       "     u'easy',\n",
       "     u'young',\n",
       "     u'man',\n",
       "     u'Living',\n",
       "     u'is',\n",
       "     u'harder'],\n",
       "    'original': 'Dying is easy, young man. Living is harder',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Dying',\n",
       "     u'is',\n",
       "     u'easy',\n",
       "     u'young',\n",
       "     u'man',\n",
       "     u'Living',\n",
       "     u'is',\n",
       "     u'harder']},\n",
       "   {'line#': 141,\n",
       "    'normalized': [u'Why', u'are', u'you', u'telling', u'me', u'this'],\n",
       "    'original': 'Why are you telling me this?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Why', u'are', u'you', u'telling', u'me', u'this']},\n",
       "   {'line#': 142,\n",
       "    'normalized': [u'I', u'm', u'being', u'honest'],\n",
       "    'original': 'I\\x92m being honest',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'm', u'being', u'honest']},\n",
       "   {'line#': 143,\n",
       "    'normalized': [u'I',\n",
       "     u'm',\n",
       "     u'working',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'third',\n",
       "     u'of',\n",
       "     u'what',\n",
       "     u'our',\n",
       "     u'Congress',\n",
       "     u'has',\n",
       "     u'promised'],\n",
       "    'original': 'I\\x92m working with a third of what our Congress has promised',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'm',\n",
       "     u'working',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'third',\n",
       "     u'of',\n",
       "     u'what',\n",
       "     u'our',\n",
       "     u'Congress',\n",
       "     u'has',\n",
       "     u'promised']},\n",
       "   {'line#': 144,\n",
       "    'normalized': [u'We',\n",
       "     u'are',\n",
       "     u'a',\n",
       "     u'powder',\n",
       "     u'keg',\n",
       "     u'about',\n",
       "     u'to',\n",
       "     u'explode'],\n",
       "    'original': 'We are a powder keg about to explode',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'are',\n",
       "     u'a',\n",
       "     u'powder',\n",
       "     u'keg',\n",
       "     u'about',\n",
       "     u'to',\n",
       "     u'explode']},\n",
       "   {'line#': 145,\n",
       "    'normalized': [u'I',\n",
       "     u'need',\n",
       "     u'someone',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'lighten',\n",
       "     u'the',\n",
       "     u'load',\n",
       "     u'So'],\n",
       "    'original': 'I need someone like you to lighten the load. So?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'need',\n",
       "     u'someone',\n",
       "     u'like',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'lighten',\n",
       "     u'the',\n",
       "     u'load',\n",
       "     u'So']},\n",
       "   {'line#': 146,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwin\\x92 away my shot!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot']},\n",
       "   {'line#': 147,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwin\\x92 away my shot!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwin', u'away', u'my', u'shot']},\n",
       "   {'line#': 148,\n",
       "    'normalized': [u'Ayo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'youn'],\n",
       "    'original': 'Ayo, I\\x92m just like my country, I\\x92m young',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Ayo',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'just',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'country',\n",
       "     u'I',\n",
       "     u'm',\n",
       "     u'youn']},\n",
       "   {'line#': 149,\n",
       "    'normalized': [u'Scrappy', u'and', u'hungry'],\n",
       "    'original': 'Scrappy and hungry!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Scrappy', u'and', u'hungry']},\n",
       "   {'line#': 150,\n",
       "    'normalized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot'],\n",
       "    'original': 'I am not throwing away my shot!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'not', u'throwing', u'away', u'my', u'shot']},\n",
       "   {'line#': 151,\n",
       "    'normalized': [u'Son'],\n",
       "    'original': 'Son',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Son']},\n",
       "   {'line#': 152,\n",
       "    'normalized': [u'We', u'are', u'outgunned', u'outmanned'],\n",
       "    'original': 'We are outgunned, outmanned!',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'We', u'are', u'outgunned', u'outmanned']},\n",
       "   {'line#': 153,\n",
       "    'normalized': [u'You',\n",
       "     u'need',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'help',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'get'],\n",
       "    'original': 'You need all the help you can get',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'need',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'help',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'get']},\n",
       "   {'line#': 154,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'some',\n",
       "     u'friends',\n",
       "     u'Laurens',\n",
       "     u'Mulligan'],\n",
       "    'original': 'I have some friends. Laurens, Mulligan',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'some',\n",
       "     u'friends',\n",
       "     u'Laurens',\n",
       "     u'Mulligan']},\n",
       "   {'line#': 155,\n",
       "    'normalized': [u'Marquis', u'de', u'Lafayette', u'okay', u'what', u'else'],\n",
       "    'original': 'Marquis de Lafayette, okay, what else?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Marquis', u'de', u'Lafayette', u'okay', u'what', u'else']},\n",
       "   {'line#': 156,\n",
       "    'normalized': [u'Outnumbered', u'outplanned'],\n",
       "    'original': 'Outnumbered, outplanned!',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Outnumbered', u'outplanned']},\n",
       "   {'line#': 157,\n",
       "    'normalized': [u'We',\n",
       "     u'll',\n",
       "     u'need',\n",
       "     u'some',\n",
       "     u'spies',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'inside'],\n",
       "    'original': 'We\\x92ll need some spies on the inside',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'll',\n",
       "     u'need',\n",
       "     u'some',\n",
       "     u'spies',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'inside']},\n",
       "   {'line#': 158,\n",
       "    'normalized': [u'Some',\n",
       "     u'King',\n",
       "     u's',\n",
       "     u'men',\n",
       "     u'who',\n",
       "     u'might',\n",
       "     u'let',\n",
       "     u'some',\n",
       "     u'things',\n",
       "     u'slide'],\n",
       "    'original': 'Some King\\x92s men who might let some things slide',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Some',\n",
       "     u'King',\n",
       "     u's',\n",
       "     u'men',\n",
       "     u'who',\n",
       "     u'might',\n",
       "     u'let',\n",
       "     u'some',\n",
       "     u'things',\n",
       "     u'slide']},\n",
       "   {'line#': 159,\n",
       "    'normalized': [u'I',\n",
       "     u'll',\n",
       "     u'write',\n",
       "     u'to',\n",
       "     u'Congress',\n",
       "     u'and',\n",
       "     u'tell',\n",
       "     u'em',\n",
       "     u'we',\n",
       "     u'need',\n",
       "     u'supplies',\n",
       "     u'you',\n",
       "     u'rally',\n",
       "     u'the',\n",
       "     u'guys'],\n",
       "    'original': 'I\\x92ll write to Congress and tell \\x91em we need supplies, you rally the guys,',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'll',\n",
       "     u'write',\n",
       "     u'to',\n",
       "     u'Congress',\n",
       "     u'and',\n",
       "     u'tell',\n",
       "     u'em',\n",
       "     u'we',\n",
       "     u'need',\n",
       "     u'supplies',\n",
       "     u'you',\n",
       "     u'rally',\n",
       "     u'the',\n",
       "     u'guys']},\n",
       "   {'line#': 160,\n",
       "    'normalized': [u'Master', u'the', u'element', u'of', u'surprise'],\n",
       "    'original': 'Master the element of surprise',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Master', u'the', u'element', u'of', u'surprise']},\n",
       "   {'line#': 161,\n",
       "    'normalized': [u'I',\n",
       "     u'll',\n",
       "     u'rise',\n",
       "     u'above',\n",
       "     u'my',\n",
       "     u'station',\n",
       "     u'organize',\n",
       "     u'your',\n",
       "     u'information',\n",
       "     u'til',\n",
       "     u'we',\n",
       "     u'rise',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'occasion',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'new',\n",
       "     u'nation',\n",
       "     u'Sir'],\n",
       "    'original': 'I\\x92ll rise above my station, organize your information, \\x91til we rise to the occasion of our new nation. Sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'll',\n",
       "     u'rise',\n",
       "     u'above',\n",
       "     u'my',\n",
       "     u'station',\n",
       "     u'organize',\n",
       "     u'your',\n",
       "     u'information',\n",
       "     u'til',\n",
       "     u'we',\n",
       "     u'rise',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'occasion',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'new',\n",
       "     u'nation',\n",
       "     u'Sir']},\n",
       "   {'line#': 162,\n",
       "    'normalized': [u'Boom'],\n",
       "    'original': 'Boom!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Boom']},\n",
       "   {'line#': 163,\n",
       "    'normalized': [u'Chicka', u'boom'],\n",
       "    'original': 'Chicka-boom!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Chicka', u'boom']},\n",
       "   {'line#': 164,\n",
       "    'normalized': [u'Whoa', u'whoa', u'whoa'],\n",
       "    'original': 'Whoa, whoa, whoa...',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY', 'WOMEN'],\n",
       "    'tokenized': [u'Whoa', u'whoa', u'whoa']},\n",
       "   {'line#': 165,\n",
       "    'normalized': [u'Whoa', u'whoa', u'whoa'],\n",
       "    'original': 'Whoa, whoa, whoa...',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY', 'WOMEN'],\n",
       "    'tokenized': [u'Whoa', u'whoa', u'whoa']},\n",
       "   {'line#': 166,\n",
       "    'normalized': [u'Whoa', u'whoa', u'whoa'],\n",
       "    'original': 'Whoa, whoa, whoa\\x85',\n",
       "    'speakers': ['ELIZA', 'ANGELICA', 'PEGGY', 'WOMEN'],\n",
       "    'tokenized': [u'Whoa', u'whoa', u'whoa']},\n",
       "   {'line#': 167,\n",
       "    'normalized': [u'Here', u'comes', u'the', u'General'],\n",
       "    'original': 'Here comes the General!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Here', u'comes', u'the', u'General']},\n",
       "   {'line#': 168,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 169,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 170,\n",
       "    'normalized': [u'Here', u'comes', u'the', u'General'],\n",
       "    'original': 'Here comes the General!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Here', u'comes', u'the', u'General']},\n",
       "   {'line#': 171,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['HAMILTON', 'SCHUYLER SISTERS', 'WOMEN'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 172,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 173,\n",
       "    'normalized': [u'Here', u'comes', u'the', u'General'],\n",
       "    'original': 'Here comes the General!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Here', u'comes', u'the', u'General']},\n",
       "   {'line#': 174,\n",
       "    'normalized': [u'Rise', u'up'],\n",
       "    'original': 'Rise up!',\n",
       "    'speakers': ['HAMILTON', 'SCHUYLER SISTERS'],\n",
       "    'tokenized': [u'Rise', u'up']},\n",
       "   {'line#': 175,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['LAURENS', 'LAFAYETTE', 'MULLIGAN'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 176,\n",
       "    'normalized': [u'Here', u'comes', u'the', u'General'],\n",
       "    'original': 'Here comes the General!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Here', u'comes', u'the', u'General']},\n",
       "   {'line#': 177,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 178,\n",
       "    'normalized': [u'And', u'his', u'right', u'hand', u'man'],\n",
       "    'original': 'And his right hand man!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'And', u'his', u'right', u'hand', u'man']},\n",
       "   {'line#': 179,\n",
       "    'normalized': [u'Boom'],\n",
       "    'original': 'Boom!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Boom']}],\n",
       "  'track': 'Right Hand Man',\n",
       "  'track#': '8'},\n",
       " {'act#': '1',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'How',\n",
       "     u'does',\n",
       "     u'the',\n",
       "     u'bastard',\n",
       "     u'orphan',\n",
       "     u'son',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'whore'],\n",
       "    'original': 'How does the bastard, orphan, son of a whore',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How',\n",
       "     u'does',\n",
       "     u'the',\n",
       "     u'bastard',\n",
       "     u'orphan',\n",
       "     u'son',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'whore']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Go', u'on', u'and', u'on'],\n",
       "    'original': 'Go on and on',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Go', u'on', u'and', u'on']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Grow', u'into', u'more', u'of', u'a', u'phenomenon'],\n",
       "    'original': 'Grow into more of a phenomenon?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Grow', u'into', u'more', u'of', u'a', u'phenomenon']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Watch',\n",
       "     u'this',\n",
       "     u'obnoxious',\n",
       "     u'arrogant',\n",
       "     u'loudmouth',\n",
       "     u'bother'],\n",
       "    'original': 'Watch this obnoxious, arrogant, loudmouth bother',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Watch',\n",
       "     u'this',\n",
       "     u'obnoxious',\n",
       "     u'arrogant',\n",
       "     u'loudmouth',\n",
       "     u'bother']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Be',\n",
       "     u'seated',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'father'],\n",
       "    'original': 'Be seated at the right hand of the father',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Be',\n",
       "     u'seated',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'right',\n",
       "     u'hand',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'father']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Washington',\n",
       "     u'hires',\n",
       "     u'Hamilton',\n",
       "     u'right',\n",
       "     u'on',\n",
       "     u'sight'],\n",
       "    'original': 'Washington hires Hamilton right on sight',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Washington',\n",
       "     u'hires',\n",
       "     u'Hamilton',\n",
       "     u'right',\n",
       "     u'on',\n",
       "     u'sight']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'But',\n",
       "     u'Hamilton',\n",
       "     u'still',\n",
       "     u'wants',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'not',\n",
       "     u'write'],\n",
       "    'original': 'But Hamilton still wants to fight, not write',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But',\n",
       "     u'Hamilton',\n",
       "     u'still',\n",
       "     u'wants',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'not',\n",
       "     u'write']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Now',\n",
       "     u'Hamilton',\n",
       "     u's',\n",
       "     u'skill',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'quill',\n",
       "     u'is',\n",
       "     u'undeniable'],\n",
       "    'original': 'Now Hamilton\\x92s skill with a quill is undeniable',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'Hamilton',\n",
       "     u's',\n",
       "     u'skill',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'quill',\n",
       "     u'is',\n",
       "     u'undeniable']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'But',\n",
       "     u'what',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'have',\n",
       "     u'in',\n",
       "     u'common',\n",
       "     u'We',\n",
       "     u're'],\n",
       "    'original': 'But what do we have in common? We\\x92re',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But',\n",
       "     u'what',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'have',\n",
       "     u'in',\n",
       "     u'common',\n",
       "     u'We',\n",
       "     u're']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Reliable', u'with', u'the'],\n",
       "    'original': 'Reliable with the',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Reliable', u'with', u'the']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Ladies'],\n",
       "    'original': 'Ladies!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'Ladies']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'There', u'are', u'so', u'many', u'to', u'deflower'],\n",
       "    'original': 'There are so many to deflower!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'There', u'are', u'so', u'many', u'to', u'deflower']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Ladies'],\n",
       "    'original': 'Ladies!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'Ladies']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Looks', u'Proximity', u'to', u'power'],\n",
       "    'original': 'Looks! Proximity to power',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Looks', u'Proximity', u'to', u'power']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Ladies'],\n",
       "    'original': 'Ladies!',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'Ladies']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'They', u'delighted', u'and', u'distracted', u'him'],\n",
       "    'original': 'They delighted and distracted him',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'They', u'delighted', u'and', u'distracted', u'him']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Martha',\n",
       "     u'Washington',\n",
       "     u'named',\n",
       "     u'her',\n",
       "     u'feral',\n",
       "     u'tomcat',\n",
       "     u'after',\n",
       "     u'him'],\n",
       "    'original': 'Martha Washington named her feral tomcat after him!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Martha',\n",
       "     u'Washington',\n",
       "     u'named',\n",
       "     u'her',\n",
       "     u'feral',\n",
       "     u'tomcat',\n",
       "     u'after',\n",
       "     u'him']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'That', u's', u'true'],\n",
       "    'original': 'That\\x92s true!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That', u's', u'true']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'1780'],\n",
       "    'original': '1780',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'1780']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'A', u'winter', u's', u'ball'],\n",
       "    'original': 'A winter\\x92s ball',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'A', u'winter', u's', u'ball']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'And',\n",
       "     u'the',\n",
       "     u'Schuyler',\n",
       "     u'sisters',\n",
       "     u'are',\n",
       "     u'the',\n",
       "     u'envy',\n",
       "     u'of',\n",
       "     u'all'],\n",
       "    'original': 'And the Schuyler sisters are the envy of all',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'the',\n",
       "     u'Schuyler',\n",
       "     u'sisters',\n",
       "     u'are',\n",
       "     u'the',\n",
       "     u'envy',\n",
       "     u'of',\n",
       "     u'all']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Yo',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'marry',\n",
       "     u'a',\n",
       "     u'sister',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'rich',\n",
       "     u'son'],\n",
       "    'original': 'Yo, if you can marry a sister, you\\x92re rich, son',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Yo',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'marry',\n",
       "     u'a',\n",
       "     u'sister',\n",
       "     u'you',\n",
       "     u're',\n",
       "     u'rich',\n",
       "     u'son']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Is',\n",
       "     u'it',\n",
       "     u'a',\n",
       "     u'question',\n",
       "     u'of',\n",
       "     u'if',\n",
       "     u'Burr',\n",
       "     u'or',\n",
       "     u'which',\n",
       "     u'one'],\n",
       "    'original': 'Is it a question of if, Burr, or which one?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is',\n",
       "     u'it',\n",
       "     u'a',\n",
       "     u'question',\n",
       "     u'of',\n",
       "     u'if',\n",
       "     u'Burr',\n",
       "     u'or',\n",
       "     u'which',\n",
       "     u'one']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey',\n",
       "    'speakers': ['HAMILTON', 'BURR', 'LAURENS'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey',\n",
       "    'speakers': ['HAMILTON', 'BURR', 'LAURENS'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Hey', u'hey'],\n",
       "    'original': 'Hey hey',\n",
       "    'speakers': ['HAMILTON', 'BURR', 'LAURENS'],\n",
       "    'tokenized': [u'Hey', u'hey']}],\n",
       "  'track': \"A Winter's Ball\",\n",
       "  'track#': '9'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'They', u'say'],\n",
       "    'original': 'They say',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'They', u'say']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'George',\n",
       "     u'Washington\\u2019s',\n",
       "     u'yielding',\n",
       "     u'his',\n",
       "     u'power',\n",
       "     u'and',\n",
       "     u'stepping',\n",
       "     u'away'],\n",
       "    'original': 'George Washington\\xe2\\x80\\x99s yielding his power and stepping away',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'George',\n",
       "     u'Washington\\u2019s',\n",
       "     u'yielding',\n",
       "     u'his',\n",
       "     u'power',\n",
       "     u'and',\n",
       "     u'stepping',\n",
       "     u'away']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Zat', u'true'],\n",
       "    'original': '\\xe2\\x80\\x98Zat true?',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Zat', u'true']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I',\n",
       "     u'wasn\\u2019t',\n",
       "     u'aware',\n",
       "     u'that',\n",
       "     u'was',\n",
       "     u'something',\n",
       "     u'a',\n",
       "     u'person',\n",
       "     u'could',\n",
       "     u'do'],\n",
       "    'original': 'I wasn\\xe2\\x80\\x99t aware that was something a person could do',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wasn\\u2019t',\n",
       "     u'aware',\n",
       "     u'that',\n",
       "     u'was',\n",
       "     u'something',\n",
       "     u'a',\n",
       "     u'person',\n",
       "     u'could',\n",
       "     u'do']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'I\\u2019m', u'perplexed'],\n",
       "    'original': 'I\\xe2\\x80\\x99m perplexed',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'I\\u2019m', u'perplexed']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Are',\n",
       "     u'they',\n",
       "     u'gonna',\n",
       "     u'keep',\n",
       "     u'on',\n",
       "     u'replacing',\n",
       "     u'whoever\\u2019s',\n",
       "     u'in',\n",
       "     u'charge'],\n",
       "    'original': 'Are they gonna keep on replacing whoever\\xe2\\x80\\x99s in charge?',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Are',\n",
       "     u'they',\n",
       "     u'gonna',\n",
       "     u'keep',\n",
       "     u'on',\n",
       "     u'replacing',\n",
       "     u'whoever\\u2019s',\n",
       "     u'in',\n",
       "     u'charge']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'If', u'so', u'who\\u2019s', u'next'],\n",
       "    'original': 'If so, who\\xe2\\x80\\x99s next?',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'If', u'so', u'who\\u2019s', u'next']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'There\\u2019s',\n",
       "     u'nobody',\n",
       "     u'else',\n",
       "     u'in',\n",
       "     u'their',\n",
       "     u'country',\n",
       "     u'who',\n",
       "     u'looms',\n",
       "     u'quite',\n",
       "     u'as',\n",
       "     u'large'],\n",
       "    'original': 'There\\xe2\\x80\\x99s nobody else in their country who looms quite as large\\xe2\\x80\\xa6',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'There\\u2019s',\n",
       "     u'nobody',\n",
       "     u'else',\n",
       "     u'in',\n",
       "     u'their',\n",
       "     u'country',\n",
       "     u'who',\n",
       "     u'looms',\n",
       "     u'quite',\n",
       "     u'as',\n",
       "     u'large']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'A',\n",
       "     u'sentinel',\n",
       "     u'whispers',\n",
       "     u'in',\n",
       "     u'King',\n",
       "     u'George\\u2019s',\n",
       "     u'ear'],\n",
       "    'original': 'A sentinel whispers in King George\\xe2\\x80\\x99s ear',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'A',\n",
       "     u'sentinel',\n",
       "     u'whispers',\n",
       "     u'in',\n",
       "     u'King',\n",
       "     u'George\\u2019s',\n",
       "     u'ear']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'John', u'Adams'],\n",
       "    'original': 'John Adams?!',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'John', u'Adams']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'I', u'know', u'him'],\n",
       "    'original': 'I know him',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'I', u'know', u'him']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'That', u'can\\u2019t', u'be'],\n",
       "    'original': 'That can\\xe2\\x80\\x99t be',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'That', u'can\\u2019t', u'be']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'That\\u2019s',\n",
       "     u'that',\n",
       "     u'little',\n",
       "     u'guy',\n",
       "     u'who',\n",
       "     u'spoke',\n",
       "     u'to',\n",
       "     u'me'],\n",
       "    'original': 'That\\xe2\\x80\\x99s that little guy who spoke to me',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'That\\u2019s',\n",
       "     u'that',\n",
       "     u'little',\n",
       "     u'guy',\n",
       "     u'who',\n",
       "     u'spoke',\n",
       "     u'to',\n",
       "     u'me']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'All', u'those', u'years', u'ago'],\n",
       "    'original': 'All those years ago',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'All', u'those', u'years', u'ago']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'What', u'was', u'it', u'eighty', u'five'],\n",
       "    'original': 'What was it, eighty-five?',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'What', u'was', u'it', u'eighty', u'five']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'That',\n",
       "     u'poor',\n",
       "     u'man',\n",
       "     u'they\\u2019re',\n",
       "     u'gonna',\n",
       "     u'eat',\n",
       "     u'him',\n",
       "     u'alive'],\n",
       "    'original': 'That poor man, they\\xe2\\x80\\x99re gonna eat him alive!',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'That',\n",
       "     u'poor',\n",
       "     u'man',\n",
       "     u'they\\u2019re',\n",
       "     u'gonna',\n",
       "     u'eat',\n",
       "     u'him',\n",
       "     u'alive']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Oceans', u'rise'],\n",
       "    'original': 'Oceans rise',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Oceans', u'rise']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Empires', u'fall'],\n",
       "    'original': 'Empires fall',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Empires', u'fall']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Next',\n",
       "     u'to',\n",
       "     u'Washington',\n",
       "     u'they',\n",
       "     u'all',\n",
       "     u'look',\n",
       "     u'small'],\n",
       "    'original': 'Next to Washington, they all look small',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Next',\n",
       "     u'to',\n",
       "     u'Washington',\n",
       "     u'they',\n",
       "     u'all',\n",
       "     u'look',\n",
       "     u'small']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'All', u'alone'],\n",
       "    'original': 'All alone',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'All', u'alone']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Watch', u'them', u'run'],\n",
       "    'original': 'Watch them run',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Watch', u'them', u'run']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'They',\n",
       "     u'will',\n",
       "     u'tear',\n",
       "     u'each',\n",
       "     u'other',\n",
       "     u'into',\n",
       "     u'pieces'],\n",
       "    'original': 'They will tear each other into pieces',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'They',\n",
       "     u'will',\n",
       "     u'tear',\n",
       "     u'each',\n",
       "     u'other',\n",
       "     u'into',\n",
       "     u'pieces']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Jesus', u'Christ', u'this', u'will', u'be', u'fun'],\n",
       "    'original': 'Jesus Christ, this will be fun!',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Jesus', u'Christ', u'this', u'will', u'be', u'fun']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da'],\n",
       "    'original': 'Da da da dat da dat da da da da ya da',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'da']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'daaaaa'],\n",
       "    'original': 'Da da da dat dat da ya daaaaa!',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Da',\n",
       "     u'da',\n",
       "     u'da',\n",
       "     u'dat',\n",
       "     u'dat',\n",
       "     u'da',\n",
       "     u'ya',\n",
       "     u'daaaaa']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Hahahahahahahahaha'],\n",
       "    'original': 'Hahahahahahahahaha',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Hahahahahahahahaha']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'President', u'John', u'Adams'],\n",
       "    'original': '\\xe2\\x80\\x9cPresident John Adams\\xe2\\x80\\x9d',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'President', u'John', u'Adams']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Good', u'Luck'],\n",
       "    'original': 'Good Luck',\n",
       "    'speakers': ['KING GEORGE'],\n",
       "    'tokenized': [u'Good', u'Luck']}],\n",
       "  'track': 'I Know Him',\n",
       "  'track#': '10'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'How',\n",
       "     u'does',\n",
       "     u'Hamilton',\n",
       "     u'the',\n",
       "     u'short',\n",
       "     u'tempered'],\n",
       "    'original': 'How does Hamilton the short-tempered',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How',\n",
       "     u'does',\n",
       "     u'Hamilton',\n",
       "     u'the',\n",
       "     u'short',\n",
       "     u'tempered']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Protean', u'creator', u'of', u'the', u'Coast', u'Guard'],\n",
       "    'original': 'Protean creator of the Coast Guard',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Protean', u'creator', u'of', u'the', u'Coast', u'Guard']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Founder', u'of', u'the', u'New', u'York', u'Post'],\n",
       "    'original': 'Founder of the New York Post',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Founder', u'of', u'the', u'New', u'York', u'Post']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Ardently', u'abuse', u'his', u'cab\\u2019net', u'post'],\n",
       "    'original': 'Ardently abuse his cab\\xe2\\x80\\x99net post',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ardently', u'abuse', u'his', u'cab\\u2019net', u'post']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Destroy', u'his', u'reputation'],\n",
       "    'original': 'Destroy his reputation?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Destroy', u'his', u'reputation']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Welcome', u'folks', u'to'],\n",
       "    'original': 'Welcome, folks, to',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Welcome', u'folks', u'to']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'The', u'Adams', u'administration'],\n",
       "    'original': 'The Adams administration!',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'Adams', u'administration']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Jefferson\\u2019s',\n",
       "     u'the',\n",
       "     u'runner',\n",
       "     u'up',\n",
       "     u'which',\n",
       "     u'makes',\n",
       "     u'him',\n",
       "     u'the',\n",
       "     u'Vice',\n",
       "     u'President'],\n",
       "    'original': 'Jefferson\\xe2\\x80\\x99s the runner-up, which makes him the Vice President',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Jefferson\\u2019s',\n",
       "     u'the',\n",
       "     u'runner',\n",
       "     u'up',\n",
       "     u'which',\n",
       "     u'makes',\n",
       "     u'him',\n",
       "     u'the',\n",
       "     u'Vice',\n",
       "     u'President']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Washington',\n",
       "     u'can\\u2019t',\n",
       "     u'help',\n",
       "     u'you',\n",
       "     u'now',\n",
       "     u'no',\n",
       "     u'more',\n",
       "     u'mister',\n",
       "     u'nice',\n",
       "     u'President'],\n",
       "    'original': 'Washington can\\xe2\\x80\\x99t help you now, no more mister nice President',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Washington',\n",
       "     u'can\\u2019t',\n",
       "     u'help',\n",
       "     u'you',\n",
       "     u'now',\n",
       "     u'no',\n",
       "     u'more',\n",
       "     u'mister',\n",
       "     u'nice',\n",
       "     u'President']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Adams', u'fires', u'Hamilton'],\n",
       "    'original': 'Adams fires Hamilton',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Adams', u'fires', u'Hamilton']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Privately',\n",
       "     u'calls',\n",
       "     u'him',\n",
       "     u'creole',\n",
       "     u'bastard',\n",
       "     u'in',\n",
       "     u'his',\n",
       "     u'taunts'],\n",
       "    'original': 'Privately calls him \\xe2\\x80\\x9ccreole bastard\\xe2\\x80\\x9d in his taunts',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Privately',\n",
       "     u'calls',\n",
       "     u'him',\n",
       "     u'creole',\n",
       "     u'bastard',\n",
       "     u'in',\n",
       "     u'his',\n",
       "     u'taunts']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Say', u'what'],\n",
       "    'original': 'Say what?!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Say', u'what']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Hamilton', u'publishes', u'his', u'response'],\n",
       "    'original': 'Hamilton publishes his response',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hamilton', u'publishes', u'his', u'response']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Sit', u'down', u'John', u'you', u'fat', u'motherfucker'],\n",
       "    'original': 'Sit down, John, you fat motherfucker',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sit', u'down', u'John', u'you', u'fat', u'motherfucker']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Hamilton', u'is', u'out', u'of', u'control'],\n",
       "    'original': 'Hamilton is out of control',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hamilton', u'is', u'out', u'of', u'control']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'This',\n",
       "     u'is',\n",
       "     u'great',\n",
       "     u'He\\u2019s',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'power',\n",
       "     u'He',\n",
       "     u'holds',\n",
       "     u'no',\n",
       "     u'office',\n",
       "     u'And',\n",
       "     u'he',\n",
       "     u'just',\n",
       "     u'destroyed',\n",
       "     u'President',\n",
       "     u'John',\n",
       "     u'Adams',\n",
       "     u'the',\n",
       "     u'only',\n",
       "     u'other',\n",
       "     u'significant',\n",
       "     u'member',\n",
       "     u'of',\n",
       "     u'his',\n",
       "     u'party'],\n",
       "    'original': 'This is great! He\\xe2\\x80\\x99s out of power. He holds no office. And he just destroyed President John Adams, the only other significant member of his party',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'is',\n",
       "     u'great',\n",
       "     u'He\\u2019s',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'power',\n",
       "     u'He',\n",
       "     u'holds',\n",
       "     u'no',\n",
       "     u'office',\n",
       "     u'And',\n",
       "     u'he',\n",
       "     u'just',\n",
       "     u'destroyed',\n",
       "     u'President',\n",
       "     u'John',\n",
       "     u'Adams',\n",
       "     u'the',\n",
       "     u'only',\n",
       "     u'other',\n",
       "     u'significant',\n",
       "     u'member',\n",
       "     u'of',\n",
       "     u'his',\n",
       "     u'party']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Hamilton\\u2019s',\n",
       "     u'a',\n",
       "     u'host',\n",
       "     u'unto',\n",
       "     u'himself',\n",
       "     u'As',\n",
       "     u'long',\n",
       "     u'as',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'hold',\n",
       "     u'a',\n",
       "     u'pen',\n",
       "     u'he\\u2019s',\n",
       "     u'a',\n",
       "     u'threat',\n",
       "     u'Let\\u2019s',\n",
       "     u'let',\n",
       "     u'him',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'we',\n",
       "     u'know'],\n",
       "    'original': 'Hamilton\\xe2\\x80\\x99s a host unto himself. As long as he can hold a pen, he\\xe2\\x80\\x99s a threat. Let\\xe2\\x80\\x99s let him know what we know',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Hamilton\\u2019s',\n",
       "     u'a',\n",
       "     u'host',\n",
       "     u'unto',\n",
       "     u'himself',\n",
       "     u'As',\n",
       "     u'long',\n",
       "     u'as',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'hold',\n",
       "     u'a',\n",
       "     u'pen',\n",
       "     u'he\\u2019s',\n",
       "     u'a',\n",
       "     u'threat',\n",
       "     u'Let\\u2019s',\n",
       "     u'let',\n",
       "     u'him',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'we',\n",
       "     u'know']}],\n",
       "  'track': 'The Adams Administration',\n",
       "  'track#': '11'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Mr', u'Vice', u'President'],\n",
       "    'original': 'Mr. Vice President',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Mr', u'Vice', u'President']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Mr', u'Madison'],\n",
       "    'original': 'Mr. Madison',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Mr', u'Madison']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Senator', u'Burr'],\n",
       "    'original': 'Senator Burr',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Senator', u'Burr']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'What', u'is', u'this'],\n",
       "    'original': 'What is this?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What', u'is', u'this']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'We',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'check',\n",
       "     u'stubs',\n",
       "     u'From',\n",
       "     u'separate',\n",
       "     u'accounts'],\n",
       "    'original': 'We have the check stubs. From separate accounts\\xe2\\x80\\xa6',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'check',\n",
       "     u'stubs',\n",
       "     u'From',\n",
       "     u'separate',\n",
       "     u'accounts']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Almost',\n",
       "     u'a',\n",
       "     u'thousand',\n",
       "     u'dollars',\n",
       "     u'paid',\n",
       "     u'in',\n",
       "     u'different',\n",
       "     u'amounts'],\n",
       "    'original': 'Almost a thousand dollars, paid in different amounts\\xe2\\x80\\xa6',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Almost',\n",
       "     u'a',\n",
       "     u'thousand',\n",
       "     u'dollars',\n",
       "     u'paid',\n",
       "     u'in',\n",
       "     u'different',\n",
       "     u'amounts']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'To',\n",
       "     u'a',\n",
       "     u'Mr',\n",
       "     u'James',\n",
       "     u'Reynolds',\n",
       "     u'way',\n",
       "     u'back',\n",
       "     u'in'],\n",
       "    'original': 'To a Mr. James Reynolds way back in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'To',\n",
       "     u'a',\n",
       "     u'Mr',\n",
       "     u'James',\n",
       "     u'Reynolds',\n",
       "     u'way',\n",
       "     u'back',\n",
       "     u'in']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Seventeen', u'ninety', u'one'],\n",
       "    'original': 'Seventeen ninety-one',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Seventeen', u'ninety', u'one']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Is',\n",
       "     u'that',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'Are',\n",
       "     u'you',\n",
       "     u'done'],\n",
       "    'original': 'Is that what you have? Are you done?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is',\n",
       "     u'that',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'Are',\n",
       "     u'you',\n",
       "     u'done']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'You',\n",
       "     u'are',\n",
       "     u'uniquely',\n",
       "     u'situated',\n",
       "     u'by',\n",
       "     u'virtue',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'position'],\n",
       "    'original': 'You are uniquely situated by virtue of your position\\xe2\\x80\\x94',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'are',\n",
       "     u'uniquely',\n",
       "     u'situated',\n",
       "     u'by',\n",
       "     u'virtue',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'position']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Though',\n",
       "     u'virtue',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'word',\n",
       "     u'I\\u2019d',\n",
       "     u'apply',\n",
       "     u'to',\n",
       "     u'this',\n",
       "     u'situation'],\n",
       "    'original': 'Though \\xe2\\x80\\x98virtue\\xe2\\x80\\x99 is not a word I\\xe2\\x80\\x99d apply to this situation\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Though',\n",
       "     u'virtue',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'a',\n",
       "     u'word',\n",
       "     u'I\\u2019d',\n",
       "     u'apply',\n",
       "     u'to',\n",
       "     u'this',\n",
       "     u'situation']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'To',\n",
       "     u'seek',\n",
       "     u'financial',\n",
       "     u'gain',\n",
       "     u'to',\n",
       "     u'stray',\n",
       "     u'from',\n",
       "     u'your',\n",
       "     u'sacred',\n",
       "     u'mission'],\n",
       "    'original': 'To seek financial gain, to stray from your sacred mission\\xe2\\x80\\x94',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'To',\n",
       "     u'seek',\n",
       "     u'financial',\n",
       "     u'gain',\n",
       "     u'to',\n",
       "     u'stray',\n",
       "     u'from',\n",
       "     u'your',\n",
       "     u'sacred',\n",
       "     u'mission']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'And',\n",
       "     u'the',\n",
       "     u'evidence',\n",
       "     u'suggests',\n",
       "     u'you\\u2019ve',\n",
       "     u'engaged',\n",
       "     u'in',\n",
       "     u'speculation'],\n",
       "    'original': 'And the evidence suggests you\\xe2\\x80\\x99ve engaged in speculation\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'the',\n",
       "     u'evidence',\n",
       "     u'suggests',\n",
       "     u'you\\u2019ve',\n",
       "     u'engaged',\n",
       "     u'in',\n",
       "     u'speculation']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'An',\n",
       "     u'immigrant',\n",
       "     u'embezzling',\n",
       "     u'our',\n",
       "     u'government',\n",
       "     u'funds'],\n",
       "    'original': 'An immigrant embezzling our government funds\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'An',\n",
       "     u'immigrant',\n",
       "     u'embezzling',\n",
       "     u'our',\n",
       "     u'government',\n",
       "     u'funds']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'I',\n",
       "     u'can',\n",
       "     u'almost',\n",
       "     u'see',\n",
       "     u'the',\n",
       "     u'headline',\n",
       "     u'your',\n",
       "     u'career',\n",
       "     u'is',\n",
       "     u'done'],\n",
       "    'original': 'I can almost see the headline, your career is done',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'can',\n",
       "     u'almost',\n",
       "     u'see',\n",
       "     u'the',\n",
       "     u'headline',\n",
       "     u'your',\n",
       "     u'career',\n",
       "     u'is',\n",
       "     u'done']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I',\n",
       "     u'hope',\n",
       "     u'you',\n",
       "     u'saved',\n",
       "     u'some',\n",
       "     u'money',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'daughter',\n",
       "     u'and',\n",
       "     u'sons'],\n",
       "    'original': 'I hope you saved some money for your daughter and sons',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'hope',\n",
       "     u'you',\n",
       "     u'saved',\n",
       "     u'some',\n",
       "     u'money',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'daughter',\n",
       "     u'and',\n",
       "     u'sons']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Ya',\n",
       "     u'best',\n",
       "     u\"g'wan\",\n",
       "     u'run',\n",
       "     u'back',\n",
       "     u'where',\n",
       "     u'ya',\n",
       "     u'come',\n",
       "     u'from'],\n",
       "    'original': \"Ya best g'wan run back where ya come from!\",\n",
       "    'speakers': ['BURR', 'JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'Ya',\n",
       "     u'best',\n",
       "     u\"g'wan\",\n",
       "     u'run',\n",
       "     u'back',\n",
       "     u'where',\n",
       "     u'ya',\n",
       "     u'come',\n",
       "     u'from']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Ha',\n",
       "     u'You',\n",
       "     u'don\\u2019t',\n",
       "     u'even',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you\\u2019re',\n",
       "     u'asking',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'confess'],\n",
       "    'original': 'Ha! You don\\xe2\\x80\\x99t even know what you\\xe2\\x80\\x99re asking me to confess',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ha',\n",
       "     u'You',\n",
       "     u'don\\u2019t',\n",
       "     u'even',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you\\u2019re',\n",
       "     u'asking',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'confess']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Confess'],\n",
       "    'original': 'Confess',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Confess']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'You',\n",
       "     u'have',\n",
       "     u'nothing',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'anything',\n",
       "     u'at',\n",
       "     u'all'],\n",
       "    'original': 'You have nothing. I don\\xe2\\x80\\x99t have to tell you anything at all',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'have',\n",
       "     u'nothing',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'anything',\n",
       "     u'at',\n",
       "     u'all']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Unless'],\n",
       "    'original': 'Unless',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Unless']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Unless'],\n",
       "    'original': 'Unless',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Unless']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'If',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'prove',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'never',\n",
       "     u'broke',\n",
       "     u'the',\n",
       "     u'law'],\n",
       "    'original': 'If I can prove that I never broke the law',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'prove',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'never',\n",
       "     u'broke',\n",
       "     u'the',\n",
       "     u'law']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Do',\n",
       "     u'you',\n",
       "     u'promise',\n",
       "     u'not',\n",
       "     u'to',\n",
       "     u'tell',\n",
       "     u'another',\n",
       "     u'soul',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'saw'],\n",
       "    'original': 'Do you promise not to tell another soul what you saw?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Do',\n",
       "     u'you',\n",
       "     u'promise',\n",
       "     u'not',\n",
       "     u'to',\n",
       "     u'tell',\n",
       "     u'another',\n",
       "     u'soul',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'saw']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'No',\n",
       "     u'one',\n",
       "     u'else',\n",
       "     u'was',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'happened'],\n",
       "    'original': 'No one else was in the room where it happened',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No',\n",
       "     u'one',\n",
       "     u'else',\n",
       "     u'was',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'happened']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Is', u'that', u'a', u'yes'],\n",
       "    'original': 'Is that a yes?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is', u'that', u'a', u'yes']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Um', u'yes'],\n",
       "    'original': 'Um, yes',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Um', u'yes']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Dear',\n",
       "     u'Sir',\n",
       "     u'I',\n",
       "     u'hope',\n",
       "     u'this',\n",
       "     u'letter',\n",
       "     u'finds',\n",
       "     u'you',\n",
       "     u'in',\n",
       "     u'good',\n",
       "     u'health'],\n",
       "    'original': '\\xe2\\x80\\x9cDear Sir, I hope this letter finds you in good health',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Dear',\n",
       "     u'Sir',\n",
       "     u'I',\n",
       "     u'hope',\n",
       "     u'this',\n",
       "     u'letter',\n",
       "     u'finds',\n",
       "     u'you',\n",
       "     u'in',\n",
       "     u'good',\n",
       "     u'health']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'And',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'prosperous',\n",
       "     u'enough',\n",
       "     u'position',\n",
       "     u'to',\n",
       "     u'put',\n",
       "     u'wealth'],\n",
       "    'original': 'And in a prosperous enough position to put wealth',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'prosperous',\n",
       "     u'enough',\n",
       "     u'position',\n",
       "     u'to',\n",
       "     u'put',\n",
       "     u'wealth']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'In',\n",
       "     u'the',\n",
       "     u'pockets',\n",
       "     u'of',\n",
       "     u'people',\n",
       "     u'like',\n",
       "     u'me',\n",
       "     u'down',\n",
       "     u'on',\n",
       "     u'their',\n",
       "     u'luck'],\n",
       "    'original': 'In the pockets of people like me: down on their luck',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'In',\n",
       "     u'the',\n",
       "     u'pockets',\n",
       "     u'of',\n",
       "     u'people',\n",
       "     u'like',\n",
       "     u'me',\n",
       "     u'down',\n",
       "     u'on',\n",
       "     u'their',\n",
       "     u'luck']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'You',\n",
       "     u'see',\n",
       "     u'it',\n",
       "     u'was',\n",
       "     u'my',\n",
       "     u'wife',\n",
       "     u'who',\n",
       "     u'you',\n",
       "     u'decided',\n",
       "     u'to'],\n",
       "    'original': 'You see, it was my wife who you decided to\\xe2\\x80\\x94\\xe2\\x80\\x9d',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u'see',\n",
       "     u'it',\n",
       "     u'was',\n",
       "     u'my',\n",
       "     u'wife',\n",
       "     u'who',\n",
       "     u'you',\n",
       "     u'decided',\n",
       "     u'to']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Whaaaat'],\n",
       "    'original': 'Whaaaat\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Whaaaat']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'She', u'courted', u'me'],\n",
       "    'original': 'She courted me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'She', u'courted', u'me']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Escorted',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'bed',\n",
       "     u'and',\n",
       "     u'when',\n",
       "     u'she',\n",
       "     u'had',\n",
       "     u'me',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'corner'],\n",
       "    'original': 'Escorted me to bed and when she had me in a corner',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Escorted',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'bed',\n",
       "     u'and',\n",
       "     u'when',\n",
       "     u'she',\n",
       "     u'had',\n",
       "     u'me',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'corner']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'That\\u2019s', u'when', u'Reynolds', u'extorted', u'me'],\n",
       "    'original': 'That\\xe2\\x80\\x99s when Reynolds extorted me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That\\u2019s', u'when', u'Reynolds', u'extorted', u'me']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'For', u'a', u'sordid', u'fee'],\n",
       "    'original': 'For a sordid fee',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'For', u'a', u'sordid', u'fee']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'I', u'paid', u'him', u'quarterly'],\n",
       "    'original': 'I paid him quarterly',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'paid', u'him', u'quarterly']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'I',\n",
       "     u'may',\n",
       "     u'have',\n",
       "     u'mortally',\n",
       "     u'wounded',\n",
       "     u'my',\n",
       "     u'prospects'],\n",
       "    'original': 'I may have mortally wounded my prospects',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'may',\n",
       "     u'have',\n",
       "     u'mortally',\n",
       "     u'wounded',\n",
       "     u'my',\n",
       "     u'prospects']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'But', u'my', u'papers', u'are', u'orderly'],\n",
       "    'original': 'But my papers are orderly!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But', u'my', u'papers', u'are', u'orderly']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'As',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'see',\n",
       "     u'I',\n",
       "     u'kept',\n",
       "     u'a',\n",
       "     u'record',\n",
       "     u'of',\n",
       "     u'every',\n",
       "     u'check',\n",
       "     u'in',\n",
       "     u'my',\n",
       "     u'checkered'],\n",
       "    'original': 'As you can see I kept a record of every check in my checkered',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'As',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'see',\n",
       "     u'I',\n",
       "     u'kept',\n",
       "     u'a',\n",
       "     u'record',\n",
       "     u'of',\n",
       "     u'every',\n",
       "     u'check',\n",
       "     u'in',\n",
       "     u'my',\n",
       "     u'checkered']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'History',\n",
       "     u'Check',\n",
       "     u'it',\n",
       "     u'again',\n",
       "     u'against',\n",
       "     u'your',\n",
       "     u'list',\n",
       "     u'n',\n",
       "     u'see',\n",
       "     u'consistency'],\n",
       "    'original': 'History. Check it again against your list n\\xe2\\x80\\x99 see consistency',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'History',\n",
       "     u'Check',\n",
       "     u'it',\n",
       "     u'again',\n",
       "     u'against',\n",
       "     u'your',\n",
       "     u'list',\n",
       "     u'n',\n",
       "     u'see',\n",
       "     u'consistency']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'I',\n",
       "     u'never',\n",
       "     u'spent',\n",
       "     u'a',\n",
       "     u'cent',\n",
       "     u'that',\n",
       "     u'wasn\\u2019t',\n",
       "     u'mine'],\n",
       "    'original': 'I never spent a cent that wasn\\xe2\\x80\\x99t mine',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'never',\n",
       "     u'spent',\n",
       "     u'a',\n",
       "     u'cent',\n",
       "     u'that',\n",
       "     u'wasn\\u2019t',\n",
       "     u'mine']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'You',\n",
       "     u'sent',\n",
       "     u'the',\n",
       "     u'dogs',\n",
       "     u'after',\n",
       "     u'my',\n",
       "     u'scent',\n",
       "     u'that\\u2019s',\n",
       "     u'fine'],\n",
       "    'original': 'You sent the dogs after my scent, that\\xe2\\x80\\x99s fine',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'sent',\n",
       "     u'the',\n",
       "     u'dogs',\n",
       "     u'after',\n",
       "     u'my',\n",
       "     u'scent',\n",
       "     u'that\\u2019s',\n",
       "     u'fine']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Yes', u'I', u'have', u'reasons', u'for', u'shame'],\n",
       "    'original': 'Yes, I have reasons for shame',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes', u'I', u'have', u'reasons', u'for', u'shame']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'But',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'not',\n",
       "     u'committed',\n",
       "     u'treason',\n",
       "     u'and',\n",
       "     u'sullied',\n",
       "     u'my',\n",
       "     u'good',\n",
       "     u'name'],\n",
       "    'original': 'But I have not committed treason and sullied my good name',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'not',\n",
       "     u'committed',\n",
       "     u'treason',\n",
       "     u'and',\n",
       "     u'sullied',\n",
       "     u'my',\n",
       "     u'good',\n",
       "     u'name']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'As',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'see',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'done',\n",
       "     u'nothing',\n",
       "     u'to',\n",
       "     u'provoke',\n",
       "     u'legal',\n",
       "     u'action'],\n",
       "    'original': 'As you can see I have done nothing to provoke legal action',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'As',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'see',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'done',\n",
       "     u'nothing',\n",
       "     u'to',\n",
       "     u'provoke',\n",
       "     u'legal',\n",
       "     u'action']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Are', u'my', u'answers', u'to', u'your', u'satisfaction'],\n",
       "    'original': 'Are my answers to your satisfaction?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Are', u'my', u'answers', u'to', u'your', u'satisfaction']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'My', u'God'],\n",
       "    'original': 'My God',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'My', u'God']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Gentlemen', u'let\\u2019s', u'go'],\n",
       "    'original': 'Gentlemen, let\\xe2\\x80\\x99s go',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Gentlemen', u'let\\u2019s', u'go']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'So'],\n",
       "    'original': 'So?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'So']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'The',\n",
       "     u'people',\n",
       "     u\"won't\",\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'we',\n",
       "     u'know'],\n",
       "    'original': \"The people won't know what we know\",\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'people',\n",
       "     u\"won't\",\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'we',\n",
       "     u'know']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'How',\n",
       "     u'do',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'won\\u2019t',\n",
       "     u'use',\n",
       "     u'this',\n",
       "     u'against',\n",
       "     u'me'],\n",
       "    'original': 'How do I know you won\\xe2\\x80\\x99t use this against me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'How',\n",
       "     u'do',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'won\\u2019t',\n",
       "     u'use',\n",
       "     u'this',\n",
       "     u'against',\n",
       "     u'me']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'The',\n",
       "     u'next',\n",
       "     u'time',\n",
       "     u'we',\n",
       "     u'go',\n",
       "     u'toe',\n",
       "     u'to',\n",
       "     u'toe'],\n",
       "    'original': 'The next time we go toe to toe?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'next',\n",
       "     u'time',\n",
       "     u'we',\n",
       "     u'go',\n",
       "     u'toe',\n",
       "     u'to',\n",
       "     u'toe']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Alexander',\n",
       "     u'rumors',\n",
       "     u'only',\n",
       "     u'grow',\n",
       "     u'And',\n",
       "     u'we',\n",
       "     u'both'],\n",
       "    'original': 'Alexander, rumors only grow. And we both',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Alexander',\n",
       "     u'rumors',\n",
       "     u'only',\n",
       "     u'grow',\n",
       "     u'And',\n",
       "     u'we',\n",
       "     u'both']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Know', u'what', u'we', u'know'],\n",
       "    'original': 'Know what we know',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Know', u'what', u'we', u'know']}],\n",
       "  'track': 'We Know',\n",
       "  'track#': '12'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'In', u'the', u'eye', u'of', u'a', u'hurricane'],\n",
       "    'original': 'In the eye of a hurricane',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'In', u'the', u'eye', u'of', u'a', u'hurricane']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'There', u'is', u'quiet'],\n",
       "    'original': 'There is quiet',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'There', u'is', u'quiet']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'For', u'just', u'a', u'moment'],\n",
       "    'original': 'For just a moment',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'For', u'just', u'a', u'moment']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'A', u'yellow', u'sky'],\n",
       "    'original': 'A yellow sky',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A', u'yellow', u'sky']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'When', u'I', u'was', u'seventeen', u'a', u'hurricane'],\n",
       "    'original': 'When I was seventeen a hurricane',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'When', u'I', u'was', u'seventeen', u'a', u'hurricane']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Destroyed', u'my', u'town'],\n",
       "    'original': 'Destroyed my town',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Destroyed', u'my', u'town']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'I', u'didn\\u2019t', u'drown'],\n",
       "    'original': 'I didn\\xe2\\x80\\x99t drown',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'didn\\u2019t', u'drown']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'I', u'couldn\\u2019t', u'seem', u'to', u'die'],\n",
       "    'original': 'I couldn\\xe2\\x80\\x99t seem to die',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'couldn\\u2019t', u'seem', u'to', u'die']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'I', u'wrote', u'my', u'way', u'out'],\n",
       "    'original': 'I wrote my way out',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'wrote', u'my', u'way', u'out']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Wrote',\n",
       "     u'everything',\n",
       "     u'down',\n",
       "     u'far',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'see'],\n",
       "    'original': 'Wrote everything down far as I could see',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Wrote',\n",
       "     u'everything',\n",
       "     u'down',\n",
       "     u'far',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'see']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'I', u'wrote', u'my', u'way', u'out'],\n",
       "    'original': 'I wrote my way out',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'wrote', u'my', u'way', u'out']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'I',\n",
       "     u'looked',\n",
       "     u'up',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'town',\n",
       "     u'had',\n",
       "     u'its',\n",
       "     u'eyes',\n",
       "     u'on',\n",
       "     u'me'],\n",
       "    'original': 'I looked up and the town had its eyes on me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'looked',\n",
       "     u'up',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'town',\n",
       "     u'had',\n",
       "     u'its',\n",
       "     u'eyes',\n",
       "     u'on',\n",
       "     u'me']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'They', u'passed', u'a', u'plate', u'around'],\n",
       "    'original': 'They passed a plate around',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'They', u'passed', u'a', u'plate', u'around']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Total', u'strangers'],\n",
       "    'original': 'Total strangers',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Total', u'strangers']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Moved', u'to', u'kindness', u'by', u'my', u'story'],\n",
       "    'original': 'Moved to kindness by my story',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Moved', u'to', u'kindness', u'by', u'my', u'story']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Raised',\n",
       "     u'enough',\n",
       "     u'for',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'book',\n",
       "     u'passage',\n",
       "     u'on',\n",
       "     u'a'],\n",
       "    'original': 'Raised enough for me to book passage on a',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Raised',\n",
       "     u'enough',\n",
       "     u'for',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'book',\n",
       "     u'passage',\n",
       "     u'on',\n",
       "     u'a']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Ship', u'that', u'was', u'New', u'York', u'bound'],\n",
       "    'original': 'Ship that was New York bound\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ship', u'that', u'was', u'New', u'York', u'bound']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'I', u'wrote', u'my', u'way', u'out', u'of', u'hell'],\n",
       "    'original': 'I wrote my way out of hell',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'wrote', u'my', u'way', u'out', u'of', u'hell']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'I', u'wrote', u'my', u'way', u'to', u'revolution'],\n",
       "    'original': 'I wrote my way to revolution',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'wrote', u'my', u'way', u'to', u'revolution']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'I',\n",
       "     u'was',\n",
       "     u'louder',\n",
       "     u'than',\n",
       "     u'the',\n",
       "     u'crack',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'bell'],\n",
       "    'original': 'I was louder than the crack in the bell',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'was',\n",
       "     u'louder',\n",
       "     u'than',\n",
       "     u'the',\n",
       "     u'crack',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'bell']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'I',\n",
       "     u'wrote',\n",
       "     u'Eliza',\n",
       "     u'love',\n",
       "     u'letters',\n",
       "     u'until',\n",
       "     u'she',\n",
       "     u'fell'],\n",
       "    'original': 'I wrote Eliza love letters until she fell',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wrote',\n",
       "     u'Eliza',\n",
       "     u'love',\n",
       "     u'letters',\n",
       "     u'until',\n",
       "     u'she',\n",
       "     u'fell']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'I',\n",
       "     u'wrote',\n",
       "     u'about',\n",
       "     u'The',\n",
       "     u'Constitution',\n",
       "     u'and',\n",
       "     u'defended',\n",
       "     u'it',\n",
       "     u'well'],\n",
       "    'original': 'I wrote about The Constitution and defended it well',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wrote',\n",
       "     u'about',\n",
       "     u'The',\n",
       "     u'Constitution',\n",
       "     u'and',\n",
       "     u'defended',\n",
       "     u'it',\n",
       "     u'well']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'And',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'face',\n",
       "     u'of',\n",
       "     u'ignorance',\n",
       "     u'and',\n",
       "     u'resistance'],\n",
       "    'original': 'And in the face of ignorance and resistance',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'face',\n",
       "     u'of',\n",
       "     u'ignorance',\n",
       "     u'and',\n",
       "     u'resistance']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'I',\n",
       "     u'wrote',\n",
       "     u'financial',\n",
       "     u'systems',\n",
       "     u'into',\n",
       "     u'existence'],\n",
       "    'original': 'I wrote financial systems into existence',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wrote',\n",
       "     u'financial',\n",
       "     u'systems',\n",
       "     u'into',\n",
       "     u'existence']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'And',\n",
       "     u'when',\n",
       "     u'my',\n",
       "     u'prayers',\n",
       "     u'to',\n",
       "     u'God',\n",
       "     u'were',\n",
       "     u'met',\n",
       "     u'with',\n",
       "     u'indifference'],\n",
       "    'original': 'And when my prayers to God were met with indifference',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'when',\n",
       "     u'my',\n",
       "     u'prayers',\n",
       "     u'to',\n",
       "     u'God',\n",
       "     u'were',\n",
       "     u'met',\n",
       "     u'with',\n",
       "     u'indifference']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'I',\n",
       "     u'picked',\n",
       "     u'up',\n",
       "     u'a',\n",
       "     u'pen',\n",
       "     u'I',\n",
       "     u'wrote',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'deliverance'],\n",
       "    'original': 'I picked up a pen, I wrote my own deliverance',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'picked',\n",
       "     u'up',\n",
       "     u'a',\n",
       "     u'pen',\n",
       "     u'I',\n",
       "     u'wrote',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'deliverance']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'In', u'the', u'eye', u'of', u'a', u'hurricane'],\n",
       "    'original': 'In the eye of a hurricane',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'In', u'the', u'eye', u'of', u'a', u'hurricane']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'There', u'is', u'quiet'],\n",
       "    'original': 'There is quiet',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'There', u'is', u'quiet']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'For', u'just', u'a', u'moment'],\n",
       "    'original': 'For just a moment',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'For', u'just', u'a', u'moment']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'A', u'yellow', u'sky'],\n",
       "    'original': 'A yellow sky',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A', u'yellow', u'sky']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'I',\n",
       "     u'was',\n",
       "     u'twelve',\n",
       "     u'when',\n",
       "     u'my',\n",
       "     u'mother',\n",
       "     u'died'],\n",
       "    'original': 'I was twelve when my mother died',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'was',\n",
       "     u'twelve',\n",
       "     u'when',\n",
       "     u'my',\n",
       "     u'mother',\n",
       "     u'died']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'She', u'was', u'holding', u'me'],\n",
       "    'original': 'She was holding me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'She', u'was', u'holding', u'me']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'We',\n",
       "     u'were',\n",
       "     u'sick',\n",
       "     u'and',\n",
       "     u'she',\n",
       "     u'was',\n",
       "     u'holding',\n",
       "     u'me'],\n",
       "    'original': 'We were sick and she was holding me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'were',\n",
       "     u'sick',\n",
       "     u'and',\n",
       "     u'she',\n",
       "     u'was',\n",
       "     u'holding',\n",
       "     u'me']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'I', u'couldn\\u2019t', u'seem', u'to', u'die'],\n",
       "    'original': 'I couldn\\xe2\\x80\\x99t seem to die',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'couldn\\u2019t', u'seem', u'to', u'die']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it'],\n",
       "    'original': 'Wait for it, wait for it, wait for it\\xe2\\x80\\xa6',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it'],\n",
       "    'original': 'Wait for it, wait for it, wait for it\\xe2\\x80\\xa6',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait'],\n",
       "    'original': 'Wait for it, wait for it, wait for it, wait\\xe2\\x80\\xa6',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'I\\u2019ll', u'write', u'my', u'way', u'out'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll write my way out\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019ll', u'write', u'my', u'way', u'out']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Write',\n",
       "     u'ev\\u2019rything',\n",
       "     u'down',\n",
       "     u'far',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'see'],\n",
       "    'original': 'Write ev\\xe2\\x80\\x99rything down, far as I can see\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Write',\n",
       "     u'ev\\u2019rything',\n",
       "     u'down',\n",
       "     u'far',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'see']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'I\\u2019ll', u'write', u'my', u'way', u'out'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll write my way out\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019ll', u'write', u'my', u'way', u'out']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Overwhelm', u'them', u'with', u'honesty'],\n",
       "    'original': 'Overwhelm them with honesty.',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Overwhelm', u'them', u'with', u'honesty']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'History', u'has', u'its', u'eyes', u'on', u'you'],\n",
       "    'original': 'History has its eyes on you',\n",
       "    'speakers': ['WASHINTON', 'ELIZA', 'ANGELICA', 'MARIA'],\n",
       "    'tokenized': [u'History', u'has', u'its', u'eyes', u'on', u'you']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'This',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'eye',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'hurricane',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'only'],\n",
       "    'original': 'This is the eye of the hurricane, this is the only',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'eye',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'hurricane',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'only']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Way', u'I', u'can', u'protect', u'my', u'legacy'],\n",
       "    'original': 'Way I can protect my legacy\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Way', u'I', u'can', u'protect', u'my', u'legacy']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait'],\n",
       "    'original': 'Wait for it, wait for it, wait for it, wait\\xe2\\x80\\xa6',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'wait']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'The', u'Reynolds', u'Pamphlet'],\n",
       "    'original': 'The Reynolds Pamphlet',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'Reynolds', u'Pamphlet']}],\n",
       "  'track': ' Hurricane',\n",
       "  'track#': '13'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'The', u'Reynolds', u'Pamphlet'],\n",
       "    'original': 'The Reynolds Pamphlet',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'The', u'Reynolds', u'Pamphlet']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Have', u'you', u'read', u'this'],\n",
       "    'original': 'Have you read this?',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'ANGELICA'],\n",
       "    'tokenized': [u'Have', u'you', u'read', u'this']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Alexander',\n",
       "     u'Hamilton',\n",
       "     u'had',\n",
       "     u'a',\n",
       "     u'torrid',\n",
       "     u'affair'],\n",
       "    'original': 'Alexander Hamilton had a torrid affair',\n",
       "    'speakers': ['BURR', 'JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'Alexander',\n",
       "     u'Hamilton',\n",
       "     u'had',\n",
       "     u'a',\n",
       "     u'torrid',\n",
       "     u'affair']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'And',\n",
       "     u'he',\n",
       "     u'wrote',\n",
       "     u'it',\n",
       "     u'down',\n",
       "     u'right',\n",
       "     u'there'],\n",
       "    'original': 'And he wrote it down right there',\n",
       "    'speakers': ['BURR', 'JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'he',\n",
       "     u'wrote',\n",
       "     u'it',\n",
       "     u'down',\n",
       "     u'right',\n",
       "     u'there']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Highlights'],\n",
       "    'original': 'Highlights!',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Highlights']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'The', u'charge', u'against', u'me'],\n",
       "    'original': '\\xe2\\x80\\x9cThe charge against me',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'The', u'charge', u'against', u'me']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Is', u'a', u'connection', u'with', u'one'],\n",
       "    'original': 'Is a connection with one',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'Is', u'a', u'connection', u'with', u'one']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'James', u'Reynolds'],\n",
       "    'original': 'James Reynolds!',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'James', u'Reynolds']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'For', u'purposes', u'of'],\n",
       "    'original': 'For purposes of',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'For', u'purposes', u'of']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Improper', u'speculation'],\n",
       "    'original': 'Improper speculation',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'Improper', u'speculation']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'My', u'real', u'crime', u'is', u'an'],\n",
       "    'original': 'My real crime is an',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'My', u'real', u'crime', u'is', u'an']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Amorous', u'connection', u'with', u'his', u'wife'],\n",
       "    'original': 'Amorous connection with his wife',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'Amorous', u'connection', u'with', u'his', u'wife']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'For', u'a', u'considerable', u'time'],\n",
       "    'original': 'For a considerable time',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'For', u'a', u'considerable', u'time']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'With', u'his', u'knowing', u'consent'],\n",
       "    'original': 'With his knowing consent',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'With', u'his', u'knowing', u'consent']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'James', u'Reynolds'],\n",
       "    'original': 'James Reynolds!',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'James', u'Reynolds']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'My', u'real', u'crime', u'is', u'an'],\n",
       "    'original': 'My real crime is an',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'My', u'real', u'crime', u'is', u'an']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Amorous', u'connection', u'with', u'his', u'wife'],\n",
       "    'original': 'Amorous connection with his wife',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Amorous', u'connection', u'with', u'his', u'wife']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Damn'],\n",
       "    'original': 'Damn!',\n",
       "    'speakers': ['MADISON', 'BURR', 'JEFFERSON'],\n",
       "    'tokenized': [u'Damn']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'I', u'had', u'frequent', u'meetings', u'with', u'her'],\n",
       "    'original': '\\xe2\\x80\\x9cI had frequent meetings with her',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'I', u'had', u'frequent', u'meetings', u'with', u'her']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Most', u'of', u'them', u'at', u'my', u'own', u'house'],\n",
       "    'original': 'Most of them at my own house.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'Most', u'of', u'them', u'at', u'my', u'own', u'house']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'At', u'his', u'own', u'house'],\n",
       "    'original': 'At his own house!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'At', u'his', u'own', u'house']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'At', u'his', u'own', u'house'],\n",
       "    'original': 'At his own house!',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'At', u'his', u'own', u'house']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Damn'],\n",
       "    'original': 'Damn!',\n",
       "    'speakers': ['DEEP VOICE'],\n",
       "    'tokenized': [u'Damn']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Mrs',\n",
       "     u'Hamilton',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'children',\n",
       "     u'being',\n",
       "     u'absent'],\n",
       "    'original': '\\xe2\\x80\\x9cMrs. Hamilton with our children being absent',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'Mrs',\n",
       "     u'Hamilton',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'children',\n",
       "     u'being',\n",
       "     u'absent']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'On', u'a', u'visit', u'to', u'her', u'father'],\n",
       "    'original': 'On a visit to her father.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON'],\n",
       "    'tokenized': [u'On', u'a', u'visit', u'to', u'her', u'father']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No\\xe2\\x80\\xa6',\n",
       "    'speakers': ['MADISON', 'BURR'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Boooo'],\n",
       "    'original': 'Boooo!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Boooo']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Have', u'you', u'read', u'this'],\n",
       "    'original': 'Have you read this?',\n",
       "    'speakers': ['MADISON', 'BURR'],\n",
       "    'tokenized': [u'Have', u'you', u'read', u'this']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well, he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Never', u'gon', u'be', u'President', u'now'],\n",
       "    'original': 'Never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['MADISON', 'BURR'],\n",
       "    'tokenized': [u'Never', u'gon', u'be', u'President', u'now']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well, he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Never', u'gon', u'be', u'President', u'now'],\n",
       "    'original': 'Never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['MADISON', 'BURR'],\n",
       "    'tokenized': [u'Never', u'gon', u'be', u'President', u'now']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'He\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'He\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'He\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Never', u'gon', u'be', u'President', u'now'],\n",
       "    'original': 'Never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['MADISON', 'BURR'],\n",
       "    'tokenized': [u'Never', u'gon', u'be', u'President', u'now']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about'],\n",
       "    'original': 'That\\xe2\\x80\\x99s one less thing to worry about',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about'],\n",
       "    'original': 'That\\xe2\\x80\\x99s one less thing to worry about!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'I', u'came', u'as', u'soon', u'as', u'I', u'heard'],\n",
       "    'original': 'I came as soon as I heard',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'came', u'as', u'soon', u'as', u'I', u'heard']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'All', u'the', u'way', u'from', u'London'],\n",
       "    'original': 'All the way from London?!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'All', u'the', u'way', u'from', u'London']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Damn'],\n",
       "    'original': 'Damn',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Damn']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Angelica', u'thank', u'God'],\n",
       "    'original': 'Angelica, thank God',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Angelica', u'thank', u'God']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Someone', u'who', u'understands', u'what', u'I\\u2019m'],\n",
       "    'original': 'Someone who understands what I\\xe2\\x80\\x99m',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Someone', u'who', u'understands', u'what', u'I\\u2019m']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Struggling', u'here', u'to', u'do'],\n",
       "    'original': 'Struggling here to do',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Struggling', u'here', u'to', u'do']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'I\\u2019m', u'not', u'here', u'for', u'you'],\n",
       "    'original': 'I\\xe2\\x80\\x99m not here for you',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I\\u2019m', u'not', u'here', u'for', u'you']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Oooooh'],\n",
       "    'original': 'Oooooh!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Oooooh']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'like',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'mind'],\n",
       "    'original': 'I know my sister like I know my own mind',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'like',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'mind']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'You',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'find',\n",
       "     u'anyone',\n",
       "     u'as',\n",
       "     u'trusting',\n",
       "     u'or',\n",
       "     u'as',\n",
       "     u'kind'],\n",
       "    'original': 'You will never find anyone as trusting or as kind',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'find',\n",
       "     u'anyone',\n",
       "     u'as',\n",
       "     u'trusting',\n",
       "     u'or',\n",
       "     u'as',\n",
       "     u'kind']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'I',\n",
       "     u'love',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'more',\n",
       "     u'than',\n",
       "     u'anything',\n",
       "     u'in',\n",
       "     u'this',\n",
       "     u'life'],\n",
       "    'original': 'I love my sister more than anything in this life',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'love',\n",
       "     u'my',\n",
       "     u'sister',\n",
       "     u'more',\n",
       "     u'than',\n",
       "     u'anything',\n",
       "     u'in',\n",
       "     u'this',\n",
       "     u'life']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'I',\n",
       "     u'will',\n",
       "     u'choose',\n",
       "     u'her',\n",
       "     u'happiness',\n",
       "     u'over',\n",
       "     u'mine',\n",
       "     u'every',\n",
       "     u'time'],\n",
       "    'original': 'I will choose her happiness over mine every time',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'will',\n",
       "     u'choose',\n",
       "     u'her',\n",
       "     u'happiness',\n",
       "     u'over',\n",
       "     u'mine',\n",
       "     u'every',\n",
       "     u'time']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Put', u'what', u'we', u'had', u'aside'],\n",
       "    'original': 'Put what we had aside',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Put', u'what', u'we', u'had', u'aside']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'I\\u2019m', u'standing', u'at', u'her', u'side'],\n",
       "    'original': 'I\\xe2\\x80\\x99m standing at her side',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I\\u2019m', u'standing', u'at', u'her', u'side']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'You', u'could', u'never', u'be', u'satisfied'],\n",
       "    'original': 'You could never be satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'You', u'could', u'never', u'be', u'satisfied']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'God', u'I', u'hope', u'you\\u2019re', u'satisfied'],\n",
       "    'original': 'God, I hope you\\xe2\\x80\\x99re satisfied',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'God', u'I', u'hope', u'you\\u2019re', u'satisfied']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well, he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well, he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well, he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about'],\n",
       "    'original': 'That\\xe2\\x80\\x99s one less thing to worry about.',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Never', u'gon', u'be', u'President', u'now'],\n",
       "    'original': 'Never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Never', u'gon', u'be', u'President', u'now']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Never', u'gon', u'be', u'President', u'now'],\n",
       "    'original': 'Never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Never', u'gon', u'be', u'President', u'now']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Never', u'gon', u'be', u'President', u'now'],\n",
       "    'original': 'Never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Never', u'gon', u'be', u'President', u'now']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about'],\n",
       "    'original': 'That\\xe2\\x80\\x99s one less thing to worry about.',\n",
       "    'speakers': ['ENSEMBLE MEN'],\n",
       "    'tokenized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'At',\n",
       "     u'least',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'honest',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'money'],\n",
       "    'original': 'At least he was honest with our money!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'At',\n",
       "     u'least',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'honest',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'money']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'At',\n",
       "     u'least',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'honest',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'money'],\n",
       "    'original': 'At least he was honest with our money!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'At',\n",
       "     u'least',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'honest',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'money']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'At',\n",
       "     u'least',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'honest',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'money'],\n",
       "    'original': 'At least I was honest with our money!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'At',\n",
       "     u'least',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'honest',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'money']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'At',\n",
       "     u'least',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'honest',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'money'],\n",
       "    'original': 'At least he was honest with our money!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'At',\n",
       "     u'least',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'honest',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'money']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['ENSEMBLE WOMEN'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['ENSEMBLE WOMEN'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['ENSEMBLE WOMEN'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about'],\n",
       "    'original': 'That\\xe2\\x80\\x99s one less thing to worry about.',\n",
       "    'speakers': ['ENSEMBLE WOMEN'],\n",
       "    'tokenized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now',\n",
       "    'speakers': ['ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now'],\n",
       "    'original': 'Well he\\xe2\\x80\\x99s never gon\\xe2\\x80\\x99 be President now.',\n",
       "    'speakers': ['ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'never',\n",
       "     u'gon',\n",
       "     u'be',\n",
       "     u'President',\n",
       "     u'now']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about'],\n",
       "    'original': 'That\\xe2\\x80\\x99s one less thing to worry about!',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'That\\u2019s',\n",
       "     u'one',\n",
       "     u'less',\n",
       "     u'thing',\n",
       "     u'to',\n",
       "     u'worry',\n",
       "     u'about']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'The', u'Reynolds', u'Pamphlet'],\n",
       "    'original': 'The Reynolds Pamphlet',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'The', u'Reynolds', u'Pamphlet']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Have', u'you', u'read', u'this'],\n",
       "    'original': 'Have you read this?',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Have', u'you', u'read', u'this']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'You',\n",
       "     u'ever',\n",
       "     u'see',\n",
       "     u'somebody',\n",
       "     u'ruin',\n",
       "     u'their',\n",
       "     u'own',\n",
       "     u'life'],\n",
       "    'original': 'You ever see somebody ruin their own life?',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u'ever',\n",
       "     u'see',\n",
       "     u'somebody',\n",
       "     u'ruin',\n",
       "     u'their',\n",
       "     u'own',\n",
       "     u'life']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'His', u'poor', u'wife'],\n",
       "    'original': 'His poor wife',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'His', u'poor', u'wife']}],\n",
       "  'track': 'The Reynolds Pamphlet',\n",
       "  'track#': '14'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'I',\n",
       "     u'saved',\n",
       "     u'every',\n",
       "     u'letter',\n",
       "     u'you',\n",
       "     u'wrote',\n",
       "     u'me'],\n",
       "    'original': 'I saved every letter you wrote me',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'saved',\n",
       "     u'every',\n",
       "     u'letter',\n",
       "     u'you',\n",
       "     u'wrote',\n",
       "     u'me']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'From', u'the', u'moment', u'I', u'read', u'them'],\n",
       "    'original': 'From the moment I read them',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'From', u'the', u'moment', u'I', u'read', u'them']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'I', u'knew', u'you', u'were', u'mine'],\n",
       "    'original': 'I knew you were mine',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'knew', u'you', u'were', u'mine']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'You', u'said', u'you', u'were', u'mine'],\n",
       "    'original': 'You said you were mine',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You', u'said', u'you', u'were', u'mine']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'I', u'thought', u'you', u'were', u'mine'],\n",
       "    'original': 'I thought you were mine',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'thought', u'you', u'were', u'mine']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Do', u'you', u'know', u'what', u'Angelica', u'said'],\n",
       "    'original': 'Do you know what Angelica said',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Do', u'you', u'know', u'what', u'Angelica', u'said']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'When',\n",
       "     u'we',\n",
       "     u'saw',\n",
       "     u'your',\n",
       "     u'first',\n",
       "     u'letter',\n",
       "     u'arrive'],\n",
       "    'original': 'When we saw your first letter arrive?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'When',\n",
       "     u'we',\n",
       "     u'saw',\n",
       "     u'your',\n",
       "     u'first',\n",
       "     u'letter',\n",
       "     u'arrive']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'She', u'said'],\n",
       "    'original': 'She said',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'She', u'said']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Be', u'careful', u'with', u'that', u'one', u'love'],\n",
       "    'original': '\\xe2\\x80\\x9cBe careful with that one, love',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Be', u'careful', u'with', u'that', u'one', u'love']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'He',\n",
       "     u'will',\n",
       "     u'do',\n",
       "     u'what',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'to',\n",
       "     u'survive'],\n",
       "    'original': 'He will do what it takes to survive.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'He',\n",
       "     u'will',\n",
       "     u'do',\n",
       "     u'what',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'to',\n",
       "     u'survive']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'You',\n",
       "     u'and',\n",
       "     u'your',\n",
       "     u'words',\n",
       "     u'flooded',\n",
       "     u'my',\n",
       "     u'senses'],\n",
       "    'original': 'You and your words flooded my senses',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'and',\n",
       "     u'your',\n",
       "     u'words',\n",
       "     u'flooded',\n",
       "     u'my',\n",
       "     u'senses']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Your', u'sentences', u'left', u'me', u'defenseless'],\n",
       "    'original': 'Your sentences left me defenseless',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Your', u'sentences', u'left', u'me', u'defenseless']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'You',\n",
       "     u'built',\n",
       "     u'me',\n",
       "     u'palaces',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'paragraphs'],\n",
       "    'original': 'You built me palaces out of paragraphs',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'built',\n",
       "     u'me',\n",
       "     u'palaces',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'paragraphs']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'You', u'built', u'cathedrals'],\n",
       "    'original': 'You built cathedrals',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You', u'built', u'cathedrals']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u're',\n",
       "     u'reading',\n",
       "     u'the',\n",
       "     u'letters',\n",
       "     u'you',\n",
       "     u'wrote',\n",
       "     u'me'],\n",
       "    'original': 'I\\xe2\\x80\\x99m re-reading the letters you wrote me',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u're',\n",
       "     u'reading',\n",
       "     u'the',\n",
       "     u'letters',\n",
       "     u'you',\n",
       "     u'wrote',\n",
       "     u'me']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'searching',\n",
       "     u'and',\n",
       "     u'scanning',\n",
       "     u'for',\n",
       "     u'answers'],\n",
       "    'original': 'I\\xe2\\x80\\x99m searching and scanning for answers',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'searching',\n",
       "     u'and',\n",
       "     u'scanning',\n",
       "     u'for',\n",
       "     u'answers']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'In', u'every', u'line'],\n",
       "    'original': 'In every line',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'In', u'every', u'line']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'For', u'some', u'kind', u'of', u'sign'],\n",
       "    'original': 'For some kind of sign',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'For', u'some', u'kind', u'of', u'sign']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'And', u'when', u'you', u'were', u'mine'],\n",
       "    'original': 'And when you were mine',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'when', u'you', u'were', u'mine']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'The', u'world', u'seemed', u'to'],\n",
       "    'original': 'The world seemed to',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'The', u'world', u'seemed', u'to']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Burn'],\n",
       "    'original': 'Burn',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Burn']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Burn'],\n",
       "    'original': 'Burn',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Burn']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'You',\n",
       "     u'published',\n",
       "     u'the',\n",
       "     u'letters',\n",
       "     u'she',\n",
       "     u'wrote',\n",
       "     u'you'],\n",
       "    'original': 'You published the letters she wrote you',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'published',\n",
       "     u'the',\n",
       "     u'letters',\n",
       "     u'she',\n",
       "     u'wrote',\n",
       "     u'you']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'You',\n",
       "     u'told',\n",
       "     u'the',\n",
       "     u'whole',\n",
       "     u'world',\n",
       "     u'how',\n",
       "     u'you',\n",
       "     u'brought'],\n",
       "    'original': 'You told the whole world how you brought',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'told',\n",
       "     u'the',\n",
       "     u'whole',\n",
       "     u'world',\n",
       "     u'how',\n",
       "     u'you',\n",
       "     u'brought']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'This', u'girl', u'into', u'our', u'bed'],\n",
       "    'original': 'This girl into our bed',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'This', u'girl', u'into', u'our', u'bed']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'In',\n",
       "     u'clearing',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'ruined',\n",
       "     u'our',\n",
       "     u'lives'],\n",
       "    'original': 'In clearing your name, you have ruined our lives',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'In',\n",
       "     u'clearing',\n",
       "     u'your',\n",
       "     u'name',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'ruined',\n",
       "     u'our',\n",
       "     u'lives']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Do', u'you', u'know', u'what', u'Angelica', u'said'],\n",
       "    'original': 'Do you know what Angelica said',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Do', u'you', u'know', u'what', u'Angelica', u'said']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'When', u'she', u'read', u'what', u'you\\u2019d', u'done'],\n",
       "    'original': 'When she read what you\\xe2\\x80\\x99d done?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'When', u'she', u'read', u'what', u'you\\u2019d', u'done']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'She', u'said'],\n",
       "    'original': 'She said',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'She', u'said']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'You', u'have', u'married', u'an', u'Icarus'],\n",
       "    'original': '\\xe2\\x80\\x9cYou have married an Icarus',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You', u'have', u'married', u'an', u'Icarus']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'He',\n",
       "     u'has',\n",
       "     u'flown',\n",
       "     u'too',\n",
       "     u'close',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'sun'],\n",
       "    'original': 'He has flown too close to the sun.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'He',\n",
       "     u'has',\n",
       "     u'flown',\n",
       "     u'too',\n",
       "     u'close',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'sun']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'You',\n",
       "     u'and',\n",
       "     u'your',\n",
       "     u'words',\n",
       "     u'obsessed',\n",
       "     u'with',\n",
       "     u'your',\n",
       "     u'legacy'],\n",
       "    'original': 'You and your words, obsessed with your legacy...',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'and',\n",
       "     u'your',\n",
       "     u'words',\n",
       "     u'obsessed',\n",
       "     u'with',\n",
       "     u'your',\n",
       "     u'legacy']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Your', u'sentences', u'border', u'on', u'senseless'],\n",
       "    'original': 'Your sentences border on senseless',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Your', u'sentences', u'border', u'on', u'senseless']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'And',\n",
       "     u'you',\n",
       "     u'are',\n",
       "     u'paranoid',\n",
       "     u'in',\n",
       "     u'every',\n",
       "     u'paragraph'],\n",
       "    'original': 'And you are paranoid in every paragraph',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And',\n",
       "     u'you',\n",
       "     u'are',\n",
       "     u'paranoid',\n",
       "     u'in',\n",
       "     u'every',\n",
       "     u'paragraph']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'How', u'they', u'perceive', u'you'],\n",
       "    'original': 'How they perceive you',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'How', u'they', u'perceive', u'you']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'You', u'you', u'you'],\n",
       "    'original': 'You, you, you\\xe2\\x80\\xa6',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You', u'you', u'you']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'erasing',\n",
       "     u'myself',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'narrative'],\n",
       "    'original': 'I\\xe2\\x80\\x99m erasing myself from the narrative',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'erasing',\n",
       "     u'myself',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'narrative']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Let',\n",
       "     u'future',\n",
       "     u'historians',\n",
       "     u'wonder',\n",
       "     u'how',\n",
       "     u'Eliza'],\n",
       "    'original': 'Let future historians wonder how Eliza',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Let',\n",
       "     u'future',\n",
       "     u'historians',\n",
       "     u'wonder',\n",
       "     u'how',\n",
       "     u'Eliza']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Reacted', u'when', u'you', u'broke', u'her', u'heart'],\n",
       "    'original': 'Reacted when you broke her heart',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Reacted', u'when', u'you', u'broke', u'her', u'heart']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'You', u'have', u'torn', u'it', u'all', u'apart'],\n",
       "    'original': 'You have torn it all apart',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You', u'have', u'torn', u'it', u'all', u'apart']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'I', u'am', u'watching', u'it'],\n",
       "    'original': 'I am watching it',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'am', u'watching', u'it']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Burn'],\n",
       "    'original': 'Burn',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Burn']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Watching', u'it', u'burn'],\n",
       "    'original': 'Watching it burn',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Watching', u'it', u'burn']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'The',\n",
       "     u'world',\n",
       "     u'has',\n",
       "     u'no',\n",
       "     u'right',\n",
       "     u'to',\n",
       "     u'my',\n",
       "     u'heart'],\n",
       "    'original': 'The world has no right to my heart',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'The',\n",
       "     u'world',\n",
       "     u'has',\n",
       "     u'no',\n",
       "     u'right',\n",
       "     u'to',\n",
       "     u'my',\n",
       "     u'heart']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'The',\n",
       "     u'world',\n",
       "     u'has',\n",
       "     u'no',\n",
       "     u'place',\n",
       "     u'in',\n",
       "     u'our',\n",
       "     u'bed'],\n",
       "    'original': 'The world has no place in our bed',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'The',\n",
       "     u'world',\n",
       "     u'has',\n",
       "     u'no',\n",
       "     u'place',\n",
       "     u'in',\n",
       "     u'our',\n",
       "     u'bed']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'They',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'to',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'said'],\n",
       "    'original': 'They don\\xe2\\x80\\x99t get to know what I said',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'They',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'to',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'said']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'I\\u2019m', u'burning', u'the', u'memories'],\n",
       "    'original': 'I\\xe2\\x80\\x99m burning the memories',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I\\u2019m', u'burning', u'the', u'memories']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Burning',\n",
       "     u'the',\n",
       "     u'letters',\n",
       "     u'that',\n",
       "     u'might',\n",
       "     u'have',\n",
       "     u'redeemed',\n",
       "     u'you'],\n",
       "    'original': 'Burning the letters that might have redeemed you',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Burning',\n",
       "     u'the',\n",
       "     u'letters',\n",
       "     u'that',\n",
       "     u'might',\n",
       "     u'have',\n",
       "     u'redeemed',\n",
       "     u'you']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'You',\n",
       "     u'forfeit',\n",
       "     u'all',\n",
       "     u'rights',\n",
       "     u'to',\n",
       "     u'my',\n",
       "     u'heart'],\n",
       "    'original': 'You forfeit all rights to my heart',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'forfeit',\n",
       "     u'all',\n",
       "     u'rights',\n",
       "     u'to',\n",
       "     u'my',\n",
       "     u'heart']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'You',\n",
       "     u'forfeit',\n",
       "     u'the',\n",
       "     u'place',\n",
       "     u'in',\n",
       "     u'our',\n",
       "     u'bed'],\n",
       "    'original': 'You forfeit the place in our bed',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'forfeit',\n",
       "     u'the',\n",
       "     u'place',\n",
       "     u'in',\n",
       "     u'our',\n",
       "     u'bed']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'You', u'sleep', u'in', u'your', u'office', u'instead'],\n",
       "    'original': 'You sleep in your office instead',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You', u'sleep', u'in', u'your', u'office', u'instead']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'With', u'only', u'the', u'memories'],\n",
       "    'original': 'With only the memories',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'With', u'only', u'the', u'memories']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Of', u'when', u'you', u'were', u'mine'],\n",
       "    'original': 'Of when you were mine',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Of', u'when', u'you', u'were', u'mine']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'I', u'hope', u'that', u'you', u'burn'],\n",
       "    'original': 'I hope that you burn',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'hope', u'that', u'you', u'burn']}],\n",
       "  'track': 'Burn',\n",
       "  'track#': '15'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Meet',\n",
       "     u'the',\n",
       "     u'latest',\n",
       "     u'graduate',\n",
       "     u'of',\n",
       "     u'King\\u2019s',\n",
       "     u'College'],\n",
       "    'original': 'Meet the latest graduate of King\\xe2\\x80\\x99s College!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Meet',\n",
       "     u'the',\n",
       "     u'latest',\n",
       "     u'graduate',\n",
       "     u'of',\n",
       "     u'King\\u2019s',\n",
       "     u'College']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'I',\n",
       "     u'prob\\u2019ly',\n",
       "     u'shouldn\\u2019t',\n",
       "     u'brag',\n",
       "     u'but',\n",
       "     u'dag',\n",
       "     u'I',\n",
       "     u'amaze',\n",
       "     u'and',\n",
       "     u'astonish'],\n",
       "    'original': 'I prob\\xe2\\x80\\x99ly shouldn\\xe2\\x80\\x99t brag, but, dag, I amaze and astonish!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I',\n",
       "     u'prob\\u2019ly',\n",
       "     u'shouldn\\u2019t',\n",
       "     u'brag',\n",
       "     u'but',\n",
       "     u'dag',\n",
       "     u'I',\n",
       "     u'amaze',\n",
       "     u'and',\n",
       "     u'astonish']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'The',\n",
       "     u'scholars',\n",
       "     u'say',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'virtuosity',\n",
       "     u'and',\n",
       "     u'brains',\n",
       "     u'as',\n",
       "     u'my',\n",
       "     u'pops'],\n",
       "    'original': 'The scholars say I got the same virtuosity and brains as my pops!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'The',\n",
       "     u'scholars',\n",
       "     u'say',\n",
       "     u'I',\n",
       "     u'got',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'virtuosity',\n",
       "     u'and',\n",
       "     u'brains',\n",
       "     u'as',\n",
       "     u'my',\n",
       "     u'pops']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'The',\n",
       "     u'ladies',\n",
       "     u'say',\n",
       "     u'my',\n",
       "     u'brain\\u2019s',\n",
       "     u'not',\n",
       "     u'where',\n",
       "     u'the',\n",
       "     u'resemblance',\n",
       "     u'stops'],\n",
       "    'original': 'The ladies say my brain\\xe2\\x80\\x99s not where the resemblance stops!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'The',\n",
       "     u'ladies',\n",
       "     u'say',\n",
       "     u'my',\n",
       "     u'brain\\u2019s',\n",
       "     u'not',\n",
       "     u'where',\n",
       "     u'the',\n",
       "     u'resemblance',\n",
       "     u'stops']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'only',\n",
       "     u'nineteen',\n",
       "     u'but',\n",
       "     u'my',\n",
       "     u'mind',\n",
       "     u'is',\n",
       "     u'older'],\n",
       "    'original': 'I\\xe2\\x80\\x99m only nineteen but my mind is older',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'only',\n",
       "     u'nineteen',\n",
       "     u'but',\n",
       "     u'my',\n",
       "     u'mind',\n",
       "     u'is',\n",
       "     u'older']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Gotta',\n",
       "     u'be',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'man',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'father',\n",
       "     u'but',\n",
       "     u'bolder'],\n",
       "    'original': 'Gotta be my own man, like my father, but bolder',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Gotta',\n",
       "     u'be',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'man',\n",
       "     u'like',\n",
       "     u'my',\n",
       "     u'father',\n",
       "     u'but',\n",
       "     u'bolder']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'I', u'shoulder', u'his', u'legacy', u'with', u'pride'],\n",
       "    'original': 'I shoulder his legacy with pride',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'shoulder', u'his', u'legacy', u'with', u'pride']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'I', u'used', u'to', u'hear', u'him', u'say'],\n",
       "    'original': 'I used to hear him say',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'used', u'to', u'hear', u'him', u'say']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'That', u'someday'],\n",
       "    'original': 'That someday',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'That', u'someday']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'I', u'would'],\n",
       "    'original': 'I would\\xe2\\x80\\x94',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'would']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Blow', u'us', u'all', u'away'],\n",
       "    'original': 'Blow us all away',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Blow', u'us', u'all', u'away']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Ladies',\n",
       "     u'I\\u2019m',\n",
       "     u'lookin',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'Mr',\n",
       "     u'George',\n",
       "     u'Eacker'],\n",
       "    'original': 'Ladies, I\\xe2\\x80\\x99m lookin for a Mr. George Eacker',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Ladies',\n",
       "     u'I\\u2019m',\n",
       "     u'lookin',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'Mr',\n",
       "     u'George',\n",
       "     u'Eacker']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Made',\n",
       "     u'a',\n",
       "     u'speech',\n",
       "     u'last',\n",
       "     u'week',\n",
       "     u'our',\n",
       "     u'Fourth',\n",
       "     u'of',\n",
       "     u'July',\n",
       "     u'speaker'],\n",
       "    'original': 'Made a speech last week, our Fourth of July speaker',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Made',\n",
       "     u'a',\n",
       "     u'speech',\n",
       "     u'last',\n",
       "     u'week',\n",
       "     u'our',\n",
       "     u'Fourth',\n",
       "     u'of',\n",
       "     u'July',\n",
       "     u'speaker']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'He',\n",
       "     u'disparaged',\n",
       "     u'my',\n",
       "     u'father\\u2019s',\n",
       "     u'legacy',\n",
       "     u'in',\n",
       "     u'front',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'crowd'],\n",
       "    'original': 'He disparaged my father\\xe2\\x80\\x99s legacy in front of a crowd',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'He',\n",
       "     u'disparaged',\n",
       "     u'my',\n",
       "     u'father\\u2019s',\n",
       "     u'legacy',\n",
       "     u'in',\n",
       "     u'front',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'crowd']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'have',\n",
       "     u'that',\n",
       "     u'I\\u2019m',\n",
       "     u'making',\n",
       "     u'my',\n",
       "     u'father',\n",
       "     u'proud'],\n",
       "    'original': 'I can\\xe2\\x80\\x99t have that, I\\xe2\\x80\\x99m making my father proud',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'have',\n",
       "     u'that',\n",
       "     u'I\\u2019m',\n",
       "     u'making',\n",
       "     u'my',\n",
       "     u'father',\n",
       "     u'proud']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I',\n",
       "     u'saw',\n",
       "     u'him',\n",
       "     u'just',\n",
       "     u'up',\n",
       "     u'Broadway',\n",
       "     u'a',\n",
       "     u'couple',\n",
       "     u'of',\n",
       "     u'blocks'],\n",
       "    'original': 'I saw him just up Broadway a couple of blocks',\n",
       "    'speakers': ['MARTHA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'saw',\n",
       "     u'him',\n",
       "     u'just',\n",
       "     u'up',\n",
       "     u'Broadway',\n",
       "     u'a',\n",
       "     u'couple',\n",
       "     u'of',\n",
       "     u'blocks']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'He', u'was', u'goin', u'to', u'see', u'a', u'play'],\n",
       "    'original': 'He was goin\\xe2\\x80\\x99 to see a play',\n",
       "    'speakers': ['MARTHA'],\n",
       "    'tokenized': [u'He', u'was', u'goin', u'to', u'see', u'a', u'play']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Well', u'I\\u2019ll', u'go', u'visit', u'his', u'box'],\n",
       "    'original': 'Well, I\\xe2\\x80\\x99ll go visit his box',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Well', u'I\\u2019ll', u'go', u'visit', u'his', u'box']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'God', u'you\\u2019re', u'a', u'fox'],\n",
       "    'original': 'God, you\\xe2\\x80\\x99re a fox',\n",
       "    'speakers': ['DOLLY'],\n",
       "    'tokenized': [u'God', u'you\\u2019re', u'a', u'fox']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'And',\n",
       "     u'y\\u2019all',\n",
       "     u'look',\n",
       "     u'pretty',\n",
       "     u'good',\n",
       "     u'in',\n",
       "     u'ya',\n",
       "     u'frocks'],\n",
       "    'original': 'And y\\xe2\\x80\\x99all look pretty good in ya\\xe2\\x80\\x99 frocks',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'And',\n",
       "     u'y\\u2019all',\n",
       "     u'look',\n",
       "     u'pretty',\n",
       "     u'good',\n",
       "     u'in',\n",
       "     u'ya',\n",
       "     u'frocks']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'How',\n",
       "     u'bout',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'get',\n",
       "     u'back',\n",
       "     u'we',\n",
       "     u'all',\n",
       "     u'strip',\n",
       "     u'down',\n",
       "     u'to',\n",
       "     u'our',\n",
       "     u'socks'],\n",
       "    'original': 'How \\xe2\\x80\\x98bout when I get back, we all strip down to our socks?',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'How',\n",
       "     u'bout',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'get',\n",
       "     u'back',\n",
       "     u'we',\n",
       "     u'all',\n",
       "     u'strip',\n",
       "     u'down',\n",
       "     u'to',\n",
       "     u'our',\n",
       "     u'socks']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Ok'],\n",
       "    'original': 'Ok!',\n",
       "    'speakers': ['BOTH'],\n",
       "    'tokenized': [u'Ok']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Blow', u'us', u'all', u'away'],\n",
       "    'original': 'Blow us all away!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Blow', u'us', u'all', u'away']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'George'],\n",
       "    'original': 'George!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'George']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Shh'],\n",
       "    'original': 'Shh',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'Shh']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'George'],\n",
       "    'original': 'George!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'George']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Shh',\n",
       "     u'I\\u2019m',\n",
       "     u'tryin',\n",
       "     u'to',\n",
       "     u'watch',\n",
       "     u'the',\n",
       "     u'show'],\n",
       "    'original': 'Shh! I\\xe2\\x80\\x99m tryin\\xe2\\x80\\x99 to watch the show!',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'Shh',\n",
       "     u'I\\u2019m',\n",
       "     u'tryin',\n",
       "     u'to',\n",
       "     u'watch',\n",
       "     u'the',\n",
       "     u'show']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Ya',\n",
       "     u'shoulda',\n",
       "     u'watched',\n",
       "     u'your',\n",
       "     u'mouth',\n",
       "     u'before',\n",
       "     u'you'],\n",
       "    'original': 'Ya\\xe2\\x80\\x99 shoulda watched your mouth before you',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Ya',\n",
       "     u'shoulda',\n",
       "     u'watched',\n",
       "     u'your',\n",
       "     u'mouth',\n",
       "     u'before',\n",
       "     u'you']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Talked', u'about', u'my', u'father', u'though'],\n",
       "    'original': 'Talked about my father though!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Talked', u'about', u'my', u'father', u'though']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'I',\n",
       "     u'didn\\u2019t',\n",
       "     u'say',\n",
       "     u'anything',\n",
       "     u'that',\n",
       "     u'wasn\\u2019t',\n",
       "     u'true'],\n",
       "    'original': 'I didn\\xe2\\x80\\x99t say anything that wasn\\xe2\\x80\\x99t true',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'didn\\u2019t',\n",
       "     u'say',\n",
       "     u'anything',\n",
       "     u'that',\n",
       "     u'wasn\\u2019t',\n",
       "     u'true']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Your',\n",
       "     u'father\\u2019s',\n",
       "     u'a',\n",
       "     u'scoundrel',\n",
       "     u'and',\n",
       "     u'so',\n",
       "     u'it',\n",
       "     u'seems',\n",
       "     u'are',\n",
       "     u'you'],\n",
       "    'original': 'Your father\\xe2\\x80\\x99s a scoundrel, and so, it seems, are you',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'Your',\n",
       "     u'father\\u2019s',\n",
       "     u'a',\n",
       "     u'scoundrel',\n",
       "     u'and',\n",
       "     u'so',\n",
       "     u'it',\n",
       "     u'seems',\n",
       "     u'are',\n",
       "     u'you']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Ooooooooooh'],\n",
       "    'original': 'Ooooooooooh!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Ooooooooooh']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'It\\u2019s', u'like', u'that'],\n",
       "    'original': 'It\\xe2\\x80\\x99s like that?',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'It\\u2019s', u'like', u'that']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Yeah', u'I', u'don\\u2019t', u'fool', u'around'],\n",
       "    'original': 'Yeah, I don\\xe2\\x80\\x99t fool around',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'Yeah', u'I', u'don\\u2019t', u'fool', u'around']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'not',\n",
       "     u'your',\n",
       "     u'little',\n",
       "     u'schoolboy',\n",
       "     u'friends'],\n",
       "    'original': 'I\\xe2\\x80\\x99m not your little schoolboy friends',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'not',\n",
       "     u'your',\n",
       "     u'little',\n",
       "     u'schoolboy',\n",
       "     u'friends']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'See', u'you', u'on', u'the', u'dueling', u'ground'],\n",
       "    'original': 'See you on the dueling ground',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'See', u'you', u'on', u'the', u'dueling', u'ground']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'That',\n",
       "     u'is',\n",
       "     u'unless',\n",
       "     u'you',\n",
       "     u'wanna',\n",
       "     u'step',\n",
       "     u'outside',\n",
       "     u'and',\n",
       "     u'go',\n",
       "     u'now'],\n",
       "    'original': 'That is, unless you wanna step outside and go now',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'That',\n",
       "     u'is',\n",
       "     u'unless',\n",
       "     u'you',\n",
       "     u'wanna',\n",
       "     u'step',\n",
       "     u'outside',\n",
       "     u'and',\n",
       "     u'go',\n",
       "     u'now']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'where',\n",
       "     u'to',\n",
       "     u'find',\n",
       "     u'you',\n",
       "     u'piss',\n",
       "     u'off'],\n",
       "    'original': 'I know where to find you, piss off',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'where',\n",
       "     u'to',\n",
       "     u'find',\n",
       "     u'you',\n",
       "     u'piss',\n",
       "     u'off']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'I\\u2019m', u'watchin', u'this', u'show', u'now'],\n",
       "    'original': 'I\\xe2\\x80\\x99m watchin\\xe2\\x80\\x99 this show now',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'I\\u2019m', u'watchin', u'this', u'show', u'now']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Shh'],\n",
       "    'original': 'Shh',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'Shh']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Pops',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'had',\n",
       "     u'only',\n",
       "     u'heard',\n",
       "     u'the',\n",
       "     u'shit',\n",
       "     u'he',\n",
       "     u'said',\n",
       "     u'about',\n",
       "     u'you'],\n",
       "    'original': 'Pops, if you had only heard the shit he said about you',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Pops',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'had',\n",
       "     u'only',\n",
       "     u'heard',\n",
       "     u'the',\n",
       "     u'shit',\n",
       "     u'he',\n",
       "     u'said',\n",
       "     u'about',\n",
       "     u'you']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'I',\n",
       "     u'doubt',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'have',\n",
       "     u'let',\n",
       "     u'it',\n",
       "     u'slide',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'not',\n",
       "     u'about',\n",
       "     u'to'],\n",
       "    'original': 'I doubt you would have let it slide and I was not about to\\xe2\\x80\\x94',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I',\n",
       "     u'doubt',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'have',\n",
       "     u'let',\n",
       "     u'it',\n",
       "     u'slide',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'not',\n",
       "     u'about',\n",
       "     u'to']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Slow', u'down'],\n",
       "    'original': 'Slow down',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Slow', u'down']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'I',\n",
       "     u'came',\n",
       "     u'to',\n",
       "     u'ask',\n",
       "     u'you',\n",
       "     u'for',\n",
       "     u'advice',\n",
       "     u'This',\n",
       "     u'is',\n",
       "     u'my',\n",
       "     u'very',\n",
       "     u'first',\n",
       "     u'duel'],\n",
       "    'original': 'I came to ask you for advice. This is my very first duel',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I',\n",
       "     u'came',\n",
       "     u'to',\n",
       "     u'ask',\n",
       "     u'you',\n",
       "     u'for',\n",
       "     u'advice',\n",
       "     u'This',\n",
       "     u'is',\n",
       "     u'my',\n",
       "     u'very',\n",
       "     u'first',\n",
       "     u'duel']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'They',\n",
       "     u'don\\u2019t',\n",
       "     u'exactly',\n",
       "     u'cover',\n",
       "     u'this',\n",
       "     u'subject',\n",
       "     u'in',\n",
       "     u'boarding',\n",
       "     u'school'],\n",
       "    'original': 'They don\\xe2\\x80\\x99t exactly cover this subject in boarding school',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'They',\n",
       "     u'don\\u2019t',\n",
       "     u'exactly',\n",
       "     u'cover',\n",
       "     u'this',\n",
       "     u'subject',\n",
       "     u'in',\n",
       "     u'boarding',\n",
       "     u'school']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Did',\n",
       "     u'your',\n",
       "     u'friends',\n",
       "     u'attempt',\n",
       "     u'to',\n",
       "     u'negotiate',\n",
       "     u'a',\n",
       "     u'peace'],\n",
       "    'original': 'Did your friends attempt to negotiate a peace?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Did',\n",
       "     u'your',\n",
       "     u'friends',\n",
       "     u'attempt',\n",
       "     u'to',\n",
       "     u'negotiate',\n",
       "     u'a',\n",
       "     u'peace']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'He',\n",
       "     u'refused',\n",
       "     u'to',\n",
       "     u'apologize',\n",
       "     u'we',\n",
       "     u'had',\n",
       "     u'to',\n",
       "     u'let',\n",
       "     u'the',\n",
       "     u'peace',\n",
       "     u'talks',\n",
       "     u'cease'],\n",
       "    'original': 'He refused to apologize, we had to let the peace talks cease',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'He',\n",
       "     u'refused',\n",
       "     u'to',\n",
       "     u'apologize',\n",
       "     u'we',\n",
       "     u'had',\n",
       "     u'to',\n",
       "     u'let',\n",
       "     u'the',\n",
       "     u'peace',\n",
       "     u'talks',\n",
       "     u'cease']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Where', u'is', u'this', u'happening'],\n",
       "    'original': 'Where is this happening?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Where', u'is', u'this', u'happening']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Across', u'the', u'river', u'in', u'Jersey'],\n",
       "    'original': 'Across the river, in Jersey',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Across', u'the', u'river', u'in', u'Jersey']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Everything', u'is', u'legal', u'in', u'New', u'Jersey'],\n",
       "    'original': 'Everything is legal in New Jersey\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON', 'PHILIP'],\n",
       "    'tokenized': [u'Everything', u'is', u'legal', u'in', u'New', u'Jersey']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Alright',\n",
       "     u'So',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'what',\n",
       "     u'you\\u2019re',\n",
       "     u'gonna',\n",
       "     u'do'],\n",
       "    'original': 'Alright. So this is what you\\xe2\\x80\\x99re gonna do:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Alright',\n",
       "     u'So',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'what',\n",
       "     u'you\\u2019re',\n",
       "     u'gonna',\n",
       "     u'do']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Stand',\n",
       "     u'there',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'man',\n",
       "     u'until',\n",
       "     u'Eacker',\n",
       "     u'is',\n",
       "     u'in',\n",
       "     u'front',\n",
       "     u'of',\n",
       "     u'you'],\n",
       "    'original': 'Stand there like a man until Eacker is in front of you',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Stand',\n",
       "     u'there',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'man',\n",
       "     u'until',\n",
       "     u'Eacker',\n",
       "     u'is',\n",
       "     u'in',\n",
       "     u'front',\n",
       "     u'of',\n",
       "     u'you']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'When',\n",
       "     u'the',\n",
       "     u'time',\n",
       "     u'comes',\n",
       "     u'fire',\n",
       "     u'your',\n",
       "     u'weapon',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'air'],\n",
       "    'original': 'When the time comes, fire your weapon in the air',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'When',\n",
       "     u'the',\n",
       "     u'time',\n",
       "     u'comes',\n",
       "     u'fire',\n",
       "     u'your',\n",
       "     u'weapon',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'air']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'This',\n",
       "     u'will',\n",
       "     u'put',\n",
       "     u'an',\n",
       "     u'end',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'whole',\n",
       "     u'affair'],\n",
       "    'original': 'This will put an end to the whole affair',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'will',\n",
       "     u'put',\n",
       "     u'an',\n",
       "     u'end',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'whole',\n",
       "     u'affair']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'But',\n",
       "     u'what',\n",
       "     u'if',\n",
       "     u'he',\n",
       "     u'decides',\n",
       "     u'to',\n",
       "     u'shoot',\n",
       "     u'Then',\n",
       "     u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'goner'],\n",
       "    'original': 'But what if he decides to shoot? Then I\\xe2\\x80\\x99m a goner',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'But',\n",
       "     u'what',\n",
       "     u'if',\n",
       "     u'he',\n",
       "     u'decides',\n",
       "     u'to',\n",
       "     u'shoot',\n",
       "     u'Then',\n",
       "     u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'goner']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'No',\n",
       "     u'He\\u2019ll',\n",
       "     u'follow',\n",
       "     u'suit',\n",
       "     u'if',\n",
       "     u'he\\u2019s',\n",
       "     u'truly',\n",
       "     u'a',\n",
       "     u'man',\n",
       "     u'of',\n",
       "     u'honor'],\n",
       "    'original': 'No. He\\xe2\\x80\\x99ll follow suit if he\\xe2\\x80\\x99s truly a man of honor',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No',\n",
       "     u'He\\u2019ll',\n",
       "     u'follow',\n",
       "     u'suit',\n",
       "     u'if',\n",
       "     u'he\\u2019s',\n",
       "     u'truly',\n",
       "     u'a',\n",
       "     u'man',\n",
       "     u'of',\n",
       "     u'honor']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'To',\n",
       "     u'take',\n",
       "     u'someone\\u2019s',\n",
       "     u'life',\n",
       "     u'that',\n",
       "     u'is',\n",
       "     u'something',\n",
       "     u'you',\n",
       "     u'can\\u2019t',\n",
       "     u'shake'],\n",
       "    'original': 'To take someone\\xe2\\x80\\x99s life, that is something you can\\xe2\\x80\\x99t shake',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'To',\n",
       "     u'take',\n",
       "     u'someone\\u2019s',\n",
       "     u'life',\n",
       "     u'that',\n",
       "     u'is',\n",
       "     u'something',\n",
       "     u'you',\n",
       "     u'can\\u2019t',\n",
       "     u'shake']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Philip',\n",
       "     u'your',\n",
       "     u'mother',\n",
       "     u'can\\u2019t',\n",
       "     u'take',\n",
       "     u'another',\n",
       "     u'heartbreak'],\n",
       "    'original': 'Philip, your mother can\\xe2\\x80\\x99t take another heartbreak',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Philip',\n",
       "     u'your',\n",
       "     u'mother',\n",
       "     u'can\\u2019t',\n",
       "     u'take',\n",
       "     u'another',\n",
       "     u'heartbreak']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Father'],\n",
       "    'original': 'Father\\xe2\\x80\\x94',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Father']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Promise', u'me', u'You', u'don\\u2019t', u'want', u'this'],\n",
       "    'original': 'Promise me. You don\\xe2\\x80\\x99t want this',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Promise', u'me', u'You', u'don\\u2019t', u'want', u'this']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Young',\n",
       "     u'man\\u2019s',\n",
       "     u'blood',\n",
       "     u'on',\n",
       "     u'your',\n",
       "     u'conscience'],\n",
       "    'original': 'Young man\\xe2\\x80\\x99s blood on your conscience',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Young',\n",
       "     u'man\\u2019s',\n",
       "     u'blood',\n",
       "     u'on',\n",
       "     u'your',\n",
       "     u'conscience']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Okay', u'I', u'promise'],\n",
       "    'original': 'Okay, I promise',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Okay', u'I', u'promise']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Come',\n",
       "     u'back',\n",
       "     u'home',\n",
       "     u'when',\n",
       "     u'you\\u2019re',\n",
       "     u'done'],\n",
       "    'original': 'Come back home when you\\xe2\\x80\\x99re done',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Come',\n",
       "     u'back',\n",
       "     u'home',\n",
       "     u'when',\n",
       "     u'you\\u2019re',\n",
       "     u'done']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Take',\n",
       "     u'my',\n",
       "     u'guns',\n",
       "     u'Be',\n",
       "     u'smart',\n",
       "     u'Make',\n",
       "     u'me',\n",
       "     u'proud',\n",
       "     u'son'],\n",
       "    'original': 'Take my guns. Be smart. Make me proud, son',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Take',\n",
       "     u'my',\n",
       "     u'guns',\n",
       "     u'Be',\n",
       "     u'smart',\n",
       "     u'Make',\n",
       "     u'me',\n",
       "     u'proud',\n",
       "     u'son']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'My', u'name', u'is', u'Philip'],\n",
       "    'original': 'My name is Philip',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'My', u'name', u'is', u'Philip']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'I', u'am', u'a', u'poet'],\n",
       "    'original': 'I am a poet',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'am', u'a', u'poet']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'nervous',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'show',\n",
       "     u'it'],\n",
       "    'original': 'I\\xe2\\x80\\x99m a little nervous, but I can\\xe2\\x80\\x99t show it',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'nervous',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'show',\n",
       "     u'it']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'sorry',\n",
       "     u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'Hamilton',\n",
       "     u'with',\n",
       "     u'pride'],\n",
       "    'original': 'I\\xe2\\x80\\x99m sorry, I\\xe2\\x80\\x99m a Hamilton with pride',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'sorry',\n",
       "     u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'Hamilton',\n",
       "     u'with',\n",
       "     u'pride']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'You',\n",
       "     u'talk',\n",
       "     u'about',\n",
       "     u'my',\n",
       "     u'father',\n",
       "     u'I',\n",
       "     u'cannot',\n",
       "     u'let',\n",
       "     u'it',\n",
       "     u'slide'],\n",
       "    'original': 'You talk about my father, I cannot let it slide',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'You',\n",
       "     u'talk',\n",
       "     u'about',\n",
       "     u'my',\n",
       "     u'father',\n",
       "     u'I',\n",
       "     u'cannot',\n",
       "     u'let',\n",
       "     u'it',\n",
       "     u'slide']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Mister',\n",
       "     u'Eacker',\n",
       "     u'How',\n",
       "     u'was',\n",
       "     u'the',\n",
       "     u'rest',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'show'],\n",
       "    'original': 'Mister Eacker! How was the rest of your show?',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Mister',\n",
       "     u'Eacker',\n",
       "     u'How',\n",
       "     u'was',\n",
       "     u'the',\n",
       "     u'rest',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'show']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'I\\u2019d', u'rather', u'skip', u'the', u'pleasantries'],\n",
       "    'original': 'I\\xe2\\x80\\x99d rather skip the pleasantries',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'I\\u2019d', u'rather', u'skip', u'the', u'pleasantries']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'Let\\u2019s', u'go'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s go',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'Let\\u2019s', u'go']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Grab', u'your', u'pistol'],\n",
       "    'original': 'Grab your pistol',\n",
       "    'speakers': ['GEORGE'],\n",
       "    'tokenized': [u'Grab', u'your', u'pistol']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Confer', u'with', u'your', u'men'],\n",
       "    'original': 'Confer with your men',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Confer', u'with', u'your', u'men']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'The',\n",
       "     u'duel',\n",
       "     u'will',\n",
       "     u'commence',\n",
       "     u'after',\n",
       "     u'we',\n",
       "     u'count',\n",
       "     u'to',\n",
       "     u'ten'],\n",
       "    'original': 'The duel will commence after we count to ten',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'The',\n",
       "     u'duel',\n",
       "     u'will',\n",
       "     u'commence',\n",
       "     u'after',\n",
       "     u'we',\n",
       "     u'count',\n",
       "     u'to',\n",
       "     u'ten']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Count', u'to', u'ten'],\n",
       "    'original': 'Count to ten!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Count', u'to', u'ten']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Look',\n",
       "     u'em',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'eye',\n",
       "     u'aim',\n",
       "     u'no',\n",
       "     u'higher'],\n",
       "    'original': 'Look \\xe2\\x80\\x98em in the eye, aim no higher',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'em',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'eye',\n",
       "     u'aim',\n",
       "     u'no',\n",
       "     u'higher']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'Summon', u'all', u'the', u'courage', u'you', u'require'],\n",
       "    'original': 'Summon all the courage you require',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Summon', u'all', u'the', u'courage', u'you', u'require']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'Then',\n",
       "     u'slowly',\n",
       "     u'and',\n",
       "     u'clearly',\n",
       "     u'aim',\n",
       "     u'your',\n",
       "     u'gun',\n",
       "     u'towards',\n",
       "     u'the',\n",
       "     u'sky'],\n",
       "    'original': 'Then slowly and clearly aim your gun towards the sky\\xe2\\x80\\x94',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'slowly',\n",
       "     u'and',\n",
       "     u'clearly',\n",
       "     u'aim',\n",
       "     u'your',\n",
       "     u'gun',\n",
       "     u'towards',\n",
       "     u'the',\n",
       "     u'sky']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'One', u'two', u'three', u'four'],\n",
       "    'original': 'One two three four',\n",
       "    'speakers': ['MALE ENSEMBLE'],\n",
       "    'tokenized': [u'One', u'two', u'three', u'four']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Five', u'six', u'seven'],\n",
       "    'original': 'Five six seven\\xe2\\x80\\x94',\n",
       "    'speakers': ['FULL ENSEMBLE'],\n",
       "    'tokenized': [u'Five', u'six', u'seven']}],\n",
       "  'track': 'Blow Us All Away',\n",
       "  'track#': '16'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Stay', u'alive'],\n",
       "    'original': 'Stay alive\\xe2\\x80\\xa6',\n",
       "    'speakers': ['ENSEMBLE WOMEN'],\n",
       "    'tokenized': [u'Stay', u'alive']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Stay', u'alive'],\n",
       "    'original': 'Stay alive\\xe2\\x80\\xa6',\n",
       "    'speakers': ['ENSEMBLE WOMEN'],\n",
       "    'tokenized': [u'Stay', u'alive']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Stay', u'alive'],\n",
       "    'original': 'Stay alive...',\n",
       "    'speakers': ['ENSEMBLE WOMEN'],\n",
       "    'tokenized': [u'Stay', u'alive']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Where\\u2019s', u'my', u'son'],\n",
       "    'original': 'Where\\xe2\\x80\\x99s my son?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Where\\u2019s', u'my', u'son']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Is', u'he', u'alive'],\n",
       "    'original': 'Is he alive?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is', u'he', u'alive']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Mr',\n",
       "     u'Hamilton',\n",
       "     u'come',\n",
       "     u'in',\n",
       "     u'They',\n",
       "     u'brought',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'half',\n",
       "     u'an',\n",
       "     u'hour',\n",
       "     u'ago',\n",
       "     u'He',\n",
       "     u'lost',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'of',\n",
       "     u'blood',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'way',\n",
       "     u'over'],\n",
       "    'original': 'Mr. Hamilton, come in. They brought him in a half an hour ago. He lost a lot of blood on the way over.',\n",
       "    'speakers': ['DOCTOR'],\n",
       "    'tokenized': [u'Mr',\n",
       "     u'Hamilton',\n",
       "     u'come',\n",
       "     u'in',\n",
       "     u'They',\n",
       "     u'brought',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'half',\n",
       "     u'an',\n",
       "     u'hour',\n",
       "     u'ago',\n",
       "     u'He',\n",
       "     u'lost',\n",
       "     u'a',\n",
       "     u'lot',\n",
       "     u'of',\n",
       "     u'blood',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'way',\n",
       "     u'over']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Yes', u'But', u'you', u'have', u'to', u'understand'],\n",
       "    'original': 'Yes. But you have to understand',\n",
       "    'speakers': ['DOCTOR'],\n",
       "    'tokenized': [u'Yes', u'But', u'you', u'have', u'to', u'understand']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'The',\n",
       "     u'bullet',\n",
       "     u'entered',\n",
       "     u'just',\n",
       "     u'above',\n",
       "     u'his',\n",
       "     u'hip',\n",
       "     u'and'],\n",
       "    'original': 'The bullet entered just above his hip and',\n",
       "    'speakers': ['DOCTOR'],\n",
       "    'tokenized': [u'The',\n",
       "     u'bullet',\n",
       "     u'entered',\n",
       "     u'just',\n",
       "     u'above',\n",
       "     u'his',\n",
       "     u'hip',\n",
       "     u'and']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Lodged', u'in', u'his', u'right', u'arm'],\n",
       "    'original': 'Lodged in his right arm',\n",
       "    'speakers': ['DOCTOR'],\n",
       "    'tokenized': [u'Lodged', u'in', u'his', u'right', u'arm']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Can', u'I', u'see', u'him', u'please'],\n",
       "    'original': 'Can I see him please?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Can', u'I', u'see', u'him', u'please']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'doing',\n",
       "     u'ev\\u2019rything',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'but',\n",
       "     u'the',\n",
       "     u'wound',\n",
       "     u'was'],\n",
       "    'original': 'I\\xe2\\x80\\x99m doing ev\\xe2\\x80\\x99rything I can, but the wound was',\n",
       "    'speakers': ['DOCTOR'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'doing',\n",
       "     u'ev\\u2019rything',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'but',\n",
       "     u'the',\n",
       "     u'wound',\n",
       "     u'was']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Already', u'infected', u'when', u'he', u'arrived'],\n",
       "    'original': 'Already infected when he arrived\\xe2\\x80\\x94',\n",
       "    'speakers': ['DOCTOR'],\n",
       "    'tokenized': [u'Already', u'infected', u'when', u'he', u'arrived']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Philip'],\n",
       "    'original': 'Philip',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Philip']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Pa'],\n",
       "    'original': 'Pa',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Pa']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'I', u'did', u'exactly', u'as', u'you', u'said', u'Pa'],\n",
       "    'original': 'I did exactly as you said, Pa',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'did', u'exactly', u'as', u'you', u'said', u'Pa']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I', u'held', u'my', u'head', u'up', u'high'],\n",
       "    'original': 'I held my head up high',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'held', u'my', u'head', u'up', u'high']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'I', u'know', u'I', u'know', u'Shh'],\n",
       "    'original': 'I know, I know. Shh',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'know', u'I', u'know', u'Shh']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'I', u'know', u'I', u'know'],\n",
       "    'original': 'I know, I know',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'know', u'I', u'know']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Shh', u'I', u'know', u'you', u'did'],\n",
       "    'original': 'Shh. I know you did',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Shh', u'I', u'know', u'you', u'did']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Ev\\u2019rything', u'just', u'right'],\n",
       "    'original': 'Ev\\xe2\\x80\\x99rything just right',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ev\\u2019rything', u'just', u'right']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Shh'],\n",
       "    'original': 'Shh',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Shh']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'I', u'know', u'I', u'know'],\n",
       "    'original': 'I know, I know',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'know', u'I', u'know']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'I', u'know', u'I', u'know'],\n",
       "    'original': 'I know, I know',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'know', u'I', u'know']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'I', u'know'],\n",
       "    'original': 'I know',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'know']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Save', u'your', u'strength', u'and'],\n",
       "    'original': 'Save your strength and',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Save', u'your', u'strength', u'and']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Stay', u'alive'],\n",
       "    'original': 'Stay alive\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Stay', u'alive']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'High'],\n",
       "    'original': 'High',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'High']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Even', u'before', u'we', u'got', u'to', u'ten'],\n",
       "    'original': 'Even before we got to ten\\xe2\\x80\\x94',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Even', u'before', u'we', u'got', u'to', u'ten']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'I', u'was', u'aiming', u'for', u'the', u'sky'],\n",
       "    'original': 'I was aiming for the sky',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'was', u'aiming', u'for', u'the', u'sky']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'I', u'was', u'aiming', u'for', u'the', u'sky'],\n",
       "    'original': 'I was aiming for the sky',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'was', u'aiming', u'for', u'the', u'sky']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Stay', u'alive'],\n",
       "    'original': 'Stay alive...',\n",
       "    'speakers': ['ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Stay', u'alive']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Is',\n",
       "     u'he',\n",
       "     u'breathing',\n",
       "     u'Is',\n",
       "     u'he',\n",
       "     u'going',\n",
       "     u'to',\n",
       "     u'survive',\n",
       "     u'this'],\n",
       "    'original': 'Is he breathing? Is he going to survive this?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Is',\n",
       "     u'he',\n",
       "     u'breathing',\n",
       "     u'Is',\n",
       "     u'he',\n",
       "     u'going',\n",
       "     u'to',\n",
       "     u'survive',\n",
       "     u'this']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Stay', u'alive'],\n",
       "    'original': 'Stay alive...',\n",
       "    'speakers': ['ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Stay', u'alive']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Who',\n",
       "     u'did',\n",
       "     u'this',\n",
       "     u'Alexander',\n",
       "     u'did',\n",
       "     u'you',\n",
       "     u'know'],\n",
       "    'original': 'Who did this, Alexander, did you know?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Who',\n",
       "     u'did',\n",
       "     u'this',\n",
       "     u'Alexander',\n",
       "     u'did',\n",
       "     u'you',\n",
       "     u'know']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Mom',\n",
       "     u'I\\u2019m',\n",
       "     u'so',\n",
       "     u'sorry',\n",
       "     u'for',\n",
       "     u'forgetting',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'taught',\n",
       "     u'me'],\n",
       "    'original': 'Mom, I\\xe2\\x80\\x99m so sorry for forgetting what you taught me',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Mom',\n",
       "     u'I\\u2019m',\n",
       "     u'so',\n",
       "     u'sorry',\n",
       "     u'for',\n",
       "     u'forgetting',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'taught',\n",
       "     u'me']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'My', u'son'],\n",
       "    'original': 'My son\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'My', u'son']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'We', u'played', u'piano'],\n",
       "    'original': 'We played piano',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'We', u'played', u'piano']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'I', u'taught', u'you', u'piano'],\n",
       "    'original': 'I taught you piano',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'taught', u'you', u'piano']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'You',\n",
       "     u'would',\n",
       "     u'put',\n",
       "     u'your',\n",
       "     u'hands',\n",
       "     u'on',\n",
       "     u'mine'],\n",
       "    'original': 'You would put your hands on mine',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'You',\n",
       "     u'would',\n",
       "     u'put',\n",
       "     u'your',\n",
       "     u'hands',\n",
       "     u'on',\n",
       "     u'mine']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'You', u'changed', u'the', u'melody', u'every', u'time'],\n",
       "    'original': 'You changed the melody every time',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You', u'changed', u'the', u'melody', u'every', u'time']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Ha',\n",
       "     u'I',\n",
       "     u'would',\n",
       "     u'always',\n",
       "     u'change',\n",
       "     u'the',\n",
       "     u'line'],\n",
       "    'original': 'Ha. I would always change the line',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Ha',\n",
       "     u'I',\n",
       "     u'would',\n",
       "     u'always',\n",
       "     u'change',\n",
       "     u'the',\n",
       "     u'line']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Shh', u'I', u'know', u'I', u'know'],\n",
       "    'original': 'Shh. I know, I know',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Shh', u'I', u'know', u'I', u'know']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'I', u'would', u'always', u'change', u'the', u'line'],\n",
       "    'original': 'I would always change the line',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'would', u'always', u'change', u'the', u'line']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'I', u'know', u'I', u'know'],\n",
       "    'original': 'I know, I know',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'know', u'I', u'know']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Un', u'deux', u'trois', u'quatre'],\n",
       "    'original': 'Un deux trois quatre',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Un', u'deux', u'trois', u'quatre']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Cinq', u'six', u'sept', u'huit', u'neuf'],\n",
       "    'original': 'Cinq six sept huit neuf',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Cinq', u'six', u'sept', u'huit', u'neuf']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Good'],\n",
       "    'original': 'Good',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Good']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Un', u'deux', u'trois', u'quatre'],\n",
       "    'original': 'Un deux trois quatre',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Un', u'deux', u'trois', u'quatre']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Cinq', u'six', u'sept'],\n",
       "    'original': 'Cinq six sept',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Cinq', u'six', u'sept']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Huit', u'neuf'],\n",
       "    'original': 'Huit neuf',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Huit', u'neuf']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Sept', u'huit', u'neuf'],\n",
       "    'original': 'Sept huit neuf\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Sept', u'huit', u'neuf']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Sept', u'huit'],\n",
       "    'original': 'Sept huit\\xe2\\x80\\xa6',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Sept', u'huit']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Un', u'deux', u'trois', u'quatre'],\n",
       "    'original': 'Un deux trois quatre',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Un', u'deux', u'trois', u'quatre']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Cinq', u'six', u'sept', u'huit', u'neuf'],\n",
       "    'original': 'Cinq six sept huit neuf',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Cinq', u'six', u'sept', u'huit', u'neuf']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Un', u'deux', u'trois'],\n",
       "    'original': 'Un deux trois\\xe2\\x80\\xa6',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Un', u'deux', u'trois']}],\n",
       "  'track': 'Stay Alive (Reprise)',\n",
       "  'track#': '17'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'There',\n",
       "     u'are',\n",
       "     u'moments',\n",
       "     u'that',\n",
       "     u'the',\n",
       "     u'words',\n",
       "     u'don\\u2019t',\n",
       "     u'reach'],\n",
       "    'original': 'There are moments that the words don\\xe2\\x80\\x99t reach',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'There',\n",
       "     u'are',\n",
       "     u'moments',\n",
       "     u'that',\n",
       "     u'the',\n",
       "     u'words',\n",
       "     u'don\\u2019t',\n",
       "     u'reach']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'There',\n",
       "     u'is',\n",
       "     u'suffering',\n",
       "     u'too',\n",
       "     u'terrible',\n",
       "     u'to',\n",
       "     u'name'],\n",
       "    'original': 'There is suffering too terrible to name',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'There',\n",
       "     u'is',\n",
       "     u'suffering',\n",
       "     u'too',\n",
       "     u'terrible',\n",
       "     u'to',\n",
       "     u'name']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'You',\n",
       "     u'hold',\n",
       "     u'your',\n",
       "     u'child',\n",
       "     u'as',\n",
       "     u'tight',\n",
       "     u'as',\n",
       "     u'you',\n",
       "     u'can'],\n",
       "    'original': 'You hold your child as tight as you can',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'hold',\n",
       "     u'your',\n",
       "     u'child',\n",
       "     u'as',\n",
       "     u'tight',\n",
       "     u'as',\n",
       "     u'you',\n",
       "     u'can']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'And', u'push', u'away', u'the', u'unimaginable'],\n",
       "    'original': 'And push away the unimaginable',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'And', u'push', u'away', u'the', u'unimaginable']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'The',\n",
       "     u'moments',\n",
       "     u'when',\n",
       "     u'you\\u2019re',\n",
       "     u'in',\n",
       "     u'so',\n",
       "     u'deep'],\n",
       "    'original': 'The moments when you\\xe2\\x80\\x99re in so deep',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'The',\n",
       "     u'moments',\n",
       "     u'when',\n",
       "     u'you\\u2019re',\n",
       "     u'in',\n",
       "     u'so',\n",
       "     u'deep']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'It',\n",
       "     u'feels',\n",
       "     u'easier',\n",
       "     u'to',\n",
       "     u'just',\n",
       "     u'swim',\n",
       "     u'down'],\n",
       "    'original': 'It feels easier to just swim down',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'It',\n",
       "     u'feels',\n",
       "     u'easier',\n",
       "     u'to',\n",
       "     u'just',\n",
       "     u'swim',\n",
       "     u'down']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'The', u'Hamiltons', u'move', u'uptown'],\n",
       "    'original': 'The Hamiltons move uptown',\n",
       "    'speakers': ['ANGELICA', 'ENSEMBLE'],\n",
       "    'tokenized': [u'The', u'Hamiltons', u'move', u'uptown']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'And',\n",
       "     u'learn',\n",
       "     u'to',\n",
       "     u'live',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'unimaginable'],\n",
       "    'original': 'And learn to live with the unimaginable',\n",
       "    'speakers': ['ANGELICA', 'ENSEMBLE'],\n",
       "    'tokenized': [u'And',\n",
       "     u'learn',\n",
       "     u'to',\n",
       "     u'live',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'unimaginable']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'I', u'spend', u'hours', u'in', u'the', u'garden'],\n",
       "    'original': 'I spend hours in the garden',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'spend', u'hours', u'in', u'the', u'garden']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'I', u'walk', u'alone', u'to', u'the', u'store'],\n",
       "    'original': 'I walk alone to the store',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'walk', u'alone', u'to', u'the', u'store']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'And', u'it\\u2019s', u'quiet', u'uptown'],\n",
       "    'original': 'And it\\xe2\\x80\\x99s quiet uptown',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'it\\u2019s', u'quiet', u'uptown']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'I', u'never', u'liked', u'the', u'quiet', u'before'],\n",
       "    'original': 'I never liked the quiet before',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'never', u'liked', u'the', u'quiet', u'before']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'I',\n",
       "     u'take',\n",
       "     u'the',\n",
       "     u'children',\n",
       "     u'to',\n",
       "     u'church',\n",
       "     u'on',\n",
       "     u'Sunday'],\n",
       "    'original': 'I take the children to church on Sunday',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'take',\n",
       "     u'the',\n",
       "     u'children',\n",
       "     u'to',\n",
       "     u'church',\n",
       "     u'on',\n",
       "     u'Sunday']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'A',\n",
       "     u'sign',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'cross',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'door'],\n",
       "    'original': 'A sign of the cross at the door',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'sign',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'cross',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'door']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'And', u'I', u'pray'],\n",
       "    'original': 'And I pray',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'I', u'pray']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'That', u'never', u'used', u'to', u'happen', u'before'],\n",
       "    'original': 'That never used to happen before',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That', u'never', u'used', u'to', u'happen', u'before']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'street',\n",
       "     u'walking',\n",
       "     u'by'],\n",
       "    'original': 'If you see him in the street, walking by',\n",
       "    'speakers': ['ANGELICA', 'WOMEN'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'street',\n",
       "     u'walking',\n",
       "     u'by']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Himself',\n",
       "     u'talking',\n",
       "     u'to',\n",
       "     u'himself',\n",
       "     u'have',\n",
       "     u'pity'],\n",
       "    'original': 'Himself, talking to himself, have pity',\n",
       "    'speakers': ['ANGELICA', 'WOMEN'],\n",
       "    'tokenized': [u'Himself',\n",
       "     u'talking',\n",
       "     u'to',\n",
       "     u'himself',\n",
       "     u'have',\n",
       "     u'pity']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Philip', u'you', u'would', u'like', u'it', u'uptown'],\n",
       "    'original': 'Philip, you would like it uptown',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Philip', u'you', u'would', u'like', u'it', u'uptown']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'It\\u2019s', u'quiet', u'uptown'],\n",
       "    'original': 'It\\xe2\\x80\\x99s quiet uptown',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'It\\u2019s', u'quiet', u'uptown']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'He',\n",
       "     u'is',\n",
       "     u'working',\n",
       "     u'through',\n",
       "     u'the',\n",
       "     u'unimaginable'],\n",
       "    'original': 'He is working through the unimaginable',\n",
       "    'speakers': ['ANGELICA', 'WOMEN'],\n",
       "    'tokenized': [u'He',\n",
       "     u'is',\n",
       "     u'working',\n",
       "     u'through',\n",
       "     u'the',\n",
       "     u'unimaginable']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'His',\n",
       "     u'hair',\n",
       "     u'has',\n",
       "     u'gone',\n",
       "     u'grey',\n",
       "     u'He',\n",
       "     u'passes',\n",
       "     u'every',\n",
       "     u'day'],\n",
       "    'original': 'His hair has gone grey. He passes every day',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'His',\n",
       "     u'hair',\n",
       "     u'has',\n",
       "     u'gone',\n",
       "     u'grey',\n",
       "     u'He',\n",
       "     u'passes',\n",
       "     u'every',\n",
       "     u'day']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'They',\n",
       "     u'say',\n",
       "     u'he',\n",
       "     u'walks',\n",
       "     u'the',\n",
       "     u'length',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'city'],\n",
       "    'original': 'They say he walks the length of the city',\n",
       "    'speakers': ['ALL MEN'],\n",
       "    'tokenized': [u'They',\n",
       "     u'say',\n",
       "     u'he',\n",
       "     u'walks',\n",
       "     u'the',\n",
       "     u'length',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'city']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'You', u'knock', u'me', u'out', u'I', u'fall', u'apart'],\n",
       "    'original': 'You knock me out, I fall apart',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You', u'knock', u'me', u'out', u'I', u'fall', u'apart']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Can', u'you', u'imagine'],\n",
       "    'original': 'Can you imagine?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Can', u'you', u'imagine']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Look', u'at', u'where', u'we', u'are'],\n",
       "    'original': 'Look at where we are',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Look', u'at', u'where', u'we', u'are']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Look', u'at', u'where', u'we', u'started'],\n",
       "    'original': 'Look at where we started',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Look', u'at', u'where', u'we', u'started']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'deserve',\n",
       "     u'you',\n",
       "     u'Eliza'],\n",
       "    'original': 'I know I don\\xe2\\x80\\x99t deserve you, Eliza',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'deserve',\n",
       "     u'you',\n",
       "     u'Eliza']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'But',\n",
       "     u'hear',\n",
       "     u'me',\n",
       "     u'out',\n",
       "     u'That',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough'],\n",
       "    'original': 'But hear me out. That would be enough',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'hear',\n",
       "     u'me',\n",
       "     u'out',\n",
       "     u'That',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'If', u'I', u'could', u'spare', u'his', u'life'],\n",
       "    'original': 'If I could spare his life',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If', u'I', u'could', u'spare', u'his', u'life']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'If',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'trade',\n",
       "     u'his',\n",
       "     u'life',\n",
       "     u'for',\n",
       "     u'mine'],\n",
       "    'original': 'If I could trade his life for mine',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'trade',\n",
       "     u'his',\n",
       "     u'life',\n",
       "     u'for',\n",
       "     u'mine']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'He\\u2019d',\n",
       "     u'be',\n",
       "     u'standing',\n",
       "     u'here',\n",
       "     u'right',\n",
       "     u'now'],\n",
       "    'original': 'He\\xe2\\x80\\x99d be standing here right now',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'He\\u2019d',\n",
       "     u'be',\n",
       "     u'standing',\n",
       "     u'here',\n",
       "     u'right',\n",
       "     u'now']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'And',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'smile',\n",
       "     u'and',\n",
       "     u'that',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough'],\n",
       "    'original': 'And you would smile, and that would be enough',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'smile',\n",
       "     u'and',\n",
       "     u'that',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'pretend', u'to', u'know'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t pretend to know',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'pretend', u'to', u'know']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'The', u'challenges', u'we\\u2019re', u'facing'],\n",
       "    'original': 'The challenges we\\xe2\\x80\\x99re facing',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'challenges', u'we\\u2019re', u'facing']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'there\\u2019s',\n",
       "     u'no',\n",
       "     u'replacing',\n",
       "     u'what',\n",
       "     u'we\\u2019ve',\n",
       "     u'lost'],\n",
       "    'original': 'I know there\\xe2\\x80\\x99s no replacing what we\\xe2\\x80\\x99ve lost',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'there\\u2019s',\n",
       "     u'no',\n",
       "     u'replacing',\n",
       "     u'what',\n",
       "     u'we\\u2019ve',\n",
       "     u'lost']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'And', u'you', u'need', u'time'],\n",
       "    'original': 'And you need time',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'you', u'need', u'time']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'But', u'I\\u2019m', u'not', u'afraid'],\n",
       "    'original': 'But I\\xe2\\x80\\x99m not afraid',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But', u'I\\u2019m', u'not', u'afraid']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'I', u'know', u'who', u'I', u'married'],\n",
       "    'original': 'I know who I married',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'know', u'who', u'I', u'married']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Just',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'stay',\n",
       "     u'here',\n",
       "     u'by',\n",
       "     u'your',\n",
       "     u'side'],\n",
       "    'original': 'Just let me stay here by your side',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Just',\n",
       "     u'let',\n",
       "     u'me',\n",
       "     u'stay',\n",
       "     u'here',\n",
       "     u'by',\n",
       "     u'your',\n",
       "     u'side']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'That', u'would', u'be', u'enough'],\n",
       "    'original': 'That would be enough',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That', u'would', u'be', u'enough']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'street',\n",
       "     u'walking',\n",
       "     u'by',\n",
       "     u'her'],\n",
       "    'original': 'If you see him in the street, walking by her',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'street',\n",
       "     u'walking',\n",
       "     u'by',\n",
       "     u'her']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Side',\n",
       "     u'talking',\n",
       "     u'by',\n",
       "     u'her',\n",
       "     u'side',\n",
       "     u'have',\n",
       "     u'pity'],\n",
       "    'original': 'Side, talking by her side, have pity',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Side',\n",
       "     u'talking',\n",
       "     u'by',\n",
       "     u'her',\n",
       "     u'side',\n",
       "     u'have',\n",
       "     u'pity']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Eliza',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'like',\n",
       "     u'it',\n",
       "     u'uptown',\n",
       "     u'It\\u2019s',\n",
       "     u'quiet',\n",
       "     u'uptown'],\n",
       "    'original': 'Eliza, do you like it uptown? It\\xe2\\x80\\x99s quiet uptown',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Eliza',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'like',\n",
       "     u'it',\n",
       "     u'uptown',\n",
       "     u'It\\u2019s',\n",
       "     u'quiet',\n",
       "     u'uptown']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'He',\n",
       "     u'is',\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'the',\n",
       "     u'unimaginable'],\n",
       "    'original': 'He is trying to do the unimaginable',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'He',\n",
       "     u'is',\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'the',\n",
       "     u'unimaginable']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'See',\n",
       "     u'them',\n",
       "     u'walking',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'park',\n",
       "     u'long',\n",
       "     u'after',\n",
       "     u'dark'],\n",
       "    'original': 'See them walking in the park, long after dark',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'See',\n",
       "     u'them',\n",
       "     u'walking',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'park',\n",
       "     u'long',\n",
       "     u'after',\n",
       "     u'dark']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Taking',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'sights',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'city'],\n",
       "    'original': 'Taking in the sights of the city',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Taking',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'sights',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'city']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Look', u'around', u'look', u'around', u'Eliza'],\n",
       "    'original': 'Look around, look around, Eliza',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Look', u'around', u'look', u'around', u'Eliza']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'They',\n",
       "     u'are',\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'the',\n",
       "     u'unimaginable'],\n",
       "    'original': 'They are trying to do the unimaginable',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'They',\n",
       "     u'are',\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'the',\n",
       "     u'unimaginable']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'There',\n",
       "     u'are',\n",
       "     u'moments',\n",
       "     u'that',\n",
       "     u'the',\n",
       "     u'words',\n",
       "     u'don\\u2019t',\n",
       "     u'reach'],\n",
       "    'original': 'There are moments that the words don\\xe2\\x80\\x99t reach',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'There',\n",
       "     u'are',\n",
       "     u'moments',\n",
       "     u'that',\n",
       "     u'the',\n",
       "     u'words',\n",
       "     u'don\\u2019t',\n",
       "     u'reach']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'There',\n",
       "     u'is',\n",
       "     u'a',\n",
       "     u'grace',\n",
       "     u'too',\n",
       "     u'powerful',\n",
       "     u'to',\n",
       "     u'name'],\n",
       "    'original': 'There is a grace too powerful to name',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'There',\n",
       "     u'is',\n",
       "     u'a',\n",
       "     u'grace',\n",
       "     u'too',\n",
       "     u'powerful',\n",
       "     u'to',\n",
       "     u'name']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'We',\n",
       "     u'push',\n",
       "     u'away',\n",
       "     u'what',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'never',\n",
       "     u'understand'],\n",
       "    'original': 'We push away what we can never understand',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'We',\n",
       "     u'push',\n",
       "     u'away',\n",
       "     u'what',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'never',\n",
       "     u'understand']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'We', u'push', u'away', u'the', u'unimaginable'],\n",
       "    'original': 'We push away the unimaginable',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'We', u'push', u'away', u'the', u'unimaginable']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'They', u'are', u'standing', u'in', u'the', u'garden'],\n",
       "    'original': 'They are standing in the garden',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'They', u'are', u'standing', u'in', u'the', u'garden']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Alexander', u'by', u'Eliza\\u2019s', u'side'],\n",
       "    'original': 'Alexander by Eliza\\xe2\\x80\\x99s side',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Alexander', u'by', u'Eliza\\u2019s', u'side']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'She', u'takes', u'his', u'hand'],\n",
       "    'original': 'She takes his hand',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'She', u'takes', u'his', u'hand']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'It\\u2019s', u'quiet', u'uptown'],\n",
       "    'original': 'It\\xe2\\x80\\x99s quiet uptown',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'It\\u2019s', u'quiet', u'uptown']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Forgiveness', u'Can', u'you', u'imagine'],\n",
       "    'original': 'Forgiveness. Can you imagine?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Forgiveness', u'Can', u'you', u'imagine']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Forgiveness', u'Can', u'you', u'imagine'],\n",
       "    'original': 'Forgiveness. Can you imagine?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Forgiveness', u'Can', u'you', u'imagine']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'If',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'street',\n",
       "     u'walking',\n",
       "     u'by',\n",
       "     u'her'],\n",
       "    'original': 'If you see him in the street, walking by her',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'If',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'street',\n",
       "     u'walking',\n",
       "     u'by',\n",
       "     u'her']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Side',\n",
       "     u'talking',\n",
       "     u'by',\n",
       "     u'her',\n",
       "     u'side',\n",
       "     u'have',\n",
       "     u'pity'],\n",
       "    'original': 'Side, talking by her side, have pity',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Side',\n",
       "     u'talking',\n",
       "     u'by',\n",
       "     u'her',\n",
       "     u'side',\n",
       "     u'have',\n",
       "     u'pity']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'They',\n",
       "     u'are',\n",
       "     u'going',\n",
       "     u'through',\n",
       "     u'the',\n",
       "     u'unimaginable'],\n",
       "    'original': 'They are going through the unimaginable',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'They',\n",
       "     u'are',\n",
       "     u'going',\n",
       "     u'through',\n",
       "     u'the',\n",
       "     u'unimaginable']}],\n",
       "  'track': \"It's Quiet Uptown\",\n",
       "  'track#': '18'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'The', u'election', u'of', u'1800'],\n",
       "    'original': 'The election of 1800',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'The', u'election', u'of', u'1800']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Can', u'we', u'get', u'back', u'to', u'politics'],\n",
       "    'original': 'Can we get back to politics?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Can', u'we', u'get', u'back', u'to', u'politics']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Please'],\n",
       "    'original': 'Please?',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Please']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Yo',\n",
       "     u'Ev\\u2019ry',\n",
       "     u'action',\n",
       "     u'has',\n",
       "     u'an',\n",
       "     u'equal',\n",
       "     u'opposite',\n",
       "     u'reaction'],\n",
       "    'original': 'Yo. Ev\\xe2\\x80\\x99ry action has an equal, opposite reaction',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Yo',\n",
       "     u'Ev\\u2019ry',\n",
       "     u'action',\n",
       "     u'has',\n",
       "     u'an',\n",
       "     u'equal',\n",
       "     u'opposite',\n",
       "     u'reaction']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'John',\n",
       "     u'Adams',\n",
       "     u'shat',\n",
       "     u'the',\n",
       "     u'bed',\n",
       "     u'I',\n",
       "     u'love',\n",
       "     u'the',\n",
       "     u'guy',\n",
       "     u'but',\n",
       "     u'he\\u2019s',\n",
       "     u'in',\n",
       "     u'traction'],\n",
       "    'original': 'John Adams shat the bed. I love the guy, but he\\xe2\\x80\\x99s in traction',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'John',\n",
       "     u'Adams',\n",
       "     u'shat',\n",
       "     u'the',\n",
       "     u'bed',\n",
       "     u'I',\n",
       "     u'love',\n",
       "     u'the',\n",
       "     u'guy',\n",
       "     u'but',\n",
       "     u'he\\u2019s',\n",
       "     u'in',\n",
       "     u'traction']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Poor',\n",
       "     u'Alexander',\n",
       "     u'Hamilton',\n",
       "     u'He',\n",
       "     u'is',\n",
       "     u'missing',\n",
       "     u'in',\n",
       "     u'action'],\n",
       "    'original': 'Poor Alexander Hamilton? He is missing in action',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Poor',\n",
       "     u'Alexander',\n",
       "     u'Hamilton',\n",
       "     u'He',\n",
       "     u'is',\n",
       "     u'missing',\n",
       "     u'in',\n",
       "     u'action']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'So', u'now', u'I\\u2019m', u'facing'],\n",
       "    'original': 'So now I\\xe2\\x80\\x99m facing\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'So', u'now', u'I\\u2019m', u'facing']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Aaron', u'Burr'],\n",
       "    'original': 'Aaron Burr!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'Aaron', u'Burr']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'With', u'his', u'own', u'faction'],\n",
       "    'original': 'With his own faction',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'With', u'his', u'own', u'faction']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'He\\u2019s',\n",
       "     u'very',\n",
       "     u'attractive',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'North',\n",
       "     u'New',\n",
       "     u'Yorkers',\n",
       "     u'like',\n",
       "     u'his',\n",
       "     u'chances'],\n",
       "    'original': 'He\\xe2\\x80\\x99s very attractive in the North. New Yorkers like his chances',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'He\\u2019s',\n",
       "     u'very',\n",
       "     u'attractive',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'North',\n",
       "     u'New',\n",
       "     u'Yorkers',\n",
       "     u'like',\n",
       "     u'his',\n",
       "     u'chances']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'He\\u2019s',\n",
       "     u'not',\n",
       "     u'very',\n",
       "     u'forthcoming',\n",
       "     u'on',\n",
       "     u'any',\n",
       "     u'particular',\n",
       "     u'stances'],\n",
       "    'original': 'He\\xe2\\x80\\x99s not very forthcoming on any particular stances',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'He\\u2019s',\n",
       "     u'not',\n",
       "     u'very',\n",
       "     u'forthcoming',\n",
       "     u'on',\n",
       "     u'any',\n",
       "     u'particular',\n",
       "     u'stances']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Ask',\n",
       "     u'him',\n",
       "     u'a',\n",
       "     u'question',\n",
       "     u'it',\n",
       "     u'glances',\n",
       "     u'off',\n",
       "     u'he',\n",
       "     u'obfuscates',\n",
       "     u'he',\n",
       "     u'dances'],\n",
       "    'original': 'Ask him a question: it glances off, he obfuscates, he dances',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Ask',\n",
       "     u'him',\n",
       "     u'a',\n",
       "     u'question',\n",
       "     u'it',\n",
       "     u'glances',\n",
       "     u'off',\n",
       "     u'he',\n",
       "     u'obfuscates',\n",
       "     u'he',\n",
       "     u'dances']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'And',\n",
       "     u'they',\n",
       "     u'say',\n",
       "     u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'Francophile',\n",
       "     u'at',\n",
       "     u'least',\n",
       "     u'they',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'where',\n",
       "     u'France',\n",
       "     u'is'],\n",
       "    'original': 'And they say I\\xe2\\x80\\x99m a Francophile: at least they know I know where France is!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'they',\n",
       "     u'say',\n",
       "     u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'Francophile',\n",
       "     u'at',\n",
       "     u'least',\n",
       "     u'they',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'know',\n",
       "     u'where',\n",
       "     u'France',\n",
       "     u'is']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Thomas',\n",
       "     u'that\\u2019s',\n",
       "     u'the',\n",
       "     u'problem',\n",
       "     u'see',\n",
       "     u'they',\n",
       "     u'see',\n",
       "     u'Burr',\n",
       "     u'as',\n",
       "     u'a',\n",
       "     u'less',\n",
       "     u'extreme',\n",
       "     u'you'],\n",
       "    'original': 'Thomas that\\xe2\\x80\\x99s the problem, see, they see Burr as a less extreme you',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Thomas',\n",
       "     u'that\\u2019s',\n",
       "     u'the',\n",
       "     u'problem',\n",
       "     u'see',\n",
       "     u'they',\n",
       "     u'see',\n",
       "     u'Burr',\n",
       "     u'as',\n",
       "     u'a',\n",
       "     u'less',\n",
       "     u'extreme',\n",
       "     u'you']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Ha'],\n",
       "    'original': 'Ha!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Ha']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'You',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'change',\n",
       "     u'course',\n",
       "     u'a',\n",
       "     u'key',\n",
       "     u'endorsement',\n",
       "     u'might',\n",
       "     u'redeem',\n",
       "     u'you'],\n",
       "    'original': 'You need to change course, a key endorsement might redeem you',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'change',\n",
       "     u'course',\n",
       "     u'a',\n",
       "     u'key',\n",
       "     u'endorsement',\n",
       "     u'might',\n",
       "     u'redeem',\n",
       "     u'you']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Who', u'did', u'you', u'have', u'in', u'mind'],\n",
       "    'original': 'Who did you have in mind?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Who', u'did', u'you', u'have', u'in', u'mind']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Don\\u2019t', u'laugh'],\n",
       "    'original': 'Don\\xe2\\x80\\x99t laugh',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Don\\u2019t', u'laugh']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Who', u'is', u'it'],\n",
       "    'original': 'Who is it?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Who', u'is', u'it']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'You',\n",
       "     u'used',\n",
       "     u'to',\n",
       "     u'work',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'staff'],\n",
       "    'original': 'You used to work on the same staff',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'used',\n",
       "     u'to',\n",
       "     u'work',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'same',\n",
       "     u'staff']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Whaaaat'],\n",
       "    'original': 'Whaaaat',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Whaaaat']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'It',\n",
       "     u'might',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'might',\n",
       "     u'be',\n",
       "     u'nice'],\n",
       "    'original': 'It might be nice, it might be nice',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'It',\n",
       "     u'might',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'might',\n",
       "     u'be',\n",
       "     u'nice']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'To', u'get', u'Hamilton', u'on', u'your', u'side'],\n",
       "    'original': 'To get Hamilton on your side',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'To', u'get', u'Hamilton', u'on', u'your', u'side']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'It',\n",
       "     u'might',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'might',\n",
       "     u'be',\n",
       "     u'nice'],\n",
       "    'original': 'It might be nice, it might be nice',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'It',\n",
       "     u'might',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'might',\n",
       "     u'be',\n",
       "     u'nice']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'To', u'get', u'Hamilton', u'on', u'your', u'side'],\n",
       "    'original': 'To get Hamilton on your side',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'To', u'get', u'Hamilton', u'on', u'your', u'side']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Talk', u'less'],\n",
       "    'original': 'Talk less!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Talk', u'less']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Smile', u'more'],\n",
       "    'original': 'Smile more!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Smile', u'more']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Don\\u2019t',\n",
       "     u'let',\n",
       "     u'em',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you\\u2019re',\n",
       "     u'against',\n",
       "     u'or',\n",
       "     u'what',\n",
       "     u'you\\u2019re',\n",
       "     u'for'],\n",
       "    'original': 'Don\\xe2\\x80\\x99t let \\xe2\\x80\\x98em know what you\\xe2\\x80\\x99re against or what you\\xe2\\x80\\x99re for!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Don\\u2019t',\n",
       "     u'let',\n",
       "     u'em',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you\\u2019re',\n",
       "     u'against',\n",
       "     u'or',\n",
       "     u'what',\n",
       "     u'you\\u2019re',\n",
       "     u'for']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Shake', u'hands', u'with', u'him'],\n",
       "    'original': 'Shake hands with him!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Shake', u'hands', u'with', u'him']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Charm', u'her'],\n",
       "    'original': 'Charm her!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Charm', u'her']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'It\\u2019s',\n",
       "     u'eighteen',\n",
       "     u'hundred',\n",
       "     u'ladies',\n",
       "     u'tell',\n",
       "     u'your',\n",
       "     u'husbands',\n",
       "     u'vote',\n",
       "     u'for'],\n",
       "    'original': 'It\\xe2\\x80\\x99s eighteen hundred, ladies, tell your husbands: vote for',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It\\u2019s',\n",
       "     u'eighteen',\n",
       "     u'hundred',\n",
       "     u'ladies',\n",
       "     u'tell',\n",
       "     u'your',\n",
       "     u'husbands',\n",
       "     u'vote',\n",
       "     u'for']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'like', u'Adams'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t like Adams',\n",
       "    'speakers': ['MALE VOTER'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'like', u'Adams']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'gonna',\n",
       "     u'lose',\n",
       "     u'that\\u2019s',\n",
       "     u'just',\n",
       "     u'defeatist'],\n",
       "    'original': 'Well, he\\xe2\\x80\\x99s gonna lose, that\\xe2\\x80\\x99s just defeatist',\n",
       "    'speakers': ['FEMALE VOTER'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'he\\u2019s',\n",
       "     u'gonna',\n",
       "     u'lose',\n",
       "     u'that\\u2019s',\n",
       "     u'just',\n",
       "     u'defeatist']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'And', u'Jefferson'],\n",
       "    'original': 'And Jefferson\\xe2\\x80\\x94',\n",
       "    'speakers': ['ANOTHER MALE VOTER'],\n",
       "    'tokenized': [u'And', u'Jefferson']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'In', u'love', u'with', u'France'],\n",
       "    'original': 'In love with France!',\n",
       "    'speakers': ['TWO MEN'],\n",
       "    'tokenized': [u'In', u'love', u'with', u'France']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Yeah', u'he\\u2019s', u'so', u'elitist'],\n",
       "    'original': 'Yeah, he\\xe2\\x80\\x99s so elitist!',\n",
       "    'speakers': ['ANOTHER FEMALE VOTER'],\n",
       "    'tokenized': [u'Yeah', u'he\\u2019s', u'so', u'elitist']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'I', u'like', u'that', u'Aaron', u'Burr'],\n",
       "    'original': 'I like that Aaron Burr!',\n",
       "    'speakers': ['TWO WOMEN'],\n",
       "    'tokenized': [u'I', u'like', u'that', u'Aaron', u'Burr']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'believe',\n",
       "     u'we\\u2019re',\n",
       "     u'here',\n",
       "     u'with',\n",
       "     u'him'],\n",
       "    'original': 'I can\\xe2\\x80\\x99t believe we\\xe2\\x80\\x99re here with him!',\n",
       "    'speakers': ['A WOMAN'],\n",
       "    'tokenized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'believe',\n",
       "     u'we\\u2019re',\n",
       "     u'here',\n",
       "     u'with',\n",
       "     u'him']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'He', u'seems', u'approachable'],\n",
       "    'original': 'He seems approachable\\xe2\\x80\\xa6?',\n",
       "    'speakers': ['A MAN'],\n",
       "    'tokenized': [u'He', u'seems', u'approachable']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Like',\n",
       "     u'you',\n",
       "     u'could',\n",
       "     u'grab',\n",
       "     u'a',\n",
       "     u'beer',\n",
       "     u'with',\n",
       "     u'him'],\n",
       "    'original': 'Like you could grab a beer with him!',\n",
       "    'speakers': ['ANOTHER MALE VOTER'],\n",
       "    'tokenized': [u'Like',\n",
       "     u'you',\n",
       "     u'could',\n",
       "     u'grab',\n",
       "     u'a',\n",
       "     u'beer',\n",
       "     u'with',\n",
       "     u'him']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Dear',\n",
       "     u'Mr',\n",
       "     u'Hamilton',\n",
       "     u'your',\n",
       "     u'fellow',\n",
       "     u'Fed\\u2019ralists',\n",
       "     u'would',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'know',\n",
       "     u'how',\n",
       "     u'you\\u2019ll',\n",
       "     u'be',\n",
       "     u'voting'],\n",
       "    'original': 'Dear Mr. Hamilton: your fellow Fed\\xe2\\x80\\x99ralists would like to know how you\\xe2\\x80\\x99ll be voting',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Dear',\n",
       "     u'Mr',\n",
       "     u'Hamilton',\n",
       "     u'your',\n",
       "     u'fellow',\n",
       "     u'Fed\\u2019ralists',\n",
       "     u'would',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'know',\n",
       "     u'how',\n",
       "     u'you\\u2019ll',\n",
       "     u'be',\n",
       "     u'voting']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'It\\u2019s', u'quiet', u'uptown'],\n",
       "    'original': 'It\\xe2\\x80\\x99s quiet uptown',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'It\\u2019s', u'quiet', u'uptown']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Dear',\n",
       "     u'Mr',\n",
       "     u'Hamilton',\n",
       "     u'John',\n",
       "     u'Adams',\n",
       "     u'doesn\\u2019t',\n",
       "     u'stand',\n",
       "     u'a',\n",
       "     u'chance',\n",
       "     u'so',\n",
       "     u'who',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'promoting'],\n",
       "    'original': 'Dear Mr. Hamilton: John Adams doesn\\xe2\\x80\\x99t stand a chance, so who are you promoting?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Dear',\n",
       "     u'Mr',\n",
       "     u'Hamilton',\n",
       "     u'John',\n",
       "     u'Adams',\n",
       "     u'doesn\\u2019t',\n",
       "     u'stand',\n",
       "     u'a',\n",
       "     u'chance',\n",
       "     u'so',\n",
       "     u'who',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'promoting']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'It\\u2019s', u'quiet', u'uptown'],\n",
       "    'original': 'It\\xe2\\x80\\x99s quiet uptown',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'It\\u2019s', u'quiet', u'uptown']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'We', u'know', u'it\\u2019s', u'lose', u'lose'],\n",
       "    'original': 'We know it\\xe2\\x80\\x99s lose-lose',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'We', u'know', u'it\\u2019s', u'lose', u'lose']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'But', u'if', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'But if you had to choose',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'But', u'if', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'We', u'know', u'it\\u2019s', u'lose', u'lose'],\n",
       "    'original': 'We know it\\xe2\\x80\\x99s lose-lose',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'We', u'know', u'it\\u2019s', u'lose', u'lose']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'But', u'if', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'But if you had to choose',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'But', u'if', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Dear', u'Mr', u'Hamilton'],\n",
       "    'original': 'Dear Mr. Hamilton:',\n",
       "    'speakers': ['EVEN MORE VOTERS'],\n",
       "    'tokenized': [u'Dear', u'Mr', u'Hamilton']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'John',\n",
       "     u'Adams',\n",
       "     u'doesn\\u2019t',\n",
       "     u'stand',\n",
       "     u'a',\n",
       "     u'chance',\n",
       "     u'so',\n",
       "     u'who',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'promoting'],\n",
       "    'original': 'John Adams doesn\\xe2\\x80\\x99t stand a chance so who are you promoting?',\n",
       "    'speakers': ['EVEN MORE VOTERS'],\n",
       "    'tokenized': [u'John',\n",
       "     u'Adams',\n",
       "     u'doesn\\u2019t',\n",
       "     u'stand',\n",
       "     u'a',\n",
       "     u'chance',\n",
       "     u'so',\n",
       "     u'who',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'promoting']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'But', u'if', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'But if you had to choose',\n",
       "    'speakers': ['EVEN MORE VOTERS'],\n",
       "    'tokenized': [u'But', u'if', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'We', u'know', u'it\\u2019s', u'lose', u'lose'],\n",
       "    'original': 'We know it\\xe2\\x80\\x99s lose-lose',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'We', u'know', u'it\\u2019s', u'lose', u'lose']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'But', u'if', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'But if you had to choose',\n",
       "    'speakers': ['MEN'],\n",
       "    'tokenized': [u'But', u'if', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'We', u'know', u'it\\u2019s', u'lose', u'lose'],\n",
       "    'original': 'We know it\\xe2\\x80\\x99s lose-lose',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'We', u'know', u'it\\u2019s', u'lose', u'lose']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'But', u'if', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'But if you had to choose',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'But', u'if', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'Well',\n",
       "     u'if',\n",
       "     u'it',\n",
       "     u'isn\\u2019t',\n",
       "     u'Aaron',\n",
       "     u'Burr',\n",
       "     u'Sir'],\n",
       "    'original': 'Well, if it isn\\xe2\\x80\\x99t Aaron Burr. Sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'if',\n",
       "     u'it',\n",
       "     u'isn\\u2019t',\n",
       "     u'Aaron',\n",
       "     u'Burr',\n",
       "     u'Sir']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'Alexander'],\n",
       "    'original': 'Alexander!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Alexander']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'You\\u2019ve',\n",
       "     u'created',\n",
       "     u'quite',\n",
       "     u'a',\n",
       "     u'stir',\n",
       "     u'sir'],\n",
       "    'original': 'You\\xe2\\x80\\x99ve created quite a stir, sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You\\u2019ve',\n",
       "     u'created',\n",
       "     u'quite',\n",
       "     u'a',\n",
       "     u'stir',\n",
       "     u'sir']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'I\\u2019m', u'going', u'door', u'to', u'door'],\n",
       "    'original': 'I\\xe2\\x80\\x99m going door to door!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I\\u2019m', u'going', u'door', u'to', u'door']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'You\\u2019re', u'openly', u'campaigning'],\n",
       "    'original': 'You\\xe2\\x80\\x99re openly campaigning?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You\\u2019re', u'openly', u'campaigning']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Sure'],\n",
       "    'original': 'Sure!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Sure']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'That\\u2019s', u'new'],\n",
       "    'original': 'That\\xe2\\x80\\x99s new',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That\\u2019s', u'new']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'Honestly', u'it\\u2019s', u'kind', u'of', u'draining'],\n",
       "    'original': 'Honestly, it\\xe2\\x80\\x99s kind of draining',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Honestly', u'it\\u2019s', u'kind', u'of', u'draining']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Is',\n",
       "     u'there',\n",
       "     u'anything',\n",
       "     u'you',\n",
       "     u'wouldn\\u2019t',\n",
       "     u'do'],\n",
       "    'original': 'Is there anything you wouldn\\xe2\\x80\\x99t do?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is',\n",
       "     u'there',\n",
       "     u'anything',\n",
       "     u'you',\n",
       "     u'wouldn\\u2019t',\n",
       "     u'do']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'No', u'I\\u2019m', u'chasing', u'what', u'I', u'want'],\n",
       "    'original': 'No. I\\xe2\\x80\\x99m chasing what I want',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'I\\u2019m', u'chasing', u'what', u'I', u'want']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'And', u'you', u'know', u'what'],\n",
       "    'original': 'And you know what?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'you', u'know', u'what']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'I', u'learned', u'that', u'from', u'you'],\n",
       "    'original': 'I learned that from you',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'learned', u'that', u'from', u'you']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'If', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'If you had to choose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'If', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'If', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'If you had to choose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'If', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'It\\u2019s', u'a', u'tie'],\n",
       "    'original': 'It\\xe2\\x80\\x99s a tie!',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'It\\u2019s', u'a', u'tie']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'If', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'If you had to choose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'If', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'If', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'If you had to choose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'If', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'It\\u2019s', u'up', u'to', u'the', u'delegates'],\n",
       "    'original': 'It\\xe2\\x80\\x99s up to the delegates!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'It\\u2019s', u'up', u'to', u'the', u'delegates']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'If', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'If you had to choose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'If', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'If', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'If you had to choose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'If', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'It\\u2019s', u'up', u'to', u'Hamilton'],\n",
       "    'original': 'It\\xe2\\x80\\x99s up to Hamilton!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'It\\u2019s', u'up', u'to', u'Hamilton']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'If', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'If you had to choose',\n",
       "    'speakers': ['VOTERS'],\n",
       "    'tokenized': [u'If', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'If', u'you', u'had', u'to', u'choose'],\n",
       "    'original': 'If you had to choose',\n",
       "    'speakers': ['VOTERS'],\n",
       "    'tokenized': [u'If', u'you', u'had', u'to', u'choose']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'If', u'you', u'had', u'to'],\n",
       "    'original': 'If you had to',\n",
       "    'speakers': ['VOTERS'],\n",
       "    'tokenized': [u'If', u'you', u'had', u'to']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'Choose'],\n",
       "    'original': 'Choose',\n",
       "    'speakers': ['VOTERS'],\n",
       "    'tokenized': [u'Choose']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'Choose'],\n",
       "    'original': 'Choose',\n",
       "    'speakers': ['VOTERS'],\n",
       "    'tokenized': [u'Choose']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'Choose'],\n",
       "    'original': 'Choose!',\n",
       "    'speakers': ['VOTERS'],\n",
       "    'tokenized': [u'Choose']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['MADISON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'Choose'],\n",
       "    'original': 'Choose',\n",
       "    'speakers': ['MADISON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Choose']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'Choose'],\n",
       "    'original': 'Choose',\n",
       "    'speakers': ['MADISON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Choose']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'Choose'],\n",
       "    'original': 'Choose!',\n",
       "    'speakers': ['MADISON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Choose']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'Jefferson', u'or', u'Burr'],\n",
       "    'original': 'Jefferson or Burr?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Jefferson', u'or', u'Burr']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'Choose'],\n",
       "    'original': 'Choose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Choose']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'Choose'],\n",
       "    'original': 'Choose',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Choose']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'Choose'],\n",
       "    'original': 'Choose!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Choose']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'Yo'],\n",
       "    'original': 'Yo',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yo']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'The',\n",
       "     u'people',\n",
       "     u'are',\n",
       "     u'asking',\n",
       "     u'to',\n",
       "     u'hear',\n",
       "     u'my',\n",
       "     u'voice'],\n",
       "    'original': 'The people are asking to hear my voice',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'people',\n",
       "     u'are',\n",
       "     u'asking',\n",
       "     u'to',\n",
       "     u'hear',\n",
       "     u'my',\n",
       "     u'voice']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'For',\n",
       "     u'the',\n",
       "     u'country',\n",
       "     u'is',\n",
       "     u'facing',\n",
       "     u'a',\n",
       "     u'difficult',\n",
       "     u'choice'],\n",
       "    'original': 'For the country is facing a difficult choice',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'For',\n",
       "     u'the',\n",
       "     u'country',\n",
       "     u'is',\n",
       "     u'facing',\n",
       "     u'a',\n",
       "     u'difficult',\n",
       "     u'choice']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'And',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'were',\n",
       "     u'to',\n",
       "     u'ask',\n",
       "     u'me',\n",
       "     u'who',\n",
       "     u'I\\u2019d',\n",
       "     u'promote'],\n",
       "    'original': 'And if you were to ask me who I\\xe2\\x80\\x99d promote\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'were',\n",
       "     u'to',\n",
       "     u'ask',\n",
       "     u'me',\n",
       "     u'who',\n",
       "     u'I\\u2019d',\n",
       "     u'promote']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'Jefferson', u'has', u'my', u'vote'],\n",
       "    'original': '\\xe2\\x80\\x94Jefferson has my vote',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Jefferson', u'has', u'my', u'vote']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'never',\n",
       "     u'agreed',\n",
       "     u'with',\n",
       "     u'Jefferson',\n",
       "     u'once'],\n",
       "    'original': 'I have never agreed with Jefferson once',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'never',\n",
       "     u'agreed',\n",
       "     u'with',\n",
       "     u'Jefferson',\n",
       "     u'once']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'We',\n",
       "     u'have',\n",
       "     u'fought',\n",
       "     u'on',\n",
       "     u'like',\n",
       "     u'seventy',\n",
       "     u'five',\n",
       "     u'diff\\u2019rent',\n",
       "     u'fronts'],\n",
       "    'original': 'We have fought on like seventy-five diff\\xe2\\x80\\x99rent fronts',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'have',\n",
       "     u'fought',\n",
       "     u'on',\n",
       "     u'like',\n",
       "     u'seventy',\n",
       "     u'five',\n",
       "     u'diff\\u2019rent',\n",
       "     u'fronts']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'But',\n",
       "     u'when',\n",
       "     u'all',\n",
       "     u'is',\n",
       "     u'said',\n",
       "     u'and',\n",
       "     u'all',\n",
       "     u'is',\n",
       "     u'done'],\n",
       "    'original': 'But when all is said and all is done',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'when',\n",
       "     u'all',\n",
       "     u'is',\n",
       "     u'said',\n",
       "     u'and',\n",
       "     u'all',\n",
       "     u'is',\n",
       "     u'done']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'Jefferson', u'has', u'beliefs', u'Burr', u'has', u'none'],\n",
       "    'original': 'Jefferson has beliefs. Burr has none',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Jefferson', u'has', u'beliefs', u'Burr', u'has', u'none']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'Oooooooooooooh'],\n",
       "    'original': 'Oooooooooooooh',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Oooooooooooooh']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'Well', u'I\\u2019ll', u'be', u'damned'],\n",
       "    'original': 'Well, I\\xe2\\x80\\x99ll be damned',\n",
       "    'speakers': ['MADISON', 'JEFFERSON'],\n",
       "    'tokenized': [u'Well', u'I\\u2019ll', u'be', u'damned']},\n",
       "   {'line#': 126,\n",
       "    'normalized': [u'Well', u'I\\u2019ll', u'be', u'damned'],\n",
       "    'original': 'Well, I\\xe2\\x80\\x99ll be damned',\n",
       "    'speakers': ['MADISON', 'JEFFERSON'],\n",
       "    'tokenized': [u'Well', u'I\\u2019ll', u'be', u'damned']},\n",
       "   {'line#': 127,\n",
       "    'normalized': [u'Hamilton\\u2019s', u'on', u'your', u'side'],\n",
       "    'original': 'Hamilton\\xe2\\x80\\x99s on your side',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Hamilton\\u2019s', u'on', u'your', u'side']},\n",
       "   {'line#': 128,\n",
       "    'normalized': [u'Well', u'I\\u2019ll', u'be', u'damned'],\n",
       "    'original': 'Well, I\\xe2\\x80\\x99ll be damned',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Well', u'I\\u2019ll', u'be', u'damned']},\n",
       "   {'line#': 129,\n",
       "    'normalized': [u'Well', u'I\\u2019ll', u'be', u'damned'],\n",
       "    'original': 'Well, I\\xe2\\x80\\x99ll be damned',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Well', u'I\\u2019ll', u'be', u'damned']},\n",
       "   {'line#': 130,\n",
       "    'normalized': [u'And'],\n",
       "    'original': 'And?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And']},\n",
       "   {'line#': 131,\n",
       "    'normalized': [u'You', u'won', u'in', u'a', u'landslide'],\n",
       "    'original': 'You won in a landslide',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'You', u'won', u'in', u'a', u'landslide']},\n",
       "   {'line#': 132,\n",
       "    'normalized': [u'Congrats', u'on', u'a', u'race', u'well', u'run'],\n",
       "    'original': 'Congrats on a race well-run',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Congrats', u'on', u'a', u'race', u'well', u'run']},\n",
       "   {'line#': 133,\n",
       "    'normalized': [u'I', u'did', u'give', u'you', u'a', u'fight'],\n",
       "    'original': 'I did give you a fight',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'did', u'give', u'you', u'a', u'fight']},\n",
       "   {'line#': 134,\n",
       "    'normalized': [u'Uh', u'huh'],\n",
       "    'original': 'Uh-huh',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Uh', u'huh']},\n",
       "   {'line#': 135,\n",
       "    'normalized': [u'I', u'look', u'forward', u'to', u'our', u'partnership'],\n",
       "    'original': 'I look forward to our partnership',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'look', u'forward', u'to', u'our', u'partnership']},\n",
       "   {'line#': 136,\n",
       "    'normalized': [u'Our', u'partnership'],\n",
       "    'original': 'Our partnership?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Our', u'partnership']},\n",
       "   {'line#': 137,\n",
       "    'normalized': [u'As', u'your', u'vice', u'President'],\n",
       "    'original': 'As your vice-President',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'As', u'your', u'vice', u'President']},\n",
       "   {'line#': 138,\n",
       "    'normalized': [u'Ha', u'Yeah', u'right'],\n",
       "    'original': 'Ha. Yeah, right',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Ha', u'Yeah', u'right']},\n",
       "   {'line#': 139,\n",
       "    'normalized': [u'You',\n",
       "     u'hear',\n",
       "     u'this',\n",
       "     u'guy',\n",
       "     u'Man',\n",
       "     u'openly',\n",
       "     u'campaigns',\n",
       "     u'against',\n",
       "     u'me',\n",
       "     u'talkin',\n",
       "     u'bout',\n",
       "     u'I',\n",
       "     u'look',\n",
       "     u'forward',\n",
       "     u'to',\n",
       "     u'our',\n",
       "     u'partnership'],\n",
       "    'original': 'You hear this guy? Man openly campaigns against me, talkin\\xe2\\x80\\x99 bout, \\xe2\\x80\\x9cI look forward to our partnership.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'hear',\n",
       "     u'this',\n",
       "     u'guy',\n",
       "     u'Man',\n",
       "     u'openly',\n",
       "     u'campaigns',\n",
       "     u'against',\n",
       "     u'me',\n",
       "     u'talkin',\n",
       "     u'bout',\n",
       "     u'I',\n",
       "     u'look',\n",
       "     u'forward',\n",
       "     u'to',\n",
       "     u'our',\n",
       "     u'partnership']},\n",
       "   {'line#': 140,\n",
       "    'normalized': [u'It\\u2019s',\n",
       "     u'crazy',\n",
       "     u'that',\n",
       "     u'the',\n",
       "     u'guy',\n",
       "     u'who',\n",
       "     u'comes',\n",
       "     u'in',\n",
       "     u'second',\n",
       "     u'gets',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'Vice',\n",
       "     u'President'],\n",
       "    'original': 'It\\xe2\\x80\\x99s crazy that the guy who comes in second gets to be Vice President',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'It\\u2019s',\n",
       "     u'crazy',\n",
       "     u'that',\n",
       "     u'the',\n",
       "     u'guy',\n",
       "     u'who',\n",
       "     u'comes',\n",
       "     u'in',\n",
       "     u'second',\n",
       "     u'gets',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'Vice',\n",
       "     u'President']},\n",
       "   {'line#': 141,\n",
       "    'normalized': [u'Yeah',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'We',\n",
       "     u'can',\n",
       "     u'change',\n",
       "     u'that',\n",
       "     u'You',\n",
       "     u'know',\n",
       "     u'why'],\n",
       "    'original': 'Yeah, you know what? We can change that. You know why?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Yeah',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'We',\n",
       "     u'can',\n",
       "     u'change',\n",
       "     u'that',\n",
       "     u'You',\n",
       "     u'know',\n",
       "     u'why']},\n",
       "   {'line#': 142,\n",
       "    'normalized': [u'Why'],\n",
       "    'original': 'Why?',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Why']},\n",
       "   {'line#': 143,\n",
       "    'normalized': [u'cuz',\n",
       "     u'I\\u2019m',\n",
       "     u'the',\n",
       "     u'President',\n",
       "     u'Hey',\n",
       "     u'Burr',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'Hamilton',\n",
       "     u'thank',\n",
       "     u'him',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'endorsement'],\n",
       "    'original': '\\xe2\\x80\\x98cuz I\\xe2\\x80\\x99m the President. Hey, Burr, when you see Hamilton, thank him for the endorsement',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'cuz',\n",
       "     u'I\\u2019m',\n",
       "     u'the',\n",
       "     u'President',\n",
       "     u'Hey',\n",
       "     u'Burr',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'see',\n",
       "     u'Hamilton',\n",
       "     u'thank',\n",
       "     u'him',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'endorsement']}],\n",
       "  'track': 'The Election of 1800',\n",
       "  'track#': '19'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Seventeen', u'Se', u'se', u'seventeen'],\n",
       "    'original': 'Seventeen. Se- se- seventeen...',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Seventeen', u'Se', u'se', u'seventeen']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Se', u'se', u'seventeen'],\n",
       "    'original': 'Se- se- seventeen\\xe2\\x80\\xa6',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Se', u'se', u'seventeen']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'1789'],\n",
       "    'original': '1789',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'1789']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'How', u'does', u'the', u'bastard', u'orphan'],\n",
       "    'original': 'How does the bastard orphan',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How', u'does', u'the', u'bastard', u'orphan']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Immigrant', u'decorated', u'war', u'vet'],\n",
       "    'original': 'Immigrant decorated war vet',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Immigrant', u'decorated', u'war', u'vet']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Unite',\n",
       "     u'the',\n",
       "     u'colonies',\n",
       "     u'through',\n",
       "     u'more',\n",
       "     u'debt'],\n",
       "    'original': 'Unite the colonies through more debt?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Unite',\n",
       "     u'the',\n",
       "     u'colonies',\n",
       "     u'through',\n",
       "     u'more',\n",
       "     u'debt']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Fight',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'founding',\n",
       "     u'fathers',\n",
       "     u'til',\n",
       "     u'he',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'forfeit'],\n",
       "    'original': 'Fight the other founding fathers til he has to forfeit?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Fight',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'founding',\n",
       "     u'fathers',\n",
       "     u'til',\n",
       "     u'he',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'forfeit']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Have', u'it', u'all', u'lose', u'it', u'all'],\n",
       "    'original': 'Have it all, lose it all',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Have', u'it', u'all', u'lose', u'it', u'all']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'You', u'ready', u'for', u'more', u'yet'],\n",
       "    'original': 'You ready for more yet?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You', u'ready', u'for', u'more', u'yet']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Treasury',\n",
       "     u'Secretary',\n",
       "     u'Washington\\u2019s',\n",
       "     u'the',\n",
       "     u'President'],\n",
       "    'original': 'Treasury Secretary. Washington\\xe2\\x80\\x99s the President',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Treasury',\n",
       "     u'Secretary',\n",
       "     u'Washington\\u2019s',\n",
       "     u'the',\n",
       "     u'President']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Ev\\u2019ry',\n",
       "     u'American',\n",
       "     u'experiment',\n",
       "     u'sets',\n",
       "     u'a',\n",
       "     u'precedent'],\n",
       "    'original': 'Ev\\xe2\\x80\\x99ry American experiment sets a precedent',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ev\\u2019ry',\n",
       "     u'American',\n",
       "     u'experiment',\n",
       "     u'sets',\n",
       "     u'a',\n",
       "     u'precedent']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Not',\n",
       "     u'so',\n",
       "     u'fast',\n",
       "     u'Someone',\n",
       "     u'came',\n",
       "     u'along',\n",
       "     u'to',\n",
       "     u'resist',\n",
       "     u'him'],\n",
       "    'original': 'Not so fast. Someone came along to resist him',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Not',\n",
       "     u'so',\n",
       "     u'fast',\n",
       "     u'Someone',\n",
       "     u'came',\n",
       "     u'along',\n",
       "     u'to',\n",
       "     u'resist',\n",
       "     u'him']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Pissed',\n",
       "     u'him',\n",
       "     u'off',\n",
       "     u'until',\n",
       "     u'we',\n",
       "     u'had',\n",
       "     u'a',\n",
       "     u'two',\n",
       "     u'party',\n",
       "     u'system'],\n",
       "    'original': 'Pissed him off until we had a two-party system',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Pissed',\n",
       "     u'him',\n",
       "     u'off',\n",
       "     u'until',\n",
       "     u'we',\n",
       "     u'had',\n",
       "     u'a',\n",
       "     u'two',\n",
       "     u'party',\n",
       "     u'system']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'You',\n",
       "     u'haven\\u2019t',\n",
       "     u'met',\n",
       "     u'him',\n",
       "     u'yet',\n",
       "     u'you',\n",
       "     u'haven\\u2019t',\n",
       "     u'had',\n",
       "     u'the',\n",
       "     u'chance'],\n",
       "    'original': 'You haven\\xe2\\x80\\x99t met him yet, you haven\\xe2\\x80\\x99t had the chance',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You',\n",
       "     u'haven\\u2019t',\n",
       "     u'met',\n",
       "     u'him',\n",
       "     u'yet',\n",
       "     u'you',\n",
       "     u'haven\\u2019t',\n",
       "     u'had',\n",
       "     u'the',\n",
       "     u'chance']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'cause',\n",
       "     u'he\\u2019s',\n",
       "     u'been',\n",
       "     u'kickin',\n",
       "     u'ass',\n",
       "     u'as',\n",
       "     u'the',\n",
       "     u'ambassador',\n",
       "     u'to',\n",
       "     u'France'],\n",
       "    'original': '\\xe2\\x80\\x98cause he\\xe2\\x80\\x99s been kickin\\xe2\\x80\\x99 ass as the ambassador to France',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'cause',\n",
       "     u'he\\u2019s',\n",
       "     u'been',\n",
       "     u'kickin',\n",
       "     u'ass',\n",
       "     u'as',\n",
       "     u'the',\n",
       "     u'ambassador',\n",
       "     u'to',\n",
       "     u'France']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'But',\n",
       "     u'someone\\u2019s',\n",
       "     u'gotta',\n",
       "     u'keep',\n",
       "     u'the',\n",
       "     u'American',\n",
       "     u'promise'],\n",
       "    'original': 'But someone\\xe2\\x80\\x99s gotta keep the American promise',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But',\n",
       "     u'someone\\u2019s',\n",
       "     u'gotta',\n",
       "     u'keep',\n",
       "     u'the',\n",
       "     u'American',\n",
       "     u'promise']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'You', u'simply', u'must', u'meet', u'Thomas', u'Thomas'],\n",
       "    'original': 'You simply must meet Thomas. Thomas!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You', u'simply', u'must', u'meet', u'Thomas', u'Thomas']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Thomas', u'Jefferson\\u2019s', u'coming', u'home'],\n",
       "    'original': 'Thomas Jefferson\\xe2\\x80\\x99s coming home!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Thomas', u'Jefferson\\u2019s', u'coming', u'home']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Thomas', u'Jefferson\\u2019s', u'coming', u'home'],\n",
       "    'original': 'Thomas Jefferson\\xe2\\x80\\x99s coming home!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Thomas', u'Jefferson\\u2019s', u'coming', u'home']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Thomas', u'Jefferson\\u2019s', u'coming', u'home'],\n",
       "    'original': 'Thomas Jefferson\\xe2\\x80\\x99s coming home!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Thomas', u'Jefferson\\u2019s', u'coming', u'home']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Thomas', u'Jefferson\\u2019s', u'coming', u'home'],\n",
       "    'original': 'Thomas Jefferson\\xe2\\x80\\x99s coming home!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Thomas', u'Jefferson\\u2019s', u'coming', u'home']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Thomas',\n",
       "     u'Jefferson\\u2019s',\n",
       "     u'coming',\n",
       "     u'home',\n",
       "     u'Lord',\n",
       "     u'he\\u2019s'],\n",
       "    'original': 'Thomas Jefferson\\xe2\\x80\\x99s coming home Lord he\\xe2\\x80\\x99s',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Thomas',\n",
       "     u'Jefferson\\u2019s',\n",
       "     u'coming',\n",
       "     u'home',\n",
       "     u'Lord',\n",
       "     u'he\\u2019s']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Been', u'off', u'in', u'Paris', u'for', u'so', u'long'],\n",
       "    'original': 'Been off in Paris for so long!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Been', u'off', u'in', u'Paris', u'for', u'so', u'long']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Aaa', u'ooo'],\n",
       "    'original': 'Aaa-ooo!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaa', u'ooo']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Aaa', u'ooo'],\n",
       "    'original': 'Aaa-ooo!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaa', u'ooo']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'France',\n",
       "     u'is',\n",
       "     u'following',\n",
       "     u'us',\n",
       "     u'to',\n",
       "     u'revolution'],\n",
       "    'original': 'France is following us to revolution',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'France',\n",
       "     u'is',\n",
       "     u'following',\n",
       "     u'us',\n",
       "     u'to',\n",
       "     u'revolution']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'There', u'is', u'no', u'more', u'status', u'quo'],\n",
       "    'original': 'There is no more status quo',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'There', u'is', u'no', u'more', u'status', u'quo']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'But', u'the', u'sun', u'comes', u'up'],\n",
       "    'original': 'But the sun comes up',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'But', u'the', u'sun', u'comes', u'up']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'And', u'the', u'world', u'still', u'spins'],\n",
       "    'original': 'And the world still spins',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And', u'the', u'world', u'still', u'spins']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Aaa', u'ooo'],\n",
       "    'original': 'Aaa-ooo!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Aaa', u'ooo']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'I',\n",
       "     u'helped',\n",
       "     u'Lafayette',\n",
       "     u'draft',\n",
       "     u'a',\n",
       "     u'declaration'],\n",
       "    'original': 'I helped Lafayette draft a declaration',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'helped',\n",
       "     u'Lafayette',\n",
       "     u'draft',\n",
       "     u'a',\n",
       "     u'declaration']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Then', u'I', u'said', u'I', u'gotta', u'go'],\n",
       "    'original': 'Then I said, \\xe2\\x80\\x98I gotta go',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Then', u'I', u'said', u'I', u'gotta', u'go']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'I', u'gotta', u'be', u'in', u'Monticello'],\n",
       "    'original': 'I gotta be in Monticello.\\xe2\\x80\\x99',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I', u'gotta', u'be', u'in', u'Monticello']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Now', u'the', u'work', u'at', u'home', u'begins'],\n",
       "    'original': 'Now the work at home begins\\xe2\\x80\\xa6',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Now', u'the', u'work', u'at', u'home', u'begins']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Aaa', u'ooo'],\n",
       "    'original': 'Aaa-ooo!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Aaa', u'ooo']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'So', u'what\\u2019d', u'I', u'miss'],\n",
       "    'original': 'So what\\xe2\\x80\\x99d I miss?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'So', u'what\\u2019d', u'I', u'miss']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'What\\u2019d', u'I', u'miss'],\n",
       "    'original': 'What\\xe2\\x80\\x99d I miss?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'What\\u2019d', u'I', u'miss']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Virginia',\n",
       "     u'my',\n",
       "     u'home',\n",
       "     u'sweet',\n",
       "     u'home',\n",
       "     u'I',\n",
       "     u'wanna',\n",
       "     u'give',\n",
       "     u'you',\n",
       "     u'a',\n",
       "     u'kiss'],\n",
       "    'original': 'Virginia, my home sweet home, I wanna give you a kiss',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Virginia',\n",
       "     u'my',\n",
       "     u'home',\n",
       "     u'sweet',\n",
       "     u'home',\n",
       "     u'I',\n",
       "     u'wanna',\n",
       "     u'give',\n",
       "     u'you',\n",
       "     u'a',\n",
       "     u'kiss']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'I\\u2019ve',\n",
       "     u'been',\n",
       "     u'in',\n",
       "     u'Paris',\n",
       "     u'meeting',\n",
       "     u'lots',\n",
       "     u'of',\n",
       "     u'different',\n",
       "     u'ladies'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve been in Paris meeting lots of different ladies...',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I\\u2019ve',\n",
       "     u'been',\n",
       "     u'in',\n",
       "     u'Paris',\n",
       "     u'meeting',\n",
       "     u'lots',\n",
       "     u'of',\n",
       "     u'different',\n",
       "     u'ladies']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'I',\n",
       "     u'guess',\n",
       "     u'I',\n",
       "     u'basic\\u2019lly',\n",
       "     u'missed',\n",
       "     u'the',\n",
       "     u'late',\n",
       "     u'eighties'],\n",
       "    'original': 'I guess I basic\\xe2\\x80\\x99lly missed the late eighties...',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'guess',\n",
       "     u'I',\n",
       "     u'basic\\u2019lly',\n",
       "     u'missed',\n",
       "     u'the',\n",
       "     u'late',\n",
       "     u'eighties']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'I',\n",
       "     u'traveled',\n",
       "     u'the',\n",
       "     u'wide',\n",
       "     u'wide',\n",
       "     u'world',\n",
       "     u'and',\n",
       "     u'came',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'this'],\n",
       "    'original': 'I traveled the wide, wide world and came back to this\\xe2\\x80\\xa6',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'traveled',\n",
       "     u'the',\n",
       "     u'wide',\n",
       "     u'wide',\n",
       "     u'world',\n",
       "     u'and',\n",
       "     u'came',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'this']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Aaa', u'ooo'],\n",
       "    'original': 'Aaa-ooo!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Aaa', u'ooo']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'There\\u2019s',\n",
       "     u'a',\n",
       "     u'letter',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'desk',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'President'],\n",
       "    'original': 'There\\xe2\\x80\\x99s a letter on my desk from the President',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'There\\u2019s',\n",
       "     u'a',\n",
       "     u'letter',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'desk',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'President']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Haven\\u2019t',\n",
       "     u'even',\n",
       "     u'put',\n",
       "     u'my',\n",
       "     u'bags',\n",
       "     u'down',\n",
       "     u'yet'],\n",
       "    'original': 'Haven\\xe2\\x80\\x99t even put my bags down yet',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Haven\\u2019t',\n",
       "     u'even',\n",
       "     u'put',\n",
       "     u'my',\n",
       "     u'bags',\n",
       "     u'down',\n",
       "     u'yet']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Sally',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'lamb',\n",
       "     u'darlin',\n",
       "     u'won\\u2019tcha',\n",
       "     u'open',\n",
       "     u'it'],\n",
       "    'original': 'Sally be a lamb, darlin\\xe2\\x80\\x99, won\\xe2\\x80\\x99tcha open it?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Sally',\n",
       "     u'be',\n",
       "     u'a',\n",
       "     u'lamb',\n",
       "     u'darlin',\n",
       "     u'won\\u2019tcha',\n",
       "     u'open',\n",
       "     u'it']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'It',\n",
       "     u'says',\n",
       "     u'the',\n",
       "     u'President\\u2019s',\n",
       "     u'assembling',\n",
       "     u'a',\n",
       "     u'cabinet'],\n",
       "    'original': 'It says the President\\xe2\\x80\\x99s assembling a cabinet',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'It',\n",
       "     u'says',\n",
       "     u'the',\n",
       "     u'President\\u2019s',\n",
       "     u'assembling',\n",
       "     u'a',\n",
       "     u'cabinet']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'And',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'Secretary',\n",
       "     u'of',\n",
       "     u'State',\n",
       "     u'great'],\n",
       "    'original': 'And that I am to be the Secretary of State, great!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'Secretary',\n",
       "     u'of',\n",
       "     u'State',\n",
       "     u'great']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'And',\n",
       "     u'that',\n",
       "     u'I\\u2019m',\n",
       "     u'already',\n",
       "     u'Senate',\n",
       "     u'approved'],\n",
       "    'original': 'And that I\\xe2\\x80\\x99m already Senate-approved...',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'that',\n",
       "     u'I\\u2019m',\n",
       "     u'already',\n",
       "     u'Senate',\n",
       "     u'approved']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'I',\n",
       "     u'just',\n",
       "     u'got',\n",
       "     u'home',\n",
       "     u'and',\n",
       "     u'now',\n",
       "     u'I\\u2019m',\n",
       "     u'headed',\n",
       "     u'up',\n",
       "     u'to',\n",
       "     u'New',\n",
       "     u'York'],\n",
       "    'original': 'I just got home and now I\\xe2\\x80\\x99m headed up to New York',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'just',\n",
       "     u'got',\n",
       "     u'home',\n",
       "     u'and',\n",
       "     u'now',\n",
       "     u'I\\u2019m',\n",
       "     u'headed',\n",
       "     u'up',\n",
       "     u'to',\n",
       "     u'New',\n",
       "     u'York']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Headin', u'to', u'New', u'York'],\n",
       "    'original': 'Headin\\xe2\\x80\\x99 to New York!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Headin', u'to', u'New', u'York']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Headin', u'to', u'New', u'York'],\n",
       "    'original': 'Headin\\xe2\\x80\\x99 to New York!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Headin', u'to', u'New', u'York']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Lookin', u'at', u'the', u'rolling', u'fields'],\n",
       "    'original': 'Lookin\\xe2\\x80\\x99 at the rolling fields',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Lookin', u'at', u'the', u'rolling', u'fields']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'believe',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'free'],\n",
       "    'original': 'I can\\xe2\\x80\\x99t believe that we are free',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'believe',\n",
       "     u'that',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'free']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Ready', u'to', u'face'],\n",
       "    'original': 'Ready to face',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Ready', u'to', u'face']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Whatever\\u2019s', u'awaiting'],\n",
       "    'original': 'Whatever\\xe2\\x80\\x99s awaiting',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Whatever\\u2019s', u'awaiting']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Me', u'in', u'N.Y.C'],\n",
       "    'original': 'Me in N.Y.C.',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Me', u'in', u'N.Y.C']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Believe', u'that', u'we', u'are', u'free'],\n",
       "    'original': 'Believe that we are free',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Believe', u'that', u'we', u'are', u'free']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Me', u'in', u'N.Y.C'],\n",
       "    'original': 'Me in N.Y.C.',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Me', u'in', u'N.Y.C']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'But',\n",
       "     u'who\\u2019s',\n",
       "     u'waitin',\n",
       "     u'for',\n",
       "     u'me',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'step',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'place'],\n",
       "    'original': 'But who\\xe2\\x80\\x99s waitin\\xe2\\x80\\x99 for me when I step in the place?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'who\\u2019s',\n",
       "     u'waitin',\n",
       "     u'for',\n",
       "     u'me',\n",
       "     u'when',\n",
       "     u'I',\n",
       "     u'step',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'place']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'My',\n",
       "     u'friend',\n",
       "     u'James',\n",
       "     u'Madison',\n",
       "     u'red',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'face'],\n",
       "    'original': 'My friend James Madison, red in the face',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'My',\n",
       "     u'friend',\n",
       "     u'James',\n",
       "     u'Madison',\n",
       "     u'red',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'face']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'He', u'grabs', u'my', u'arm', u'and'],\n",
       "    'original': 'He grabs my arm and',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'He', u'grabs', u'my', u'arm', u'and']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'I', u'respond'],\n",
       "    'original': 'I respond',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I', u'respond']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'What\\u2019s', u'goin', u'on'],\n",
       "    'original': '\\xe2\\x80\\x9cWhat\\xe2\\x80\\x99s goin\\xe2\\x80\\x99 on?\\xe2\\x80\\x9d',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'What\\u2019s', u'goin', u'on']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Aaa', u'ooo'],\n",
       "    'original': 'Aaa-ooo!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Aaa', u'ooo']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Thomas',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'engaged',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'battle',\n",
       "     u'for',\n",
       "     u'our',\n",
       "     u'nation\\u2019s',\n",
       "     u'very',\n",
       "     u'soul'],\n",
       "    'original': 'Thomas, we are engaged in a battle for our nation\\xe2\\x80\\x99s very soul',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Thomas',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'engaged',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'battle',\n",
       "     u'for',\n",
       "     u'our',\n",
       "     u'nation\\u2019s',\n",
       "     u'very',\n",
       "     u'soul']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Can',\n",
       "     u'you',\n",
       "     u'get',\n",
       "     u'us',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'mess',\n",
       "     u'we\\u2019re',\n",
       "     u'in'],\n",
       "    'original': 'Can you get us out of the mess we\\xe2\\x80\\x99re in?',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Can',\n",
       "     u'you',\n",
       "     u'get',\n",
       "     u'us',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'mess',\n",
       "     u'we\\u2019re',\n",
       "     u'in']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Aaa', u'ooo'],\n",
       "    'original': 'Aaa-ooo!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Aaa', u'ooo']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'Hamilton\\u2019s',\n",
       "     u'new',\n",
       "     u'financial',\n",
       "     u'plan',\n",
       "     u'is',\n",
       "     u'nothing',\n",
       "     u'less'],\n",
       "    'original': 'Hamilton\\xe2\\x80\\x99s new financial plan is nothing less',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Hamilton\\u2019s',\n",
       "     u'new',\n",
       "     u'financial',\n",
       "     u'plan',\n",
       "     u'is',\n",
       "     u'nothing',\n",
       "     u'less']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'Than', u'government', u'control'],\n",
       "    'original': 'Than government control',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Than', u'government', u'control']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'I\\u2019ve',\n",
       "     u'been',\n",
       "     u'fighting',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'South',\n",
       "     u'alone'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve been fighting for the South alone',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'I\\u2019ve',\n",
       "     u'been',\n",
       "     u'fighting',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'South',\n",
       "     u'alone']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'Where', u'have', u'you', u'been'],\n",
       "    'original': 'Where have you been?',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Where', u'have', u'you', u'been']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'Aaa', u'ooo'],\n",
       "    'original': 'Aaa-ooo!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Aaa', u'ooo']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Uh', u'France'],\n",
       "    'original': 'Uh...France.',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Uh', u'France']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'We', u'have', u'to', u'win'],\n",
       "    'original': 'We have to win',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'We', u'have', u'to', u'win']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'What\\u2019d', u'I', u'miss'],\n",
       "    'original': 'What\\xe2\\x80\\x99d I miss?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'What\\u2019d', u'I', u'miss']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'What\\u2019d', u'I', u'miss'],\n",
       "    'original': 'What\\xe2\\x80\\x99d I miss?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'What\\u2019d', u'I', u'miss']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Headfirst', u'into', u'a', u'political', u'abyss'],\n",
       "    'original': 'Headfirst into a political abyss!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Headfirst', u'into', u'a', u'political', u'abyss']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'my',\n",
       "     u'first',\n",
       "     u'cabinet',\n",
       "     u'meeting',\n",
       "     u'today'],\n",
       "    'original': 'I have my first cabinet meeting today',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'my',\n",
       "     u'first',\n",
       "     u'cabinet',\n",
       "     u'meeting',\n",
       "     u'today']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'I',\n",
       "     u'guess',\n",
       "     u'I',\n",
       "     u'better',\n",
       "     u'think',\n",
       "     u'of',\n",
       "     u'something',\n",
       "     u'to',\n",
       "     u'say'],\n",
       "    'original': 'I guess I better think of something to say',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'guess',\n",
       "     u'I',\n",
       "     u'better',\n",
       "     u'think',\n",
       "     u'of',\n",
       "     u'something',\n",
       "     u'to',\n",
       "     u'say']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'I\\u2019m', u'already', u'on', u'my', u'way'],\n",
       "    'original': 'I\\xe2\\x80\\x99m already on my way',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I\\u2019m', u'already', u'on', u'my', u'way']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Let\\u2019s',\n",
       "     u'get',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'bottom',\n",
       "     u'of',\n",
       "     u'this'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s get to the bottom of this\\xe2\\x80\\xa6',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Let\\u2019s',\n",
       "     u'get',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'bottom',\n",
       "     u'of',\n",
       "     u'this']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'Wha', u'Wha', u'What\\u2019d', u'I', u'miss'],\n",
       "    'original': 'Wha? Wha? What\\xe2\\x80\\x99d I miss?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Wha', u'Wha', u'What\\u2019d', u'I', u'miss']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'I\\u2019ve', u'come', u'home', u'to', u'this'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve come home to this?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'I\\u2019ve', u'come', u'home', u'to', u'this']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'Headfirst', u'into', u'the', u'abyss'],\n",
       "    'original': 'Headfirst, into the abyss!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Headfirst', u'into', u'the', u'abyss']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'Chik', u'a', u'pow'],\n",
       "    'original': 'Chik-a-pow!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Chik', u'a', u'pow']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'On', u'my', u'way'],\n",
       "    'original': 'On my way',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'On', u'my', u'way']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'What', u'did', u'I', u'miss'],\n",
       "    'original': 'What did I miss?',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'What', u'did', u'I', u'miss']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Ahhh', u'ah'],\n",
       "    'original': 'Ahhh ah!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Ahhh', u'ah']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'Mr', u'Jefferson', u'welcome', u'home'],\n",
       "    'original': 'Mr. Jefferson, welcome home',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Mr', u'Jefferson', u'welcome', u'home']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'Mr', u'Jefferson', u'Alexander', u'Hamilton'],\n",
       "    'original': 'Mr. Jefferson? Alexander Hamilton',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Mr', u'Jefferson', u'Alexander', u'Hamilton']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'Mr', u'Jefferson', u'welcome', u'home'],\n",
       "    'original': 'Mr. Jefferson, welcome home',\n",
       "    'speakers': ['WASHINGTON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Mr', u'Jefferson', u'welcome', u'home']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'Mr', u'Jefferson', u'welcome', u'home'],\n",
       "    'original': 'Mr. Jefferson, welcome home',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Mr', u'Jefferson', u'welcome', u'home']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'Sir',\n",
       "     u'you\\u2019ve',\n",
       "     u'been',\n",
       "     u'off',\n",
       "     u'in',\n",
       "     u'Paris',\n",
       "     u'for',\n",
       "     u'so',\n",
       "     u'long'],\n",
       "    'original': 'Sir, you\\xe2\\x80\\x99ve been off in Paris for so long!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Sir',\n",
       "     u'you\\u2019ve',\n",
       "     u'been',\n",
       "     u'off',\n",
       "     u'in',\n",
       "     u'Paris',\n",
       "     u'for',\n",
       "     u'so',\n",
       "     u'long']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'So', u'what', u'did', u'I', u'miss'],\n",
       "    'original': 'So what did I miss?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'So', u'what', u'did', u'I', u'miss']}],\n",
       "  'track': \"What'd I Miss\",\n",
       "  'track#': '1'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'How', u'does', u'Hamilton'],\n",
       "    'original': 'How does Hamilton',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How', u'does', u'Hamilton']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'An', u'arrogant'],\n",
       "    'original': 'An arrogant',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'An', u'arrogant']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Immigrant', u'orphan'],\n",
       "    'original': 'Immigrant, orphan',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Immigrant', u'orphan']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Bastard', u'whoreson'],\n",
       "    'original': 'Bastard, whoreson',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Bastard', u'whoreson']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Somehow', u'endorse'],\n",
       "    'original': 'Somehow endorse',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Somehow', u'endorse']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Thomas', u'Jefferson', u'his', u'enemy'],\n",
       "    'original': 'Thomas Jefferson, his enemy',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Thomas', u'Jefferson', u'his', u'enemy']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'A',\n",
       "     u'man',\n",
       "     u'he\\u2019s',\n",
       "     u'despised',\n",
       "     u'since',\n",
       "     u'the',\n",
       "     u'beginning'],\n",
       "    'original': 'A man he\\xe2\\x80\\x99s despised since the beginning',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'A',\n",
       "     u'man',\n",
       "     u'he\\u2019s',\n",
       "     u'despised',\n",
       "     u'since',\n",
       "     u'the',\n",
       "     u'beginning']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Just', u'to', u'keep', u'me', u'from', u'winning'],\n",
       "    'original': 'Just to keep me from winning?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Just', u'to', u'keep', u'me', u'from', u'winning']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'I',\n",
       "     u'wanna',\n",
       "     u'be',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'happens'],\n",
       "    'original': 'I wanna be in the room where it happens\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wanna',\n",
       "     u'be',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'happens']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'You\\u2019ve', u'kept', u'me', u'from'],\n",
       "    'original': 'You\\xe2\\x80\\x99ve kept me from\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You\\u2019ve', u'kept', u'me', u'from']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'For', u'the', u'last', u'time'],\n",
       "    'original': 'For the last time',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'For', u'the', u'last', u'time']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Dear', u'Alexander'],\n",
       "    'original': 'Dear Alexander:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Dear', u'Alexander']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I', u'am', u'slow', u'to', u'anger'],\n",
       "    'original': 'I am slow to anger',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'am', u'slow', u'to', u'anger']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'But', u'I', u'toe', u'the', u'line'],\n",
       "    'original': 'But I toe the line',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But', u'I', u'toe', u'the', u'line']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'As', u'I', u'reckon', u'with', u'the', u'effects'],\n",
       "    'original': 'As I reckon with the effects',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'As', u'I', u'reckon', u'with', u'the', u'effects']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Of', u'your', u'life', u'on', u'mine'],\n",
       "    'original': 'Of your life on mine',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Of', u'your', u'life', u'on', u'mine']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'I', u'look', u'back', u'on', u'where', u'I', u'failed'],\n",
       "    'original': 'I look back on where I failed',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'look', u'back', u'on', u'where', u'I', u'failed']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'And', u'in', u'every', u'place', u'I', u'checked'],\n",
       "    'original': 'And in every place I checked',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And', u'in', u'every', u'place', u'I', u'checked']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'The',\n",
       "     u'only',\n",
       "     u'common',\n",
       "     u'thread',\n",
       "     u'has',\n",
       "     u'been',\n",
       "     u'your',\n",
       "     u'disrespect'],\n",
       "    'original': 'The only common thread has been your disrespect',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The',\n",
       "     u'only',\n",
       "     u'common',\n",
       "     u'thread',\n",
       "     u'has',\n",
       "     u'been',\n",
       "     u'your',\n",
       "     u'disrespect']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Now', u'you', u'call', u'me', u'amoral'],\n",
       "    'original': 'Now you call me \\xe2\\x80\\x9camoral,\\xe2\\x80\\x9d',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Now', u'you', u'call', u'me', u'amoral']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'A', u'dangerous', u'disgrace'],\n",
       "    'original': 'A \\xe2\\x80\\x9cdangerous disgrace,\\xe2\\x80\\x9d',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'A', u'dangerous', u'disgrace']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'If', u'you\\u2019ve', u'got', u'something', u'to', u'say'],\n",
       "    'original': 'If you\\xe2\\x80\\x99ve got something to say',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'If', u'you\\u2019ve', u'got', u'something', u'to', u'say']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Name', u'a', u'time', u'and', u'place'],\n",
       "    'original': 'Name a time and place',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Name', u'a', u'time', u'and', u'place']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Face', u'to', u'face'],\n",
       "    'original': 'Face to face',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Face', u'to', u'face']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'honor',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'Your',\n",
       "     u'Obedient',\n",
       "     u'Servant'],\n",
       "    'original': 'I have the honor to be Your Obedient Servant',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'honor',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'Your',\n",
       "     u'Obedient',\n",
       "     u'Servant']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'A', u'dot', u'Burr'],\n",
       "    'original': 'A dot Burr',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'A', u'dot', u'Burr']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Mr', u'Vice', u'President'],\n",
       "    'original': 'Mr. Vice President:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Mr', u'Vice', u'President']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'I',\n",
       "     u'am',\n",
       "     u'not',\n",
       "     u'the',\n",
       "     u'reason',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'trusts',\n",
       "     u'you'],\n",
       "    'original': 'I am not the reason no one trusts you',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'am',\n",
       "     u'not',\n",
       "     u'the',\n",
       "     u'reason',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'trusts',\n",
       "     u'you']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'No', u'one', u'knows', u'what', u'you', u'believe'],\n",
       "    'original': 'No one knows what you believe',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No', u'one', u'knows', u'what', u'you', u'believe']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'I',\n",
       "     u'will',\n",
       "     u'not',\n",
       "     u'equivocate',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'opinion'],\n",
       "    'original': 'I will not equivocate on my opinion',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'will',\n",
       "     u'not',\n",
       "     u'equivocate',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'opinion']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'always',\n",
       "     u'worn',\n",
       "     u'it',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'sleeve'],\n",
       "    'original': 'I have always worn it on my sleeve',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'always',\n",
       "     u'worn',\n",
       "     u'it',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'sleeve']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Even',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'said',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'think',\n",
       "     u'I',\n",
       "     u'said'],\n",
       "    'original': 'Even if I said what you think I said',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Even',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'said',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'think',\n",
       "     u'I',\n",
       "     u'said']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'You',\n",
       "     u'would',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'cite',\n",
       "     u'a',\n",
       "     u'more',\n",
       "     u'specific',\n",
       "     u'grievance'],\n",
       "    'original': 'You would need to cite a more specific grievance',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'would',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'cite',\n",
       "     u'a',\n",
       "     u'more',\n",
       "     u'specific',\n",
       "     u'grievance']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Here\\u2019s',\n",
       "     u'an',\n",
       "     u'itemized',\n",
       "     u'list',\n",
       "     u'of',\n",
       "     u'thirty',\n",
       "     u'years',\n",
       "     u'of',\n",
       "     u'disagreements'],\n",
       "    'original': 'Here\\xe2\\x80\\x99s an itemized list of thirty years of disagreements',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Here\\u2019s',\n",
       "     u'an',\n",
       "     u'itemized',\n",
       "     u'list',\n",
       "     u'of',\n",
       "     u'thirty',\n",
       "     u'years',\n",
       "     u'of',\n",
       "     u'disagreements']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Sweet', u'Jesus'],\n",
       "    'original': 'Sweet Jesus',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Sweet', u'Jesus']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Hey', u'I', u'have', u'not', u'been', u'shy'],\n",
       "    'original': 'Hey, I have not been shy',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey', u'I', u'have', u'not', u'been', u'shy']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'I',\n",
       "     u'am',\n",
       "     u'just',\n",
       "     u'a',\n",
       "     u'guy',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'public',\n",
       "     u'eye'],\n",
       "    'original': 'I am just a guy in the public eye',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'am',\n",
       "     u'just',\n",
       "     u'a',\n",
       "     u'guy',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'public',\n",
       "     u'eye']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'Tryin',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'my',\n",
       "     u'best',\n",
       "     u'for',\n",
       "     u'our',\n",
       "     u'republic'],\n",
       "    'original': 'Tryin\\xe2\\x80\\x99 to do my best for our republic',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Tryin',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'my',\n",
       "     u'best',\n",
       "     u'for',\n",
       "     u'our',\n",
       "     u'republic']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'wanna', u'fight'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t wanna fight',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'wanna', u'fight']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'But',\n",
       "     u'I',\n",
       "     u'won\\u2019t',\n",
       "     u'apologize',\n",
       "     u'for',\n",
       "     u'doing',\n",
       "     u'what\\u2019s',\n",
       "     u'right'],\n",
       "    'original': 'But I won\\xe2\\x80\\x99t apologize for doing what\\xe2\\x80\\x99s right',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'I',\n",
       "     u'won\\u2019t',\n",
       "     u'apologize',\n",
       "     u'for',\n",
       "     u'doing',\n",
       "     u'what\\u2019s',\n",
       "     u'right']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'honor',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'Your',\n",
       "     u'Obedient',\n",
       "     u'Servant'],\n",
       "    'original': 'I have the honor to be Your Obedient Servant',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'honor',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'Your',\n",
       "     u'Obedient',\n",
       "     u'Servant']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'A', u'dot', u'Ham'],\n",
       "    'original': 'A dot Ham',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A', u'dot', u'Ham']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Careful', u'how', u'you', u'proceed', u'good', u'man'],\n",
       "    'original': 'Careful how you proceed, good man',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Careful', u'how', u'you', u'proceed', u'good', u'man']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Intemperate', u'indeed', u'good', u'man'],\n",
       "    'original': 'Intemperate indeed, good man',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Intemperate', u'indeed', u'good', u'man']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Answer',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'accusations',\n",
       "     u'I',\n",
       "     u'lay',\n",
       "     u'at',\n",
       "     u'your',\n",
       "     u'feet',\n",
       "     u'or'],\n",
       "    'original': 'Answer for the accusations I lay at your feet or',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Answer',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'accusations',\n",
       "     u'I',\n",
       "     u'lay',\n",
       "     u'at',\n",
       "     u'your',\n",
       "     u'feet',\n",
       "     u'or']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Prepare', u'to', u'bleed', u'good', u'man'],\n",
       "    'original': 'Prepare to bleed, good man',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Prepare', u'to', u'bleed', u'good', u'man']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Burr', u'your', u'grievance', u'is', u'legitimate'],\n",
       "    'original': 'Burr, your grievance is legitimate',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr', u'your', u'grievance', u'is', u'legitimate']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'I',\n",
       "     u'stand',\n",
       "     u'by',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'said',\n",
       "     u'every',\n",
       "     u'bit',\n",
       "     u'of',\n",
       "     u'it'],\n",
       "    'original': 'I stand by what I said, every bit of it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'stand',\n",
       "     u'by',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'said',\n",
       "     u'every',\n",
       "     u'bit',\n",
       "     u'of',\n",
       "     u'it']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'You', u'stand', u'only', u'for', u'yourself'],\n",
       "    'original': 'You stand only for yourself',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You', u'stand', u'only', u'for', u'yourself']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'It\\u2019s', u'what', u'you', u'do'],\n",
       "    'original': 'It\\xe2\\x80\\x99s what you do',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'It\\u2019s', u'what', u'you', u'do']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'apologize',\n",
       "     u'because',\n",
       "     u'it\\u2019s',\n",
       "     u'true'],\n",
       "    'original': 'I can\\xe2\\x80\\x99t apologize because it\\xe2\\x80\\x99s true',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'apologize',\n",
       "     u'because',\n",
       "     u'it\\u2019s',\n",
       "     u'true']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Then', u'stand', u'Alexander'],\n",
       "    'original': 'Then stand, Alexander',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Then', u'stand', u'Alexander']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Weehawken', u'Dawn'],\n",
       "    'original': 'Weehawken. Dawn',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Weehawken', u'Dawn']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Guns', u'Drawn'],\n",
       "    'original': 'Guns. Drawn',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Guns', u'Drawn']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'You\\u2019re', u'on'],\n",
       "    'original': 'You\\xe2\\x80\\x99re on',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You\\u2019re', u'on']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'honor',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'Your',\n",
       "     u'Obedient',\n",
       "     u'Servant'],\n",
       "    'original': 'I have the honor to be Your Obedient Servant',\n",
       "    'speakers': ['BURR', 'HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'honor',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'Your',\n",
       "     u'Obedient',\n",
       "     u'Servant']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'A', u'dot', u'Ham'],\n",
       "    'original': 'A dot Ham',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A', u'dot', u'Ham']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'A', u'dot', u'Burr'],\n",
       "    'original': 'A dot Burr',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'A', u'dot', u'Burr']}],\n",
       "  'track': 'Your Obedient Servant',\n",
       "  'track#': '20'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Alexander', u'come', u'back', u'to', u'sleep'],\n",
       "    'original': 'Alexander, come back to sleep',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Alexander', u'come', u'back', u'to', u'sleep']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'an',\n",
       "     u'early',\n",
       "     u'meeting',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'town'],\n",
       "    'original': 'I have an early meeting out of town',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'an',\n",
       "     u'early',\n",
       "     u'meeting',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'town']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'It\\u2019s', u'still', u'dark', u'outside'],\n",
       "    'original': 'It\\xe2\\x80\\x99s still dark outside',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'It\\u2019s', u'still', u'dark', u'outside']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'write',\n",
       "     u'something',\n",
       "     u'down'],\n",
       "    'original': 'I know. I just need to write something down',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'write',\n",
       "     u'something',\n",
       "     u'down']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you\\u2019re',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time'],\n",
       "    'original': 'Why do you write like you\\xe2\\x80\\x99re running out of time?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you\\u2019re',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Shhh'],\n",
       "    'original': 'Shhh',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Shhh']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Come',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'bed',\n",
       "     u'That',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough'],\n",
       "    'original': 'Come back to bed. That would be enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Come',\n",
       "     u'back',\n",
       "     u'to',\n",
       "     u'bed',\n",
       "     u'That',\n",
       "     u'would',\n",
       "     u'be',\n",
       "     u'enough']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'I\\u2019ll',\n",
       "     u'be',\n",
       "     u'back',\n",
       "     u'before',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'I\\u2019m',\n",
       "     u'gone'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll be back before you know I\\xe2\\x80\\x99m gone',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019ll',\n",
       "     u'be',\n",
       "     u'back',\n",
       "     u'before',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'I\\u2019m',\n",
       "     u'gone']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Come', u'back', u'to', u'sleep'],\n",
       "    'original': 'Come back to sleep',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Come', u'back', u'to', u'sleep']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'This', u'meeting\\u2019s', u'at', u'dawn'],\n",
       "    'original': 'This meeting\\xe2\\x80\\x99s at dawn',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'This', u'meeting\\u2019s', u'at', u'dawn']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Well', u'I\\u2019m', u'going', u'back', u'to', u'sleep'],\n",
       "    'original': 'Well, I\\xe2\\x80\\x99m going back to sleep',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Well', u'I\\u2019m', u'going', u'back', u'to', u'sleep']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Hey',\n",
       "     u'Best',\n",
       "     u'of',\n",
       "     u'wives',\n",
       "     u'and',\n",
       "     u'best',\n",
       "     u'of',\n",
       "     u'women'],\n",
       "    'original': 'Hey. Best of wives and best of women',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'Best',\n",
       "     u'of',\n",
       "     u'wives',\n",
       "     u'and',\n",
       "     u'best',\n",
       "     u'of',\n",
       "     u'women']}],\n",
       "  'track': 'Best of Wives and Best of Women',\n",
       "  'track#': '21'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'One', u'two', u'three', u'four'],\n",
       "    'original': 'One two three four',\n",
       "    'speakers': ['MALE COMPANY'],\n",
       "    'tokenized': [u'One', u'two', u'three', u'four']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Five', u'six', u'seven', u'eight', u'nine'],\n",
       "    'original': 'Five six seven eight nine\\xe2\\x80\\x94',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Five', u'six', u'seven', u'eight', u'nine']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'There',\n",
       "     u'are',\n",
       "     u'ten',\n",
       "     u'things',\n",
       "     u'you',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'know'],\n",
       "    'original': 'There are ten things you need to know',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'There',\n",
       "     u'are',\n",
       "     u'ten',\n",
       "     u'things',\n",
       "     u'you',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'know']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Number', u'one'],\n",
       "    'original': 'Number one!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'one']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'We',\n",
       "     u'rowed',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'Hudson',\n",
       "     u'at',\n",
       "     u'dawn'],\n",
       "    'original': 'We rowed across the Hudson at dawn',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'We',\n",
       "     u'rowed',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'Hudson',\n",
       "     u'at',\n",
       "     u'dawn']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'My',\n",
       "     u'friend',\n",
       "     u'William',\n",
       "     u'P',\n",
       "     u'Van',\n",
       "     u'Ness',\n",
       "     u'signed',\n",
       "     u'on',\n",
       "     u'as',\n",
       "     u'my'],\n",
       "    'original': 'My friend, William P. Van Ness signed on as my\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'My',\n",
       "     u'friend',\n",
       "     u'William',\n",
       "     u'P',\n",
       "     u'Van',\n",
       "     u'Ness',\n",
       "     u'signed',\n",
       "     u'on',\n",
       "     u'as',\n",
       "     u'my']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Number', u'two'],\n",
       "    'original': 'Number two!',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Number', u'two']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Hamilton', u'arrived', u'with', u'his', u'crew'],\n",
       "    'original': 'Hamilton arrived with his crew:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hamilton', u'arrived', u'with', u'his', u'crew']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Nathaniel',\n",
       "     u'Pendleton',\n",
       "     u'and',\n",
       "     u'a',\n",
       "     u'doctor',\n",
       "     u'that',\n",
       "     u'he',\n",
       "     u'knew'],\n",
       "    'original': 'Nathaniel Pendleton and a doctor that he knew',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Nathaniel',\n",
       "     u'Pendleton',\n",
       "     u'and',\n",
       "     u'a',\n",
       "     u'doctor',\n",
       "     u'that',\n",
       "     u'he',\n",
       "     u'knew']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Number', u'three'],\n",
       "    'original': 'Number three!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'three']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'I',\n",
       "     u'watched',\n",
       "     u'Hamilton',\n",
       "     u'examine',\n",
       "     u'the',\n",
       "     u'terrain'],\n",
       "    'original': 'I watched Hamilton examine the terrain',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'watched',\n",
       "     u'Hamilton',\n",
       "     u'examine',\n",
       "     u'the',\n",
       "     u'terrain']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'I',\n",
       "     u'wish',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'what',\n",
       "     u'was',\n",
       "     u'happ\\u2019ning',\n",
       "     u'in',\n",
       "     u'his',\n",
       "     u'brain'],\n",
       "    'original': 'I wish I could tell you what was happ\\xe2\\x80\\x99ning in his brain',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wish',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'what',\n",
       "     u'was',\n",
       "     u'happ\\u2019ning',\n",
       "     u'in',\n",
       "     u'his',\n",
       "     u'brain']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'This',\n",
       "     u'man',\n",
       "     u'has',\n",
       "     u'poisoned',\n",
       "     u'my',\n",
       "     u'political',\n",
       "     u'pursuits'],\n",
       "    'original': 'This man has poisoned my political pursuits!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'This',\n",
       "     u'man',\n",
       "     u'has',\n",
       "     u'poisoned',\n",
       "     u'my',\n",
       "     u'political',\n",
       "     u'pursuits']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Most',\n",
       "     u'disputes',\n",
       "     u'die',\n",
       "     u'and',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'shoots'],\n",
       "    'original': 'Most disputes die and no one shoots!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Most',\n",
       "     u'disputes',\n",
       "     u'die',\n",
       "     u'and',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'shoots']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Number', u'four'],\n",
       "    'original': 'Number four!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'four']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Hamilton', u'drew', u'first', u'position'],\n",
       "    'original': 'Hamilton drew first position',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hamilton', u'drew', u'first', u'position']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Looking',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'man',\n",
       "     u'on',\n",
       "     u'a',\n",
       "     u'mission'],\n",
       "    'original': 'Looking, to the world, like a man on a mission',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Looking',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'man',\n",
       "     u'on',\n",
       "     u'a',\n",
       "     u'mission']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'This',\n",
       "     u'is',\n",
       "     u'a',\n",
       "     u'soldier',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'marksman\\u2019s',\n",
       "     u'ability'],\n",
       "    'original': 'This is a soldier with a marksman\\xe2\\x80\\x99s ability',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'This',\n",
       "     u'is',\n",
       "     u'a',\n",
       "     u'soldier',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'marksman\\u2019s',\n",
       "     u'ability']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'The',\n",
       "     u'doctor',\n",
       "     u'turned',\n",
       "     u'around',\n",
       "     u'so',\n",
       "     u'he',\n",
       "     u'could',\n",
       "     u'have',\n",
       "     u'deniability'],\n",
       "    'original': 'The doctor turned around so he could have deniability',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The',\n",
       "     u'doctor',\n",
       "     u'turned',\n",
       "     u'around',\n",
       "     u'so',\n",
       "     u'he',\n",
       "     u'could',\n",
       "     u'have',\n",
       "     u'deniability']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'COMPANY'],\n",
       "    'original': 'COMPANY',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'COMPANY']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Five'],\n",
       "    'original': 'Five!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Five']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'BURR'],\n",
       "    'original': 'BURR',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'BURR']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Now',\n",
       "     u'I',\n",
       "     u'didn\\u2019t',\n",
       "     u'know',\n",
       "     u'this',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'time'],\n",
       "    'original': 'Now I didn\\xe2\\x80\\x99t know this at the time',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'I',\n",
       "     u'didn\\u2019t',\n",
       "     u'know',\n",
       "     u'this',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'time']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'But', u'we', u'were'],\n",
       "    'original': 'But we were\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But', u'we', u'were']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Near', u'the', u'same', u'spot'],\n",
       "    'original': 'Near the same spot',\n",
       "    'speakers': ['BURR', 'PHILIP'],\n",
       "    'tokenized': [u'Near', u'the', u'same', u'spot']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Your', u'son', u'died', u'is', u'that'],\n",
       "    'original': 'Your son died, is that',\n",
       "    'speakers': ['BURR', 'PHILIP'],\n",
       "    'tokenized': [u'Your', u'son', u'died', u'is', u'that']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Why'],\n",
       "    'original': 'Why\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR', 'PHILIP'],\n",
       "    'tokenized': [u'Why']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Near', u'the', u'same', u'spot'],\n",
       "    'original': 'Near the same spot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Near', u'the', u'same', u'spot']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'My', u'son', u'died', u'is', u'that'],\n",
       "    'original': 'My son died, is that',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'son', u'died', u'is', u'that']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Why'],\n",
       "    'original': 'Why\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Why']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Six'],\n",
       "    'original': 'Six!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Six']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'He',\n",
       "     u'examined',\n",
       "     u'his',\n",
       "     u'gun',\n",
       "     u'with',\n",
       "     u'such',\n",
       "     u'rigor'],\n",
       "    'original': 'He examined his gun with such rigor?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He',\n",
       "     u'examined',\n",
       "     u'his',\n",
       "     u'gun',\n",
       "     u'with',\n",
       "     u'such',\n",
       "     u'rigor']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'I',\n",
       "     u'watched',\n",
       "     u'as',\n",
       "     u'he',\n",
       "     u'methodically',\n",
       "     u'fiddled',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'trigger'],\n",
       "    'original': 'I watched as he methodically fiddled with the trigger',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'watched',\n",
       "     u'as',\n",
       "     u'he',\n",
       "     u'methodically',\n",
       "     u'fiddled',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'trigger']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Seven'],\n",
       "    'original': 'Seven!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Seven']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Confession',\n",
       "     u'time',\n",
       "     u'Here\\u2019s',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'got'],\n",
       "    'original': 'Confession time? Here\\xe2\\x80\\x99s what I got:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Confession',\n",
       "     u'time',\n",
       "     u'Here\\u2019s',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'got']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'My',\n",
       "     u'fellow',\n",
       "     u'soldiers\\u2019ll',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'terrible',\n",
       "     u'shot'],\n",
       "    'original': 'My fellow soldiers\\xe2\\x80\\x99ll tell you I\\xe2\\x80\\x99m a terrible shot',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'My',\n",
       "     u'fellow',\n",
       "     u'soldiers\\u2019ll',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'terrible',\n",
       "     u'shot']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Number', u'eight'],\n",
       "    'original': 'Number eight!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'eight']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Your', u'last', u'chance', u'to', u'negotiate'],\n",
       "    'original': 'Your last chance to negotiate',\n",
       "    'speakers': ['BURR', 'HAMILTON', 'ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Your', u'last', u'chance', u'to', u'negotiate']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Send',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'seconds',\n",
       "     u'see',\n",
       "     u'if',\n",
       "     u'they',\n",
       "     u'can',\n",
       "     u'set',\n",
       "     u'the',\n",
       "     u'record',\n",
       "     u'straight'],\n",
       "    'original': 'Send in your seconds, see if they can set the record straight',\n",
       "    'speakers': ['BURR', 'HAMILTON', 'ENSEMBLE MEN'],\n",
       "    'tokenized': [u'Send',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'seconds',\n",
       "     u'see',\n",
       "     u'if',\n",
       "     u'they',\n",
       "     u'can',\n",
       "     u'set',\n",
       "     u'the',\n",
       "     u'record',\n",
       "     u'straight']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'They',\n",
       "     u'won\\u2019t',\n",
       "     u'teach',\n",
       "     u'you',\n",
       "     u'this',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'classes'],\n",
       "    'original': 'They won\\xe2\\x80\\x99t teach you this in your classes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'They',\n",
       "     u'won\\u2019t',\n",
       "     u'teach',\n",
       "     u'you',\n",
       "     u'this',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'classes']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'But',\n",
       "     u'look',\n",
       "     u'it',\n",
       "     u'up',\n",
       "     u'Hamilton',\n",
       "     u'was',\n",
       "     u'wearing',\n",
       "     u'his',\n",
       "     u'glasses'],\n",
       "    'original': 'But look it up, Hamilton was wearing his glasses',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But',\n",
       "     u'look',\n",
       "     u'it',\n",
       "     u'up',\n",
       "     u'Hamilton',\n",
       "     u'was',\n",
       "     u'wearing',\n",
       "     u'his',\n",
       "     u'glasses']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Why', u'If', u'not', u'to', u'take', u'deadly', u'aim'],\n",
       "    'original': 'Why? If not to take deadly aim?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Why', u'If', u'not', u'to', u'take', u'deadly', u'aim']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'It\\u2019s',\n",
       "     u'him',\n",
       "     u'or',\n",
       "     u'me',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'same'],\n",
       "    'original': 'It\\xe2\\x80\\x99s him or me, the world will never be the same',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It\\u2019s',\n",
       "     u'him',\n",
       "     u'or',\n",
       "     u'me',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'will',\n",
       "     u'never',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'same']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'I',\n",
       "     u'had',\n",
       "     u'only',\n",
       "     u'one',\n",
       "     u'thought',\n",
       "     u'before',\n",
       "     u'the',\n",
       "     u'slaughter'],\n",
       "    'original': 'I had only one thought before the slaughter:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'had',\n",
       "     u'only',\n",
       "     u'one',\n",
       "     u'thought',\n",
       "     u'before',\n",
       "     u'the',\n",
       "     u'slaughter']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'This',\n",
       "     u'man',\n",
       "     u'will',\n",
       "     u'not',\n",
       "     u'make',\n",
       "     u'an',\n",
       "     u'orphan',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'daughter'],\n",
       "    'original': 'This man will not make an orphan of my daughter',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'This',\n",
       "     u'man',\n",
       "     u'will',\n",
       "     u'not',\n",
       "     u'make',\n",
       "     u'an',\n",
       "     u'orphan',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'daughter']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Number', u'nine'],\n",
       "    'original': 'Number nine!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'nine']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Look',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'eye',\n",
       "     u'aim',\n",
       "     u'no',\n",
       "     u'higher'],\n",
       "    'original': 'Look him in the eye, aim no higher',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'him',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'eye',\n",
       "     u'aim',\n",
       "     u'no',\n",
       "     u'higher']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Summon', u'all', u'the', u'courage', u'you', u'require'],\n",
       "    'original': 'Summon all the courage you require',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Summon', u'all', u'the', u'courage', u'you', u'require']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Then', u'count'],\n",
       "    'original': 'Then count:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Then', u'count']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'One',\n",
       "     u'two',\n",
       "     u'three',\n",
       "     u'four',\n",
       "     u'five',\n",
       "     u'six',\n",
       "     u'seven',\n",
       "     u'eight',\n",
       "     u'nine'],\n",
       "    'original': 'One two three four five six seven eight nine',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'One',\n",
       "     u'two',\n",
       "     u'three',\n",
       "     u'four',\n",
       "     u'five',\n",
       "     u'six',\n",
       "     u'seven',\n",
       "     u'eight',\n",
       "     u'nine']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Number', u'ten', u'paces', u'Fire'],\n",
       "    'original': 'Number ten paces! Fire!\\xe2\\x80\\x94',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Number', u'ten', u'paces', u'Fire']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'I',\n",
       "     u'imagine',\n",
       "     u'death',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'it',\n",
       "     u'feels',\n",
       "     u'more',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'memory'],\n",
       "    'original': 'I imagine death so much it feels more like a memory',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'imagine',\n",
       "     u'death',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'it',\n",
       "     u'feels',\n",
       "     u'more',\n",
       "     u'like',\n",
       "     u'a',\n",
       "     u'memory']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Is',\n",
       "     u'this',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'gets',\n",
       "     u'me',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'feet',\n",
       "     u'sev\\u2019ral',\n",
       "     u'feet',\n",
       "     u'ahead',\n",
       "     u'of',\n",
       "     u'me'],\n",
       "    'original': 'Is this where it gets me, on my feet, sev\\xe2\\x80\\x99ral feet ahead of me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Is',\n",
       "     u'this',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'gets',\n",
       "     u'me',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'feet',\n",
       "     u'sev\\u2019ral',\n",
       "     u'feet',\n",
       "     u'ahead',\n",
       "     u'of',\n",
       "     u'me']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'I',\n",
       "     u'see',\n",
       "     u'it',\n",
       "     u'coming',\n",
       "     u'do',\n",
       "     u'I',\n",
       "     u'run',\n",
       "     u'or',\n",
       "     u'fire',\n",
       "     u'my',\n",
       "     u'gun',\n",
       "     u'or',\n",
       "     u'let',\n",
       "     u'it',\n",
       "     u'be'],\n",
       "    'original': 'I see it coming, do I run or fire my gun or let it be?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'see',\n",
       "     u'it',\n",
       "     u'coming',\n",
       "     u'do',\n",
       "     u'I',\n",
       "     u'run',\n",
       "     u'or',\n",
       "     u'fire',\n",
       "     u'my',\n",
       "     u'gun',\n",
       "     u'or',\n",
       "     u'let',\n",
       "     u'it',\n",
       "     u'be']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'There', u'is', u'no', u'beat', u'no', u'melody'],\n",
       "    'original': 'There is no beat, no melody',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'There', u'is', u'no', u'beat', u'no', u'melody']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Burr', u'my', u'first', u'friend', u'my', u'enemy'],\n",
       "    'original': 'Burr, my first friend, my enemy',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr', u'my', u'first', u'friend', u'my', u'enemy']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Maybe', u'the', u'last', u'face', u'I', u'ever', u'see'],\n",
       "    'original': 'Maybe the last face I ever see',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Maybe', u'the', u'last', u'face', u'I', u'ever', u'see']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'If',\n",
       "     u'I',\n",
       "     u'throw',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot',\n",
       "     u'is',\n",
       "     u'this',\n",
       "     u'how',\n",
       "     u'you\\u2019ll',\n",
       "     u'remember',\n",
       "     u'me'],\n",
       "    'original': 'If I throw away my shot, is this how you\\xe2\\x80\\x99ll remember me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'I',\n",
       "     u'throw',\n",
       "     u'away',\n",
       "     u'my',\n",
       "     u'shot',\n",
       "     u'is',\n",
       "     u'this',\n",
       "     u'how',\n",
       "     u'you\\u2019ll',\n",
       "     u'remember',\n",
       "     u'me']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'What',\n",
       "     u'if',\n",
       "     u'this',\n",
       "     u'bullet',\n",
       "     u'is',\n",
       "     u'my',\n",
       "     u'legacy'],\n",
       "    'original': 'What if this bullet is my legacy?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What',\n",
       "     u'if',\n",
       "     u'this',\n",
       "     u'bullet',\n",
       "     u'is',\n",
       "     u'my',\n",
       "     u'legacy']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Legacy', u'What', u'is', u'a', u'legacy'],\n",
       "    'original': 'Legacy. What is a legacy?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Legacy', u'What', u'is', u'a', u'legacy']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'It\\u2019s',\n",
       "     u'planting',\n",
       "     u'seeds',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'garden',\n",
       "     u'you',\n",
       "     u'never',\n",
       "     u'get',\n",
       "     u'to',\n",
       "     u'see'],\n",
       "    'original': 'It\\xe2\\x80\\x99s planting seeds in a garden you never get to see',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'It\\u2019s',\n",
       "     u'planting',\n",
       "     u'seeds',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'garden',\n",
       "     u'you',\n",
       "     u'never',\n",
       "     u'get',\n",
       "     u'to',\n",
       "     u'see']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'I',\n",
       "     u'wrote',\n",
       "     u'some',\n",
       "     u'notes',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'beginning',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'song',\n",
       "     u'someone',\n",
       "     u'will',\n",
       "     u'sing',\n",
       "     u'for',\n",
       "     u'me'],\n",
       "    'original': 'I wrote some notes at the beginning of a song someone will sing for me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wrote',\n",
       "     u'some',\n",
       "     u'notes',\n",
       "     u'at',\n",
       "     u'the',\n",
       "     u'beginning',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'song',\n",
       "     u'someone',\n",
       "     u'will',\n",
       "     u'sing',\n",
       "     u'for',\n",
       "     u'me']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'America',\n",
       "     u'you',\n",
       "     u'great',\n",
       "     u'unfinished',\n",
       "     u'symphony',\n",
       "     u'you',\n",
       "     u'sent',\n",
       "     u'for',\n",
       "     u'me'],\n",
       "    'original': 'America, you great unfinished symphony, you sent for me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'America',\n",
       "     u'you',\n",
       "     u'great',\n",
       "     u'unfinished',\n",
       "     u'symphony',\n",
       "     u'you',\n",
       "     u'sent',\n",
       "     u'for',\n",
       "     u'me']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'You', u'let', u'me', u'make', u'a', u'difference'],\n",
       "    'original': 'You let me make a difference',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You', u'let', u'me', u'make', u'a', u'difference']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'A',\n",
       "     u'place',\n",
       "     u'where',\n",
       "     u'even',\n",
       "     u'orphan',\n",
       "     u'immigrants'],\n",
       "    'original': 'A place where even orphan immigrants',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'place',\n",
       "     u'where',\n",
       "     u'even',\n",
       "     u'orphan',\n",
       "     u'immigrants']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Can',\n",
       "     u'leave',\n",
       "     u'their',\n",
       "     u'fingerprints',\n",
       "     u'and',\n",
       "     u'rise',\n",
       "     u'up'],\n",
       "    'original': 'Can leave their fingerprints and rise up',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Can',\n",
       "     u'leave',\n",
       "     u'their',\n",
       "     u'fingerprints',\n",
       "     u'and',\n",
       "     u'rise',\n",
       "     u'up']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time',\n",
       "     u'I\\u2019m',\n",
       "     u'running',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'time\\u2019s',\n",
       "     u'up'],\n",
       "    'original': 'I\\xe2\\x80\\x99m running out of time. I\\xe2\\x80\\x99m running, and my time\\xe2\\x80\\x99s up',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'time',\n",
       "     u'I\\u2019m',\n",
       "     u'running',\n",
       "     u'and',\n",
       "     u'my',\n",
       "     u'time\\u2019s',\n",
       "     u'up']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'Wise', u'up', u'Eyes', u'up'],\n",
       "    'original': 'Wise up. Eyes up',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Wise', u'up', u'Eyes', u'up']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'I',\n",
       "     u'catch',\n",
       "     u'a',\n",
       "     u'glimpse',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side'],\n",
       "    'original': 'I catch a glimpse of the other side',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'catch',\n",
       "     u'a',\n",
       "     u'glimpse',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Laurens',\n",
       "     u'leads',\n",
       "     u'a',\n",
       "     u'soldiers',\n",
       "     u'chorus',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side'],\n",
       "    'original': 'Laurens leads a soldiers\\xe2\\x80\\x99 chorus on the other side',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Laurens',\n",
       "     u'leads',\n",
       "     u'a',\n",
       "     u'soldiers',\n",
       "     u'chorus',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'My', u'son', u'is', u'on', u'the', u'other', u'side'],\n",
       "    'original': 'My son is on the other side',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'son', u'is', u'on', u'the', u'other', u'side']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'He\\u2019s',\n",
       "     u'with',\n",
       "     u'my',\n",
       "     u'mother',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side'],\n",
       "    'original': 'He\\xe2\\x80\\x99s with my mother on the other side',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'He\\u2019s',\n",
       "     u'with',\n",
       "     u'my',\n",
       "     u'mother',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Washington',\n",
       "     u'is',\n",
       "     u'watching',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side'],\n",
       "    'original': 'Washington is watching from the other side',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Washington',\n",
       "     u'is',\n",
       "     u'watching',\n",
       "     u'from',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Teach', u'me', u'how', u'to', u'say', u'goodbye'],\n",
       "    'original': 'Teach me how to say goodbye',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Teach', u'me', u'how', u'to', u'say', u'goodbye']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'Rise', u'up', u'rise', u'up', u'rise', u'up'],\n",
       "    'original': 'Rise up, rise up, rise up',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Rise', u'up', u'rise', u'up', u'rise', u'up']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'My', u'love', u'take', u'your', u'time'],\n",
       "    'original': 'My love, take your time',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'love', u'take', u'your', u'time']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'I\\u2019ll',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll see you on the other side',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019ll',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'other',\n",
       "     u'side']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'Raise', u'a', u'glass', u'to', u'freedom'],\n",
       "    'original': 'Raise a glass to freedom...',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Raise', u'a', u'glass', u'to', u'freedom']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'He', u'aims', u'his', u'pistol', u'at', u'the', u'sky'],\n",
       "    'original': 'He aims his pistol at the sky\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'He', u'aims', u'his', u'pistol', u'at', u'the', u'sky']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Wait'],\n",
       "    'original': 'Wait!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Wait']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'I',\n",
       "     u'strike',\n",
       "     u'him',\n",
       "     u'right',\n",
       "     u'between',\n",
       "     u'his',\n",
       "     u'ribs'],\n",
       "    'original': 'I strike him right between his ribs',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'strike',\n",
       "     u'him',\n",
       "     u'right',\n",
       "     u'between',\n",
       "     u'his',\n",
       "     u'ribs']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'I',\n",
       "     u'walk',\n",
       "     u'towards',\n",
       "     u'him',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'ushered',\n",
       "     u'away'],\n",
       "    'original': 'I walk towards him, but I am ushered away',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'walk',\n",
       "     u'towards',\n",
       "     u'him',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'ushered',\n",
       "     u'away']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'They',\n",
       "     u'row',\n",
       "     u'him',\n",
       "     u'back',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'Hudson'],\n",
       "    'original': 'They row him back across the Hudson',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'They',\n",
       "     u'row',\n",
       "     u'him',\n",
       "     u'back',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'Hudson']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'I', u'get', u'a', u'drink'],\n",
       "    'original': 'I get a drink',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'get', u'a', u'drink']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'Aaaah'],\n",
       "    'original': 'Aaaah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaaah']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'Aaaah'],\n",
       "    'original': 'Aaaah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaaah']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Aaaah'],\n",
       "    'original': 'Aaaah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaaah']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'I', u'hear', u'wailing', u'in', u'the', u'streets'],\n",
       "    'original': 'I hear wailing in the streets',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'hear', u'wailing', u'in', u'the', u'streets']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'Aaaah'],\n",
       "    'original': 'Aaaah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaaah']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'Aaaah'],\n",
       "    'original': 'Aaaah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaaah']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'Aaaah'],\n",
       "    'original': 'Aaaah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaaah']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'Somebody',\n",
       "     u'tells',\n",
       "     u'me',\n",
       "     u'You\\u2019d',\n",
       "     u'better',\n",
       "     u'hide'],\n",
       "    'original': 'Somebody tells me, \\xe2\\x80\\x9cYou\\xe2\\x80\\x99d better hide.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Somebody',\n",
       "     u'tells',\n",
       "     u'me',\n",
       "     u'You\\u2019d',\n",
       "     u'better',\n",
       "     u'hide']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Aaaah'],\n",
       "    'original': 'Aaaah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaaah']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'Aaaah'],\n",
       "    'original': 'Aaaah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaaah']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'Aaaah'],\n",
       "    'original': 'Aaaah',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Aaaah']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'They', u'say'],\n",
       "    'original': 'They say',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'They', u'say']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'Angelica', u'and', u'Eliza'],\n",
       "    'original': 'Angelica and Eliza\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR', 'ANGELICA'],\n",
       "    'tokenized': [u'Angelica', u'and', u'Eliza']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'Were',\n",
       "     u'both',\n",
       "     u'at',\n",
       "     u'his',\n",
       "     u'side',\n",
       "     u'when',\n",
       "     u'he',\n",
       "     u'died'],\n",
       "    'original': 'Were both at his side when he died',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Were',\n",
       "     u'both',\n",
       "     u'at',\n",
       "     u'his',\n",
       "     u'side',\n",
       "     u'when',\n",
       "     u'he',\n",
       "     u'died']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'Death', u'doesn\\u2019t', u'discriminate'],\n",
       "    'original': 'Death doesn\\xe2\\x80\\x99t discriminate',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Death', u'doesn\\u2019t', u'discriminate']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Between', u'the', u'sinners', u'and', u'the', u'saints'],\n",
       "    'original': 'Between the sinners and the saints',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Between', u'the', u'sinners', u'and', u'the', u'saints']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes'],\n",
       "    'original': 'It takes and it takes and it takes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'and',\n",
       "     u'it',\n",
       "     u'takes']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'History', u'obliterates'],\n",
       "    'original': 'History obliterates',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'History', u'obliterates']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'In', u'every', u'picture', u'it', u'paints'],\n",
       "    'original': 'In every picture it paints',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'In', u'every', u'picture', u'it', u'paints']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'It',\n",
       "     u'paints',\n",
       "     u'me',\n",
       "     u'and',\n",
       "     u'all',\n",
       "     u'my',\n",
       "     u'mistakes'],\n",
       "    'original': 'It paints me and all my mistakes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'paints',\n",
       "     u'me',\n",
       "     u'and',\n",
       "     u'all',\n",
       "     u'my',\n",
       "     u'mistakes']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'When', u'Alexander', u'aimed'],\n",
       "    'original': 'When Alexander aimed',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'When', u'Alexander', u'aimed']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'At', u'the', u'sky'],\n",
       "    'original': 'At the sky',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'At', u'the', u'sky']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'He',\n",
       "     u'may',\n",
       "     u'have',\n",
       "     u'been',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'one',\n",
       "     u'to',\n",
       "     u'die'],\n",
       "    'original': 'He may have been the first one to die',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'He',\n",
       "     u'may',\n",
       "     u'have',\n",
       "     u'been',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'one',\n",
       "     u'to',\n",
       "     u'die']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'But',\n",
       "     u'I\\u2019m',\n",
       "     u'the',\n",
       "     u'one',\n",
       "     u'who',\n",
       "     u'paid',\n",
       "     u'for',\n",
       "     u'it'],\n",
       "    'original': 'But I\\xe2\\x80\\x99m the one who paid for it',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But',\n",
       "     u'I\\u2019m',\n",
       "     u'the',\n",
       "     u'one',\n",
       "     u'who',\n",
       "     u'paid',\n",
       "     u'for',\n",
       "     u'it']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'I', u'survived', u'but', u'I', u'paid', u'for', u'it'],\n",
       "    'original': 'I survived, but I paid for it',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'survived', u'but', u'I', u'paid', u'for', u'it']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'Now',\n",
       "     u'I\\u2019m',\n",
       "     u'the',\n",
       "     u'villain',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'history'],\n",
       "    'original': 'Now I\\xe2\\x80\\x99m the villain in your history',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'I\\u2019m',\n",
       "     u'the',\n",
       "     u'villain',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'history']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'I',\n",
       "     u'was',\n",
       "     u'too',\n",
       "     u'young',\n",
       "     u'and',\n",
       "     u'blind',\n",
       "     u'to',\n",
       "     u'see'],\n",
       "    'original': 'I was too young and blind to see...',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'was',\n",
       "     u'too',\n",
       "     u'young',\n",
       "     u'and',\n",
       "     u'blind',\n",
       "     u'to',\n",
       "     u'see']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'I', u'should\\u2019ve', u'known'],\n",
       "    'original': 'I should\\xe2\\x80\\x99ve known',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'should\\u2019ve', u'known']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'I', u'should\\u2019ve', u'known'],\n",
       "    'original': 'I should\\xe2\\x80\\x99ve known',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'should\\u2019ve', u'known']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'The',\n",
       "     u'world',\n",
       "     u'was',\n",
       "     u'wide',\n",
       "     u'enough',\n",
       "     u'for',\n",
       "     u'both',\n",
       "     u'Hamilton',\n",
       "     u'and',\n",
       "     u'me'],\n",
       "    'original': 'The world was wide enough for both Hamilton and me',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The',\n",
       "     u'world',\n",
       "     u'was',\n",
       "     u'wide',\n",
       "     u'enough',\n",
       "     u'for',\n",
       "     u'both',\n",
       "     u'Hamilton',\n",
       "     u'and',\n",
       "     u'me']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'The',\n",
       "     u'world',\n",
       "     u'was',\n",
       "     u'wide',\n",
       "     u'enough',\n",
       "     u'for',\n",
       "     u'both',\n",
       "     u'Hamilton',\n",
       "     u'and',\n",
       "     u'me'],\n",
       "    'original': 'The world was wide enough for both Hamilton and me',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The',\n",
       "     u'world',\n",
       "     u'was',\n",
       "     u'wide',\n",
       "     u'enough',\n",
       "     u'for',\n",
       "     u'both',\n",
       "     u'Hamilton',\n",
       "     u'and',\n",
       "     u'me']}],\n",
       "  'track': 'The World Was Wide Enough',\n",
       "  'track#': '22'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Let',\n",
       "     u'me',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'wish',\n",
       "     u'I\\u2019d',\n",
       "     u'known'],\n",
       "    'original': 'Let me tell you what I wish I\\xe2\\x80\\x99d known',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Let',\n",
       "     u'me',\n",
       "     u'tell',\n",
       "     u'you',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'wish',\n",
       "     u'I\\u2019d',\n",
       "     u'known']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'When',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'young',\n",
       "     u'and',\n",
       "     u'dreamed',\n",
       "     u'of',\n",
       "     u'glory'],\n",
       "    'original': 'When I was young and dreamed of glory',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'When',\n",
       "     u'I',\n",
       "     u'was',\n",
       "     u'young',\n",
       "     u'and',\n",
       "     u'dreamed',\n",
       "     u'of',\n",
       "     u'glory']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'You', u'have', u'no', u'control'],\n",
       "    'original': 'You have no control:',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You', u'have', u'no', u'control']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Who', u'lives'],\n",
       "    'original': 'Who lives',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who', u'lives']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Who', u'dies'],\n",
       "    'original': 'Who dies',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who', u'dies']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Who', u'tells', u'your', u'story'],\n",
       "    'original': 'Who tells your story?',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who', u'tells', u'your', u'story']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'President', u'Jefferson'],\n",
       "    'original': 'President Jefferson:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'President', u'Jefferson']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'I\\u2019ll',\n",
       "     u'give',\n",
       "     u'him',\n",
       "     u'this',\n",
       "     u'his',\n",
       "     u'financial',\n",
       "     u'system',\n",
       "     u'is',\n",
       "     u'a'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll give him this: his financial system is a',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I\\u2019ll',\n",
       "     u'give',\n",
       "     u'him',\n",
       "     u'this',\n",
       "     u'his',\n",
       "     u'financial',\n",
       "     u'system',\n",
       "     u'is',\n",
       "     u'a']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Work',\n",
       "     u'of',\n",
       "     u'genius',\n",
       "     u'I',\n",
       "     u'couldn\\u2019t',\n",
       "     u'undo',\n",
       "     u'it',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'tried'],\n",
       "    'original': 'Work of genius. I couldn\\xe2\\x80\\x99t undo it if I tried',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Work',\n",
       "     u'of',\n",
       "     u'genius',\n",
       "     u'I',\n",
       "     u'couldn\\u2019t',\n",
       "     u'undo',\n",
       "     u'it',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'tried']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'And', u'I', u'tried'],\n",
       "    'original': 'And I tried',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And', u'I', u'tried']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Who', u'lives'],\n",
       "    'original': 'Who lives',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who', u'lives']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Who', u'dies'],\n",
       "    'original': 'Who dies',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who', u'dies']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Who', u'tells', u'your', u'story'],\n",
       "    'original': 'Who tells your story?',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who', u'tells', u'your', u'story']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'President', u'Madison'],\n",
       "    'original': 'President Madison:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'President', u'Madison']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'He',\n",
       "     u'took',\n",
       "     u'our',\n",
       "     u'country',\n",
       "     u'from',\n",
       "     u'bankruptcy',\n",
       "     u'to',\n",
       "     u'prosperity'],\n",
       "    'original': 'He took our country from bankruptcy to prosperity',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'He',\n",
       "     u'took',\n",
       "     u'our',\n",
       "     u'country',\n",
       "     u'from',\n",
       "     u'bankruptcy',\n",
       "     u'to',\n",
       "     u'prosperity']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I',\n",
       "     u'hate',\n",
       "     u'to',\n",
       "     u'admit',\n",
       "     u'it',\n",
       "     u'but',\n",
       "     u'he',\n",
       "     u'doesn\\u2019t',\n",
       "     u'get',\n",
       "     u'enough',\n",
       "     u'credit'],\n",
       "    'original': 'I hate to admit it, but he doesn\\xe2\\x80\\x99t get enough credit',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'hate',\n",
       "     u'to',\n",
       "     u'admit',\n",
       "     u'it',\n",
       "     u'but',\n",
       "     u'he',\n",
       "     u'doesn\\u2019t',\n",
       "     u'get',\n",
       "     u'enough',\n",
       "     u'credit']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'For', u'all', u'the', u'credit', u'he', u'gave', u'us'],\n",
       "    'original': 'For all the credit he gave us',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'For', u'all', u'the', u'credit', u'he', u'gave', u'us']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Who', u'lives'],\n",
       "    'original': 'Who lives',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who', u'lives']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Who', u'dies'],\n",
       "    'original': 'Who dies',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who', u'dies']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Who', u'tells', u'your', u'story'],\n",
       "    'original': 'Who tells your story?',\n",
       "    'speakers': ['WASHINGTON', 'COMPANY'],\n",
       "    'tokenized': [u'Who', u'tells', u'your', u'story']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Every',\n",
       "     u'other',\n",
       "     u'founding',\n",
       "     u\"father's\",\n",
       "     u'story',\n",
       "     u'gets',\n",
       "     u'told'],\n",
       "    'original': \"Every other founding father's story gets told\",\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Every',\n",
       "     u'other',\n",
       "     u'founding',\n",
       "     u\"father's\",\n",
       "     u'story',\n",
       "     u'gets',\n",
       "     u'told']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Every',\n",
       "     u'other',\n",
       "     u'founding',\n",
       "     u'father',\n",
       "     u'gets',\n",
       "     u'to',\n",
       "     u'grow',\n",
       "     u'old'],\n",
       "    'original': 'Every other founding father gets to grow old',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Every',\n",
       "     u'other',\n",
       "     u'founding',\n",
       "     u'father',\n",
       "     u'gets',\n",
       "     u'to',\n",
       "     u'grow',\n",
       "     u'old']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'But',\n",
       "     u'when',\n",
       "     u'you\\u2019re',\n",
       "     u'gone',\n",
       "     u'who',\n",
       "     u'remembers',\n",
       "     u'your',\n",
       "     u'name'],\n",
       "    'original': 'But when you\\xe2\\x80\\x99re gone, who remembers your name?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But',\n",
       "     u'when',\n",
       "     u'you\\u2019re',\n",
       "     u'gone',\n",
       "     u'who',\n",
       "     u'remembers',\n",
       "     u'your',\n",
       "     u'name']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Who', u'keeps', u'your', u'flame'],\n",
       "    'original': 'Who keeps your flame?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Who', u'keeps', u'your', u'flame']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Who', u'tells', u'your', u'story'],\n",
       "    'original': 'Who tells your story?',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Who', u'tells', u'your', u'story']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Who', u'tells', u'your', u'story'],\n",
       "    'original': 'Who tells your story?',\n",
       "    'speakers': ['BURR', 'MEN'],\n",
       "    'tokenized': [u'Who', u'tells', u'your', u'story']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Who', u'tells', u'your', u'story'],\n",
       "    'original': 'Who tells your story?',\n",
       "    'speakers': ['ANGELICA', 'WOMEN'],\n",
       "    'tokenized': [u'Who', u'tells', u'your', u'story']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Your', u'story'],\n",
       "    'original': 'Your story?',\n",
       "    'speakers': ['ANGELICA', 'WOMEN'],\n",
       "    'tokenized': [u'Your', u'story']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'I',\n",
       "     u'put',\n",
       "     u'myself',\n",
       "     u'back',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'narrative'],\n",
       "    'original': 'I put myself back in the narrative',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'put',\n",
       "     u'myself',\n",
       "     u'back',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'narrative']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza',\n",
       "    'speakers': ['WOMEN'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'I', u'stop', u'wasting', u'time', u'on', u'tears'],\n",
       "    'original': 'I stop wasting time on tears',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'stop', u'wasting', u'time', u'on', u'tears']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'I', u'live', u'another', u'fifty', u'years'],\n",
       "    'original': 'I live another fifty years',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'live', u'another', u'fifty', u'years']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'It\\u2019s', u'not', u'enough'],\n",
       "    'original': 'It\\xe2\\x80\\x99s not enough',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'It\\u2019s', u'not', u'enough']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'I',\n",
       "     u'interview',\n",
       "     u'every',\n",
       "     u'soldier',\n",
       "     u'who',\n",
       "     u'fought',\n",
       "     u'by',\n",
       "     u'your',\n",
       "     u'side'],\n",
       "    'original': 'I interview every soldier who fought by your side',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'interview',\n",
       "     u'every',\n",
       "     u'soldier',\n",
       "     u'who',\n",
       "     u'fought',\n",
       "     u'by',\n",
       "     u'your',\n",
       "     u'side']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'She', u'tells', u'our', u'story'],\n",
       "    'original': 'She tells our story',\n",
       "    'speakers': ['MULLIGAN', 'LAFAYETTE', 'LAURENS'],\n",
       "    'tokenized': [u'She', u'tells', u'our', u'story']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'I',\n",
       "     u'try',\n",
       "     u'to',\n",
       "     u'make',\n",
       "     u'sense',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'thousands',\n",
       "     u'of',\n",
       "     u'pages',\n",
       "     u'of',\n",
       "     u'writings'],\n",
       "    'original': 'I try to make sense of your thousands of pages of writings',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'try',\n",
       "     u'to',\n",
       "     u'make',\n",
       "     u'sense',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'thousands',\n",
       "     u'of',\n",
       "     u'pages',\n",
       "     u'of',\n",
       "     u'writings']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'You',\n",
       "     u'really',\n",
       "     u'do',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you\\u2019re',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of'],\n",
       "    'original': 'You really do write like you\\xe2\\x80\\x99re running out of\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'really',\n",
       "     u'do',\n",
       "     u'write',\n",
       "     u'like',\n",
       "     u'you\\u2019re',\n",
       "     u'running',\n",
       "     u'out',\n",
       "     u'of']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ELIZA', 'COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'I', u'rely', u'on'],\n",
       "    'original': 'I rely on\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'rely', u'on']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica',\n",
       "    'speakers': ['ELIZA', 'ANGELICA'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'While', u'she\\u2019s', u'alive'],\n",
       "    'original': 'While she\\xe2\\x80\\x99s alive\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'While', u'she\\u2019s', u'alive']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'We', u'tell', u'your', u'story'],\n",
       "    'original': 'We tell your story',\n",
       "    'speakers': ['ELIZA', 'ANGELICA'],\n",
       "    'tokenized': [u'We', u'tell', u'your', u'story']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'She', u'is', u'buried', u'in', u'Trinity', u'Church'],\n",
       "    'original': 'She is buried in Trinity Church',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'She', u'is', u'buried', u'in', u'Trinity', u'Church']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Near', u'you'],\n",
       "    'original': 'Near you',\n",
       "    'speakers': ['ELIZA', 'ANGELICA'],\n",
       "    'tokenized': [u'Near', u'you']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'When',\n",
       "     u'I',\n",
       "     u'needed',\n",
       "     u'her',\n",
       "     u'most',\n",
       "     u'she',\n",
       "     u'was',\n",
       "     u'right',\n",
       "     u'on'],\n",
       "    'original': 'When I needed her most, she was right on\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'When',\n",
       "     u'I',\n",
       "     u'needed',\n",
       "     u'her',\n",
       "     u'most',\n",
       "     u'she',\n",
       "     u'was',\n",
       "     u'right',\n",
       "     u'on']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ELIZA', 'COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'And', u'I\\u2019m', u'still', u'not', u'through'],\n",
       "    'original': 'And I\\xe2\\x80\\x99m still not through',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'I\\u2019m', u'still', u'not', u'through']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'I',\n",
       "     u'ask',\n",
       "     u'myself',\n",
       "     u'What',\n",
       "     u'would',\n",
       "     u'you',\n",
       "     u'do',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'had',\n",
       "     u'more'],\n",
       "    'original': 'I ask myself, \\xe2\\x80\\x9cWhat would you do if you had more\\xe2\\x80\\x94\\xe2\\x80\\x9d',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'ask',\n",
       "     u'myself',\n",
       "     u'What',\n",
       "     u'would',\n",
       "     u'you',\n",
       "     u'do',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'had',\n",
       "     u'more']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ELIZA', 'COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'The', u'Lord', u'in', u'his', u'kindness'],\n",
       "    'original': 'The Lord, in his kindness',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'The', u'Lord', u'in', u'his', u'kindness']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'He',\n",
       "     u'gives',\n",
       "     u'me',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'always',\n",
       "     u'wanted'],\n",
       "    'original': 'He gives me what you always wanted',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'He',\n",
       "     u'gives',\n",
       "     u'me',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'always',\n",
       "     u'wanted']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'He', u'gives', u'me', u'more'],\n",
       "    'original': 'He gives me more\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'He', u'gives', u'me', u'more']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ELIZA', 'COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'I',\n",
       "     u'raise',\n",
       "     u'funds',\n",
       "     u'in',\n",
       "     u'D.C',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'Washington',\n",
       "     u'Monument'],\n",
       "    'original': 'I raise funds in D.C. for the Washington Monument',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'raise',\n",
       "     u'funds',\n",
       "     u'in',\n",
       "     u'D.C',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'Washington',\n",
       "     u'Monument']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'She', u'tells', u'my', u'story'],\n",
       "    'original': 'She tells my story',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'She', u'tells', u'my', u'story']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'I', u'speak', u'out', u'against', u'slavery'],\n",
       "    'original': 'I speak out against slavery',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'speak', u'out', u'against', u'slavery']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'You',\n",
       "     u'could',\n",
       "     u'have',\n",
       "     u'done',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'more',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'only',\n",
       "     u'had'],\n",
       "    'original': 'You could have done so much more if you only had\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'could',\n",
       "     u'have',\n",
       "     u'done',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'more',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'only',\n",
       "     u'had']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ELIZA', 'COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'And',\n",
       "     u'when',\n",
       "     u'my',\n",
       "     u'time',\n",
       "     u'is',\n",
       "     u'up',\n",
       "     u'have',\n",
       "     u'I',\n",
       "     u'done',\n",
       "     u'enough'],\n",
       "    'original': 'And when my time is up, have I done enough?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And',\n",
       "     u'when',\n",
       "     u'my',\n",
       "     u'time',\n",
       "     u'is',\n",
       "     u'up',\n",
       "     u'have',\n",
       "     u'I',\n",
       "     u'done',\n",
       "     u'enough']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Will', u'they', u'tell', u'our', u'story'],\n",
       "    'original': 'Will they tell our story?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Will', u'they', u'tell', u'our', u'story']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Will', u'they', u'tell', u'your', u'story'],\n",
       "    'original': 'Will they tell your story?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Will', u'they', u'tell', u'your', u'story']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Oh',\n",
       "     u'Can',\n",
       "     u'I',\n",
       "     u'show',\n",
       "     u'you',\n",
       "     u'what',\n",
       "     u'I\\u2019m',\n",
       "     u'proudest',\n",
       "     u'of'],\n",
       "    'original': 'Oh. Can I show you what I\\xe2\\x80\\x99m proudest of?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Oh',\n",
       "     u'Can',\n",
       "     u'I',\n",
       "     u'show',\n",
       "     u'you',\n",
       "     u'what',\n",
       "     u'I\\u2019m',\n",
       "     u'proudest',\n",
       "     u'of']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'The', u'orphanage'],\n",
       "    'original': 'The orphanage',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'orphanage']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'I',\n",
       "     u'established',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'private',\n",
       "     u'orphanage',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'City'],\n",
       "    'original': 'I established the first private orphanage in New York City',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'established',\n",
       "     u'the',\n",
       "     u'first',\n",
       "     u'private',\n",
       "     u'orphanage',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'City']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'The', u'orphanage'],\n",
       "    'original': 'The orphanage',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'orphanage']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'I',\n",
       "     u'help',\n",
       "     u'to',\n",
       "     u'raise',\n",
       "     u'hundreds',\n",
       "     u'of',\n",
       "     u'children'],\n",
       "    'original': 'I help to raise hundreds of children',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'help',\n",
       "     u'to',\n",
       "     u'raise',\n",
       "     u'hundreds',\n",
       "     u'of',\n",
       "     u'children']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'I', u'get', u'to', u'see', u'them', u'growing', u'up'],\n",
       "    'original': 'I get to see them growing up',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'get', u'to', u'see', u'them', u'growing', u'up']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'The', u'orphanage'],\n",
       "    'original': 'The orphanage',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'orphanage']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'In',\n",
       "     u'their',\n",
       "     u'eyes',\n",
       "     u'I',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'Alexander'],\n",
       "    'original': 'In their eyes I see you, Alexander',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'In',\n",
       "     u'their',\n",
       "     u'eyes',\n",
       "     u'I',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'Alexander']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'I', u'see', u'you', u'every'],\n",
       "    'original': 'I see you every\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I', u'see', u'you', u'every']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ELIZA', 'COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'And', u'when', u'my', u'time', u'is', u'up'],\n",
       "    'original': 'And when my time is up',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'when', u'my', u'time', u'is', u'up']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'Have', u'I', u'done', u'enough'],\n",
       "    'original': 'Have I done enough?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Have', u'I', u'done', u'enough']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Will', u'they', u'tell', u'my', u'story'],\n",
       "    'original': 'Will they tell my story?',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Will', u'they', u'tell', u'my', u'story']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Will', u'they', u'tell', u'your', u'story'],\n",
       "    'original': 'Will they tell your story?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Will', u'they', u'tell', u'your', u'story']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'Oh',\n",
       "     u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'wait',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'again'],\n",
       "    'original': 'Oh, I can\\xe2\\x80\\x99t wait to see you again',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Oh',\n",
       "     u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'wait',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'you',\n",
       "     u'again']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'It\\u2019s', u'only', u'a', u'matter', u'of'],\n",
       "    'original': 'It\\xe2\\x80\\x99s only a matter of\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'It\\u2019s', u'only', u'a', u'matter', u'of']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time',\n",
       "    'speakers': ['ELIZA', 'COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Will', u'they', u'tell', u'your', u'story'],\n",
       "    'original': 'Will they tell your story?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Will', u'they', u'tell', u'your', u'story']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'Who',\n",
       "     u'lives',\n",
       "     u'who',\n",
       "     u'dies',\n",
       "     u'who',\n",
       "     u'tells',\n",
       "     u'your',\n",
       "     u'story'],\n",
       "    'original': 'Who lives, who dies, who tells your story?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Who',\n",
       "     u'lives',\n",
       "     u'who',\n",
       "     u'dies',\n",
       "     u'who',\n",
       "     u'tells',\n",
       "     u'your',\n",
       "     u'story']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'Will', u'they', u'tell', u'your', u'story'],\n",
       "    'original': 'Will they tell your story?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Will', u'they', u'tell', u'your', u'story']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'Who', u'lives', u'who', u'dies'],\n",
       "    'original': 'Who lives, who dies\\xe2\\x80\\x94',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Who', u'lives', u'who', u'dies']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time\\xe2\\x80\\xa6',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time\\xe2\\x80\\xa6',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'Time'],\n",
       "    'original': 'Time...',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Time']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Who', u'tells', u'your', u'story'],\n",
       "    'original': 'Who tells your story?',\n",
       "    'speakers': ['FULL COMPANY'],\n",
       "    'tokenized': [u'Who', u'tells', u'your', u'story']}],\n",
       "  'track': 'Who Lives, Who Dies, Who Tells Your Story',\n",
       "  'track#': '23'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Ladies',\n",
       "     u'and',\n",
       "     u'gentlemen',\n",
       "     u'you',\n",
       "     u'coulda',\n",
       "     u'been',\n",
       "     u'anywhere',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'tonight',\n",
       "     u'but',\n",
       "     u'you\\u2019re',\n",
       "     u'here',\n",
       "     u'with',\n",
       "     u'us',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'City',\n",
       "     u'Are',\n",
       "     u'you',\n",
       "     u'ready',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'cabinet',\n",
       "     u'meeting'],\n",
       "    'original': 'Ladies and gentlemen, you coulda been anywhere in the world tonight, but you\\xe2\\x80\\x99re here with us in New York City. Are you ready for a cabinet meeting???',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Ladies',\n",
       "     u'and',\n",
       "     u'gentlemen',\n",
       "     u'you',\n",
       "     u'coulda',\n",
       "     u'been',\n",
       "     u'anywhere',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'tonight',\n",
       "     u'but',\n",
       "     u'you\\u2019re',\n",
       "     u'here',\n",
       "     u'with',\n",
       "     u'us',\n",
       "     u'in',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'City',\n",
       "     u'Are',\n",
       "     u'you',\n",
       "     u'ready',\n",
       "     u'for',\n",
       "     u'a',\n",
       "     u'cabinet',\n",
       "     u'meeting']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'The',\n",
       "     u'issue',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'table',\n",
       "     u'Secretary',\n",
       "     u'Hamilton\\u2019s',\n",
       "     u'plan',\n",
       "     u'to',\n",
       "     u'assume',\n",
       "     u'state',\n",
       "     u'debt',\n",
       "     u'and',\n",
       "     u'establish',\n",
       "     u'a',\n",
       "     u'national',\n",
       "     u'bank',\n",
       "     u'Secretary',\n",
       "     u'Jefferson',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'floor',\n",
       "     u'sir'],\n",
       "    'original': 'The issue on the table: Secretary Hamilton\\xe2\\x80\\x99s plan to assume state debt and establish a national bank. Secretary Jefferson, you have the floor, sir',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'issue',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'table',\n",
       "     u'Secretary',\n",
       "     u'Hamilton\\u2019s',\n",
       "     u'plan',\n",
       "     u'to',\n",
       "     u'assume',\n",
       "     u'state',\n",
       "     u'debt',\n",
       "     u'and',\n",
       "     u'establish',\n",
       "     u'a',\n",
       "     u'national',\n",
       "     u'bank',\n",
       "     u'Secretary',\n",
       "     u'Jefferson',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'floor',\n",
       "     u'sir']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Life',\n",
       "     u'liberty',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'pursuit',\n",
       "     u'of',\n",
       "     u'happiness'],\n",
       "    'original': '\\xe2\\x80\\x98Life, liberty and the pursuit of happiness.\\xe2\\x80\\x99',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Life',\n",
       "     u'liberty',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'pursuit',\n",
       "     u'of',\n",
       "     u'happiness']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'We',\n",
       "     u'fought',\n",
       "     u'for',\n",
       "     u'these',\n",
       "     u'ideals',\n",
       "     u'we',\n",
       "     u'shouldn\\u2019t',\n",
       "     u'settle',\n",
       "     u'for',\n",
       "     u'less'],\n",
       "    'original': 'We fought for these ideals; we shouldn\\xe2\\x80\\x99t settle for less',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'fought',\n",
       "     u'for',\n",
       "     u'these',\n",
       "     u'ideals',\n",
       "     u'we',\n",
       "     u'shouldn\\u2019t',\n",
       "     u'settle',\n",
       "     u'for',\n",
       "     u'less']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'These',\n",
       "     u'are',\n",
       "     u'wise',\n",
       "     u'words',\n",
       "     u'enterprising',\n",
       "     u'men',\n",
       "     u'quote',\n",
       "     u'em'],\n",
       "    'original': 'These are wise words, enterprising men quote \\xe2\\x80\\x98em',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'These',\n",
       "     u'are',\n",
       "     u'wise',\n",
       "     u'words',\n",
       "     u'enterprising',\n",
       "     u'men',\n",
       "     u'quote',\n",
       "     u'em']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Don\\u2019t',\n",
       "     u'act',\n",
       "     u'surprised',\n",
       "     u'you',\n",
       "     u'guys',\n",
       "     u'cuz',\n",
       "     u'I',\n",
       "     u'wrote',\n",
       "     u'em'],\n",
       "    'original': 'Don\\xe2\\x80\\x99t act surprised, you guys, cuz I wrote \\xe2\\x80\\x98em',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Don\\u2019t',\n",
       "     u'act',\n",
       "     u'surprised',\n",
       "     u'you',\n",
       "     u'guys',\n",
       "     u'cuz',\n",
       "     u'I',\n",
       "     u'wrote',\n",
       "     u'em']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Oww'],\n",
       "    'original': 'Oww',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'Oww']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'But', u'Hamilton', u'forgets'],\n",
       "    'original': 'But Hamilton forgets',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'But', u'Hamilton', u'forgets']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'His',\n",
       "     u'plan',\n",
       "     u'would',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'government',\n",
       "     u'assume',\n",
       "     u'state\\u2019s',\n",
       "     u'debts'],\n",
       "    'original': 'His plan would have the government assume state\\xe2\\x80\\x99s debts',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'His',\n",
       "     u'plan',\n",
       "     u'would',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'government',\n",
       "     u'assume',\n",
       "     u'state\\u2019s',\n",
       "     u'debts']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Now',\n",
       "     u'place',\n",
       "     u'your',\n",
       "     u'bets',\n",
       "     u'as',\n",
       "     u'to',\n",
       "     u'who',\n",
       "     u'that',\n",
       "     u'benefits'],\n",
       "    'original': 'Now, place your bets as to who that benefits:',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'place',\n",
       "     u'your',\n",
       "     u'bets',\n",
       "     u'as',\n",
       "     u'to',\n",
       "     u'who',\n",
       "     u'that',\n",
       "     u'benefits']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'The',\n",
       "     u'very',\n",
       "     u'seat',\n",
       "     u'of',\n",
       "     u'government',\n",
       "     u'where',\n",
       "     u'Hamilton',\n",
       "     u'sits'],\n",
       "    'original': 'The very seat of government where Hamilton sits',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'very',\n",
       "     u'seat',\n",
       "     u'of',\n",
       "     u'government',\n",
       "     u'where',\n",
       "     u'Hamilton',\n",
       "     u'sits']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Not', u'true'],\n",
       "    'original': 'Not true!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Not', u'true']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Ooh', u'if', u'the', u'shoe', u'fits', u'wear', u'it'],\n",
       "    'original': 'Ooh, if the shoe fits, wear it',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Ooh', u'if', u'the', u'shoe', u'fits', u'wear', u'it']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'If', u'New', u'York\\u2019s', u'in', u'debt'],\n",
       "    'original': 'If New York\\xe2\\x80\\x99s in debt\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'If', u'New', u'York\\u2019s', u'in', u'debt']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Why',\n",
       "     u'should',\n",
       "     u'Virginia',\n",
       "     u'bear',\n",
       "     u'it',\n",
       "     u'Uh',\n",
       "     u'Our',\n",
       "     u'debts',\n",
       "     u'are',\n",
       "     u'paid',\n",
       "     u'I\\u2019m',\n",
       "     u'afraid'],\n",
       "    'original': 'Why should Virginia bear it? Uh! Our debts are paid, I\\xe2\\x80\\x99m afraid',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Why',\n",
       "     u'should',\n",
       "     u'Virginia',\n",
       "     u'bear',\n",
       "     u'it',\n",
       "     u'Uh',\n",
       "     u'Our',\n",
       "     u'debts',\n",
       "     u'are',\n",
       "     u'paid',\n",
       "     u'I\\u2019m',\n",
       "     u'afraid']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Don\\u2019t',\n",
       "     u'tax',\n",
       "     u'the',\n",
       "     u'South',\n",
       "     u'cuz',\n",
       "     u'we',\n",
       "     u'got',\n",
       "     u'it',\n",
       "     u'made',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'shade'],\n",
       "    'original': 'Don\\xe2\\x80\\x99t tax the South cuz we got it made in the shade',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Don\\u2019t',\n",
       "     u'tax',\n",
       "     u'the',\n",
       "     u'South',\n",
       "     u'cuz',\n",
       "     u'we',\n",
       "     u'got',\n",
       "     u'it',\n",
       "     u'made',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'shade']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'In',\n",
       "     u'Virginia',\n",
       "     u'we',\n",
       "     u'plant',\n",
       "     u'seeds',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'ground'],\n",
       "    'original': 'In Virginia, we plant seeds in the ground',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'In',\n",
       "     u'Virginia',\n",
       "     u'we',\n",
       "     u'plant',\n",
       "     u'seeds',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'ground']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'We',\n",
       "     u'create',\n",
       "     u'You',\n",
       "     u'just',\n",
       "     u'wanna',\n",
       "     u'move',\n",
       "     u'our',\n",
       "     u'money',\n",
       "     u'around'],\n",
       "    'original': 'We create. You just wanna move our money around',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'create',\n",
       "     u'You',\n",
       "     u'just',\n",
       "     u'wanna',\n",
       "     u'move',\n",
       "     u'our',\n",
       "     u'money',\n",
       "     u'around']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'This',\n",
       "     u'financial',\n",
       "     u'plan',\n",
       "     u'is',\n",
       "     u'an',\n",
       "     u'outrageous',\n",
       "     u'demand'],\n",
       "    'original': 'This financial plan is an outrageous demand',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'financial',\n",
       "     u'plan',\n",
       "     u'is',\n",
       "     u'an',\n",
       "     u'outrageous',\n",
       "     u'demand']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'And',\n",
       "     u'it\\u2019s',\n",
       "     u'too',\n",
       "     u'many',\n",
       "     u'damn',\n",
       "     u'pages',\n",
       "     u'for',\n",
       "     u'any',\n",
       "     u'man',\n",
       "     u'to',\n",
       "     u'understand'],\n",
       "    'original': 'And it\\xe2\\x80\\x99s too many damn pages for any man to understand',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'it\\u2019s',\n",
       "     u'too',\n",
       "     u'many',\n",
       "     u'damn',\n",
       "     u'pages',\n",
       "     u'for',\n",
       "     u'any',\n",
       "     u'man',\n",
       "     u'to',\n",
       "     u'understand']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Stand',\n",
       "     u'with',\n",
       "     u'me',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'land',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'free'],\n",
       "    'original': 'Stand with me in the land of the free',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Stand',\n",
       "     u'with',\n",
       "     u'me',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'land',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'free']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'And',\n",
       "     u'pray',\n",
       "     u'to',\n",
       "     u'God',\n",
       "     u'we',\n",
       "     u'never',\n",
       "     u'see',\n",
       "     u'Hamilton\\u2019s',\n",
       "     u'candidacy'],\n",
       "    'original': 'And pray to God we never see Hamilton\\xe2\\x80\\x99s candidacy',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'pray',\n",
       "     u'to',\n",
       "     u'God',\n",
       "     u'we',\n",
       "     u'never',\n",
       "     u'see',\n",
       "     u'Hamilton\\u2019s',\n",
       "     u'candidacy']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Look',\n",
       "     u'when',\n",
       "     u'Britain',\n",
       "     u'taxed',\n",
       "     u'our',\n",
       "     u'tea',\n",
       "     u'we',\n",
       "     u'got',\n",
       "     u'frisky'],\n",
       "    'original': 'Look, when Britain taxed our tea, we got frisky',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Look',\n",
       "     u'when',\n",
       "     u'Britain',\n",
       "     u'taxed',\n",
       "     u'our',\n",
       "     u'tea',\n",
       "     u'we',\n",
       "     u'got',\n",
       "     u'frisky']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Imagine',\n",
       "     u'what',\n",
       "     u'gon',\n",
       "     u'happen',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'try',\n",
       "     u'to',\n",
       "     u'tax',\n",
       "     u'our',\n",
       "     u'whisky'],\n",
       "    'original': 'Imagine what gon\\xe2\\x80\\x99 happen when you try to tax our whisky',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Imagine',\n",
       "     u'what',\n",
       "     u'gon',\n",
       "     u'happen',\n",
       "     u'when',\n",
       "     u'you',\n",
       "     u'try',\n",
       "     u'to',\n",
       "     u'tax',\n",
       "     u'our',\n",
       "     u'whisky']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u\"That's\", u'my', u'alcohol'],\n",
       "    'original': \"That's my alcohol!\",\n",
       "    'speakers': ['CROWD'],\n",
       "    'tokenized': [u\"That's\", u'my', u'alcohol']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Thank', u'you', u'Secretary', u'Jefferson'],\n",
       "    'original': 'Thank you, Secretary Jefferson',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Thank', u'you', u'Secretary', u'Jefferson']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Secretary', u'Hamilton', u'your', u'response'],\n",
       "    'original': 'Secretary Hamilton, your response',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Secretary', u'Hamilton', u'your', u'response']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Thomas',\n",
       "     u'That',\n",
       "     u'was',\n",
       "     u'a',\n",
       "     u'real',\n",
       "     u'nice',\n",
       "     u'declaration'],\n",
       "    'original': 'Thomas. That was a real nice declaration',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Thomas',\n",
       "     u'That',\n",
       "     u'was',\n",
       "     u'a',\n",
       "     u'real',\n",
       "     u'nice',\n",
       "     u'declaration']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Welcome',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'present',\n",
       "     u'we\\u2019re',\n",
       "     u'running',\n",
       "     u'a',\n",
       "     u'real',\n",
       "     u'nation'],\n",
       "    'original': 'Welcome to the present, we\\xe2\\x80\\x99re running a real nation',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Welcome',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'present',\n",
       "     u'we\\u2019re',\n",
       "     u'running',\n",
       "     u'a',\n",
       "     u'real',\n",
       "     u'nation']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Would',\n",
       "     u'you',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'join',\n",
       "     u'us',\n",
       "     u'or',\n",
       "     u'stay',\n",
       "     u'mellow'],\n",
       "    'original': 'Would you like to join us, or stay mellow',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Would',\n",
       "     u'you',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'join',\n",
       "     u'us',\n",
       "     u'or',\n",
       "     u'stay',\n",
       "     u'mellow']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Doin',\n",
       "     u'whatever',\n",
       "     u'the',\n",
       "     u'hell',\n",
       "     u'it',\n",
       "     u'is',\n",
       "     u'you',\n",
       "     u'do',\n",
       "     u'in',\n",
       "     u'Monticello'],\n",
       "    'original': 'Doin\\xe2\\x80\\x99 whatever the hell it is you do in Monticello?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Doin',\n",
       "     u'whatever',\n",
       "     u'the',\n",
       "     u'hell',\n",
       "     u'it',\n",
       "     u'is',\n",
       "     u'you',\n",
       "     u'do',\n",
       "     u'in',\n",
       "     u'Monticello']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'If',\n",
       "     u'we',\n",
       "     u'assume',\n",
       "     u'the',\n",
       "     u'debts',\n",
       "     u'the',\n",
       "     u'union',\n",
       "     u'gets'],\n",
       "    'original': 'If we assume the debts, the union gets',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'we',\n",
       "     u'assume',\n",
       "     u'the',\n",
       "     u'debts',\n",
       "     u'the',\n",
       "     u'union',\n",
       "     u'gets']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'A',\n",
       "     u'new',\n",
       "     u'line',\n",
       "     u'of',\n",
       "     u'credit',\n",
       "     u'a',\n",
       "     u'financial',\n",
       "     u'diuretic'],\n",
       "    'original': 'A new line of credit, a financial diuretic',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'new',\n",
       "     u'line',\n",
       "     u'of',\n",
       "     u'credit',\n",
       "     u'a',\n",
       "     u'financial',\n",
       "     u'diuretic']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'How',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'not',\n",
       "     u'get',\n",
       "     u'it',\n",
       "     u'If',\n",
       "     u'we\\u2019re',\n",
       "     u'aggressive',\n",
       "     u'and',\n",
       "     u'competitive'],\n",
       "    'original': 'How do you not get it? If we\\xe2\\x80\\x99re aggressive and competitive',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'How',\n",
       "     u'do',\n",
       "     u'you',\n",
       "     u'not',\n",
       "     u'get',\n",
       "     u'it',\n",
       "     u'If',\n",
       "     u'we\\u2019re',\n",
       "     u'aggressive',\n",
       "     u'and',\n",
       "     u'competitive']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'The',\n",
       "     u'union',\n",
       "     u'gets',\n",
       "     u'a',\n",
       "     u'boost',\n",
       "     u'You\\u2019d',\n",
       "     u'rather',\n",
       "     u'give',\n",
       "     u'it',\n",
       "     u'a',\n",
       "     u'sedative'],\n",
       "    'original': 'The union gets a boost. You\\xe2\\x80\\x99d rather give it a sedative?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'union',\n",
       "     u'gets',\n",
       "     u'a',\n",
       "     u'boost',\n",
       "     u'You\\u2019d',\n",
       "     u'rather',\n",
       "     u'give',\n",
       "     u'it',\n",
       "     u'a',\n",
       "     u'sedative']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'A',\n",
       "     u'civics',\n",
       "     u'lesson',\n",
       "     u'from',\n",
       "     u'a',\n",
       "     u'slaver',\n",
       "     u'Hey',\n",
       "     u'neighbor'],\n",
       "    'original': 'A civics lesson from a slaver. Hey neighbor',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'civics',\n",
       "     u'lesson',\n",
       "     u'from',\n",
       "     u'a',\n",
       "     u'slaver',\n",
       "     u'Hey',\n",
       "     u'neighbor']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'Your',\n",
       "     u'debts',\n",
       "     u'are',\n",
       "     u'paid',\n",
       "     u'cuz',\n",
       "     u'you',\n",
       "     u'don\\u2019t',\n",
       "     u'pay',\n",
       "     u'for',\n",
       "     u'labor'],\n",
       "    'original': 'Your debts are paid cuz you don\\xe2\\x80\\x99t pay for labor',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Your',\n",
       "     u'debts',\n",
       "     u'are',\n",
       "     u'paid',\n",
       "     u'cuz',\n",
       "     u'you',\n",
       "     u'don\\u2019t',\n",
       "     u'pay',\n",
       "     u'for',\n",
       "     u'labor']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'We',\n",
       "     u'plant',\n",
       "     u'seeds',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'South',\n",
       "     u'We',\n",
       "     u'create'],\n",
       "    'original': '\\xe2\\x80\\x9cWe plant seeds in the South. We create.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'plant',\n",
       "     u'seeds',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'South',\n",
       "     u'We',\n",
       "     u'create']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Yeah', u'keep', u'ranting'],\n",
       "    'original': 'Yeah, keep ranting',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yeah', u'keep', u'ranting']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'We',\n",
       "     u'know',\n",
       "     u'who\\u2019s',\n",
       "     u'really',\n",
       "     u'doing',\n",
       "     u'the',\n",
       "     u'planting'],\n",
       "    'original': 'We know who\\xe2\\x80\\x99s really doing the planting',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'know',\n",
       "     u'who\\u2019s',\n",
       "     u'really',\n",
       "     u'doing',\n",
       "     u'the',\n",
       "     u'planting']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'And',\n",
       "     u'another',\n",
       "     u'thing',\n",
       "     u'Mr',\n",
       "     u'Age',\n",
       "     u'of',\n",
       "     u'Enlightenment'],\n",
       "    'original': 'And another thing, Mr. Age of Enlightenment',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'another',\n",
       "     u'thing',\n",
       "     u'Mr',\n",
       "     u'Age',\n",
       "     u'of',\n",
       "     u'Enlightenment']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Don\\u2019t',\n",
       "     u'lecture',\n",
       "     u'me',\n",
       "     u'about',\n",
       "     u'the',\n",
       "     u'war',\n",
       "     u'you',\n",
       "     u'didn\\u2019t',\n",
       "     u'fight',\n",
       "     u'in',\n",
       "     u'it'],\n",
       "    'original': 'Don\\xe2\\x80\\x99t lecture me about the war, you didn\\xe2\\x80\\x99t fight in it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Don\\u2019t',\n",
       "     u'lecture',\n",
       "     u'me',\n",
       "     u'about',\n",
       "     u'the',\n",
       "     u'war',\n",
       "     u'you',\n",
       "     u'didn\\u2019t',\n",
       "     u'fight',\n",
       "     u'in',\n",
       "     u'it']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'You',\n",
       "     u'think',\n",
       "     u'I\\u2019m',\n",
       "     u'frightened',\n",
       "     u'of',\n",
       "     u'you',\n",
       "     u'man'],\n",
       "    'original': 'You think I\\xe2\\x80\\x99m frightened of you, man?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'think',\n",
       "     u'I\\u2019m',\n",
       "     u'frightened',\n",
       "     u'of',\n",
       "     u'you',\n",
       "     u'man']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'We', u'almost', u'died', u'in', u'the', u'trench'],\n",
       "    'original': 'We almost died in the trench',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We', u'almost', u'died', u'in', u'the', u'trench']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'While',\n",
       "     u'you',\n",
       "     u'were',\n",
       "     u'off',\n",
       "     u'getting',\n",
       "     u'high',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'French'],\n",
       "    'original': 'While you were off getting high with the French',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'While',\n",
       "     u'you',\n",
       "     u'were',\n",
       "     u'off',\n",
       "     u'getting',\n",
       "     u'high',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'French']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Thomas',\n",
       "     u'Jefferson',\n",
       "     u'always',\n",
       "     u'hesitant',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'President'],\n",
       "    'original': 'Thomas Jefferson, always hesitant with the President',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Thomas',\n",
       "     u'Jefferson',\n",
       "     u'always',\n",
       "     u'hesitant',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'President']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Reticent',\n",
       "     u'there',\n",
       "     u'isn\\u2019t',\n",
       "     u'a',\n",
       "     u'plan',\n",
       "     u'he',\n",
       "     u'doesn\\u2019t',\n",
       "     u'jettison'],\n",
       "    'original': 'Reticent\\xe2\\x80\\x94there isn\\xe2\\x80\\x99t a plan he doesn\\xe2\\x80\\x99t jettison',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Reticent',\n",
       "     u'there',\n",
       "     u'isn\\u2019t',\n",
       "     u'a',\n",
       "     u'plan',\n",
       "     u'he',\n",
       "     u'doesn\\u2019t',\n",
       "     u'jettison']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Madison',\n",
       "     u'you\\u2019re',\n",
       "     u'mad',\n",
       "     u'as',\n",
       "     u'a',\n",
       "     u'hatter',\n",
       "     u'son',\n",
       "     u'take',\n",
       "     u'your',\n",
       "     u'medicine'],\n",
       "    'original': 'Madison, you\\xe2\\x80\\x99re mad as a hatter, son, take your medicine',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Madison',\n",
       "     u'you\\u2019re',\n",
       "     u'mad',\n",
       "     u'as',\n",
       "     u'a',\n",
       "     u'hatter',\n",
       "     u'son',\n",
       "     u'take',\n",
       "     u'your',\n",
       "     u'medicine']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Damn',\n",
       "     u'you\\u2019re',\n",
       "     u'in',\n",
       "     u'worse',\n",
       "     u'shape',\n",
       "     u'than',\n",
       "     u'the',\n",
       "     u'national',\n",
       "     u'debt',\n",
       "     u'is',\n",
       "     u'in'],\n",
       "    'original': 'Damn, you\\xe2\\x80\\x99re in worse shape than the national debt is in',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Damn',\n",
       "     u'you\\u2019re',\n",
       "     u'in',\n",
       "     u'worse',\n",
       "     u'shape',\n",
       "     u'than',\n",
       "     u'the',\n",
       "     u'national',\n",
       "     u'debt',\n",
       "     u'is',\n",
       "     u'in']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Sittin', u'there', u'useless', u'as', u'two', u'shits'],\n",
       "    'original': 'Sittin\\xe2\\x80\\x99 there useless as two shits',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sittin', u'there', u'useless', u'as', u'two', u'shits']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Hey',\n",
       "     u'turn',\n",
       "     u'around',\n",
       "     u'bend',\n",
       "     u'over',\n",
       "     u'I\\u2019ll',\n",
       "     u'show',\n",
       "     u'you'],\n",
       "    'original': 'Hey, turn around, bend over, I\\xe2\\x80\\x99ll show you',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'turn',\n",
       "     u'around',\n",
       "     u'bend',\n",
       "     u'over',\n",
       "     u'I\\u2019ll',\n",
       "     u'show',\n",
       "     u'you']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Where', u'my', u'shoe', u'fits'],\n",
       "    'original': 'Where my shoe fits',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Where', u'my', u'shoe', u'fits']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Excuse',\n",
       "     u'me',\n",
       "     u'Madison',\n",
       "     u'Jefferson',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'walk',\n",
       "     u'Hamilton',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'walk',\n",
       "     u'We\\u2019ll',\n",
       "     u'reconvene',\n",
       "     u'after',\n",
       "     u'a',\n",
       "     u'brief',\n",
       "     u'recess',\n",
       "     u'Hamilton'],\n",
       "    'original': 'Excuse me? Madison, Jefferson, take a walk! Hamilton, take a walk! We\\xe2\\x80\\x99ll reconvene after a brief recess. Hamilton!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Excuse',\n",
       "     u'me',\n",
       "     u'Madison',\n",
       "     u'Jefferson',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'walk',\n",
       "     u'Hamilton',\n",
       "     u'take',\n",
       "     u'a',\n",
       "     u'walk',\n",
       "     u'We\\u2019ll',\n",
       "     u'reconvene',\n",
       "     u'after',\n",
       "     u'a',\n",
       "     u'brief',\n",
       "     u'recess',\n",
       "     u'Hamilton']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'A', u'word'],\n",
       "    'original': 'A word',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'A', u'word']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'You', u'don\\u2019t', u'have', u'the', u'votes'],\n",
       "    'original': 'You don\\xe2\\x80\\x99t have the votes',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'You', u'don\\u2019t', u'have', u'the', u'votes']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'You', u'don\\u2019t', u'have', u'the', u'votes'],\n",
       "    'original': 'You don\\xe2\\x80\\x99t have the votes',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'You', u'don\\u2019t', u'have', u'the', u'votes']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Aha', u'ha', u'ha', u'ha'],\n",
       "    'original': 'Aha-ha-ha ha!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Aha', u'ha', u'ha', u'ha']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'You\\u2019re',\n",
       "     u'gonna',\n",
       "     u'need',\n",
       "     u'congressional',\n",
       "     u'approval',\n",
       "     u'and',\n",
       "     u'you',\n",
       "     u'don\\u2019t',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'votes'],\n",
       "    'original': 'You\\xe2\\x80\\x99re gonna need congressional approval and you don\\xe2\\x80\\x99t have the votes',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'You\\u2019re',\n",
       "     u'gonna',\n",
       "     u'need',\n",
       "     u'congressional',\n",
       "     u'approval',\n",
       "     u'and',\n",
       "     u'you',\n",
       "     u'don\\u2019t',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'votes']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Such',\n",
       "     u'a',\n",
       "     u'blunder',\n",
       "     u'sometimes',\n",
       "     u'it',\n",
       "     u'makes',\n",
       "     u'me',\n",
       "     u'wonder',\n",
       "     u'why',\n",
       "     u'I',\n",
       "     u'even',\n",
       "     u'bring',\n",
       "     u'the',\n",
       "     u'thunder'],\n",
       "    'original': 'Such a blunder sometimes it makes me wonder why I even bring the thunder',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Such',\n",
       "     u'a',\n",
       "     u'blunder',\n",
       "     u'sometimes',\n",
       "     u'it',\n",
       "     u'makes',\n",
       "     u'me',\n",
       "     u'wonder',\n",
       "     u'why',\n",
       "     u'I',\n",
       "     u'even',\n",
       "     u'bring',\n",
       "     u'the',\n",
       "     u'thunder']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Why', u'he', u'even', u'brings', u'the', u'thunder'],\n",
       "    'original': 'Why he even brings the thunder\\xe2\\x80\\xa6',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Why', u'he', u'even', u'brings', u'the', u'thunder']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'You', u'wanna', u'pull', u'yourself', u'together'],\n",
       "    'original': 'You wanna pull yourself together?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You', u'wanna', u'pull', u'yourself', u'together']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'sorry',\n",
       "     u'these',\n",
       "     u'Virginians',\n",
       "     u'are',\n",
       "     u'birds',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'feather'],\n",
       "    'original': 'I\\xe2\\x80\\x99m sorry, these Virginians are birds of a feather',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'sorry',\n",
       "     u'these',\n",
       "     u'Virginians',\n",
       "     u'are',\n",
       "     u'birds',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'feather']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'Young',\n",
       "     u'man',\n",
       "     u'I\\u2019m',\n",
       "     u'from',\n",
       "     u'Virginia',\n",
       "     u'so',\n",
       "     u'watch',\n",
       "     u'your',\n",
       "     u'mouth'],\n",
       "    'original': 'Young man, I\\xe2\\x80\\x99m from Virginia, so watch your mouth',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Young',\n",
       "     u'man',\n",
       "     u'I\\u2019m',\n",
       "     u'from',\n",
       "     u'Virginia',\n",
       "     u'so',\n",
       "     u'watch',\n",
       "     u'your',\n",
       "     u'mouth']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'So',\n",
       "     u'we',\n",
       "     u'let',\n",
       "     u'Congress',\n",
       "     u'get',\n",
       "     u'held',\n",
       "     u'hostage',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'South'],\n",
       "    'original': 'So we let Congress get held hostage by the South?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'So',\n",
       "     u'we',\n",
       "     u'let',\n",
       "     u'Congress',\n",
       "     u'get',\n",
       "     u'held',\n",
       "     u'hostage',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'South']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'You', u'need', u'the', u'votes'],\n",
       "    'original': 'You need the votes',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You', u'need', u'the', u'votes']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'No',\n",
       "     u'we',\n",
       "     u'need',\n",
       "     u'bold',\n",
       "     u'strokes',\n",
       "     u'We',\n",
       "     u'need',\n",
       "     u'this',\n",
       "     u'plan'],\n",
       "    'original': 'No, we need bold strokes. We need this plan',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No',\n",
       "     u'we',\n",
       "     u'need',\n",
       "     u'bold',\n",
       "     u'strokes',\n",
       "     u'We',\n",
       "     u'need',\n",
       "     u'this',\n",
       "     u'plan']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'No',\n",
       "     u'you',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'convince',\n",
       "     u'more',\n",
       "     u'folks'],\n",
       "    'original': 'No, you need to convince more folks',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'No',\n",
       "     u'you',\n",
       "     u'need',\n",
       "     u'to',\n",
       "     u'convince',\n",
       "     u'more',\n",
       "     u'folks']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'James',\n",
       "     u'Madison',\n",
       "     u'won\\u2019t',\n",
       "     u'talk',\n",
       "     u'to',\n",
       "     u'me',\n",
       "     u'that\\u2019s',\n",
       "     u'a',\n",
       "     u'nonstarter'],\n",
       "    'original': 'James Madison won\\xe2\\x80\\x99t talk to me, that\\xe2\\x80\\x99s a nonstarter',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'James',\n",
       "     u'Madison',\n",
       "     u'won\\u2019t',\n",
       "     u'talk',\n",
       "     u'to',\n",
       "     u'me',\n",
       "     u'that\\u2019s',\n",
       "     u'a',\n",
       "     u'nonstarter']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Winning',\n",
       "     u'was',\n",
       "     u'easy',\n",
       "     u'young',\n",
       "     u'man',\n",
       "     u'Governing\\u2019s',\n",
       "     u'harder'],\n",
       "    'original': 'Winning was easy, young man. Governing\\xe2\\x80\\x99s harder',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Winning',\n",
       "     u'was',\n",
       "     u'easy',\n",
       "     u'young',\n",
       "     u'man',\n",
       "     u'Governing\\u2019s',\n",
       "     u'harder']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'They\\u2019re', u'being', u'intransigent'],\n",
       "    'original': 'They\\xe2\\x80\\x99re being intransigent',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'They\\u2019re', u'being', u'intransigent']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'You', u'have', u'to', u'find', u'a', u'compromise'],\n",
       "    'original': 'You have to find a compromise',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You', u'have', u'to', u'find', u'a', u'compromise']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'But',\n",
       "     u'they',\n",
       "     u'don\\u2019t',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'plan',\n",
       "     u'they',\n",
       "     u'just',\n",
       "     u'hate',\n",
       "     u'mine'],\n",
       "    'original': 'But they don\\xe2\\x80\\x99t have a plan, they just hate mine!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'they',\n",
       "     u'don\\u2019t',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'plan',\n",
       "     u'they',\n",
       "     u'just',\n",
       "     u'hate',\n",
       "     u'mine']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Convince', u'them', u'otherwise'],\n",
       "    'original': 'Convince them otherwise',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Convince', u'them', u'otherwise']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'What',\n",
       "     u'happens',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'congressional',\n",
       "     u'approval'],\n",
       "    'original': 'What happens if I don\\xe2\\x80\\x99t get congressional approval?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What',\n",
       "     u'happens',\n",
       "     u'if',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'congressional',\n",
       "     u'approval']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'I',\n",
       "     u'imagine',\n",
       "     u'they\\u2019ll',\n",
       "     u'call',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'removal'],\n",
       "    'original': 'I imagine they\\xe2\\x80\\x99ll call for your removal',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'imagine',\n",
       "     u'they\\u2019ll',\n",
       "     u'call',\n",
       "     u'for',\n",
       "     u'your',\n",
       "     u'removal']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'Figure',\n",
       "     u'it',\n",
       "     u'out',\n",
       "     u'Alexander',\n",
       "     u'That\\u2019s',\n",
       "     u'an',\n",
       "     u'order',\n",
       "     u'from',\n",
       "     u'your',\n",
       "     u'commander'],\n",
       "    'original': 'Figure it out, Alexander. That\\xe2\\x80\\x99s an order from your commander',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Figure',\n",
       "     u'it',\n",
       "     u'out',\n",
       "     u'Alexander',\n",
       "     u'That\\u2019s',\n",
       "     u'an',\n",
       "     u'order',\n",
       "     u'from',\n",
       "     u'your',\n",
       "     u'commander']}],\n",
       "  'track': 'Cabinet Battle #1',\n",
       "  'track#': '2'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Un', u'deux', u'trois', u'quatre'],\n",
       "    'original': 'Un deux trois quatre',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Un', u'deux', u'trois', u'quatre']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Cinq', u'six', u'sept', u'huit', u'neuf'],\n",
       "    'original': 'Cinq six sept huit neuf',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Cinq', u'six', u'sept', u'huit', u'neuf']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Good', u'Un', u'deux', u'trois', u'quatre'],\n",
       "    'original': 'Good! Un deux trois quatre',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Good', u'Un', u'deux', u'trois', u'quatre']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Cinq', u'six', u'sept', u'huit', u'neuf'],\n",
       "    'original': 'Cinq six sept huit neuf',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Cinq', u'six', u'sept', u'huit', u'neuf']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Sept', u'huit', u'neuf'],\n",
       "    'original': 'Sept huit neuf\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Sept', u'huit', u'neuf']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Sept', u'huit', u'neuf'],\n",
       "    'original': 'Sept huit neuf\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Sept', u'huit', u'neuf']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Un', u'deux', u'trois', u'quatre'],\n",
       "    'original': 'Un deux trois quatre',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Un', u'deux', u'trois', u'quatre']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Cinq', u'six', u'sept', u'huit', u'neuf'],\n",
       "    'original': 'Cinq six sept huit neuf',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Cinq', u'six', u'sept', u'huit', u'neuf']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Un', u'deux', u'trois', u'quatre'],\n",
       "    'original': 'Un deux trois quatre',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Un', u'deux', u'trois', u'quatre']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Cinq', u'six', u'sept', u'huit', u'neuf'],\n",
       "    'original': 'Cinq six sept huit neuf',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Cinq', u'six', u'sept', u'huit', u'neuf']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Sept', u'huit', u'neuf'],\n",
       "    'original': 'Sept huit neuf\\xe2\\x80\\x94',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Sept', u'huit', u'neuf']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Sept', u'huit', u'neuf'],\n",
       "    'original': 'Sept huit neuf\\xe2\\x80\\x94',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Sept', u'huit', u'neuf']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'One',\n",
       "     u'two',\n",
       "     u'three',\n",
       "     u'four',\n",
       "     u'five',\n",
       "     u'six',\n",
       "     u'seven',\n",
       "     u'eight',\n",
       "     u'nine'],\n",
       "    'original': 'One two three four five six seven eight nine!',\n",
       "    'speakers': ['ELIZA', 'PHILIP'],\n",
       "    'tokenized': [u'One',\n",
       "     u'two',\n",
       "     u'three',\n",
       "     u'four',\n",
       "     u'five',\n",
       "     u'six',\n",
       "     u'seven',\n",
       "     u'eight',\n",
       "     u'nine']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'My', u'dearest', u'Angelica'],\n",
       "    'original': 'My dearest, Angelica',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'dearest', u'Angelica']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Tomorrow', u'and', u'tomorrow', u'and', u'tomorrow'],\n",
       "    'original': '\\xe2\\x80\\x9cTomorrow and tomorrow and tomorrow',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Tomorrow', u'and', u'tomorrow', u'and', u'tomorrow']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Creeps',\n",
       "     u'in',\n",
       "     u'this',\n",
       "     u'petty',\n",
       "     u'pace',\n",
       "     u'from',\n",
       "     u'day',\n",
       "     u'to',\n",
       "     u'day'],\n",
       "    'original': 'Creeps in this petty pace from day to day\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Creeps',\n",
       "     u'in',\n",
       "     u'this',\n",
       "     u'petty',\n",
       "     u'pace',\n",
       "     u'from',\n",
       "     u'day',\n",
       "     u'to',\n",
       "     u'day']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'I',\n",
       "     u'trust',\n",
       "     u'you\\u2019ll',\n",
       "     u'understand',\n",
       "     u'the',\n",
       "     u'reference',\n",
       "     u'to'],\n",
       "    'original': 'I trust you\\xe2\\x80\\x99ll understand the reference to',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'trust',\n",
       "     u'you\\u2019ll',\n",
       "     u'understand',\n",
       "     u'the',\n",
       "     u'reference',\n",
       "     u'to']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Another',\n",
       "     u'Scottish',\n",
       "     u'tragedy',\n",
       "     u'without',\n",
       "     u'my',\n",
       "     u'having',\n",
       "     u'to',\n",
       "     u'name',\n",
       "     u'the',\n",
       "     u'play'],\n",
       "    'original': 'Another Scottish tragedy without my having to name the play',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Another',\n",
       "     u'Scottish',\n",
       "     u'tragedy',\n",
       "     u'without',\n",
       "     u'my',\n",
       "     u'having',\n",
       "     u'to',\n",
       "     u'name',\n",
       "     u'the',\n",
       "     u'play']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'They',\n",
       "     u'think',\n",
       "     u'me',\n",
       "     u'Macbeth',\n",
       "     u'and',\n",
       "     u'ambition',\n",
       "     u'is',\n",
       "     u'my',\n",
       "     u'folly'],\n",
       "    'original': 'They think me Macbeth, and ambition is my folly',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'They',\n",
       "     u'think',\n",
       "     u'me',\n",
       "     u'Macbeth',\n",
       "     u'and',\n",
       "     u'ambition',\n",
       "     u'is',\n",
       "     u'my',\n",
       "     u'folly']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'polymath',\n",
       "     u'a',\n",
       "     u'pain',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'ass',\n",
       "     u'a',\n",
       "     u'massive',\n",
       "     u'pain'],\n",
       "    'original': 'I\\xe2\\x80\\x99m a polymath, a pain in the ass, a massive pain',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'a',\n",
       "     u'polymath',\n",
       "     u'a',\n",
       "     u'pain',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'ass',\n",
       "     u'a',\n",
       "     u'massive',\n",
       "     u'pain']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Madison',\n",
       "     u'is',\n",
       "     u'Banquo',\n",
       "     u'Jefferson\\u2019s',\n",
       "     u'Macduff'],\n",
       "    'original': 'Madison is Banquo, Jefferson\\xe2\\x80\\x99s Macduff',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Madison',\n",
       "     u'is',\n",
       "     u'Banquo',\n",
       "     u'Jefferson\\u2019s',\n",
       "     u'Macduff']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'And',\n",
       "     u'Birnam',\n",
       "     u'Wood',\n",
       "     u'is',\n",
       "     u'Congress',\n",
       "     u'on',\n",
       "     u'its',\n",
       "     u'way',\n",
       "     u'to',\n",
       "     u'Dunsinane'],\n",
       "    'original': 'And Birnam Wood is Congress on its way to Dunsinane',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'Birnam',\n",
       "     u'Wood',\n",
       "     u'is',\n",
       "     u'Congress',\n",
       "     u'on',\n",
       "     u'its',\n",
       "     u'way',\n",
       "     u'to',\n",
       "     u'Dunsinane']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'And', u'there', u'you', u'are', u'an', u'ocean', u'away'],\n",
       "    'original': 'And there you are, an ocean away',\n",
       "    'speakers': ['HAMILTON', 'ANGELICA'],\n",
       "    'tokenized': [u'And', u'there', u'you', u'are', u'an', u'ocean', u'away']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Do',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'live',\n",
       "     u'an',\n",
       "     u'ocean',\n",
       "     u'away'],\n",
       "    'original': 'Do you have to live an ocean away?',\n",
       "    'speakers': ['HAMILTON', 'ANGELICA'],\n",
       "    'tokenized': [u'Do',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'live',\n",
       "     u'an',\n",
       "     u'ocean',\n",
       "     u'away']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Thoughts', u'of', u'you', u'subside'],\n",
       "    'original': 'Thoughts of you subside',\n",
       "    'speakers': ['HAMILTON', 'ANGELICA'],\n",
       "    'tokenized': [u'Thoughts', u'of', u'you', u'subside']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Then', u'I', u'get', u'another', u'letter'],\n",
       "    'original': 'Then I get another letter',\n",
       "    'speakers': ['HAMILTON', 'ANGELICA'],\n",
       "    'tokenized': [u'Then', u'I', u'get', u'another', u'letter']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'I', u'cannot', u'put', u'the', u'notion', u'away'],\n",
       "    'original': 'I cannot put the notion away\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON', 'ANGELICA'],\n",
       "    'tokenized': [u'I', u'cannot', u'put', u'the', u'notion', u'away']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Take', u'a', u'break'],\n",
       "    'original': 'Take a break',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Take', u'a', u'break']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'I', u'am', u'on', u'my', u'way'],\n",
       "    'original': 'I am on my way',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'on', u'my', u'way']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'There\\u2019s',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'surprise',\n",
       "     u'before',\n",
       "     u'supper'],\n",
       "    'original': 'There\\xe2\\x80\\x99s a little surprise before supper',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'There\\u2019s',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'surprise',\n",
       "     u'before',\n",
       "     u'supper']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'And', u'it', u'cannot', u'wait'],\n",
       "    'original': 'And it cannot wait',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And', u'it', u'cannot', u'wait']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'I\\u2019ll',\n",
       "     u'be',\n",
       "     u'there',\n",
       "     u'in',\n",
       "     u'just',\n",
       "     u'a',\n",
       "     u'minute',\n",
       "     u'save',\n",
       "     u'my',\n",
       "     u'plate'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll be there in just a minute, save my plate',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019ll',\n",
       "     u'be',\n",
       "     u'there',\n",
       "     u'in',\n",
       "     u'just',\n",
       "     u'a',\n",
       "     u'minute',\n",
       "     u'save',\n",
       "     u'my',\n",
       "     u'plate']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Alexander'],\n",
       "    'original': 'Alexander\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Alexander']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Okay', u'okay'],\n",
       "    'original': 'Okay, okay\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Okay', u'okay']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Your',\n",
       "     u'son',\n",
       "     u'is',\n",
       "     u'nine',\n",
       "     u'years',\n",
       "     u'old',\n",
       "     u'today'],\n",
       "    'original': 'Your son is nine years old today',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Your',\n",
       "     u'son',\n",
       "     u'is',\n",
       "     u'nine',\n",
       "     u'years',\n",
       "     u'old',\n",
       "     u'today']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'And',\n",
       "     u'he',\n",
       "     u'has',\n",
       "     u'something',\n",
       "     u'that',\n",
       "     u'he\\u2019d',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'say'],\n",
       "    'original': 'And he has something that he\\xe2\\x80\\x99d like to say',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'And',\n",
       "     u'he',\n",
       "     u'has',\n",
       "     u'something',\n",
       "     u'that',\n",
       "     u'he\\u2019d',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'say']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'He\\u2019s', u'been', u'practicing', u'all', u'day'],\n",
       "    'original': 'He\\xe2\\x80\\x99s been practicing all day',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'He\\u2019s', u'been', u'practicing', u'all', u'day']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Philip', u'take', u'it', u'away'],\n",
       "    'original': 'Philip, take it away\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Philip', u'take', u'it', u'away']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Daddy', u'daddy', u'look'],\n",
       "    'original': 'Daddy, daddy, look\\xe2\\x80\\x94',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Daddy', u'daddy', u'look']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'My', u'name', u'is', u'Philip'],\n",
       "    'original': 'My name is Philip',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'My', u'name', u'is', u'Philip']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'I', u'am', u'a', u'poet'],\n",
       "    'original': 'I am a poet',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'am', u'a', u'poet']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'I', u'wrote', u'this', u'poem', u'just'],\n",
       "    'original': 'I wrote this poem just',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'wrote', u'this', u'poem', u'just']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'To', u'show', u'it'],\n",
       "    'original': 'To show it',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'To', u'show', u'it']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'And', u'I', u'just', u'turned', u'nine'],\n",
       "    'original': 'And I just turned nine',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'And', u'I', u'just', u'turned', u'nine']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'You', u'can', u'write', u'rhymes'],\n",
       "    'original': 'You can write rhymes',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'You', u'can', u'write', u'rhymes']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'But', u'you', u'can\\u2019t', u'write', u'mine'],\n",
       "    'original': 'But you can\\xe2\\x80\\x99t write mine',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'But', u'you', u'can\\u2019t', u'write', u'mine']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'I', u'practice', u'French'],\n",
       "    'original': 'I practice French',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I', u'practice', u'French']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'And', u'play', u'piano', u'with', u'my', u'mother'],\n",
       "    'original': 'And play piano with my mother',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'And', u'play', u'piano', u'with', u'my', u'mother']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'sister',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'want',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'brother'],\n",
       "    'original': 'I have a sister, but I want a little brother',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'sister',\n",
       "     u'but',\n",
       "     u'I',\n",
       "     u'want',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'brother']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'My',\n",
       "     u'daddy\\u2019s',\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'start',\n",
       "     u'America\\u2019s',\n",
       "     u'bank'],\n",
       "    'original': 'My daddy\\xe2\\x80\\x99s trying to start America\\xe2\\x80\\x99s bank',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'My',\n",
       "     u'daddy\\u2019s',\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'start',\n",
       "     u'America\\u2019s',\n",
       "     u'bank']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Un', u'deux', u'trois', u'quatre', u'cinq'],\n",
       "    'original': 'Un deux trois quatre cinq!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Un', u'deux', u'trois', u'quatre', u'cinq']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Uh', u'huh'],\n",
       "    'original': 'Uh-huh!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Uh', u'huh']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Okay'],\n",
       "    'original': 'Okay!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Okay']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Bravo'],\n",
       "    'original': 'Bravo!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Bravo']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Take', u'a', u'break'],\n",
       "    'original': 'Take a break',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Take', u'a', u'break']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Hey', u'our', u'kid', u'is', u'pretty', u'great'],\n",
       "    'original': 'Hey, our kid is pretty great',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey', u'our', u'kid', u'is', u'pretty', u'great']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Run', u'away', u'with', u'us', u'for', u'the', u'summer'],\n",
       "    'original': 'Run away with us for the summer',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Run', u'away', u'with', u'us', u'for', u'the', u'summer']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Let\\u2019s', u'go', u'upstate'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s go upstate',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Let\\u2019s', u'go', u'upstate']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Eliza',\n",
       "     u'I\\u2019ve',\n",
       "     u'got',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'plate'],\n",
       "    'original': 'Eliza, I\\xe2\\x80\\x99ve got so much on my plate',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Eliza',\n",
       "     u'I\\u2019ve',\n",
       "     u'got',\n",
       "     u'so',\n",
       "     u'much',\n",
       "     u'on',\n",
       "     u'my',\n",
       "     u'plate']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'We',\n",
       "     u'can',\n",
       "     u'all',\n",
       "     u'go',\n",
       "     u'stay',\n",
       "     u'with',\n",
       "     u'my',\n",
       "     u'father'],\n",
       "    'original': 'We can all go stay with my father',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'We',\n",
       "     u'can',\n",
       "     u'all',\n",
       "     u'go',\n",
       "     u'stay',\n",
       "     u'with',\n",
       "     u'my',\n",
       "     u'father']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'There\\u2019s', u'a', u'lake', u'I', u'know'],\n",
       "    'original': 'There\\xe2\\x80\\x99s a lake I know\\xe2\\x80\\xa6',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'There\\u2019s', u'a', u'lake', u'I', u'know']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'I', u'know'],\n",
       "    'original': 'I know',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'know']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'In', u'a', u'nearby', u'park'],\n",
       "    'original': 'In a nearby park',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'In', u'a', u'nearby', u'park']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'I\\u2019d', u'love', u'to', u'go'],\n",
       "    'original': 'I\\xe2\\x80\\x99d love to go',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019d', u'love', u'to', u'go']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'You',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'go',\n",
       "     u'when',\n",
       "     u'the',\n",
       "     u'night',\n",
       "     u'gets',\n",
       "     u'dark'],\n",
       "    'original': 'You and I can go when the night gets dark\\xe2\\x80\\xa6',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'go',\n",
       "     u'when',\n",
       "     u'the',\n",
       "     u'night',\n",
       "     u'gets',\n",
       "     u'dark']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'I', u'will', u'try', u'to', u'get', u'away'],\n",
       "    'original': 'I will try to get away',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'will', u'try', u'to', u'get', u'away']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'My', u'dearest', u'Alexander'],\n",
       "    'original': 'My dearest Alexander',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'My', u'dearest', u'Alexander']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'You', u'must', u'get', u'through', u'to', u'Jefferson'],\n",
       "    'original': 'You must get through to Jefferson',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'You', u'must', u'get', u'through', u'to', u'Jefferson']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Sit', u'down', u'with', u'him', u'and', u'compromise'],\n",
       "    'original': 'Sit down with him and compromise',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Sit', u'down', u'with', u'him', u'and', u'compromise']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'Don\\u2019t', u'stop', u'til', u'you', u'agree'],\n",
       "    'original': 'Don\\xe2\\x80\\x99t stop \\xe2\\x80\\x98til you agree',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Don\\u2019t', u'stop', u'til', u'you', u'agree']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'Your', u'fav\\u2019rite', u'older', u'sister'],\n",
       "    'original': 'Your fav\\xe2\\x80\\x99rite older sister',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Your', u'fav\\u2019rite', u'older', u'sister']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Angelica', u'reminds', u'you'],\n",
       "    'original': 'Angelica, reminds you',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Angelica', u'reminds', u'you']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'There\\u2019s',\n",
       "     u'someone',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'corner',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'way',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'sea'],\n",
       "    'original': 'There\\xe2\\x80\\x99s someone in your corner all the way across the sea',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'There\\u2019s',\n",
       "     u'someone',\n",
       "     u'in',\n",
       "     u'your',\n",
       "     u'corner',\n",
       "     u'all',\n",
       "     u'the',\n",
       "     u'way',\n",
       "     u'across',\n",
       "     u'the',\n",
       "     u'sea']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'In',\n",
       "     u'a',\n",
       "     u'letter',\n",
       "     u'I',\n",
       "     u'received',\n",
       "     u'from',\n",
       "     u'you',\n",
       "     u'two',\n",
       "     u'weeks',\n",
       "     u'ago'],\n",
       "    'original': 'In a letter I received from you two weeks ago',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'In',\n",
       "     u'a',\n",
       "     u'letter',\n",
       "     u'I',\n",
       "     u'received',\n",
       "     u'from',\n",
       "     u'you',\n",
       "     u'two',\n",
       "     u'weeks',\n",
       "     u'ago']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'I',\n",
       "     u'noticed',\n",
       "     u'a',\n",
       "     u'comma',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'middle',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'phrase'],\n",
       "    'original': 'I noticed a comma in the middle of a phrase',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'noticed',\n",
       "     u'a',\n",
       "     u'comma',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'middle',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'phrase']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'It',\n",
       "     u'changed',\n",
       "     u'the',\n",
       "     u'meaning',\n",
       "     u'Did',\n",
       "     u'you',\n",
       "     u'intend',\n",
       "     u'this'],\n",
       "    'original': 'It changed the meaning. Did you intend this?',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'It',\n",
       "     u'changed',\n",
       "     u'the',\n",
       "     u'meaning',\n",
       "     u'Did',\n",
       "     u'you',\n",
       "     u'intend',\n",
       "     u'this']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'One',\n",
       "     u'stroke',\n",
       "     u'and',\n",
       "     u'you\\u2019ve',\n",
       "     u'consumed',\n",
       "     u'my',\n",
       "     u'waking',\n",
       "     u'days'],\n",
       "    'original': 'One stroke and you\\xe2\\x80\\x99ve consumed my waking days',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'One',\n",
       "     u'stroke',\n",
       "     u'and',\n",
       "     u'you\\u2019ve',\n",
       "     u'consumed',\n",
       "     u'my',\n",
       "     u'waking',\n",
       "     u'days']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'It', u'says'],\n",
       "    'original': 'It says:',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'It', u'says']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'My', u'dearest', u'Angelica'],\n",
       "    'original': '\\xe2\\x80\\x9cMy dearest Angelica\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON', 'ANGELICA'],\n",
       "    'tokenized': [u'My', u'dearest', u'Angelica']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'With',\n",
       "     u'a',\n",
       "     u'comma',\n",
       "     u'after',\n",
       "     u'dearest',\n",
       "     u'You\\u2019ve',\n",
       "     u'written'],\n",
       "    'original': 'With a comma after \\xe2\\x80\\x9cdearest.\\xe2\\x80\\x9d You\\xe2\\x80\\x99ve written',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'With',\n",
       "     u'a',\n",
       "     u'comma',\n",
       "     u'after',\n",
       "     u'dearest',\n",
       "     u'You\\u2019ve',\n",
       "     u'written']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'My', u'dearest', u'Angelica'],\n",
       "    'original': '\\xe2\\x80\\x9cMy dearest, Angelica.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON', 'ANGELICA'],\n",
       "    'tokenized': [u'My', u'dearest', u'Angelica']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'Anyway', u'all', u'this', u'to', u'say'],\n",
       "    'original': 'Anyway, all this to say',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Anyway', u'all', u'this', u'to', u'say']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'I\\u2019m', u'coming', u'home', u'this', u'summer'],\n",
       "    'original': 'I\\xe2\\x80\\x99m coming home this summer',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I\\u2019m', u'coming', u'home', u'this', u'summer']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'At', u'my', u'sister\\u2019s', u'invitation'],\n",
       "    'original': 'At my sister\\xe2\\x80\\x99s invitation',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'At', u'my', u'sister\\u2019s', u'invitation']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'I\\u2019ll',\n",
       "     u'be',\n",
       "     u'there',\n",
       "     u'with',\n",
       "     u'your',\n",
       "     u'fam\\u2019ly'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll be there with your fam\\xe2\\x80\\x99ly',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I\\u2019ll',\n",
       "     u'be',\n",
       "     u'there',\n",
       "     u'with',\n",
       "     u'your',\n",
       "     u'fam\\u2019ly']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'If', u'you', u'make', u'your', u'way', u'upstate'],\n",
       "    'original': 'If you make your way upstate',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'If', u'you', u'make', u'your', u'way', u'upstate']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'I', u'know', u'you\\u2019re', u'very', u'busy'],\n",
       "    'original': 'I know you\\xe2\\x80\\x99re very busy',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'know', u'you\\u2019re', u'very', u'busy']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'I', u'know', u'your', u'work\\u2019s', u'important'],\n",
       "    'original': 'I know your work\\xe2\\x80\\x99s important',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'know', u'your', u'work\\u2019s', u'important']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'But',\n",
       "     u'I\\u2019m',\n",
       "     u'crossing',\n",
       "     u'the',\n",
       "     u'ocean',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'can\\u2019t',\n",
       "     u'wait'],\n",
       "    'original': 'But I\\xe2\\x80\\x99m crossing the ocean and I just can\\xe2\\x80\\x99t wait',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'But',\n",
       "     u'I\\u2019m',\n",
       "     u'crossing',\n",
       "     u'the',\n",
       "     u'ocean',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'just',\n",
       "     u'can\\u2019t',\n",
       "     u'wait']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'You', u'won\\u2019t', u'be', u'an', u'ocean', u'away'],\n",
       "    'original': 'You won\\xe2\\x80\\x99t be an ocean away',\n",
       "    'speakers': ['HAMILTON', 'ANGELICA'],\n",
       "    'tokenized': [u'You', u'won\\u2019t', u'be', u'an', u'ocean', u'away']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'You', u'will', u'only', u'be', u'a', u'moment', u'away'],\n",
       "    'original': 'You will only be a moment away\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON', 'ANGELICA'],\n",
       "    'tokenized': [u'You', u'will', u'only', u'be', u'a', u'moment', u'away']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'Alexander',\n",
       "     u'come',\n",
       "     u'downstairs',\n",
       "     u'Angelica\\u2019s',\n",
       "     u'arriving',\n",
       "     u'today'],\n",
       "    'original': 'Alexander, come downstairs. Angelica\\xe2\\x80\\x99s arriving today!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Alexander',\n",
       "     u'come',\n",
       "     u'downstairs',\n",
       "     u'Angelica\\u2019s',\n",
       "     u'arriving',\n",
       "     u'today']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Angelica'],\n",
       "    'original': 'Angelica!',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Angelica']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'Eliza'],\n",
       "    'original': 'Eliza!',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Eliza']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'The', u'Schuyler', u'sisters'],\n",
       "    'original': 'The Schuyler sisters!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'Schuyler', u'sisters']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'Alexander'],\n",
       "    'original': 'Alexander',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Alexander']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'Hi'],\n",
       "    'original': 'Hi',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hi']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'It\\u2019s', u'good', u'to', u'see', u'your', u'face'],\n",
       "    'original': 'It\\xe2\\x80\\x99s good to see your face',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'It\\u2019s', u'good', u'to', u'see', u'your', u'face']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'Angelica',\n",
       "     u'tell',\n",
       "     u'this',\n",
       "     u'man',\n",
       "     u'John',\n",
       "     u'Adams',\n",
       "     u'spends',\n",
       "     u'the',\n",
       "     u'summer',\n",
       "     u'with',\n",
       "     u'his',\n",
       "     u'family'],\n",
       "    'original': 'Angelica, tell this man John Adams spends the summer with his family',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Angelica',\n",
       "     u'tell',\n",
       "     u'this',\n",
       "     u'man',\n",
       "     u'John',\n",
       "     u'Adams',\n",
       "     u'spends',\n",
       "     u'the',\n",
       "     u'summer',\n",
       "     u'with',\n",
       "     u'his',\n",
       "     u'family']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Angelica',\n",
       "     u'tell',\n",
       "     u'my',\n",
       "     u'wife',\n",
       "     u'John',\n",
       "     u'Adams',\n",
       "     u'doesn\\u2019t',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'real',\n",
       "     u'job',\n",
       "     u'anyway'],\n",
       "    'original': 'Angelica, tell my wife John Adams doesn\\xe2\\x80\\x99t have a real job anyway',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Angelica',\n",
       "     u'tell',\n",
       "     u'my',\n",
       "     u'wife',\n",
       "     u'John',\n",
       "     u'Adams',\n",
       "     u'doesn\\u2019t',\n",
       "     u'have',\n",
       "     u'a',\n",
       "     u'real',\n",
       "     u'job',\n",
       "     u'anyway']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'you\\u2019re', u'not', u'joining', u'us', u'Wait'],\n",
       "    'original': '\\xe2\\x80\\xa6you\\xe2\\x80\\x99re not joining us? Wait',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'you\\u2019re', u'not', u'joining', u'us', u'Wait']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'afraid',\n",
       "     u'I',\n",
       "     u'cannot',\n",
       "     u'join',\n",
       "     u'you',\n",
       "     u'upstate'],\n",
       "    'original': 'I\\xe2\\x80\\x99m afraid I cannot join you upstate',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'afraid',\n",
       "     u'I',\n",
       "     u'cannot',\n",
       "     u'join',\n",
       "     u'you',\n",
       "     u'upstate']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'Alexander', u'I', u'came', u'all', u'this', u'way'],\n",
       "    'original': 'Alexander, I came all this way',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Alexander', u'I', u'came', u'all', u'this', u'way']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'She', u'came', u'all', u'this', u'way'],\n",
       "    'original': 'She came all this way\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'She', u'came', u'all', u'this', u'way']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'All', u'this', u'way'],\n",
       "    'original': 'All this way\\xe2\\x80\\x94',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'All', u'this', u'way']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'Take', u'a', u'break'],\n",
       "    'original': 'Take a break',\n",
       "    'speakers': ['ELIZA', 'ANGELICA'],\n",
       "    'tokenized': [u'Take', u'a', u'break']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'You',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'my',\n",
       "     u'plan',\n",
       "     u'through',\n",
       "     u'Congress'],\n",
       "    'original': 'You know I have to get my plan through Congress',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'know',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'my',\n",
       "     u'plan',\n",
       "     u'through',\n",
       "     u'Congress']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'Run', u'away', u'with', u'us', u'for', u'the', u'summer'],\n",
       "    'original': 'Run away with us for the summer',\n",
       "    'speakers': ['ELIZA', 'ANGELICA'],\n",
       "    'tokenized': [u'Run', u'away', u'with', u'us', u'for', u'the', u'summer']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'Let\\u2019s', u'go', u'upstate'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s go upstate',\n",
       "    'speakers': ['ELIZA', 'ANGELICA'],\n",
       "    'tokenized': [u'Let\\u2019s', u'go', u'upstate']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'I',\n",
       "     u'lose',\n",
       "     u'my',\n",
       "     u'job',\n",
       "     u'if',\n",
       "     u'we',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'this',\n",
       "     u'plan',\n",
       "     u'through',\n",
       "     u'Congress'],\n",
       "    'original': 'I lose my job if we don\\xe2\\x80\\x99t get this plan through Congress',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'lose',\n",
       "     u'my',\n",
       "     u'job',\n",
       "     u'if',\n",
       "     u'we',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'this',\n",
       "     u'plan',\n",
       "     u'through',\n",
       "     u'Congress']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'We',\n",
       "     u'can',\n",
       "     u'all',\n",
       "     u'go',\n",
       "     u'stay',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'father'],\n",
       "    'original': 'We can all go stay with our father',\n",
       "    'speakers': ['ELIZA', 'ANGELICA'],\n",
       "    'tokenized': [u'We',\n",
       "     u'can',\n",
       "     u'all',\n",
       "     u'go',\n",
       "     u'stay',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'father']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'There\\u2019s', u'a', u'lake', u'I', u'know'],\n",
       "    'original': 'There\\xe2\\x80\\x99s a lake I know',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'There\\u2019s', u'a', u'lake', u'I', u'know']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'In', u'a', u'nearby', u'park'],\n",
       "    'original': 'In a nearby park',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'In', u'a', u'nearby', u'park']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'You', u'and', u'I', u'can', u'go'],\n",
       "    'original': 'You and I can go',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'You', u'and', u'I', u'can', u'go']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'Take', u'a', u'break', u'and', u'get', u'away'],\n",
       "    'original': 'Take a break and get away\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Take', u'a', u'break', u'and', u'get', u'away']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'Let\\u2019s', u'go', u'upstate'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s go upstate',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Let\\u2019s', u'go', u'upstate']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'Where', u'we', u'can', u'stay'],\n",
       "    'original': 'Where we can stay',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Where', u'we', u'can', u'stay']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'Look', u'around', u'look', u'around'],\n",
       "    'original': 'Look around, look around',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Look', u'around', u'look', u'around']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'At',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now'],\n",
       "    'original': 'At how lucky we are to be alive right now\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'At',\n",
       "     u'how',\n",
       "     u'lucky',\n",
       "     u'we',\n",
       "     u'are',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'alive',\n",
       "     u'right',\n",
       "     u'now']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'We', u'can', u'go'],\n",
       "    'original': 'We can go\\xe2\\x80\\x94',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'We', u'can', u'go']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'When', u'the', u'night', u'gets', u'dark'],\n",
       "    'original': 'When the night gets dark',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'When', u'the', u'night', u'gets', u'dark']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'Take', u'a', u'break'],\n",
       "    'original': 'Take a break.',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Take', u'a', u'break']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'I', u'know', u'I\\u2019ll', u'miss', u'your', u'face'],\n",
       "    'original': 'I know I\\xe2\\x80\\x99ll miss your face\\xe2\\x80\\x94',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'I', u'know', u'I\\u2019ll', u'miss', u'your', u'face']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'Screw',\n",
       "     u'your',\n",
       "     u'courage',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'sticking',\n",
       "     u'place'],\n",
       "    'original': 'Screw your courage to the sticking place\\xe2\\x80\\x94',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Screw',\n",
       "     u'your',\n",
       "     u'courage',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'sticking',\n",
       "     u'place']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'Eliza\\u2019s', u'right'],\n",
       "    'original': 'Eliza\\xe2\\x80\\x99s right\\xe2\\x80\\x94',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Eliza\\u2019s', u'right']},\n",
       "   {'line#': 126,\n",
       "    'normalized': [u'Take', u'a', u'break'],\n",
       "    'original': 'Take a break',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Take', u'a', u'break']},\n",
       "   {'line#': 127,\n",
       "    'normalized': [u'Run', u'away', u'with', u'us', u'for', u'the', u'summer'],\n",
       "    'original': 'Run away with us for the summer\\xe2\\x80\\x94',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Run', u'away', u'with', u'us', u'for', u'the', u'summer']},\n",
       "   {'line#': 128,\n",
       "    'normalized': [u'Let\\u2019s', u'go', u'upstate'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s go upstate',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Let\\u2019s', u'go', u'upstate']},\n",
       "   {'line#': 129,\n",
       "    'normalized': [u'We',\n",
       "     u'can',\n",
       "     u'all',\n",
       "     u'go',\n",
       "     u'stay',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'father'],\n",
       "    'original': 'We can all go stay with our father',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'We',\n",
       "     u'can',\n",
       "     u'all',\n",
       "     u'go',\n",
       "     u'stay',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'father']},\n",
       "   {'line#': 130,\n",
       "    'normalized': [u'If', u'you', u'take', u'your', u'time'],\n",
       "    'original': 'If you take your time\\xe2\\x80\\x94',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'If', u'you', u'take', u'your', u'time']},\n",
       "   {'line#': 131,\n",
       "    'normalized': [u'You', u'will', u'make', u'your', u'mark'],\n",
       "    'original': 'You will make your mark',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'You', u'will', u'make', u'your', u'mark']},\n",
       "   {'line#': 132,\n",
       "    'normalized': [u'Close', u'your', u'eyes', u'and', u'dream'],\n",
       "    'original': 'Close your eyes and dream\\xe2\\x80\\x94',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Close', u'your', u'eyes', u'and', u'dream']},\n",
       "   {'line#': 133,\n",
       "    'normalized': [u'When', u'the', u'night', u'gets', u'dark'],\n",
       "    'original': 'When the night gets dark',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'When', u'the', u'night', u'gets', u'dark']},\n",
       "   {'line#': 134,\n",
       "    'normalized': [u'Take', u'a', u'break'],\n",
       "    'original': 'Take a break.',\n",
       "    'speakers': ['ANGELICA'],\n",
       "    'tokenized': [u'Take', u'a', u'break']},\n",
       "   {'line#': 135,\n",
       "    'normalized': [u'I',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'my',\n",
       "     u'plan',\n",
       "     u'through',\n",
       "     u'Congress'],\n",
       "    'original': 'I have to get my plan through Congress',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'my',\n",
       "     u'plan',\n",
       "     u'through',\n",
       "     u'Congress']},\n",
       "   {'line#': 136,\n",
       "    'normalized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'stop',\n",
       "     u'until',\n",
       "     u'I',\n",
       "     u'get',\n",
       "     u'this',\n",
       "     u'plan',\n",
       "     u'through',\n",
       "     u'Congress'],\n",
       "    'original': 'I can\\xe2\\x80\\x99t stop until I get this plan through Congress',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'can\\u2019t',\n",
       "     u'stop',\n",
       "     u'until',\n",
       "     u'I',\n",
       "     u'get',\n",
       "     u'this',\n",
       "     u'plan',\n",
       "     u'through',\n",
       "     u'Congress']}],\n",
       "  'track': 'Take a Break',\n",
       "  'track#': '3'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'There\\u2019s',\n",
       "     u'nothing',\n",
       "     u'like',\n",
       "     u'summer',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'city'],\n",
       "    'original': 'There\\xe2\\x80\\x99s nothing like summer in the city',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'There\\u2019s',\n",
       "     u'nothing',\n",
       "     u'like',\n",
       "     u'summer',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'city']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Someone',\n",
       "     u'under',\n",
       "     u'stress',\n",
       "     u'meets',\n",
       "     u'someone',\n",
       "     u'looking',\n",
       "     u'pretty'],\n",
       "    'original': 'Someone under stress meets someone looking pretty',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Someone',\n",
       "     u'under',\n",
       "     u'stress',\n",
       "     u'meets',\n",
       "     u'someone',\n",
       "     u'looking',\n",
       "     u'pretty']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'There\\u2019s',\n",
       "     u'trouble',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'air',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'smell',\n",
       "     u'it'],\n",
       "    'original': 'There\\xe2\\x80\\x99s trouble in the air, you can smell it',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'There\\u2019s',\n",
       "     u'trouble',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'air',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'smell',\n",
       "     u'it']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'And',\n",
       "     u'Alexander\\u2019s',\n",
       "     u'by',\n",
       "     u'himself',\n",
       "     u'I\\u2019ll',\n",
       "     u'let',\n",
       "     u'him',\n",
       "     u'tell',\n",
       "     u'it'],\n",
       "    'original': 'And Alexander\\xe2\\x80\\x99s by himself. I\\xe2\\x80\\x99ll let him tell it',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'Alexander\\u2019s',\n",
       "     u'by',\n",
       "     u'himself',\n",
       "     u'I\\u2019ll',\n",
       "     u'let',\n",
       "     u'him',\n",
       "     u'tell',\n",
       "     u'it']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'I', u'hadn\\u2019t', u'slept', u'in', u'a', u'week'],\n",
       "    'original': 'I hadn\\xe2\\x80\\x99t slept in a week',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'hadn\\u2019t', u'slept', u'in', u'a', u'week']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'I', u'was', u'weak', u'I', u'was', u'awake'],\n",
       "    'original': 'I was weak, I was awake',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'was', u'weak', u'I', u'was', u'awake']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'You', u'never', u'seen', u'a', u'bastard', u'orphan'],\n",
       "    'original': 'You never seen a bastard orphan',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You', u'never', u'seen', u'a', u'bastard', u'orphan']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'More', u'in', u'need', u'of', u'a', u'break'],\n",
       "    'original': 'More in need of a break',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'More', u'in', u'need', u'of', u'a', u'break']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Longing', u'for', u'Angelica'],\n",
       "    'original': 'Longing for Angelica',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Longing', u'for', u'Angelica']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Missing', u'my', u'wife'],\n",
       "    'original': 'Missing my wife',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Missing', u'my', u'wife']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'That\\u2019s',\n",
       "     u'when',\n",
       "     u'Miss',\n",
       "     u'Maria',\n",
       "     u'Reynolds',\n",
       "     u'walked',\n",
       "     u'into',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'she',\n",
       "     u'said'],\n",
       "    'original': 'That\\xe2\\x80\\x99s when Miss Maria Reynolds walked into my life, she said:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That\\u2019s',\n",
       "     u'when',\n",
       "     u'Miss',\n",
       "     u'Maria',\n",
       "     u'Reynolds',\n",
       "     u'walked',\n",
       "     u'into',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'she',\n",
       "     u'said']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'are',\n",
       "     u'a',\n",
       "     u'man',\n",
       "     u'of',\n",
       "     u'honor'],\n",
       "    'original': 'I know you are a man of honor',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'are',\n",
       "     u'a',\n",
       "     u'man',\n",
       "     u'of',\n",
       "     u'honor']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'so',\n",
       "     u'sorry',\n",
       "     u'to',\n",
       "     u'bother',\n",
       "     u'you',\n",
       "     u'at',\n",
       "     u'home'],\n",
       "    'original': 'I\\xe2\\x80\\x99m so sorry to bother you at home',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'so',\n",
       "     u'sorry',\n",
       "     u'to',\n",
       "     u'bother',\n",
       "     u'you',\n",
       "     u'at',\n",
       "     u'home']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'But',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'know',\n",
       "     u'where',\n",
       "     u'to',\n",
       "     u'go',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'came',\n",
       "     u'here',\n",
       "     u'all',\n",
       "     u'alone'],\n",
       "    'original': 'But I don\\xe2\\x80\\x99t know where to go, and I came here all alone\\xe2\\x80\\xa6',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'But',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'know',\n",
       "     u'where',\n",
       "     u'to',\n",
       "     u'go',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'came',\n",
       "     u'here',\n",
       "     u'all',\n",
       "     u'alone']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'She', u'said'],\n",
       "    'original': 'She said:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'She', u'said']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'My', u'husband\\u2019s', u'doin', u'me', u'wrong'],\n",
       "    'original': 'My husband\\xe2\\x80\\x99s doin\\xe2\\x80\\x99 me wrong',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'My', u'husband\\u2019s', u'doin', u'me', u'wrong']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Beatin', u'me', u'cheatin', u'me', u'mistreatin', u'me'],\n",
       "    'original': 'Beatin\\xe2\\x80\\x99 me, cheatin\\xe2\\x80\\x99 me, mistreatin\\xe2\\x80\\x99 me...',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Beatin', u'me', u'cheatin', u'me', u'mistreatin', u'me']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Suddenly', u'he\\u2019s', u'up', u'and', u'gone'],\n",
       "    'original': 'Suddenly he\\xe2\\x80\\x99s up and gone',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Suddenly', u'he\\u2019s', u'up', u'and', u'gone']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'means',\n",
       "     u'to',\n",
       "     u'go',\n",
       "     u'on'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t have the means to go on',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'means',\n",
       "     u'to',\n",
       "     u'go',\n",
       "     u'on']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'So',\n",
       "     u'I',\n",
       "     u'offered',\n",
       "     u'her',\n",
       "     u'a',\n",
       "     u'loan',\n",
       "     u'I',\n",
       "     u'offered',\n",
       "     u'to',\n",
       "     u'walk',\n",
       "     u'her',\n",
       "     u'home',\n",
       "     u'she',\n",
       "     u'said'],\n",
       "    'original': 'So I offered her a loan, I offered to walk her home, she said',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'So',\n",
       "     u'I',\n",
       "     u'offered',\n",
       "     u'her',\n",
       "     u'a',\n",
       "     u'loan',\n",
       "     u'I',\n",
       "     u'offered',\n",
       "     u'to',\n",
       "     u'walk',\n",
       "     u'her',\n",
       "     u'home',\n",
       "     u'she',\n",
       "     u'said']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'You\\u2019re', u'too', u'kind', u'sir'],\n",
       "    'original': 'You\\xe2\\x80\\x99re too kind, sir',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'You\\u2019re', u'too', u'kind', u'sir']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'I',\n",
       "     u'gave',\n",
       "     u'her',\n",
       "     u'thirty',\n",
       "     u'bucks',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'had',\n",
       "     u'socked',\n",
       "     u'away'],\n",
       "    'original': 'I gave her thirty bucks that I had socked away',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'gave',\n",
       "     u'her',\n",
       "     u'thirty',\n",
       "     u'bucks',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'had',\n",
       "     u'socked',\n",
       "     u'away']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'She', u'lived', u'a', u'block', u'away', u'she', u'said'],\n",
       "    'original': 'She lived a block away, she said:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'She', u'lived', u'a', u'block', u'away', u'she', u'said']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'This', u'one\\u2019s', u'mine', u'sir'],\n",
       "    'original': 'This one\\xe2\\x80\\x99s mine, sir',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'This', u'one\\u2019s', u'mine', u'sir']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Then',\n",
       "     u'I',\n",
       "     u'said',\n",
       "     u'well',\n",
       "     u'I',\n",
       "     u'should',\n",
       "     u'head',\n",
       "     u'back',\n",
       "     u'home'],\n",
       "    'original': 'Then I said, \\xe2\\x80\\x9cwell, I should head back home,\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'I',\n",
       "     u'said',\n",
       "     u'well',\n",
       "     u'I',\n",
       "     u'should',\n",
       "     u'head',\n",
       "     u'back',\n",
       "     u'home']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'She',\n",
       "     u'turned',\n",
       "     u'red',\n",
       "     u'she',\n",
       "     u'led',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'her',\n",
       "     u'bed'],\n",
       "    'original': 'She turned red, she led me to her bed',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'She',\n",
       "     u'turned',\n",
       "     u'red',\n",
       "     u'she',\n",
       "     u'led',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'her',\n",
       "     u'bed']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Let', u'her', u'legs', u'spread', u'and', u'said'],\n",
       "    'original': 'Let her legs spread and said:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Let', u'her', u'legs', u'spread', u'and', u'said']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Stay'],\n",
       "    'original': 'Stay?',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Stay']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Hey'],\n",
       "    'original': 'Hey\\xe2\\x80\\xa6',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Hey']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'That\\u2019s', u'when', u'I', u'began', u'to', u'pray'],\n",
       "    'original': 'That\\xe2\\x80\\x99s when I began to pray:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That\\u2019s', u'when', u'I', u'began', u'to', u'pray']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Lord', u'show', u'me', u'how', u'to'],\n",
       "    'original': 'Lord, show me how to',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Lord', u'show', u'me', u'how', u'to']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'know', u'how', u'to'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t know how to',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'know', u'how', u'to']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'But',\n",
       "     u'my',\n",
       "     u'God',\n",
       "     u'she',\n",
       "     u'looks',\n",
       "     u'so',\n",
       "     u'helpless'],\n",
       "    'original': 'But my God, she looks so helpless',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'my',\n",
       "     u'God',\n",
       "     u'she',\n",
       "     u'looks',\n",
       "     u'so',\n",
       "     u'helpless']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'And', u'her', u'body\\u2019s', u'saying', u'hell', u'yes'],\n",
       "    'original': 'And her body\\xe2\\x80\\x99s saying, \\xe2\\x80\\x9chell, yes\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'her', u'body\\u2019s', u'saying', u'hell', u'yes']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa...',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'Nooo', u'show', u'me', u'how', u'to'],\n",
       "    'original': 'Nooo, show me how to',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Nooo', u'show', u'me', u'how', u'to']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this',\n",
       "    'speakers': ['HAMILTON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'know', u'how', u'to'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t know how to',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'know', u'how', u'to']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this',\n",
       "    'speakers': ['HAMILTON', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'In', u'my', u'mind', u'I\\u2019m', u'tryin', u'to', u'go'],\n",
       "    'original': 'In my mind, I\\xe2\\x80\\x99m tryin\\xe2\\x80\\x99 to go',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'In', u'my', u'mind', u'I\\u2019m', u'tryin', u'to', u'go']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Go', u'Go', u'Go'],\n",
       "    'original': 'Go! Go! Go!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Go', u'Go', u'Go']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Then',\n",
       "     u'her',\n",
       "     u'mouth',\n",
       "     u'is',\n",
       "     u'on',\n",
       "     u'mine',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'say'],\n",
       "    'original': 'Then her mouth is on mine, and I don\\xe2\\x80\\x99t say\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'her',\n",
       "     u'mouth',\n",
       "     u'is',\n",
       "     u'on',\n",
       "     u'mine',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'say']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'No', u'No'],\n",
       "    'original': 'No! No!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'No', u'No']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'No', u'No'],\n",
       "    'original': 'No! No!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'No', u'No']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'No', u'No'],\n",
       "    'original': 'No! No!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'No', u'No']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'No', u'No'],\n",
       "    'original': 'No! No!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'No', u'No']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'I',\n",
       "     u'wish',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'say',\n",
       "     u'that',\n",
       "     u'was',\n",
       "     u'the',\n",
       "     u'last',\n",
       "     u'time'],\n",
       "    'original': 'I wish I could say that was the last time',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wish',\n",
       "     u'I',\n",
       "     u'could',\n",
       "     u'say',\n",
       "     u'that',\n",
       "     u'was',\n",
       "     u'the',\n",
       "     u'last',\n",
       "     u'time']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'I',\n",
       "     u'said',\n",
       "     u'that',\n",
       "     u'last',\n",
       "     u'time',\n",
       "     u'It',\n",
       "     u'became',\n",
       "     u'a',\n",
       "     u'pastime'],\n",
       "    'original': 'I said that last time. It became a pastime',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'said',\n",
       "     u'that',\n",
       "     u'last',\n",
       "     u'time',\n",
       "     u'It',\n",
       "     u'became',\n",
       "     u'a',\n",
       "     u'pastime']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'A',\n",
       "     u'month',\n",
       "     u'into',\n",
       "     u'this',\n",
       "     u'endeavor',\n",
       "     u'I',\n",
       "     u'received',\n",
       "     u'a',\n",
       "     u'letter'],\n",
       "    'original': 'A month into this endeavor I received a letter',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'month',\n",
       "     u'into',\n",
       "     u'this',\n",
       "     u'endeavor',\n",
       "     u'I',\n",
       "     u'received',\n",
       "     u'a',\n",
       "     u'letter']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'From',\n",
       "     u'a',\n",
       "     u'Mr',\n",
       "     u'James',\n",
       "     u'Reynolds',\n",
       "     u'even',\n",
       "     u'better',\n",
       "     u'it',\n",
       "     u'said'],\n",
       "    'original': 'From a Mr. James Reynolds, even better, it said:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'From',\n",
       "     u'a',\n",
       "     u'Mr',\n",
       "     u'James',\n",
       "     u'Reynolds',\n",
       "     u'even',\n",
       "     u'better',\n",
       "     u'it',\n",
       "     u'said']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Dear',\n",
       "     u'Sir',\n",
       "     u'I',\n",
       "     u'hope',\n",
       "     u'this',\n",
       "     u'letter',\n",
       "     u'finds',\n",
       "     u'you',\n",
       "     u'in',\n",
       "     u'good',\n",
       "     u'health'],\n",
       "    'original': 'Dear Sir, I hope this letter finds you in good health',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'Dear',\n",
       "     u'Sir',\n",
       "     u'I',\n",
       "     u'hope',\n",
       "     u'this',\n",
       "     u'letter',\n",
       "     u'finds',\n",
       "     u'you',\n",
       "     u'in',\n",
       "     u'good',\n",
       "     u'health']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'And',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'prosperous',\n",
       "     u'enough',\n",
       "     u'position',\n",
       "     u'to',\n",
       "     u'put',\n",
       "     u'wealth'],\n",
       "    'original': 'And in a prosperous enough position to put wealth',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'And',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'prosperous',\n",
       "     u'enough',\n",
       "     u'position',\n",
       "     u'to',\n",
       "     u'put',\n",
       "     u'wealth']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'In',\n",
       "     u'the',\n",
       "     u'pockets',\n",
       "     u'of',\n",
       "     u'people',\n",
       "     u'like',\n",
       "     u'me',\n",
       "     u'down',\n",
       "     u'on',\n",
       "     u'their',\n",
       "     u'luck'],\n",
       "    'original': 'In the pockets of people like me: down on their luck',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'In',\n",
       "     u'the',\n",
       "     u'pockets',\n",
       "     u'of',\n",
       "     u'people',\n",
       "     u'like',\n",
       "     u'me',\n",
       "     u'down',\n",
       "     u'on',\n",
       "     u'their',\n",
       "     u'luck']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'You',\n",
       "     u'see',\n",
       "     u'that',\n",
       "     u'was',\n",
       "     u'my',\n",
       "     u'wife',\n",
       "     u'who',\n",
       "     u'you',\n",
       "     u'decided',\n",
       "     u'to'],\n",
       "    'original': 'You see, that was my wife who you decided to',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'You',\n",
       "     u'see',\n",
       "     u'that',\n",
       "     u'was',\n",
       "     u'my',\n",
       "     u'wife',\n",
       "     u'who',\n",
       "     u'you',\n",
       "     u'decided',\n",
       "     u'to']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Fuuuu'],\n",
       "    'original': 'Fuuuu\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Fuuuu']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'Uh',\n",
       "     u'oh',\n",
       "     u'You',\n",
       "     u'made',\n",
       "     u'the',\n",
       "     u'wrong',\n",
       "     u'sucker',\n",
       "     u'a',\n",
       "     u'cuckold'],\n",
       "    'original': 'Uh-oh! You made the wrong sucker a cuckold',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'Uh',\n",
       "     u'oh',\n",
       "     u'You',\n",
       "     u'made',\n",
       "     u'the',\n",
       "     u'wrong',\n",
       "     u'sucker',\n",
       "     u'a',\n",
       "     u'cuckold']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'So',\n",
       "     u'time',\n",
       "     u'to',\n",
       "     u'pay',\n",
       "     u'the',\n",
       "     u'piper',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'pants',\n",
       "     u'you',\n",
       "     u'unbuckled'],\n",
       "    'original': 'So time to pay the piper for the pants you unbuckled',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'So',\n",
       "     u'time',\n",
       "     u'to',\n",
       "     u'pay',\n",
       "     u'the',\n",
       "     u'piper',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'pants',\n",
       "     u'you',\n",
       "     u'unbuckled']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'And',\n",
       "     u'hey',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'keep',\n",
       "     u'seein',\n",
       "     u'my',\n",
       "     u'whore',\n",
       "     u'wife'],\n",
       "    'original': 'And hey, you can keep seein\\xe2\\x80\\x99 my whore wife',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'And',\n",
       "     u'hey',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'keep',\n",
       "     u'seein',\n",
       "     u'my',\n",
       "     u'whore',\n",
       "     u'wife']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'If',\n",
       "     u'the',\n",
       "     u'price',\n",
       "     u'is',\n",
       "     u'right',\n",
       "     u'if',\n",
       "     u'not',\n",
       "     u'I\\u2019m',\n",
       "     u'telling',\n",
       "     u'your',\n",
       "     u'wife'],\n",
       "    'original': 'If the price is right: if not I\\xe2\\x80\\x99m telling your wife',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'If',\n",
       "     u'the',\n",
       "     u'price',\n",
       "     u'is',\n",
       "     u'right',\n",
       "     u'if',\n",
       "     u'not',\n",
       "     u'I\\u2019m',\n",
       "     u'telling',\n",
       "     u'your',\n",
       "     u'wife']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'I',\n",
       "     u'hid',\n",
       "     u'the',\n",
       "     u'letter',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'raced',\n",
       "     u'to',\n",
       "     u'her',\n",
       "     u'place'],\n",
       "    'original': 'I hid the letter and I raced to her place',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'hid',\n",
       "     u'the',\n",
       "     u'letter',\n",
       "     u'and',\n",
       "     u'I',\n",
       "     u'raced',\n",
       "     u'to',\n",
       "     u'her',\n",
       "     u'place']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'Screamed',\n",
       "     u'How',\n",
       "     u'could',\n",
       "     u'you',\n",
       "     u'in',\n",
       "     u'her',\n",
       "     u'face'],\n",
       "    'original': 'Screamed \\xe2\\x80\\x9cHow could you?!\\xe2\\x80\\x9d in her face',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Screamed',\n",
       "     u'How',\n",
       "     u'could',\n",
       "     u'you',\n",
       "     u'in',\n",
       "     u'her',\n",
       "     u'face']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'She', u'said'],\n",
       "    'original': 'She said:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'She', u'said']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'No', u'sir'],\n",
       "    'original': 'No, sir!',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'No', u'sir']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'Half',\n",
       "     u'dressed',\n",
       "     u'apologetic',\n",
       "     u'A',\n",
       "     u'mess',\n",
       "     u'she',\n",
       "     u'looked'],\n",
       "    'original': 'Half dressed, apologetic. A mess, she looked',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Half',\n",
       "     u'dressed',\n",
       "     u'apologetic',\n",
       "     u'A',\n",
       "     u'mess',\n",
       "     u'she',\n",
       "     u'looked']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'Pathetic', u'she', u'cried'],\n",
       "    'original': 'Pathetic, she cried:',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Pathetic', u'she', u'cried']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'Please', u'don\\u2019t', u'go', u'sir'],\n",
       "    'original': 'Please don\\xe2\\x80\\x99t go, sir!',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Please', u'don\\u2019t', u'go', u'sir']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'So', u'was', u'your', u'whole', u'story', u'a', u'setup'],\n",
       "    'original': 'So was your whole story a setup?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'So', u'was', u'your', u'whole', u'story', u'a', u'setup']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'know', u'about', u'any', u'letter'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t know about any letter!',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'know', u'about', u'any', u'letter']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Stop', u'crying'],\n",
       "    'original': 'Stop crying',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Stop', u'crying']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Goddamnit', u'get', u'up'],\n",
       "    'original': 'Goddamnit, get up!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Goddamnit', u'get', u'up']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'I', u'didn\\u2019t', u'know', u'any', u'better'],\n",
       "    'original': 'I didn\\xe2\\x80\\x99t know any better',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'I', u'didn\\u2019t', u'know', u'any', u'better']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'I', u'am', u'ruined'],\n",
       "    'original': 'I am ruined...',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'am', u'ruined']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Please',\n",
       "     u'don\\u2019t',\n",
       "     u'leave',\n",
       "     u'me',\n",
       "     u'with',\n",
       "     u'him',\n",
       "     u'helpless'],\n",
       "    'original': 'Please don\\xe2\\x80\\x99t leave me with him helpless',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Please',\n",
       "     u'don\\u2019t',\n",
       "     u'leave',\n",
       "     u'me',\n",
       "     u'with',\n",
       "     u'him',\n",
       "     u'helpless']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'Just',\n",
       "     u'give',\n",
       "     u'him',\n",
       "     u'what',\n",
       "     u'he',\n",
       "     u'wants',\n",
       "     u'and',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'have',\n",
       "     u'me'],\n",
       "    'original': 'Just give him what he wants and you can have me',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Just',\n",
       "     u'give',\n",
       "     u'him',\n",
       "     u'what',\n",
       "     u'he',\n",
       "     u'wants',\n",
       "     u'and',\n",
       "     u'you',\n",
       "     u'can',\n",
       "     u'have',\n",
       "     u'me']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'Whatever', u'you', u'want'],\n",
       "    'original': 'Whatever you want,',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Whatever', u'you', u'want']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'I',\n",
       "     u'am',\n",
       "     u'helpless',\n",
       "     u'how',\n",
       "     u'could',\n",
       "     u'I',\n",
       "     u'do',\n",
       "     u'this'],\n",
       "    'original': 'I am helpless\\xe2\\x80\\x94how could I do this?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'am',\n",
       "     u'helpless',\n",
       "     u'how',\n",
       "     u'could',\n",
       "     u'I',\n",
       "     u'do',\n",
       "     u'this']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'want', u'you'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t want you',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'want', u'you']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'want', u'you'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t want you',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'want', u'you']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'If', u'you', u'pay'],\n",
       "    'original': 'If you pay',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'If', u'you', u'pay']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'You', u'can', u'stay'],\n",
       "    'original': 'You can stay',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'You', u'can', u'stay']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Tonight'],\n",
       "    'original': 'Tonight',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Tonight']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'Helpless'],\n",
       "    'original': 'Helpless',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Helpless']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'Whoa'],\n",
       "    'original': 'Whoa!',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Whoa']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'How', u'can', u'you'],\n",
       "    'original': 'How can you',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'How', u'can', u'you']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this?',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes.',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'I', u'don\\u2019t'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don\\u2019t']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'Lord', u'show', u'me', u'how', u'to'],\n",
       "    'original': 'Lord, show me how to',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Lord', u'show', u'me', u'how', u'to']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'know', u'how', u'to'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t know how to',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'know', u'how', u'to']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'Cuz', u'the', u'situation\\u2019s', u'helpless'],\n",
       "    'original': 'Cuz the situation\\xe2\\x80\\x99s helpless',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Cuz', u'the', u'situation\\u2019s', u'helpless']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'And',\n",
       "     u'her',\n",
       "     u'body\\u2019s',\n",
       "     u'screaming',\n",
       "     u'Hell',\n",
       "     u'yes'],\n",
       "    'original': 'And her body\\xe2\\x80\\x99s screaming, \\xe2\\x80\\x9cHell, yes\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'her',\n",
       "     u'body\\u2019s',\n",
       "     u'screaming',\n",
       "     u'Hell',\n",
       "     u'yes']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'No', u'show', u'me', u'how', u'to'],\n",
       "    'original': 'No, show me how to',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No', u'show', u'me', u'how', u'to']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'How', u'can', u'I'],\n",
       "    'original': 'How can I',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'How', u'can', u'I']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'There', u'is', u'nowhere', u'I', u'can', u'go'],\n",
       "    'original': 'There is nowhere I can go',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'There', u'is', u'nowhere', u'I', u'can', u'go']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'When',\n",
       "     u'her',\n",
       "     u'body\\u2019s',\n",
       "     u'on',\n",
       "     u'mine',\n",
       "     u'I',\n",
       "     u'do',\n",
       "     u'not',\n",
       "     u'say'],\n",
       "    'original': 'When her body\\xe2\\x80\\x99s on mine I do not say\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'When',\n",
       "     u'her',\n",
       "     u'body\\u2019s',\n",
       "     u'on',\n",
       "     u'mine',\n",
       "     u'I',\n",
       "     u'do',\n",
       "     u'not',\n",
       "     u'say']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes!',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes!',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes!',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'Yes'],\n",
       "    'original': 'Yes!',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Yes']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'Go', u'Go', u'Go'],\n",
       "    'original': 'Go! Go! Go!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Go', u'Go', u'Go']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 126,\n",
       "    'normalized': [u'Say', u'no', u'to', u'this'],\n",
       "    'original': 'Say no to this\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Say', u'no', u'to', u'this']},\n",
       "   {'line#': 127,\n",
       "    'normalized': [u'I', u'don\\u2019t', u'say', u'no', u'to', u'this'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t say no to this',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'don\\u2019t', u'say', u'no', u'to', u'this']},\n",
       "   {'line#': 128,\n",
       "    'normalized': [u'There', u'is', u'nowhere', u'I', u'can', u'go'],\n",
       "    'original': 'There is nowhere I can go.',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'There', u'is', u'nowhere', u'I', u'can', u'go']},\n",
       "   {'line#': 129,\n",
       "    'normalized': [u'Don\\u2019t', u'say', u'no', u'to', u'this'],\n",
       "    'original': 'Don\\xe2\\x80\\x99t say no to this',\n",
       "    'speakers': ['MARIA'],\n",
       "    'tokenized': [u'Don\\u2019t', u'say', u'no', u'to', u'this']},\n",
       "   {'line#': 130,\n",
       "    'normalized': [u'Go', u'go', u'go'],\n",
       "    'original': 'Go go go...',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Go', u'go', u'go']},\n",
       "   {'line#': 131,\n",
       "    'normalized': [u'So'],\n",
       "    'original': 'So?',\n",
       "    'speakers': ['JAMES'],\n",
       "    'tokenized': [u'So']},\n",
       "   {'line#': 132,\n",
       "    'normalized': [u'Nobody', u'needs', u'to', u'know'],\n",
       "    'original': 'Nobody needs to know',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Nobody', u'needs', u'to', u'know']}],\n",
       "  'track': 'Say No to This',\n",
       "  'track#': '4'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Ah', u'Mister', u'Secretary'],\n",
       "    'original': 'Ah, Mister Secretary',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ah', u'Mister', u'Secretary']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Mister', u'Burr', u'sir'],\n",
       "    'original': 'Mister Burr, sir',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Mister', u'Burr', u'sir']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Didja',\n",
       "     u'hear',\n",
       "     u'the',\n",
       "     u'news',\n",
       "     u'about',\n",
       "     u'good',\n",
       "     u'old',\n",
       "     u'General',\n",
       "     u'Mercer'],\n",
       "    'original': 'Didja hear the news about good old General Mercer?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Didja',\n",
       "     u'hear',\n",
       "     u'the',\n",
       "     u'news',\n",
       "     u'about',\n",
       "     u'good',\n",
       "     u'old',\n",
       "     u'General',\n",
       "     u'Mercer']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'You', u'know', u'Clermont', u'Street'],\n",
       "    'original': 'You know Clermont Street?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You', u'know', u'Clermont', u'Street']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Yeah'],\n",
       "    'original': 'Yeah',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yeah']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'They',\n",
       "     u'renamed',\n",
       "     u'it',\n",
       "     u'after',\n",
       "     u'him',\n",
       "     u'The',\n",
       "     u'Mercer',\n",
       "     u'legacy',\n",
       "     u'is',\n",
       "     u'secure'],\n",
       "    'original': 'They renamed it after him. The Mercer legacy is secure',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'They',\n",
       "     u'renamed',\n",
       "     u'it',\n",
       "     u'after',\n",
       "     u'him',\n",
       "     u'The',\n",
       "     u'Mercer',\n",
       "     u'legacy',\n",
       "     u'is',\n",
       "     u'secure']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Sure'],\n",
       "    'original': 'Sure',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sure']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'And',\n",
       "     u'all',\n",
       "     u'he',\n",
       "     u'had',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'was',\n",
       "     u'die'],\n",
       "    'original': 'And all he had to do was die',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'all',\n",
       "     u'he',\n",
       "     u'had',\n",
       "     u'to',\n",
       "     u'do',\n",
       "     u'was',\n",
       "     u'die']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'That\\u2019s', u'a', u'lot', u'less', u'work'],\n",
       "    'original': 'That\\xe2\\x80\\x99s a lot less work',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That\\u2019s', u'a', u'lot', u'less', u'work']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'We', u'oughta', u'give', u'it', u'a', u'try'],\n",
       "    'original': 'We oughta give it a try',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'We', u'oughta', u'give', u'it', u'a', u'try']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Ha'],\n",
       "    'original': 'Ha',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ha']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Now',\n",
       "     u'how\\u2019re',\n",
       "     u'you',\n",
       "     u'gonna',\n",
       "     u'get',\n",
       "     u'your',\n",
       "     u'debt',\n",
       "     u'plan',\n",
       "     u'through'],\n",
       "    'original': 'Now how\\xe2\\x80\\x99re you gonna get your debt plan through?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'how\\u2019re',\n",
       "     u'you',\n",
       "     u'gonna',\n",
       "     u'get',\n",
       "     u'your',\n",
       "     u'debt',\n",
       "     u'plan',\n",
       "     u'through']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'I',\n",
       "     u'guess',\n",
       "     u'I\\u2019m',\n",
       "     u'gonna',\n",
       "     u'fin\\u2019ly',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'listen',\n",
       "     u'to',\n",
       "     u'you'],\n",
       "    'original': 'I guess I\\xe2\\x80\\x99m gonna fin\\xe2\\x80\\x99ly have to listen to you',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'guess',\n",
       "     u'I\\u2019m',\n",
       "     u'gonna',\n",
       "     u'fin\\u2019ly',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'listen',\n",
       "     u'to',\n",
       "     u'you']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Really'],\n",
       "    'original': 'Really?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Really']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'Talk', u'less', u'Smile', u'more'],\n",
       "    'original': '\\xe2\\x80\\x9cTalk less. Smile more.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Talk', u'less', u'Smile', u'more']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Ha'],\n",
       "    'original': 'Ha',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ha']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Do',\n",
       "     u'whatever',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'my',\n",
       "     u'plan',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'Congress',\n",
       "     u'floor'],\n",
       "    'original': 'Do whatever it takes to get my plan on the Congress floor',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Do',\n",
       "     u'whatever',\n",
       "     u'it',\n",
       "     u'takes',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'my',\n",
       "     u'plan',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'Congress',\n",
       "     u'floor']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Now',\n",
       "     u'Madison',\n",
       "     u'and',\n",
       "     u'Jefferson',\n",
       "     u'are',\n",
       "     u'merciless'],\n",
       "    'original': 'Now, Madison and Jefferson are merciless.',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Now',\n",
       "     u'Madison',\n",
       "     u'and',\n",
       "     u'Jefferson',\n",
       "     u'are',\n",
       "     u'merciless']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Well',\n",
       "     u'hate',\n",
       "     u'the',\n",
       "     u'sin',\n",
       "     u'love',\n",
       "     u'the',\n",
       "     u'sinner'],\n",
       "    'original': 'Well, hate the sin, love the sinner',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Well',\n",
       "     u'hate',\n",
       "     u'the',\n",
       "     u'sin',\n",
       "     u'love',\n",
       "     u'the',\n",
       "     u'sinner']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'sorry',\n",
       "     u'Burr',\n",
       "     u'I\\u2019ve',\n",
       "     u'gotta',\n",
       "     u'go'],\n",
       "    'original': 'I\\xe2\\x80\\x99m sorry Burr, I\\xe2\\x80\\x99ve gotta go',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'sorry',\n",
       "     u'Burr',\n",
       "     u'I\\u2019ve',\n",
       "     u'gotta',\n",
       "     u'go']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'But'],\n",
       "    'original': 'But\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Decisions', u'are', u'happening', u'over', u'dinner'],\n",
       "    'original': 'Decisions are happening over dinner',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Decisions', u'are', u'happening', u'over', u'dinner']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Two',\n",
       "     u'Virginians',\n",
       "     u'and',\n",
       "     u'an',\n",
       "     u'immigrant',\n",
       "     u'walk',\n",
       "     u'into',\n",
       "     u'a',\n",
       "     u'room'],\n",
       "    'original': 'Two Virginians and an immigrant walk into a room',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Two',\n",
       "     u'Virginians',\n",
       "     u'and',\n",
       "     u'an',\n",
       "     u'immigrant',\n",
       "     u'walk',\n",
       "     u'into',\n",
       "     u'a',\n",
       "     u'room']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'Diametric\\u2019ly', u'opposed', u'foes'],\n",
       "    'original': 'Diametric\\xe2\\x80\\x99ly opposed, foes',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Diametric\\u2019ly', u'opposed', u'foes']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'They',\n",
       "     u'emerge',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'compromise',\n",
       "     u'having',\n",
       "     u'opened',\n",
       "     u'doors',\n",
       "     u'that',\n",
       "     u'were'],\n",
       "    'original': 'They emerge with a compromise, having opened doors that were',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'They',\n",
       "     u'emerge',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'compromise',\n",
       "     u'having',\n",
       "     u'opened',\n",
       "     u'doors',\n",
       "     u'that',\n",
       "     u'were']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Previously', u'closed'],\n",
       "    'original': 'Previously closed',\n",
       "    'speakers': ['BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Previously', u'closed']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Bros'],\n",
       "    'original': 'Bros',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Bros']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'BURR'],\n",
       "    'original': 'BURR',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'BURR']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'The',\n",
       "     u'immigrant',\n",
       "     u'emerges',\n",
       "     u'with',\n",
       "     u'unprecedented',\n",
       "     u'financial',\n",
       "     u'power'],\n",
       "    'original': 'The immigrant emerges with unprecedented financial power',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'The',\n",
       "     u'immigrant',\n",
       "     u'emerges',\n",
       "     u'with',\n",
       "     u'unprecedented',\n",
       "     u'financial',\n",
       "     u'power']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'A',\n",
       "     u'system',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'shape',\n",
       "     u'however',\n",
       "     u'he',\n",
       "     u'wants'],\n",
       "    'original': 'A system he can shape however he wants',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'A',\n",
       "     u'system',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'shape',\n",
       "     u'however',\n",
       "     u'he',\n",
       "     u'wants']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'The',\n",
       "     u'Virginians',\n",
       "     u'emerge',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'nation\\u2019s',\n",
       "     u'capital'],\n",
       "    'original': 'The Virginians emerge with the nation\\xe2\\x80\\x99s capital',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'The',\n",
       "     u'Virginians',\n",
       "     u'emerge',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'nation\\u2019s',\n",
       "     u'capital']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'And',\n",
       "     u'here\\u2019s',\n",
       "     u'the',\n",
       "     u'pi\\xe8ce',\n",
       "     u'de',\n",
       "     u'r\\xe9sistance'],\n",
       "    'original': 'And here\\xe2\\x80\\x99s the pi\\xc3\\xa8ce de r\\xc3\\xa9sistance:',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'And',\n",
       "     u'here\\u2019s',\n",
       "     u'the',\n",
       "     u'pi\\xe8ce',\n",
       "     u'de',\n",
       "     u'r\\xe9sistance']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'No', u'one', u'else', u'was', u'in'],\n",
       "    'original': 'No one else was in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'one', u'else', u'was', u'in']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'No', u'one', u'else', u'was', u'in'],\n",
       "    'original': 'No one else was in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'one', u'else', u'was', u'in']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'No',\n",
       "     u'one',\n",
       "     u'really',\n",
       "     u'knows',\n",
       "     u'how',\n",
       "     u'the',\n",
       "     u'game',\n",
       "     u'is',\n",
       "     u'played'],\n",
       "    'original': 'No one really knows how the game is played',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No',\n",
       "     u'one',\n",
       "     u'really',\n",
       "     u'knows',\n",
       "     u'how',\n",
       "     u'the',\n",
       "     u'game',\n",
       "     u'is',\n",
       "     u'played']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'The', u'art', u'of', u'the', u'trade'],\n",
       "    'original': 'The art of the trade',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'art', u'of', u'the', u'trade']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'How', u'the', u'sausage', u'gets', u'made'],\n",
       "    'original': 'How the sausage gets made',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'How', u'the', u'sausage', u'gets', u'made']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'We', u'just', u'assume', u'that', u'it', u'happens'],\n",
       "    'original': 'We just assume that it happens',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'We', u'just', u'assume', u'that', u'it', u'happens']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'But', u'no', u'one', u'else', u'is', u'in'],\n",
       "    'original': 'But no one else is in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But', u'no', u'one', u'else', u'is', u'in']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens.',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Game', u'is', u'played'],\n",
       "    'original': 'Game is played',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Game', u'is', u'played']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'How', u'the', u'sausage', u'gets', u'made'],\n",
       "    'original': 'How the sausage gets made',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'How', u'the', u'sausage', u'gets', u'made']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Assume', u'that', u'it', u'happens'],\n",
       "    'original': 'Assume that it happens',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Assume', u'that', u'it', u'happens']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens.',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Thomas', u'claims'],\n",
       "    'original': 'Thomas claims\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Thomas', u'claims']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Alexander',\n",
       "     u'was',\n",
       "     u'on',\n",
       "     u'Washington\\u2019s',\n",
       "     u'doorstep',\n",
       "     u'one',\n",
       "     u'day'],\n",
       "    'original': 'Alexander was on Washington\\xe2\\x80\\x99s doorstep one day',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Alexander',\n",
       "     u'was',\n",
       "     u'on',\n",
       "     u'Washington\\u2019s',\n",
       "     u'doorstep',\n",
       "     u'one',\n",
       "     u'day']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'In', u'distress', u'n', u'disarray'],\n",
       "    'original': 'In distress \\xe2\\x80\\x98n disarray',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'In', u'distress', u'n', u'disarray']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Thomas', u'claims'],\n",
       "    'original': 'Thomas claims\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Thomas', u'claims']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Alexander', u'said'],\n",
       "    'original': 'Alexander said\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Alexander', u'said']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'I\\u2019ve', u'nowhere', u'else', u'to', u'turn'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve nowhere else to turn!',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019ve', u'nowhere', u'else', u'to', u'turn']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'And',\n",
       "     u'basic\\u2019ly',\n",
       "     u'begged',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'join',\n",
       "     u'the',\n",
       "     u'fray'],\n",
       "    'original': 'And basic\\xe2\\x80\\x99ly begged me to join the fray',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'basic\\u2019ly',\n",
       "     u'begged',\n",
       "     u'me',\n",
       "     u'to',\n",
       "     u'join',\n",
       "     u'the',\n",
       "     u'fray']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Thomas', u'claims'],\n",
       "    'original': 'Thomas claims\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Thomas', u'claims']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'I', u'approached', u'Madison', u'and', u'said'],\n",
       "    'original': 'I approached Madison and said\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I', u'approached', u'Madison', u'and', u'said']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'hate',\n",
       "     u'im',\n",
       "     u'but',\n",
       "     u'let\\u2019s',\n",
       "     u'hear',\n",
       "     u'what',\n",
       "     u'he',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'say'],\n",
       "    'original': '\\xe2\\x80\\x9cI know you hate \\xe2\\x80\\x98im, but let\\xe2\\x80\\x99s hear what he has to say.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'you',\n",
       "     u'hate',\n",
       "     u'im',\n",
       "     u'but',\n",
       "     u'let\\u2019s',\n",
       "     u'hear',\n",
       "     u'what',\n",
       "     u'he',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'say']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'Thomas', u'claims'],\n",
       "    'original': 'Thomas claims\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Thomas', u'claims']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Well', u'I', u'arranged', u'the', u'meeting'],\n",
       "    'original': 'Well, I arranged the meeting',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Well', u'I', u'arranged', u'the', u'meeting']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'I',\n",
       "     u'arranged',\n",
       "     u'the',\n",
       "     u'menu',\n",
       "     u'the',\n",
       "     u'venue',\n",
       "     u'the',\n",
       "     u'seating'],\n",
       "    'original': 'I arranged the menu, the venue, the seating',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'arranged',\n",
       "     u'the',\n",
       "     u'menu',\n",
       "     u'the',\n",
       "     u'venue',\n",
       "     u'the',\n",
       "     u'seating']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'But'],\n",
       "    'original': 'But!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'No', u'one', u'else', u'was', u'in'],\n",
       "    'original': 'No one else was in\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'one', u'else', u'was', u'in']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'No', u'one', u'else', u'was', u'in'],\n",
       "    'original': 'No one else was in\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'one', u'else', u'was', u'in']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'No', u'one', u'really', u'knows', u'how', u'the'],\n",
       "    'original': 'No one really knows how the',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No', u'one', u'really', u'knows', u'how', u'the']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'Parties', u'get', u'to', u'yesssss'],\n",
       "    'original': 'Parties get to yesssss',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Parties', u'get', u'to', u'yesssss']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'The', u'pieces', u'that', u'are', u'sacrificed', u'in'],\n",
       "    'original': 'The pieces that are sacrificed in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'pieces', u'that', u'are', u'sacrificed', u'in']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Ev\\u2019ry', u'game', u'of', u'chesssss'],\n",
       "    'original': 'Ev\\xe2\\x80\\x99ry game of chesssss',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Ev\\u2019ry', u'game', u'of', u'chesssss']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'We', u'just', u'assume', u'that', u'it', u'happens'],\n",
       "    'original': 'We just assume that it happens',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'We', u'just', u'assume', u'that', u'it', u'happens']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'But', u'no', u'one', u'else', u'is', u'in'],\n",
       "    'original': 'But no one else is in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But', u'no', u'one', u'else', u'is', u'in']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens.',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'Parties', u'get', u'to', u'yesssss'],\n",
       "    'original': 'Parties get to yesssss',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Parties', u'get', u'to', u'yesssss']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'Ev\\u2019ry', u'game', u'of', u'chesssss'],\n",
       "    'original': 'Ev\\xe2\\x80\\x99ry game of chesssss',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Ev\\u2019ry', u'game', u'of', u'chesssss']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'Assume', u'that', u'it', u'happens'],\n",
       "    'original': 'Assume that it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Assume', u'that', u'it', u'happens']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens.',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'Meanwhile'],\n",
       "    'original': 'Meanwhile\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Meanwhile']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'Madison',\n",
       "     u'is',\n",
       "     u'grappling',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'fact',\n",
       "     u'that',\n",
       "     u'not',\n",
       "     u'ev\\u2019ry',\n",
       "     u'issue',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'settled',\n",
       "     u'by',\n",
       "     u'committee'],\n",
       "    'original': 'Madison is grappling with the fact that not ev\\xe2\\x80\\x99ry issue can be settled by committee',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Madison',\n",
       "     u'is',\n",
       "     u'grappling',\n",
       "     u'with',\n",
       "     u'the',\n",
       "     u'fact',\n",
       "     u'that',\n",
       "     u'not',\n",
       "     u'ev\\u2019ry',\n",
       "     u'issue',\n",
       "     u'can',\n",
       "     u'be',\n",
       "     u'settled',\n",
       "     u'by',\n",
       "     u'committee']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'Meanwhile'],\n",
       "    'original': 'Meanwhile\\xe2\\x80\\x94',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Meanwhile']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'Congress',\n",
       "     u'is',\n",
       "     u'fighting',\n",
       "     u'over',\n",
       "     u'where',\n",
       "     u'to',\n",
       "     u'put',\n",
       "     u'the',\n",
       "     u'capital'],\n",
       "    'original': 'Congress is fighting over where to put the capital\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Congress',\n",
       "     u'is',\n",
       "     u'fighting',\n",
       "     u'over',\n",
       "     u'where',\n",
       "     u'to',\n",
       "     u'put',\n",
       "     u'the',\n",
       "     u'capital']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'Company', u'screams', u'in', u'chaos'],\n",
       "    'original': 'Company screams in chaos',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Company', u'screams', u'in', u'chaos']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'It', u'isn\\u2019t', u'pretty'],\n",
       "    'original': 'It isn\\xe2\\x80\\x99t pretty',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It', u'isn\\u2019t', u'pretty']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'Then',\n",
       "     u'Jefferson',\n",
       "     u'approaches',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'dinner',\n",
       "     u'and',\n",
       "     u'invite'],\n",
       "    'original': 'Then Jefferson approaches with a dinner and invite',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Then',\n",
       "     u'Jefferson',\n",
       "     u'approaches',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'dinner',\n",
       "     u'and',\n",
       "     u'invite']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'And',\n",
       "     u'Madison',\n",
       "     u'responds',\n",
       "     u'with',\n",
       "     u'Virginian',\n",
       "     u'insight'],\n",
       "    'original': 'And Madison responds with Virginian insight:',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'Madison',\n",
       "     u'responds',\n",
       "     u'with',\n",
       "     u'Virginian',\n",
       "     u'insight']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'Maybe',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'solve',\n",
       "     u'one',\n",
       "     u'problem',\n",
       "     u'with',\n",
       "     u'another',\n",
       "     u'and',\n",
       "     u'win',\n",
       "     u'a',\n",
       "     u'victory',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'Southerners',\n",
       "     u'in',\n",
       "     u'other',\n",
       "     u'words'],\n",
       "    'original': 'Maybe we can solve one problem with another and win a victory for the Southerners, in other words\\xe2\\x80\\x94',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Maybe',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'solve',\n",
       "     u'one',\n",
       "     u'problem',\n",
       "     u'with',\n",
       "     u'another',\n",
       "     u'and',\n",
       "     u'win',\n",
       "     u'a',\n",
       "     u'victory',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'Southerners',\n",
       "     u'in',\n",
       "     u'other',\n",
       "     u'words']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'Oh', u'ho'],\n",
       "    'original': 'Oh-ho!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Oh', u'ho']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'A', u'quid', u'pro', u'quo'],\n",
       "    'original': 'A quid pro quo',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'A', u'quid', u'pro', u'quo']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'I', u'suppose'],\n",
       "    'original': 'I suppose',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I', u'suppose']},\n",
       "   {'line#': 99,\n",
       "    'normalized': [u'Wouldn\\u2019t',\n",
       "     u'you',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'work',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'closer',\n",
       "     u'to',\n",
       "     u'home'],\n",
       "    'original': 'Wouldn\\xe2\\x80\\x99t you like to work a little closer to home?',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Wouldn\\u2019t',\n",
       "     u'you',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'work',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'closer',\n",
       "     u'to',\n",
       "     u'home']},\n",
       "   {'line#': 100,\n",
       "    'normalized': [u'Actually', u'I', u'would'],\n",
       "    'original': 'Actually, I would',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Actually', u'I', u'would']},\n",
       "   {'line#': 101,\n",
       "    'normalized': [u'Well', u'I', u'propose', u'the', u'Potomac'],\n",
       "    'original': 'Well, I propose the Potomac',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Well', u'I', u'propose', u'the', u'Potomac']},\n",
       "   {'line#': 102,\n",
       "    'normalized': [u'And',\n",
       "     u'you\\u2019ll',\n",
       "     u'provide',\n",
       "     u'him',\n",
       "     u'his',\n",
       "     u'votes'],\n",
       "    'original': 'And you\\xe2\\x80\\x99ll provide him his votes?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'you\\u2019ll',\n",
       "     u'provide',\n",
       "     u'him',\n",
       "     u'his',\n",
       "     u'votes']},\n",
       "   {'line#': 103,\n",
       "    'normalized': [u'Well', u'we\\u2019ll', u'see', u'how', u'it', u'goes'],\n",
       "    'original': 'Well, we\\xe2\\x80\\x99ll see how it goes',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Well', u'we\\u2019ll', u'see', u'how', u'it', u'goes']},\n",
       "   {'line#': 104,\n",
       "    'normalized': [u'Let\\u2019s', u'go'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s go',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Let\\u2019s', u'go']},\n",
       "   {'line#': 105,\n",
       "    'normalized': [u'No'],\n",
       "    'original': 'No!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'No']},\n",
       "   {'line#': 106,\n",
       "    'normalized': [u'one', u'else', u'was', u'in'],\n",
       "    'original': '\\xe2\\x80\\x94one else was in',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'one', u'else', u'was', u'in']},\n",
       "   {'line#': 107,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 108,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 109,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 110,\n",
       "    'normalized': [u'No', u'one', u'else', u'was', u'in'],\n",
       "    'original': 'No one else was in',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'No', u'one', u'else', u'was', u'in']},\n",
       "   {'line#': 111,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 112,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 113,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happened'],\n",
       "    'original': 'The room where it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happened']},\n",
       "   {'line#': 114,\n",
       "    'normalized': [u'My', u'God'],\n",
       "    'original': 'My God!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'My', u'God']},\n",
       "   {'line#': 115,\n",
       "    'normalized': [u'In', u'God', u'we', u'trust'],\n",
       "    'original': 'In God we trust',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'In', u'God', u'we', u'trust']},\n",
       "   {'line#': 116,\n",
       "    'normalized': [u'But',\n",
       "     u'we\\u2019ll',\n",
       "     u'never',\n",
       "     u'really',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'got',\n",
       "     u'discussed'],\n",
       "    'original': 'But we\\xe2\\x80\\x99ll never really know what got discussed',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'But',\n",
       "     u'we\\u2019ll',\n",
       "     u'never',\n",
       "     u'really',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'got',\n",
       "     u'discussed']},\n",
       "   {'line#': 117,\n",
       "    'normalized': [u'Click', u'boom', u'then', u'it', u'happened'],\n",
       "    'original': 'Click-boom then it happened',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Click', u'boom', u'then', u'it', u'happened']},\n",
       "   {'line#': 118,\n",
       "    'normalized': [u'And',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'else',\n",
       "     u'was',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'happened'],\n",
       "    'original': 'And no one else was in the room where it happened',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'And',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'else',\n",
       "     u'was',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'room',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'happened']},\n",
       "   {'line#': 119,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 120,\n",
       "    'normalized': [u'What',\n",
       "     u'did',\n",
       "     u'they',\n",
       "     u'say',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'sell',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'City',\n",
       "     u'down',\n",
       "     u'the',\n",
       "     u'river'],\n",
       "    'original': 'What did they say to you to get you to sell New York City down the river?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'What',\n",
       "     u'did',\n",
       "     u'they',\n",
       "     u'say',\n",
       "     u'to',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'get',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'sell',\n",
       "     u'New',\n",
       "     u'York',\n",
       "     u'City',\n",
       "     u'down',\n",
       "     u'the',\n",
       "     u'river']},\n",
       "   {'line#': 121,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 122,\n",
       "    'normalized': [u'Did',\n",
       "     u'Washington',\n",
       "     u'know',\n",
       "     u'about',\n",
       "     u'the',\n",
       "     u'dinner'],\n",
       "    'original': 'Did Washington know about the dinner?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Did',\n",
       "     u'Washington',\n",
       "     u'know',\n",
       "     u'about',\n",
       "     u'the',\n",
       "     u'dinner']},\n",
       "   {'line#': 123,\n",
       "    'normalized': [u'Was',\n",
       "     u'there',\n",
       "     u'Presidential',\n",
       "     u'pressure',\n",
       "     u'to',\n",
       "     u'deliver'],\n",
       "    'original': 'Was there Presidential pressure to deliver?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Was',\n",
       "     u'there',\n",
       "     u'Presidential',\n",
       "     u'pressure',\n",
       "     u'to',\n",
       "     u'deliver']},\n",
       "   {'line#': 124,\n",
       "    'normalized': [u'Alexander', u'Hamilton'],\n",
       "    'original': 'Alexander Hamilton!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Alexander', u'Hamilton']},\n",
       "   {'line#': 125,\n",
       "    'normalized': [u'Or',\n",
       "     u'did',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'even',\n",
       "     u'then',\n",
       "     u'it',\n",
       "     u'doesn\\u2019t',\n",
       "     u'matter'],\n",
       "    'original': 'Or did you know, even then, it doesn\\xe2\\x80\\x99t matter',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Or',\n",
       "     u'did',\n",
       "     u'you',\n",
       "     u'know',\n",
       "     u'even',\n",
       "     u'then',\n",
       "     u'it',\n",
       "     u'doesn\\u2019t',\n",
       "     u'matter']},\n",
       "   {'line#': 126,\n",
       "    'normalized': [u'Where', u'you', u'put', u'the', u'U.S', u'Capital'],\n",
       "    'original': 'Where you put the U.S. Capital?',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Where', u'you', u'put', u'the', u'U.S', u'Capital']},\n",
       "   {'line#': 127,\n",
       "    'normalized': [u'Cuz', u'we\\u2019ll', u'have', u'the', u'banks'],\n",
       "    'original': 'Cuz we\\xe2\\x80\\x99ll have the banks',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Cuz', u'we\\u2019ll', u'have', u'the', u'banks']},\n",
       "   {'line#': 128,\n",
       "    'normalized': [u'We\\u2019re', u'in', u'the', u'same', u'spot'],\n",
       "    'original': 'We\\xe2\\x80\\x99re in the same spot',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We\\u2019re', u'in', u'the', u'same', u'spot']},\n",
       "   {'line#': 129,\n",
       "    'normalized': [u'You', u'got', u'more', u'than', u'you', u'gave'],\n",
       "    'original': 'You got more than you gave',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You', u'got', u'more', u'than', u'you', u'gave']},\n",
       "   {'line#': 130,\n",
       "    'normalized': [u'And', u'I', u'wanted', u'what', u'I', u'got'],\n",
       "    'original': 'And I wanted what I got',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'I', u'wanted', u'what', u'I', u'got']},\n",
       "   {'line#': 131,\n",
       "    'normalized': [u'When',\n",
       "     u'you',\n",
       "     u'got',\n",
       "     u'skin',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'game',\n",
       "     u'you',\n",
       "     u'stay',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'game'],\n",
       "    'original': 'When you got skin in the game, you stay in the game',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'When',\n",
       "     u'you',\n",
       "     u'got',\n",
       "     u'skin',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'game',\n",
       "     u'you',\n",
       "     u'stay',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'game']},\n",
       "   {'line#': 132,\n",
       "    'normalized': [u'But',\n",
       "     u'you',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'win',\n",
       "     u'unless',\n",
       "     u'you',\n",
       "     u'play',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'game'],\n",
       "    'original': 'But you don\\xe2\\x80\\x99t get a win unless you play in the game',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'you',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'win',\n",
       "     u'unless',\n",
       "     u'you',\n",
       "     u'play',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'game']},\n",
       "   {'line#': 133,\n",
       "    'normalized': [u'Oh',\n",
       "     u'you',\n",
       "     u'get',\n",
       "     u'love',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'You',\n",
       "     u'get',\n",
       "     u'hate',\n",
       "     u'for',\n",
       "     u'it'],\n",
       "    'original': 'Oh, you get love for it. You get hate for it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Oh',\n",
       "     u'you',\n",
       "     u'get',\n",
       "     u'love',\n",
       "     u'for',\n",
       "     u'it',\n",
       "     u'You',\n",
       "     u'get',\n",
       "     u'hate',\n",
       "     u'for',\n",
       "     u'it']},\n",
       "   {'line#': 134,\n",
       "    'normalized': [u'You', u'get', u'nothing', u'if', u'you'],\n",
       "    'original': 'You get nothing if you\\xe2\\x80\\xa6',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You', u'get', u'nothing', u'if', u'you']},\n",
       "   {'line#': 135,\n",
       "    'normalized': [u'Wait', u'for', u'it', u'wait', u'for', u'it', u'wait'],\n",
       "    'original': 'Wait for it, wait for it, wait!',\n",
       "    'speakers': ['HAMILTON', 'COMPANY'],\n",
       "    'tokenized': [u'Wait', u'for', u'it', u'wait', u'for', u'it', u'wait']},\n",
       "   {'line#': 136,\n",
       "    'normalized': [u'God', u'help', u'and', u'forgive', u'me'],\n",
       "    'original': 'God help and forgive me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'God', u'help', u'and', u'forgive', u'me']},\n",
       "   {'line#': 137,\n",
       "    'normalized': [u'I', u'wanna', u'build'],\n",
       "    'original': 'I wanna build',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I', u'wanna', u'build']},\n",
       "   {'line#': 138,\n",
       "    'normalized': [u'Something', u'that\\u2019s', u'gonna'],\n",
       "    'original': 'Something that\\xe2\\x80\\x99s gonna',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Something', u'that\\u2019s', u'gonna']},\n",
       "   {'line#': 139,\n",
       "    'normalized': [u'Outlive', u'me'],\n",
       "    'original': 'Outlive me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Outlive', u'me']},\n",
       "   {'line#': 140,\n",
       "    'normalized': [u'What', u'do', u'you', u'want', u'Burr'],\n",
       "    'original': 'What do you want, Burr?',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON', 'MADISON', 'WASHINGTON'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'want', u'Burr']},\n",
       "   {'line#': 141,\n",
       "    'normalized': [u'What', u'do', u'you', u'want', u'Burr'],\n",
       "    'original': 'What do you want, Burr?',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON', 'MADISON', 'WASHINGTON'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'want', u'Burr']},\n",
       "   {'line#': 142,\n",
       "    'normalized': [u'If', u'you', u'stand', u'for', u'nothing'],\n",
       "    'original': 'If you stand for nothing',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON', 'MADISON', 'WASHINGTON'],\n",
       "    'tokenized': [u'If', u'you', u'stand', u'for', u'nothing']},\n",
       "   {'line#': 143,\n",
       "    'normalized': [u'Burr', u'then', u'what', u'do', u'you', u'fall', u'for'],\n",
       "    'original': 'Burr, then what do you fall for?',\n",
       "    'speakers': ['HAMILTON', 'JEFFERSON', 'MADISON', 'WASHINGTON'],\n",
       "    'tokenized': [u'Burr', u'then', u'what', u'do', u'you', u'fall', u'for']},\n",
       "   {'line#': 144,\n",
       "    'normalized': [u'What', u'do', u'you', u'want', u'Burr'],\n",
       "    'original': 'What do you want, Burr?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'want', u'Burr']},\n",
       "   {'line#': 145,\n",
       "    'normalized': [u'What', u'do', u'you', u'want', u'Burr'],\n",
       "    'original': 'What do you want, Burr?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'want', u'Burr']},\n",
       "   {'line#': 146,\n",
       "    'normalized': [u'What', u'do', u'you', u'want', u'Burr'],\n",
       "    'original': 'What do you want, Burr?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'want', u'Burr']},\n",
       "   {'line#': 147,\n",
       "    'normalized': [u'What', u'do', u'you', u'want'],\n",
       "    'original': 'What do you want?',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'want']},\n",
       "   {'line#': 148,\n",
       "    'normalized': [u'I'],\n",
       "    'original': 'I',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I']},\n",
       "   {'line#': 149,\n",
       "    'normalized': [u'Wanna', u'be', u'in'],\n",
       "    'original': 'Wanna be in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Wanna', u'be', u'in']},\n",
       "   {'line#': 150,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 151,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 152,\n",
       "    'normalized': [u'I'],\n",
       "    'original': 'I',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I']},\n",
       "   {'line#': 153,\n",
       "    'normalized': [u'Wanna', u'be', u'in'],\n",
       "    'original': 'Wanna be in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Wanna', u'be', u'in']},\n",
       "   {'line#': 154,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 155,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 156,\n",
       "    'normalized': [u'I'],\n",
       "    'original': 'I',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I']},\n",
       "   {'line#': 157,\n",
       "    'normalized': [u'Wanna', u'be'],\n",
       "    'original': 'Wanna be',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Wanna', u'be']},\n",
       "   {'line#': 158,\n",
       "    'normalized': [u'In', u'the', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'In the room where it happens',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'In', u'the', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 159,\n",
       "    'normalized': [u'I'],\n",
       "    'original': 'I',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I']},\n",
       "   {'line#': 160,\n",
       "    'normalized': [u'I', u'wanna', u'be', u'in', u'the', u'room'],\n",
       "    'original': 'I wanna be in the room\\xe2\\x80\\xa6',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'wanna', u'be', u'in', u'the', u'room']},\n",
       "   {'line#': 161,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 162,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 163,\n",
       "    'normalized': [u'I', u'wanna', u'be'],\n",
       "    'original': 'I wanna be',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'wanna', u'be']},\n",
       "   {'line#': 164,\n",
       "    'normalized': [u'I', u'wanna', u'be'],\n",
       "    'original': 'I wanna be',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I', u'wanna', u'be']},\n",
       "   {'line#': 165,\n",
       "    'normalized': [u'I\\u2019ve', u'got', u'to', u'be'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve got to be',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I\\u2019ve', u'got', u'to', u'be']},\n",
       "   {'line#': 166,\n",
       "    'normalized': [u'I\\u2019ve', u'got', u'to', u'be'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve got to be',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I\\u2019ve', u'got', u'to', u'be']},\n",
       "   {'line#': 167,\n",
       "    'normalized': [u'In', u'that', u'room'],\n",
       "    'original': 'In that room',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'In', u'that', u'room']},\n",
       "   {'line#': 168,\n",
       "    'normalized': [u'In', u'that', u'big', u'ol', u'room'],\n",
       "    'original': 'In that big ol\\xe2\\x80\\x99 room',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'In', u'that', u'big', u'ol', u'room']},\n",
       "   {'line#': 169,\n",
       "    'normalized': [u'I', u'wanna', u'be', u'in'],\n",
       "    'original': 'I wanna be in',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'I', u'wanna', u'be', u'in']},\n",
       "   {'line#': 170,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 171,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 172,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 173,\n",
       "    'normalized': [u'I', u'wanna', u'be', u'in', u'the', u'room'],\n",
       "    'original': 'I wanna be in the room',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'I', u'wanna', u'be', u'in', u'the', u'room']},\n",
       "   {'line#': 174,\n",
       "    'normalized': [u'Where', u'it', u'happens'],\n",
       "    'original': 'Where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Where', u'it', u'happens']},\n",
       "   {'line#': 175,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 176,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 177,\n",
       "    'normalized': [u'I', u'wanna', u'be', u'in'],\n",
       "    'original': 'I wanna be in',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'I', u'wanna', u'be', u'in']},\n",
       "   {'line#': 178,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 179,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 180,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 181,\n",
       "    'normalized': [u'I', u'wanna', u'be', u'in'],\n",
       "    'original': 'I wanna be in',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'I', u'wanna', u'be', u'in']},\n",
       "   {'line#': 182,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 183,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 184,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens.',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 185,\n",
       "    'normalized': [u'The', u'art', u'of', u'the', u'compromise'],\n",
       "    'original': 'The art of the compromise\\xe2\\x80\\x94',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'art', u'of', u'the', u'compromise']},\n",
       "   {'line#': 186,\n",
       "    'normalized': [u'Hold',\n",
       "     u'your',\n",
       "     u'nose',\n",
       "     u'and',\n",
       "     u'close',\n",
       "     u'your',\n",
       "     u'eyes'],\n",
       "    'original': 'Hold your nose and close your eyes',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Hold',\n",
       "     u'your',\n",
       "     u'nose',\n",
       "     u'and',\n",
       "     u'close',\n",
       "     u'your',\n",
       "     u'eyes']},\n",
       "   {'line#': 187,\n",
       "    'normalized': [u'We',\n",
       "     u'want',\n",
       "     u'our',\n",
       "     u'leaders',\n",
       "     u'to',\n",
       "     u'save',\n",
       "     u'the',\n",
       "     u'day'],\n",
       "    'original': 'We want our leaders to save the day\\xe2\\x80\\x94',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'We',\n",
       "     u'want',\n",
       "     u'our',\n",
       "     u'leaders',\n",
       "     u'to',\n",
       "     u'save',\n",
       "     u'the',\n",
       "     u'day']},\n",
       "   {'line#': 188,\n",
       "    'normalized': [u'But',\n",
       "     u'we',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'say',\n",
       "     u'in',\n",
       "     u'what',\n",
       "     u'they',\n",
       "     u'trade',\n",
       "     u'away'],\n",
       "    'original': 'But we don\\xe2\\x80\\x99t get a say in what they trade away',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But',\n",
       "     u'we',\n",
       "     u'don\\u2019t',\n",
       "     u'get',\n",
       "     u'a',\n",
       "     u'say',\n",
       "     u'in',\n",
       "     u'what',\n",
       "     u'they',\n",
       "     u'trade',\n",
       "     u'away']},\n",
       "   {'line#': 189,\n",
       "    'normalized': [u'We', u'dream', u'of', u'a', u'brand', u'new', u'start'],\n",
       "    'original': 'We dream of a brand new start\\xe2\\x80\\x94',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'We', u'dream', u'of', u'a', u'brand', u'new', u'start']},\n",
       "   {'line#': 190,\n",
       "    'normalized': [u'But',\n",
       "     u'we',\n",
       "     u'dream',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'dark',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'most',\n",
       "     u'part'],\n",
       "    'original': 'But we dream in the dark for the most part',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But',\n",
       "     u'we',\n",
       "     u'dream',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'dark',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'most',\n",
       "     u'part']},\n",
       "   {'line#': 191,\n",
       "    'normalized': [u'Dark', u'as', u'a', u'tomb', u'where', u'it', u'happens'],\n",
       "    'original': 'Dark as a tomb where it happens',\n",
       "    'speakers': ['BURR', 'COMPANY'],\n",
       "    'tokenized': [u'Dark', u'as', u'a', u'tomb', u'where', u'it', u'happens']},\n",
       "   {'line#': 192,\n",
       "    'normalized': [u'I\\u2019ve', u'got', u'to', u'be', u'in'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve got to be in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I\\u2019ve', u'got', u'to', u'be', u'in']},\n",
       "   {'line#': 193,\n",
       "    'normalized': [u'The', u'room'],\n",
       "    'original': 'The room\\xe2\\x80\\xa6',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room']},\n",
       "   {'line#': 194,\n",
       "    'normalized': [u'I\\u2019ve', u'got', u'to', u'be'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve got to be...',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I\\u2019ve', u'got', u'to', u'be']},\n",
       "   {'line#': 195,\n",
       "    'normalized': [u'I\\u2019ve', u'got', u'to', u'be'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve got to be...',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I\\u2019ve', u'got', u'to', u'be']},\n",
       "   {'line#': 196,\n",
       "    'normalized': [u'Oh', u'I\\u2019ve', u'got', u'to', u'be', u'in'],\n",
       "    'original': 'Oh, I\\xe2\\x80\\x99ve got to be in',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Oh', u'I\\u2019ve', u'got', u'to', u'be', u'in']},\n",
       "   {'line#': 197,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens\\xe2\\x80\\xa6',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 198,\n",
       "    'normalized': [u'I\\u2019ve',\n",
       "     u'got',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'I\\u2019ve',\n",
       "     u'gotta',\n",
       "     u'be',\n",
       "     u'I\\u2019ve',\n",
       "     u'gotta',\n",
       "     u'be'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve got to be, I\\xe2\\x80\\x99ve gotta be, I\\xe2\\x80\\x99ve gotta be\\xe2\\x80\\xa6',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I\\u2019ve',\n",
       "     u'got',\n",
       "     u'to',\n",
       "     u'be',\n",
       "     u'I\\u2019ve',\n",
       "     u'gotta',\n",
       "     u'be',\n",
       "     u'I\\u2019ve',\n",
       "     u'gotta',\n",
       "     u'be']},\n",
       "   {'line#': 199,\n",
       "    'normalized': [u'In', u'the', u'room'],\n",
       "    'original': 'In the room!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'In', u'the', u'room']},\n",
       "   {'line#': 200,\n",
       "    'normalized': [u'Click', u'boom'],\n",
       "    'original': 'Click-boom!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Click', u'boom']},\n",
       "   {'line#': 201,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 202,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 203,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 204,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 205,\n",
       "    'normalized': [u'The', u'room', u'where', u'it', u'happens'],\n",
       "    'original': 'The room where it happens',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'The', u'room', u'where', u'it', u'happens']},\n",
       "   {'line#': 206,\n",
       "    'normalized': [u'I', u'wanna', u'be', u'in', u'the', u'room'],\n",
       "    'original': 'I wanna be in the room',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'I', u'wanna', u'be', u'in', u'the', u'room']},\n",
       "   {'line#': 207,\n",
       "    'normalized': [u'Where', u'it', u'happens'],\n",
       "    'original': 'Where it happens!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Where', u'it', u'happens']},\n",
       "   {'line#': 208,\n",
       "    'normalized': [u'Click', u'boom'],\n",
       "    'original': 'Click-boom!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Click', u'boom']}],\n",
       "  'track': 'The Room Where It Happens',\n",
       "  'track#': '5'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Look'],\n",
       "    'original': 'Look!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Look']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Grandpa\\u2019s', u'in', u'the', u'paper'],\n",
       "    'original': 'Grandpa\\xe2\\x80\\x99s in the paper!',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Grandpa\\u2019s', u'in', u'the', u'paper']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'War',\n",
       "     u'hero',\n",
       "     u'Philip',\n",
       "     u'Schuyler',\n",
       "     u'loses',\n",
       "     u'senate',\n",
       "     u'seat',\n",
       "     u'to',\n",
       "     u'young',\n",
       "     u'upstart',\n",
       "     u'Aaron',\n",
       "     u'Burr'],\n",
       "    'original': '\\xe2\\x80\\x9cWar hero Philip Schuyler loses senate seat to young upstart Aaron Burr\\xe2\\x80\\x9d',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'War',\n",
       "     u'hero',\n",
       "     u'Philip',\n",
       "     u'Schuyler',\n",
       "     u'loses',\n",
       "     u'senate',\n",
       "     u'seat',\n",
       "     u'to',\n",
       "     u'young',\n",
       "     u'upstart',\n",
       "     u'Aaron',\n",
       "     u'Burr']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Grandpa',\n",
       "     u'just',\n",
       "     u'lost',\n",
       "     u'his',\n",
       "     u'seat',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'senate'],\n",
       "    'original': 'Grandpa just lost his seat in the senate',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Grandpa',\n",
       "     u'just',\n",
       "     u'lost',\n",
       "     u'his',\n",
       "     u'seat',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'senate']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Sometimes', u'that\\u2019s', u'how', u'it', u'goes'],\n",
       "    'original': 'Sometimes that\\xe2\\x80\\x99s how it goes',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'Sometimes', u'that\\u2019s', u'how', u'it', u'goes']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Daddy\\u2019s',\n",
       "     u'gonna',\n",
       "     u'find',\n",
       "     u'out',\n",
       "     u'any',\n",
       "     u'minute'],\n",
       "    'original': 'Daddy\\xe2\\x80\\x99s gonna find out any minute',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Daddy\\u2019s',\n",
       "     u'gonna',\n",
       "     u'find',\n",
       "     u'out',\n",
       "     u'any',\n",
       "     u'minute']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'I\\u2019m', u'sure', u'he', u'already', u'knows'],\n",
       "    'original': 'I\\xe2\\x80\\x99m sure he already knows',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'I\\u2019m', u'sure', u'he', u'already', u'knows']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'Further', u'down'],\n",
       "    'original': 'Further down',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Further', u'down']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Further', u'down'],\n",
       "    'original': 'Further down',\n",
       "    'speakers': ['PHILIP', 'ELIZA'],\n",
       "    'tokenized': [u'Further', u'down']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Let\\u2019s',\n",
       "     u'meet',\n",
       "     u'the',\n",
       "     u'newest',\n",
       "     u'senator',\n",
       "     u'from',\n",
       "     u'New',\n",
       "     u'York'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s meet the newest senator from New York',\n",
       "    'speakers': ['PHILIP'],\n",
       "    'tokenized': [u'Let\\u2019s',\n",
       "     u'meet',\n",
       "     u'the',\n",
       "     u'newest',\n",
       "     u'senator',\n",
       "     u'from',\n",
       "     u'New',\n",
       "     u'York']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'New', u'York'],\n",
       "    'original': 'New York',\n",
       "    'speakers': ['ELIZA'],\n",
       "    'tokenized': [u'New', u'York']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Our', u'senator'],\n",
       "    'original': 'Our senator',\n",
       "    'speakers': ['PHILIP', 'ELIZA'],\n",
       "    'tokenized': [u'Our', u'senator']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'Burr'],\n",
       "    'original': 'Burr?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Burr']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Since',\n",
       "     u'when',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'a',\n",
       "     u'Democratic',\n",
       "     u'Republican'],\n",
       "    'original': 'Since when are you a Democratic-Republican?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Since',\n",
       "     u'when',\n",
       "     u'are',\n",
       "     u'you',\n",
       "     u'a',\n",
       "     u'Democratic',\n",
       "     u'Republican']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Since',\n",
       "     u'being',\n",
       "     u'one',\n",
       "     u'put',\n",
       "     u'me',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'up',\n",
       "     u'and',\n",
       "     u'up',\n",
       "     u'again'],\n",
       "    'original': 'Since being one put me on the up and up again',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Since',\n",
       "     u'being',\n",
       "     u'one',\n",
       "     u'put',\n",
       "     u'me',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'up',\n",
       "     u'and',\n",
       "     u'up',\n",
       "     u'again']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'No',\n",
       "     u'one',\n",
       "     u'knows',\n",
       "     u'who',\n",
       "     u'you',\n",
       "     u'are',\n",
       "     u'or',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'do'],\n",
       "    'original': 'No one knows who you are or what you do',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No',\n",
       "     u'one',\n",
       "     u'knows',\n",
       "     u'who',\n",
       "     u'you',\n",
       "     u'are',\n",
       "     u'or',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'do']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'They', u'don\\u2019t', u'need', u'to', u'know', u'me'],\n",
       "    'original': 'They don\\xe2\\x80\\x99t need to know me',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'They', u'don\\u2019t', u'need', u'to', u'know', u'me']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'They', u'don\\u2019t', u'like', u'you'],\n",
       "    'original': 'They don\\xe2\\x80\\x99t like you',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'They', u'don\\u2019t', u'like', u'you']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'Excuse', u'me'],\n",
       "    'original': 'Excuse me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Excuse', u'me']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Oh',\n",
       "     u'Wall',\n",
       "     u'Street',\n",
       "     u'thinks',\n",
       "     u'you\\u2019re',\n",
       "     u'great'],\n",
       "    'original': 'Oh, Wall Street thinks you\\xe2\\x80\\x99re great',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Oh',\n",
       "     u'Wall',\n",
       "     u'Street',\n",
       "     u'thinks',\n",
       "     u'you\\u2019re',\n",
       "     u'great']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'You\\u2019ll',\n",
       "     u'always',\n",
       "     u'be',\n",
       "     u'adored',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'things',\n",
       "     u'you',\n",
       "     u'create'],\n",
       "    'original': 'You\\xe2\\x80\\x99ll always be adored by the things you create',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'You\\u2019ll',\n",
       "     u'always',\n",
       "     u'be',\n",
       "     u'adored',\n",
       "     u'by',\n",
       "     u'the',\n",
       "     u'things',\n",
       "     u'you',\n",
       "     u'create']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'But', u'upstate'],\n",
       "    'original': 'But upstate\\xe2\\x80\\x94',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'But', u'upstate']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Wait'],\n",
       "    'original': 'Wait',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Wait']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'people', u'think', u'you\\u2019re', u'crooked'],\n",
       "    'original': '\\xe2\\x80\\x94people think you\\xe2\\x80\\x99re crooked',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'people', u'think', u'you\\u2019re', u'crooked']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Schuyler\\u2019s',\n",
       "     u'seat',\n",
       "     u'was',\n",
       "     u'up',\n",
       "     u'for',\n",
       "     u'grabs',\n",
       "     u'so',\n",
       "     u'I',\n",
       "     u'took',\n",
       "     u'it'],\n",
       "    'original': 'Schuyler\\xe2\\x80\\x99s seat was up for grabs so I took it',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Schuyler\\u2019s',\n",
       "     u'seat',\n",
       "     u'was',\n",
       "     u'up',\n",
       "     u'for',\n",
       "     u'grabs',\n",
       "     u'so',\n",
       "     u'I',\n",
       "     u'took',\n",
       "     u'it']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'I\\u2019ve',\n",
       "     u'always',\n",
       "     u'considered',\n",
       "     u'you',\n",
       "     u'a',\n",
       "     u'friend'],\n",
       "    'original': 'I\\xe2\\x80\\x99ve always considered you a friend',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019ve',\n",
       "     u'always',\n",
       "     u'considered',\n",
       "     u'you',\n",
       "     u'a',\n",
       "     u'friend']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'see',\n",
       "     u'why',\n",
       "     u'that',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'end'],\n",
       "    'original': 'I don\\xe2\\x80\\x99t see why that has to end',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'see',\n",
       "     u'why',\n",
       "     u'that',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'end']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'You',\n",
       "     u'changed',\n",
       "     u'parties',\n",
       "     u'to',\n",
       "     u'run',\n",
       "     u'against',\n",
       "     u'my',\n",
       "     u'father',\n",
       "     u'in',\n",
       "     u'law'],\n",
       "    'original': 'You changed parties to run against my father-in-law',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'changed',\n",
       "     u'parties',\n",
       "     u'to',\n",
       "     u'run',\n",
       "     u'against',\n",
       "     u'my',\n",
       "     u'father',\n",
       "     u'in',\n",
       "     u'law']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'I',\n",
       "     u'changed',\n",
       "     u'parties',\n",
       "     u'to',\n",
       "     u'seize',\n",
       "     u'the',\n",
       "     u'opportunity',\n",
       "     u'I',\n",
       "     u'saw'],\n",
       "    'original': 'I changed parties to seize the opportunity I saw',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'changed',\n",
       "     u'parties',\n",
       "     u'to',\n",
       "     u'seize',\n",
       "     u'the',\n",
       "     u'opportunity',\n",
       "     u'I',\n",
       "     u'saw']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'I',\n",
       "     u'swear',\n",
       "     u'your',\n",
       "     u'pride',\n",
       "     u'will',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'death',\n",
       "     u'of',\n",
       "     u'us',\n",
       "     u'all'],\n",
       "    'original': 'I swear your pride will be the death of us all',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'I',\n",
       "     u'swear',\n",
       "     u'your',\n",
       "     u'pride',\n",
       "     u'will',\n",
       "     u'be',\n",
       "     u'the',\n",
       "     u'death',\n",
       "     u'of',\n",
       "     u'us',\n",
       "     u'all']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Beware', u'it', u'goeth', u'before', u'the', u'fall'],\n",
       "    'original': 'Beware, it goeth before the fall',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Beware', u'it', u'goeth', u'before', u'the', u'fall']}],\n",
       "  'track': 'Schuyler Defeated',\n",
       "  'track#': '6'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'The',\n",
       "     u'issue',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'table',\n",
       "     u'France',\n",
       "     u'is',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'verge',\n",
       "     u'of',\n",
       "     u'war',\n",
       "     u'with',\n",
       "     u'England'],\n",
       "    'original': 'The issue on the table: France is on the verge of war with England',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'issue',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'table',\n",
       "     u'France',\n",
       "     u'is',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'verge',\n",
       "     u'of',\n",
       "     u'war',\n",
       "     u'with',\n",
       "     u'England']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'And',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'provide',\n",
       "     u'aid',\n",
       "     u'and',\n",
       "     u'our',\n",
       "     u'troops',\n",
       "     u'to',\n",
       "     u'our',\n",
       "     u'French',\n",
       "     u'allies',\n",
       "     u'or',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'stay',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'it'],\n",
       "    'original': 'And do we provide aid and our troops to our French allies or do we stay out of it?',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'provide',\n",
       "     u'aid',\n",
       "     u'and',\n",
       "     u'our',\n",
       "     u'troops',\n",
       "     u'to',\n",
       "     u'our',\n",
       "     u'French',\n",
       "     u'allies',\n",
       "     u'or',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'stay',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'it']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'Remember',\n",
       "     u'my',\n",
       "     u'decision',\n",
       "     u'on',\n",
       "     u'this',\n",
       "     u'matter',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'subject',\n",
       "     u'to',\n",
       "     u'congressional',\n",
       "     u'approval'],\n",
       "    'original': 'Remember, my decision on this matter is not subject to congressional approval',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Remember',\n",
       "     u'my',\n",
       "     u'decision',\n",
       "     u'on',\n",
       "     u'this',\n",
       "     u'matter',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'subject',\n",
       "     u'to',\n",
       "     u'congressional',\n",
       "     u'approval']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'The',\n",
       "     u'only',\n",
       "     u'person',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'convince',\n",
       "     u'is',\n",
       "     u'me'],\n",
       "    'original': 'The only person you have to convince is me',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'only',\n",
       "     u'person',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'convince',\n",
       "     u'is',\n",
       "     u'me']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Secretary',\n",
       "     u'Jefferson',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'floor',\n",
       "     u'sir'],\n",
       "    'original': 'Secretary Jefferson, you have the floor, sir',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Secretary',\n",
       "     u'Jefferson',\n",
       "     u'you',\n",
       "     u'have',\n",
       "     u'the',\n",
       "     u'floor',\n",
       "     u'sir']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'When',\n",
       "     u'we',\n",
       "     u'were',\n",
       "     u'on',\n",
       "     u'death\\u2019s',\n",
       "     u'door',\n",
       "     u'when',\n",
       "     u'we',\n",
       "     u'were',\n",
       "     u'needy'],\n",
       "    'original': 'When we were on death\\xe2\\x80\\x99s door, when we were needy',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'When',\n",
       "     u'we',\n",
       "     u'were',\n",
       "     u'on',\n",
       "     u'death\\u2019s',\n",
       "     u'door',\n",
       "     u'when',\n",
       "     u'we',\n",
       "     u'were',\n",
       "     u'needy']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'We',\n",
       "     u'made',\n",
       "     u'a',\n",
       "     u'promise',\n",
       "     u'we',\n",
       "     u'signed',\n",
       "     u'a',\n",
       "     u'treaty'],\n",
       "    'original': 'We made a promise, we signed a treaty',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'made',\n",
       "     u'a',\n",
       "     u'promise',\n",
       "     u'we',\n",
       "     u'signed',\n",
       "     u'a',\n",
       "     u'treaty']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'We',\n",
       "     u'needed',\n",
       "     u'money',\n",
       "     u'and',\n",
       "     u'guns',\n",
       "     u'and',\n",
       "     u'half',\n",
       "     u'a',\n",
       "     u'chance'],\n",
       "    'original': 'We needed money and guns and half a chance',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'needed',\n",
       "     u'money',\n",
       "     u'and',\n",
       "     u'guns',\n",
       "     u'and',\n",
       "     u'half',\n",
       "     u'a',\n",
       "     u'chance']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'Who', u'provided', u'those', u'funds'],\n",
       "    'original': 'Who provided those funds?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Who', u'provided', u'those', u'funds']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'France'],\n",
       "    'original': 'France',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'France']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'In',\n",
       "     u'return',\n",
       "     u'they',\n",
       "     u'didn\\u2019t',\n",
       "     u'ask',\n",
       "     u'for',\n",
       "     u'land'],\n",
       "    'original': 'In return, they didn\\xe2\\x80\\x99t ask for land',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'In',\n",
       "     u'return',\n",
       "     u'they',\n",
       "     u'didn\\u2019t',\n",
       "     u'ask',\n",
       "     u'for',\n",
       "     u'land']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'Only',\n",
       "     u'a',\n",
       "     u'promise',\n",
       "     u'that',\n",
       "     u'we\\u2019d',\n",
       "     u'lend',\n",
       "     u'a',\n",
       "     u'hand'],\n",
       "    'original': 'Only a promise that we\\xe2\\x80\\x99d lend a hand',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Only',\n",
       "     u'a',\n",
       "     u'promise',\n",
       "     u'that',\n",
       "     u'we\\u2019d',\n",
       "     u'lend',\n",
       "     u'a',\n",
       "     u'hand']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'And',\n",
       "     u'stand',\n",
       "     u'with',\n",
       "     u'them',\n",
       "     u'if',\n",
       "     u'they',\n",
       "     u'fought',\n",
       "     u'against',\n",
       "     u'oppressors'],\n",
       "    'original': 'And stand with them if they fought against oppressors',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'stand',\n",
       "     u'with',\n",
       "     u'them',\n",
       "     u'if',\n",
       "     u'they',\n",
       "     u'fought',\n",
       "     u'against',\n",
       "     u'oppressors']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'And',\n",
       "     u'revolution',\n",
       "     u'is',\n",
       "     u'messy',\n",
       "     u'but',\n",
       "     u'now',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'time',\n",
       "     u'to',\n",
       "     u'stand'],\n",
       "    'original': 'And revolution is messy but now is the time to stand',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'revolution',\n",
       "     u'is',\n",
       "     u'messy',\n",
       "     u'but',\n",
       "     u'now',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'time',\n",
       "     u'to',\n",
       "     u'stand']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Stand',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'brothers',\n",
       "     u'as',\n",
       "     u'they',\n",
       "     u'fight',\n",
       "     u'against',\n",
       "     u'tyranny'],\n",
       "    'original': 'Stand with our brothers as they fight against tyranny',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Stand',\n",
       "     u'with',\n",
       "     u'our',\n",
       "     u'brothers',\n",
       "     u'as',\n",
       "     u'they',\n",
       "     u'fight',\n",
       "     u'against',\n",
       "     u'tyranny']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'I',\n",
       "     u'know',\n",
       "     u'that',\n",
       "     u'Alexander',\n",
       "     u'Hamilton',\n",
       "     u'is',\n",
       "     u'here',\n",
       "     u'and',\n",
       "     u'he'],\n",
       "    'original': 'I know that Alexander Hamilton is here and he',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'know',\n",
       "     u'that',\n",
       "     u'Alexander',\n",
       "     u'Hamilton',\n",
       "     u'is',\n",
       "     u'here',\n",
       "     u'and',\n",
       "     u'he']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Would', u'rather', u'not', u'have', u'this', u'debate'],\n",
       "    'original': 'Would rather not have this debate',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Would', u'rather', u'not', u'have', u'this', u'debate']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'I\\u2019ll',\n",
       "     u'remind',\n",
       "     u'you',\n",
       "     u'that',\n",
       "     u'he',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'Secretary',\n",
       "     u'of',\n",
       "     u'State'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll remind you that he is not Secretary of State',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I\\u2019ll',\n",
       "     u'remind',\n",
       "     u'you',\n",
       "     u'that',\n",
       "     u'he',\n",
       "     u'is',\n",
       "     u'not',\n",
       "     u'Secretary',\n",
       "     u'of',\n",
       "     u'State']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'He', u'knows', u'nothing', u'of', u'loyalty'],\n",
       "    'original': 'He knows nothing of loyalty',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'He', u'knows', u'nothing', u'of', u'loyalty']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Smells',\n",
       "     u'like',\n",
       "     u'new',\n",
       "     u'money',\n",
       "     u'dresses',\n",
       "     u'like',\n",
       "     u'fake',\n",
       "     u'royalty'],\n",
       "    'original': 'Smells like new money, dresses like fake royalty',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Smells',\n",
       "     u'like',\n",
       "     u'new',\n",
       "     u'money',\n",
       "     u'dresses',\n",
       "     u'like',\n",
       "     u'fake',\n",
       "     u'royalty']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Desperate', u'to', u'rise', u'above', u'his', u'station'],\n",
       "    'original': 'Desperate to rise above his station',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Desperate', u'to', u'rise', u'above', u'his', u'station']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Everything',\n",
       "     u'he',\n",
       "     u'does',\n",
       "     u'betrays',\n",
       "     u'the',\n",
       "     u'ideals',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'nation'],\n",
       "    'original': 'Everything he does betrays the ideals of our nation',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Everything',\n",
       "     u'he',\n",
       "     u'does',\n",
       "     u'betrays',\n",
       "     u'the',\n",
       "     u'ideals',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'nation']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Ooh'],\n",
       "    'original': 'Ooh!!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Ooh']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'Hey',\n",
       "     u'and',\n",
       "     u'if',\n",
       "     u'ya',\n",
       "     u'don\\u2019t',\n",
       "     u'know',\n",
       "     u'now',\n",
       "     u'ya',\n",
       "     u'know',\n",
       "     u'Mr',\n",
       "     u'President'],\n",
       "    'original': 'Hey, and if ya don\\xe2\\x80\\x99t know, now ya know, Mr. President',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Hey',\n",
       "     u'and',\n",
       "     u'if',\n",
       "     u'ya',\n",
       "     u'don\\u2019t',\n",
       "     u'know',\n",
       "     u'now',\n",
       "     u'ya',\n",
       "     u'know',\n",
       "     u'Mr',\n",
       "     u'President']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Thank',\n",
       "     u'you',\n",
       "     u'Secretary',\n",
       "     u'Jefferson',\n",
       "     u'Secretary',\n",
       "     u'Hamilton',\n",
       "     u'your',\n",
       "     u'response'],\n",
       "    'original': 'Thank you, Secretary Jefferson. Secretary Hamilton, your response',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Thank',\n",
       "     u'you',\n",
       "     u'Secretary',\n",
       "     u'Jefferson',\n",
       "     u'Secretary',\n",
       "     u'Hamilton',\n",
       "     u'your',\n",
       "     u'response']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'You',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'Goddamn',\n",
       "     u'mind',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'think'],\n",
       "    'original': 'You must be out of your Goddamn mind if you think',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'out',\n",
       "     u'of',\n",
       "     u'your',\n",
       "     u'Goddamn',\n",
       "     u'mind',\n",
       "     u'if',\n",
       "     u'you',\n",
       "     u'think']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'The',\n",
       "     u'President',\n",
       "     u'is',\n",
       "     u'gonna',\n",
       "     u'bring',\n",
       "     u'the',\n",
       "     u'nation',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'brink'],\n",
       "    'original': 'The President is gonna bring the nation to the brink',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'President',\n",
       "     u'is',\n",
       "     u'gonna',\n",
       "     u'bring',\n",
       "     u'the',\n",
       "     u'nation',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'brink']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Of',\n",
       "     u'meddling',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'middle',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'military',\n",
       "     u'mess'],\n",
       "    'original': 'Of meddling in the middle of a military mess',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Of',\n",
       "     u'meddling',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'middle',\n",
       "     u'of',\n",
       "     u'a',\n",
       "     u'military',\n",
       "     u'mess']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'A',\n",
       "     u'game',\n",
       "     u'of',\n",
       "     u'chess',\n",
       "     u'where',\n",
       "     u'France',\n",
       "     u'is',\n",
       "     u'Queen',\n",
       "     u'and',\n",
       "     u'Kingless'],\n",
       "    'original': 'A game of chess, where France is Queen and Kingless',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'A',\n",
       "     u'game',\n",
       "     u'of',\n",
       "     u'chess',\n",
       "     u'where',\n",
       "     u'France',\n",
       "     u'is',\n",
       "     u'Queen',\n",
       "     u'and',\n",
       "     u'Kingless']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'We',\n",
       "     u'signed',\n",
       "     u'a',\n",
       "     u'treaty',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'King',\n",
       "     u'whose',\n",
       "     u'head',\n",
       "     u'is',\n",
       "     u'now',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'basket'],\n",
       "    'original': 'We signed a treaty with a King whose head is now in a basket',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'signed',\n",
       "     u'a',\n",
       "     u'treaty',\n",
       "     u'with',\n",
       "     u'a',\n",
       "     u'King',\n",
       "     u'whose',\n",
       "     u'head',\n",
       "     u'is',\n",
       "     u'now',\n",
       "     u'in',\n",
       "     u'a',\n",
       "     u'basket']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Would',\n",
       "     u'you',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'it',\n",
       "     u'out',\n",
       "     u'and',\n",
       "     u'ask',\n",
       "     u'it'],\n",
       "    'original': 'Would you like to take it out and ask it?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Would',\n",
       "     u'you',\n",
       "     u'like',\n",
       "     u'to',\n",
       "     u'take',\n",
       "     u'it',\n",
       "     u'out',\n",
       "     u'and',\n",
       "     u'ask',\n",
       "     u'it']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Should',\n",
       "     u'we',\n",
       "     u'honor',\n",
       "     u'our',\n",
       "     u'treaty',\n",
       "     u'King',\n",
       "     u'Louis',\n",
       "     u'head'],\n",
       "    'original': '\\xe2\\x80\\x9cShould we honor our treaty, King Louis\\xe2\\x80\\x99 head?\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Should',\n",
       "     u'we',\n",
       "     u'honor',\n",
       "     u'our',\n",
       "     u'treaty',\n",
       "     u'King',\n",
       "     u'Louis',\n",
       "     u'head']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'Uh',\n",
       "     u'do',\n",
       "     u'whatever',\n",
       "     u'you',\n",
       "     u'want',\n",
       "     u'I\\u2019m',\n",
       "     u'super',\n",
       "     u'dead'],\n",
       "    'original': '\\xe2\\x80\\x9cUh\\xe2\\x80\\xa6 do whatever you want, I\\xe2\\x80\\x99m super dead.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Uh',\n",
       "     u'do',\n",
       "     u'whatever',\n",
       "     u'you',\n",
       "     u'want',\n",
       "     u'I\\u2019m',\n",
       "     u'super',\n",
       "     u'dead']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'Enough', u'Hamilton', u'is', u'right'],\n",
       "    'original': 'Enough. Hamilton is right',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Enough', u'Hamilton', u'is', u'right']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Mr', u'President'],\n",
       "    'original': 'Mr. President\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Mr', u'President']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'We\\u2019re',\n",
       "     u'too',\n",
       "     u'fragile',\n",
       "     u'to',\n",
       "     u'start',\n",
       "     u'another',\n",
       "     u'fight'],\n",
       "    'original': 'We\\xe2\\x80\\x99re too fragile to start another fight',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We\\u2019re',\n",
       "     u'too',\n",
       "     u'fragile',\n",
       "     u'to',\n",
       "     u'start',\n",
       "     u'another',\n",
       "     u'fight']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'But',\n",
       "     u'sir',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'not',\n",
       "     u'fight',\n",
       "     u'for',\n",
       "     u'freedom'],\n",
       "    'original': 'But sir, do we not fight for freedom?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'sir',\n",
       "     u'do',\n",
       "     u'we',\n",
       "     u'not',\n",
       "     u'fight',\n",
       "     u'for',\n",
       "     u'freedom']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'Sure',\n",
       "     u'when',\n",
       "     u'the',\n",
       "     u'French',\n",
       "     u'figure',\n",
       "     u'out',\n",
       "     u'who\\u2019s',\n",
       "     u'gonna',\n",
       "     u'lead',\n",
       "     u'em'],\n",
       "    'original': 'Sure, when the French figure out who\\xe2\\x80\\x99s gonna lead \\xe2\\x80\\x98em',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Sure',\n",
       "     u'when',\n",
       "     u'the',\n",
       "     u'French',\n",
       "     u'figure',\n",
       "     u'out',\n",
       "     u'who\\u2019s',\n",
       "     u'gonna',\n",
       "     u'lead',\n",
       "     u'em']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'The', u'people', u'are', u'leading'],\n",
       "    'original': 'The people are leading\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'The', u'people', u'are', u'leading']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'The', u'people', u'are', u'rioting'],\n",
       "    'original': 'The people are rioting',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The', u'people', u'are', u'rioting']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'There\\u2019s',\n",
       "     u'a',\n",
       "     u'difference',\n",
       "     u'Frankly',\n",
       "     u'it\\u2019s',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'disquieting',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'let',\n",
       "     u'your',\n",
       "     u'ideals',\n",
       "     u'blind',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'reality'],\n",
       "    'original': 'There\\xe2\\x80\\x99s a difference. Frankly, it\\xe2\\x80\\x99s a little disquieting you would let your ideals blind you to reality',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'There\\u2019s',\n",
       "     u'a',\n",
       "     u'difference',\n",
       "     u'Frankly',\n",
       "     u'it\\u2019s',\n",
       "     u'a',\n",
       "     u'little',\n",
       "     u'disquieting',\n",
       "     u'you',\n",
       "     u'would',\n",
       "     u'let',\n",
       "     u'your',\n",
       "     u'ideals',\n",
       "     u'blind',\n",
       "     u'you',\n",
       "     u'to',\n",
       "     u'reality']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'Sir'],\n",
       "    'original': 'Sir',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Draft', u'a', u'statement', u'of', u'neutrality'],\n",
       "    'original': 'Draft a statement of neutrality',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Draft', u'a', u'statement', u'of', u'neutrality']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'Did', u'you', u'forget', u'Lafayette'],\n",
       "    'original': 'Did you forget Lafayette?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Did', u'you', u'forget', u'Lafayette']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'Have', u'you', u'an', u'ounce', u'of', u'regret'],\n",
       "    'original': 'Have you an ounce of regret?',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Have', u'you', u'an', u'ounce', u'of', u'regret']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'You',\n",
       "     u'accumulate',\n",
       "     u'debt',\n",
       "     u'you',\n",
       "     u'accumulate',\n",
       "     u'power'],\n",
       "    'original': 'You accumulate debt, you accumulate power',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'accumulate',\n",
       "     u'debt',\n",
       "     u'you',\n",
       "     u'accumulate',\n",
       "     u'power']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Yet',\n",
       "     u'in',\n",
       "     u'their',\n",
       "     u'hour',\n",
       "     u'of',\n",
       "     u'need',\n",
       "     u'you',\n",
       "     u'forget'],\n",
       "    'original': 'Yet in their hour of need, you forget',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Yet',\n",
       "     u'in',\n",
       "     u'their',\n",
       "     u'hour',\n",
       "     u'of',\n",
       "     u'need',\n",
       "     u'you',\n",
       "     u'forget']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Lafayette\\u2019s',\n",
       "     u'a',\n",
       "     u'smart',\n",
       "     u'man',\n",
       "     u'he\\u2019ll',\n",
       "     u'be',\n",
       "     u'fine'],\n",
       "    'original': 'Lafayette\\xe2\\x80\\x99s a smart man, he\\xe2\\x80\\x99ll be fine',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Lafayette\\u2019s',\n",
       "     u'a',\n",
       "     u'smart',\n",
       "     u'man',\n",
       "     u'he\\u2019ll',\n",
       "     u'be',\n",
       "     u'fine']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'And',\n",
       "     u'before',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'your',\n",
       "     u'friend',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'mine'],\n",
       "    'original': 'And before he was your friend, he was mine',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'before',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'your',\n",
       "     u'friend',\n",
       "     u'he',\n",
       "     u'was',\n",
       "     u'mine']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'If',\n",
       "     u'we',\n",
       "     u'try',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'in',\n",
       "     u'every',\n",
       "     u'revolution',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'we',\n",
       "     u'never',\n",
       "     u'stop'],\n",
       "    'original': 'If we try to fight in every revolution in the world, we never stop',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'we',\n",
       "     u'try',\n",
       "     u'to',\n",
       "     u'fight',\n",
       "     u'in',\n",
       "     u'every',\n",
       "     u'revolution',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'world',\n",
       "     u'we',\n",
       "     u'never',\n",
       "     u'stop']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Where', u'do', u'we', u'draw', u'the', u'line'],\n",
       "    'original': 'Where do we draw the line?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Where', u'do', u'we', u'draw', u'the', u'line']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'So', u'quick', u'witted'],\n",
       "    'original': 'So quick-witted',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'So', u'quick', u'witted']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Alas', u'I', u'admit', u'it'],\n",
       "    'original': 'Alas, I admit it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Alas', u'I', u'admit', u'it']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'I', u'bet', u'you', u'were', u'quite', u'a', u'lawyer'],\n",
       "    'original': 'I bet you were quite a lawyer',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I', u'bet', u'you', u'were', u'quite', u'a', u'lawyer']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'My', u'defendants', u'got', u'acquitted'],\n",
       "    'original': 'My defendants got acquitted',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'My', u'defendants', u'got', u'acquitted']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'Yeah', u'Well', u'someone', u'oughta', u'remind', u'you'],\n",
       "    'original': 'Yeah. Well, someone oughta remind you',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Yeah', u'Well', u'someone', u'oughta', u'remind', u'you']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'What'],\n",
       "    'original': 'What?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'You\\u2019re',\n",
       "     u'nothing',\n",
       "     u'without',\n",
       "     u'Washington',\n",
       "     u'behind',\n",
       "     u'you'],\n",
       "    'original': 'You\\xe2\\x80\\x99re nothing without Washington behind you',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'You\\u2019re',\n",
       "     u'nothing',\n",
       "     u'without',\n",
       "     u'Washington',\n",
       "     u'behind',\n",
       "     u'you']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'Hamilton'],\n",
       "    'original': 'Hamilton!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Hamilton']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Daddy\\u2019s', u'calling'],\n",
       "    'original': 'Daddy\\xe2\\x80\\x99s calling!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Daddy\\u2019s', u'calling']}],\n",
       "  'track': 'Cabinet Battle #2',\n",
       "  'track#': '7'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have'],\n",
       "    'original': 'It must be nice, it must be nice to have',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'Washington', u'on', u'your', u'side'],\n",
       "    'original': 'Washington on your side',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Washington', u'on', u'your', u'side']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have'],\n",
       "    'original': 'It must be nice, it must be nice to have',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'Washington', u'on', u'your', u'side'],\n",
       "    'original': 'Washington on your side',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Washington', u'on', u'your', u'side']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Ev\\u2019ry',\n",
       "     u'action',\n",
       "     u'has',\n",
       "     u'its',\n",
       "     u'equal',\n",
       "     u'opposite',\n",
       "     u'reactions'],\n",
       "    'original': 'Ev\\xe2\\x80\\x99ry action has its equal, opposite reactions',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Ev\\u2019ry',\n",
       "     u'action',\n",
       "     u'has',\n",
       "     u'its',\n",
       "     u'equal',\n",
       "     u'opposite',\n",
       "     u'reactions']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'Thanks',\n",
       "     u'to',\n",
       "     u'Hamilton',\n",
       "     u'our',\n",
       "     u'cab\\u2019net\\u2019s',\n",
       "     u'fractured',\n",
       "     u'into',\n",
       "     u'factions'],\n",
       "    'original': 'Thanks to Hamilton, our cab\\xe2\\x80\\x99net\\xe2\\x80\\x99s fractured into factions',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Thanks',\n",
       "     u'to',\n",
       "     u'Hamilton',\n",
       "     u'our',\n",
       "     u'cab\\u2019net\\u2019s',\n",
       "     u'fractured',\n",
       "     u'into',\n",
       "     u'factions']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Try',\n",
       "     u'not',\n",
       "     u'to',\n",
       "     u'crack',\n",
       "     u'under',\n",
       "     u'the',\n",
       "     u'stress',\n",
       "     u'we\\u2019re',\n",
       "     u'breaking',\n",
       "     u'down',\n",
       "     u'like',\n",
       "     u'fractions'],\n",
       "    'original': 'Try not to crack under the stress, we\\xe2\\x80\\x99re breaking down like fractions',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Try',\n",
       "     u'not',\n",
       "     u'to',\n",
       "     u'crack',\n",
       "     u'under',\n",
       "     u'the',\n",
       "     u'stress',\n",
       "     u'we\\u2019re',\n",
       "     u'breaking',\n",
       "     u'down',\n",
       "     u'like',\n",
       "     u'fractions']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'We',\n",
       "     u'smack',\n",
       "     u'each',\n",
       "     u'other',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'press',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'don\\u2019t',\n",
       "     u'print',\n",
       "     u'retractions'],\n",
       "    'original': 'We smack each other in the press, and we don\\xe2\\x80\\x99t print retractions',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'We',\n",
       "     u'smack',\n",
       "     u'each',\n",
       "     u'other',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'press',\n",
       "     u'and',\n",
       "     u'we',\n",
       "     u'don\\u2019t',\n",
       "     u'print',\n",
       "     u'retractions']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'I',\n",
       "     u'get',\n",
       "     u'no',\n",
       "     u'satisfaction',\n",
       "     u'witnessing',\n",
       "     u'his',\n",
       "     u'fits',\n",
       "     u'of',\n",
       "     u'passion'],\n",
       "    'original': 'I get no satisfaction witnessing his fits of passion',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'get',\n",
       "     u'no',\n",
       "     u'satisfaction',\n",
       "     u'witnessing',\n",
       "     u'his',\n",
       "     u'fits',\n",
       "     u'of',\n",
       "     u'passion']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'The',\n",
       "     u'way',\n",
       "     u'he',\n",
       "     u'primps',\n",
       "     u'and',\n",
       "     u'preens',\n",
       "     u'and',\n",
       "     u'dresses',\n",
       "     u'like',\n",
       "     u'the',\n",
       "     u'pits',\n",
       "     u'of',\n",
       "     u'fashion'],\n",
       "    'original': 'The way he primps and preens and dresses like the pits of fashion',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'way',\n",
       "     u'he',\n",
       "     u'primps',\n",
       "     u'and',\n",
       "     u'preens',\n",
       "     u'and',\n",
       "     u'dresses',\n",
       "     u'like',\n",
       "     u'the',\n",
       "     u'pits',\n",
       "     u'of',\n",
       "     u'fashion']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Our',\n",
       "     u'poorest',\n",
       "     u'citizens',\n",
       "     u'our',\n",
       "     u'farmers',\n",
       "     u'live',\n",
       "     u'ration',\n",
       "     u'to',\n",
       "     u'ration'],\n",
       "    'original': 'Our poorest citizens, our farmers, live ration to ration',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Our',\n",
       "     u'poorest',\n",
       "     u'citizens',\n",
       "     u'our',\n",
       "     u'farmers',\n",
       "     u'live',\n",
       "     u'ration',\n",
       "     u'to',\n",
       "     u'ration']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'As',\n",
       "     u'Wall',\n",
       "     u'Street',\n",
       "     u'robs',\n",
       "     u'em',\n",
       "     u'blind',\n",
       "     u'in',\n",
       "     u'search',\n",
       "     u'of',\n",
       "     u'chips',\n",
       "     u'to',\n",
       "     u'cash',\n",
       "     u'in'],\n",
       "    'original': 'As Wall Street robs \\xe2\\x80\\x98em blind in search of chips to cash in',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'As',\n",
       "     u'Wall',\n",
       "     u'Street',\n",
       "     u'robs',\n",
       "     u'em',\n",
       "     u'blind',\n",
       "     u'in',\n",
       "     u'search',\n",
       "     u'of',\n",
       "     u'chips',\n",
       "     u'to',\n",
       "     u'cash',\n",
       "     u'in']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'This',\n",
       "     u'prick',\n",
       "     u'is',\n",
       "     u'askin',\n",
       "     u'for',\n",
       "     u'someone',\n",
       "     u'to',\n",
       "     u'bring',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'task'],\n",
       "    'original': 'This prick is askin\\xe2\\x80\\x99 for someone to bring him to task',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'prick',\n",
       "     u'is',\n",
       "     u'askin',\n",
       "     u'for',\n",
       "     u'someone',\n",
       "     u'to',\n",
       "     u'bring',\n",
       "     u'him',\n",
       "     u'to',\n",
       "     u'task']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'Somebody',\n",
       "     u'gimme',\n",
       "     u'some',\n",
       "     u'dirt',\n",
       "     u'on',\n",
       "     u'this',\n",
       "     u'vacuous',\n",
       "     u'mass',\n",
       "     u'so',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'at',\n",
       "     u'last',\n",
       "     u'unmask',\n",
       "     u'him'],\n",
       "    'original': 'Somebody gimme some dirt on this vacuous mass so we can at last unmask him',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Somebody',\n",
       "     u'gimme',\n",
       "     u'some',\n",
       "     u'dirt',\n",
       "     u'on',\n",
       "     u'this',\n",
       "     u'vacuous',\n",
       "     u'mass',\n",
       "     u'so',\n",
       "     u'we',\n",
       "     u'can',\n",
       "     u'at',\n",
       "     u'last',\n",
       "     u'unmask',\n",
       "     u'him']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'I\\u2019ll',\n",
       "     u'pull',\n",
       "     u'the',\n",
       "     u'trigger',\n",
       "     u'on',\n",
       "     u'him',\n",
       "     u'someone',\n",
       "     u'load',\n",
       "     u'the',\n",
       "     u'gun',\n",
       "     u'and',\n",
       "     u'cock',\n",
       "     u'it'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll pull the trigger on him, someone load the gun and cock it',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I\\u2019ll',\n",
       "     u'pull',\n",
       "     u'the',\n",
       "     u'trigger',\n",
       "     u'on',\n",
       "     u'him',\n",
       "     u'someone',\n",
       "     u'load',\n",
       "     u'the',\n",
       "     u'gun',\n",
       "     u'and',\n",
       "     u'cock',\n",
       "     u'it']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'While',\n",
       "     u'we',\n",
       "     u'were',\n",
       "     u'all',\n",
       "     u'watching',\n",
       "     u'he',\n",
       "     u'got',\n",
       "     u'Washington',\n",
       "     u'in',\n",
       "     u'his',\n",
       "     u'pocket'],\n",
       "    'original': 'While we were all watching, he got Washington in his pocket',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'While',\n",
       "     u'we',\n",
       "     u'were',\n",
       "     u'all',\n",
       "     u'watching',\n",
       "     u'he',\n",
       "     u'got',\n",
       "     u'Washington',\n",
       "     u'in',\n",
       "     u'his',\n",
       "     u'pocket']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have'],\n",
       "    'original': 'It must be nice, it must be nice to have',\n",
       "    'speakers': ['JEFFERSON', 'BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'Washington', u'on', u'your', u'side'],\n",
       "    'original': 'Washington on your side',\n",
       "    'speakers': ['JEFFERSON', 'BURR'],\n",
       "    'tokenized': [u'Washington', u'on', u'your', u'side']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have'],\n",
       "    'original': 'It must be nice, it must be nice to have',\n",
       "    'speakers': ['JEFFERSON', 'BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'Washington', u'on', u'your', u'side'],\n",
       "    'original': 'Washington on your side',\n",
       "    'speakers': ['JEFFERSON', 'BURR'],\n",
       "    'tokenized': [u'Washington', u'on', u'your', u'side']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Look', u'back', u'at', u'the', u'Bill', u'of', u'Rights'],\n",
       "    'original': 'Look back at the Bill of Rights',\n",
       "    'speakers': ['JEFFERSON', 'BURR'],\n",
       "    'tokenized': [u'Look', u'back', u'at', u'the', u'Bill', u'of', u'Rights']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'Which', u'I', u'wrote'],\n",
       "    'original': 'Which I wrote',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Which', u'I', u'wrote']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'The', u'ink', u'hasn\\u2019t', u'dried'],\n",
       "    'original': 'The ink hasn\\xe2\\x80\\x99t dried',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'The', u'ink', u'hasn\\u2019t', u'dried']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have'],\n",
       "    'original': 'It must be nice, it must be nice to have',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'Washington', u'on', u'your', u'side'],\n",
       "    'original': 'Washington on your side',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Washington', u'on', u'your', u'side']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'So',\n",
       "     u'he\\u2019s',\n",
       "     u'doubled',\n",
       "     u'the',\n",
       "     u'size',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'government'],\n",
       "    'original': 'So he\\xe2\\x80\\x99s doubled the size of the government',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'So',\n",
       "     u'he\\u2019s',\n",
       "     u'doubled',\n",
       "     u'the',\n",
       "     u'size',\n",
       "     u'of',\n",
       "     u'the',\n",
       "     u'government']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'Wasn\\u2019t',\n",
       "     u'the',\n",
       "     u'trouble',\n",
       "     u'with',\n",
       "     u'much',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'previous',\n",
       "     u'government',\n",
       "     u'size'],\n",
       "    'original': 'Wasn\\xe2\\x80\\x99t the trouble with much of our previous government size?',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Wasn\\u2019t',\n",
       "     u'the',\n",
       "     u'trouble',\n",
       "     u'with',\n",
       "     u'much',\n",
       "     u'of',\n",
       "     u'our',\n",
       "     u'previous',\n",
       "     u'government',\n",
       "     u'size']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'Look', u'in', u'his', u'eyes'],\n",
       "    'original': 'Look in his eyes!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Look', u'in', u'his', u'eyes']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'See', u'how', u'he', u'lies'],\n",
       "    'original': 'See how he lies',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'See', u'how', u'he', u'lies']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'Follow', u'the', u'scent', u'of', u'his', u'enterprise'],\n",
       "    'original': 'Follow the scent of his enterprise',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Follow', u'the', u'scent', u'of', u'his', u'enterprise']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'Centralizing', u'national', u'credit'],\n",
       "    'original': 'Centralizing national credit',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Centralizing', u'national', u'credit']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'And', u'making', u'American', u'credit', u'competitive'],\n",
       "    'original': 'And making American credit competitive',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'And', u'making', u'American', u'credit', u'competitive']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'If',\n",
       "     u'we',\n",
       "     u'don\\u2019t',\n",
       "     u'stop',\n",
       "     u'it',\n",
       "     u'we',\n",
       "     u'aid',\n",
       "     u'and',\n",
       "     u'abet',\n",
       "     u'it'],\n",
       "    'original': 'If we don\\xe2\\x80\\x99t stop it we aid and abet it',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'we',\n",
       "     u'don\\u2019t',\n",
       "     u'stop',\n",
       "     u'it',\n",
       "     u'we',\n",
       "     u'aid',\n",
       "     u'and',\n",
       "     u'abet',\n",
       "     u'it']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'I', u'have', u'to', u'resign'],\n",
       "    'original': 'I have to resign',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I', u'have', u'to', u'resign']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'Somebody',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'stand',\n",
       "     u'up',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'South'],\n",
       "    'original': 'Somebody has to stand up for the South!',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Somebody',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'stand',\n",
       "     u'up',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'South']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'Somebody',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'stand',\n",
       "     u'up',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'mouth'],\n",
       "    'original': 'Somebody has to stand up to his mouth!',\n",
       "    'speakers': ['BURR'],\n",
       "    'tokenized': [u'Somebody',\n",
       "     u'has',\n",
       "     u'to',\n",
       "     u'stand',\n",
       "     u'up',\n",
       "     u'to',\n",
       "     u'his',\n",
       "     u'mouth']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'If',\n",
       "     u'there\\u2019s',\n",
       "     u'a',\n",
       "     u'fire',\n",
       "     u'you\\u2019re',\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'douse'],\n",
       "    'original': 'If there\\xe2\\x80\\x99s a fire you\\xe2\\x80\\x99re trying to douse',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'there\\u2019s',\n",
       "     u'a',\n",
       "     u'fire',\n",
       "     u'you\\u2019re',\n",
       "     u'trying',\n",
       "     u'to',\n",
       "     u'douse']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'You',\n",
       "     u'can\\u2019t',\n",
       "     u'put',\n",
       "     u'it',\n",
       "     u'out',\n",
       "     u'from',\n",
       "     u'inside',\n",
       "     u'the',\n",
       "     u'house'],\n",
       "    'original': 'You can\\xe2\\x80\\x99t put it out from inside the house',\n",
       "    'speakers': ['MADISON', 'JEFFERSON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'can\\u2019t',\n",
       "     u'put',\n",
       "     u'it',\n",
       "     u'out',\n",
       "     u'from',\n",
       "     u'inside',\n",
       "     u'the',\n",
       "     u'house']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'cabinet',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'complicit',\n",
       "     u'in'],\n",
       "    'original': 'I\\xe2\\x80\\x99m in the cabinet. I am complicit in',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'cabinet',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'complicit',\n",
       "     u'in']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'Watching',\n",
       "     u'him',\n",
       "     u'grabbin',\n",
       "     u'at',\n",
       "     u'power',\n",
       "     u'and',\n",
       "     u'kiss',\n",
       "     u'it'],\n",
       "    'original': 'Watching him grabbin\\xe2\\x80\\x99 at power and kiss it',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'Watching',\n",
       "     u'him',\n",
       "     u'grabbin',\n",
       "     u'at',\n",
       "     u'power',\n",
       "     u'and',\n",
       "     u'kiss',\n",
       "     u'it']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'If', u'Washington', u'isn\\u2019t', u'gon', u'listen'],\n",
       "    'original': 'If Washington isn\\xe2\\x80\\x99t gon\\xe2\\x80\\x99 listen',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'If', u'Washington', u'isn\\u2019t', u'gon', u'listen']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'To',\n",
       "     u'disciplined',\n",
       "     u'dissidents',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'difference'],\n",
       "    'original': 'To disciplined dissidents, this is the difference:',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'To',\n",
       "     u'disciplined',\n",
       "     u'dissidents',\n",
       "     u'this',\n",
       "     u'is',\n",
       "     u'the',\n",
       "     u'difference']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'This', u'kid', u'is', u'out'],\n",
       "    'original': 'This kid is out!',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'This', u'kid', u'is', u'out']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['MADISON', 'BURR', 'JEFFERSON'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'This',\n",
       "     u'immigrant',\n",
       "     u'isn\\u2019t',\n",
       "     u'somebody',\n",
       "     u'we',\n",
       "     u'chose'],\n",
       "    'original': 'This immigrant isn\\xe2\\x80\\x99t somebody we chose',\n",
       "    'speakers': ['MADISON', 'BURR', 'JEFFERSON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'immigrant',\n",
       "     u'isn\\u2019t',\n",
       "     u'somebody',\n",
       "     u'we',\n",
       "     u'chose']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['MADISON', 'BURR', 'JEFFERSON'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'This',\n",
       "     u'immigrant\\u2019s',\n",
       "     u'keeping',\n",
       "     u'us',\n",
       "     u'all',\n",
       "     u'on',\n",
       "     u'our',\n",
       "     u'toes'],\n",
       "    'original': 'This immigrant\\xe2\\x80\\x99s keeping us all on our toes',\n",
       "    'speakers': ['MADISON', 'BURR', 'JEFFERSON'],\n",
       "    'tokenized': [u'This',\n",
       "     u'immigrant\\u2019s',\n",
       "     u'keeping',\n",
       "     u'us',\n",
       "     u'all',\n",
       "     u'on',\n",
       "     u'our',\n",
       "     u'toes']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['MADISON', 'BURR', 'JEFFERSON'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'Let\\u2019s',\n",
       "     u'show',\n",
       "     u'these',\n",
       "     u'Federalists',\n",
       "     u'who',\n",
       "     u'they\\u2019re',\n",
       "     u'up',\n",
       "     u'against'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s show these Federalists who they\\xe2\\x80\\x99re up against!',\n",
       "    'speakers': ['MADISON', 'BURR', 'JEFFERSON'],\n",
       "    'tokenized': [u'Let\\u2019s',\n",
       "     u'show',\n",
       "     u'these',\n",
       "     u'Federalists',\n",
       "     u'who',\n",
       "     u'they\\u2019re',\n",
       "     u'up',\n",
       "     u'against']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['MADISON', 'BURR', 'JEFFERSON'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Southern', u'motherfuckin'],\n",
       "    'original': 'Southern motherfuckin\\xe2\\x80\\x99\\xe2\\x80\\x94',\n",
       "    'speakers': ['JEFFERSON', 'MADISON'],\n",
       "    'tokenized': [u'Southern', u'motherfuckin']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Democratic', u'Republicans'],\n",
       "    'original': 'Democratic-Republicans!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Democratic', u'Republicans']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR', 'ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'Let\\u2019s',\n",
       "     u'follow',\n",
       "     u'the',\n",
       "     u'money',\n",
       "     u'and',\n",
       "     u'see',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'goes'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s follow the money and see where it goes',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Let\\u2019s',\n",
       "     u'follow',\n",
       "     u'the',\n",
       "     u'money',\n",
       "     u'and',\n",
       "     u'see',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'goes']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'Because',\n",
       "     u'every',\n",
       "     u'second',\n",
       "     u'the',\n",
       "     u'Treasury',\n",
       "     u'grows'],\n",
       "    'original': 'Because every second the Treasury grows',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Because',\n",
       "     u'every',\n",
       "     u'second',\n",
       "     u'the',\n",
       "     u'Treasury',\n",
       "     u'grows']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'Oh'],\n",
       "    'original': 'Oh!',\n",
       "    'speakers': ['ENSEMBLE'],\n",
       "    'tokenized': [u'Oh']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'If',\n",
       "     u'we',\n",
       "     u'follow',\n",
       "     u'the',\n",
       "     u'money',\n",
       "     u'and',\n",
       "     u'see',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'leads'],\n",
       "    'original': 'If we follow the money and see where it leads',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'If',\n",
       "     u'we',\n",
       "     u'follow',\n",
       "     u'the',\n",
       "     u'money',\n",
       "     u'and',\n",
       "     u'see',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'leads']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'Get',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'weeds',\n",
       "     u'look',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'seeds',\n",
       "     u'of'],\n",
       "    'original': 'Get in the weeds, look for the seeds of',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Get',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'weeds',\n",
       "     u'look',\n",
       "     u'for',\n",
       "     u'the',\n",
       "     u'seeds',\n",
       "     u'of']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Hamilton\\u2019s', u'misdeeds'],\n",
       "    'original': 'Hamilton\\xe2\\x80\\x99s misdeeds',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Hamilton\\u2019s', u'misdeeds']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice'],\n",
       "    'original': 'It must be nice. It must be nice',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'Follow',\n",
       "     u'the',\n",
       "     u'money',\n",
       "     u'and',\n",
       "     u'see',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'goes'],\n",
       "    'original': 'Follow the money and see where it goes',\n",
       "    'speakers': ['MADISON'],\n",
       "    'tokenized': [u'Follow',\n",
       "     u'the',\n",
       "     u'money',\n",
       "     u'and',\n",
       "     u'see',\n",
       "     u'where',\n",
       "     u'it',\n",
       "     u'goes']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice'],\n",
       "    'original': 'It must be nice. It must be nice',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'The', u'emperor', u'has', u'no', u'clothes'],\n",
       "    'original': 'The emperor has no clothes',\n",
       "    'speakers': ['JEFFERSON'],\n",
       "    'tokenized': [u'The', u'emperor', u'has', u'no', u'clothes']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'We',\n",
       "     u'won\\u2019t',\n",
       "     u'be',\n",
       "     u'invisible',\n",
       "     u'We',\n",
       "     u'won\\u2019t',\n",
       "     u'be',\n",
       "     u'denied'],\n",
       "    'original': 'We won\\xe2\\x80\\x99t be invisible. We won\\xe2\\x80\\x99t be denied',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'We',\n",
       "     u'won\\u2019t',\n",
       "     u'be',\n",
       "     u'invisible',\n",
       "     u'We',\n",
       "     u'won\\u2019t',\n",
       "     u'be',\n",
       "     u'denied']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'Still'],\n",
       "    'original': 'Still',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Still']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have'],\n",
       "    'original': 'It must be nice, it must be nice to have',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'It',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'it',\n",
       "     u'must',\n",
       "     u'be',\n",
       "     u'nice',\n",
       "     u'to',\n",
       "     u'have']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'Washington', u'on', u'your', u'side'],\n",
       "    'original': 'Washington on your side',\n",
       "    'speakers': ['JEFFERSON', 'MADISON', 'BURR'],\n",
       "    'tokenized': [u'Washington', u'on', u'your', u'side']}],\n",
       "  'track': 'Washington On Your Side',\n",
       "  'track#': '8'},\n",
       " {'act#': '2',\n",
       "  'lyrics': [{'line#': 0,\n",
       "    'normalized': [u'Mr',\n",
       "     u'President',\n",
       "     u'you',\n",
       "     u'asked',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'me'],\n",
       "    'original': 'Mr. President, you asked to see me?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Mr',\n",
       "     u'President',\n",
       "     u'you',\n",
       "     u'asked',\n",
       "     u'to',\n",
       "     u'see',\n",
       "     u'me']},\n",
       "   {'line#': 1,\n",
       "    'normalized': [u'I', u'know', u'you\\u2019re', u'busy'],\n",
       "    'original': 'I know you\\xe2\\x80\\x99re busy',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'know', u'you\\u2019re', u'busy']},\n",
       "   {'line#': 2,\n",
       "    'normalized': [u'What', u'do', u'you', u'need', u'sir', u'Sir'],\n",
       "    'original': 'What do you need, sir? Sir?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'What', u'do', u'you', u'need', u'sir', u'Sir']},\n",
       "   {'line#': 3,\n",
       "    'normalized': [u'I',\n",
       "     u'wanna',\n",
       "     u'give',\n",
       "     u'you',\n",
       "     u'a',\n",
       "     u'word',\n",
       "     u'of',\n",
       "     u'warning'],\n",
       "    'original': 'I wanna give you a word of warning',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wanna',\n",
       "     u'give',\n",
       "     u'you',\n",
       "     u'a',\n",
       "     u'word',\n",
       "     u'of',\n",
       "     u'warning']},\n",
       "   {'line#': 4,\n",
       "    'normalized': [u'Sir',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'heard'],\n",
       "    'original': 'Sir, I don\\xe2\\x80\\x99t know what you heard',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir',\n",
       "     u'I',\n",
       "     u'don\\u2019t',\n",
       "     u'know',\n",
       "     u'what',\n",
       "     u'you',\n",
       "     u'heard']},\n",
       "   {'line#': 5,\n",
       "    'normalized': [u'But',\n",
       "     u'whatever',\n",
       "     u'it',\n",
       "     u'is',\n",
       "     u'Jefferson',\n",
       "     u'started',\n",
       "     u'it'],\n",
       "    'original': 'But whatever it is, Jefferson started it',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But',\n",
       "     u'whatever',\n",
       "     u'it',\n",
       "     u'is',\n",
       "     u'Jefferson',\n",
       "     u'started',\n",
       "     u'it']},\n",
       "   {'line#': 6,\n",
       "    'normalized': [u'Thomas', u'Jefferson', u'resigned', u'this', u'morning'],\n",
       "    'original': 'Thomas Jefferson resigned this morning',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Thomas', u'Jefferson', u'resigned', u'this', u'morning']},\n",
       "   {'line#': 7,\n",
       "    'normalized': [u'You\\u2019re', u'kidding'],\n",
       "    'original': 'You\\xe2\\x80\\x99re kidding',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You\\u2019re', u'kidding']},\n",
       "   {'line#': 8,\n",
       "    'normalized': [u'I', u'need', u'a', u'favor'],\n",
       "    'original': 'I need a favor',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'need', u'a', u'favor']},\n",
       "   {'line#': 9,\n",
       "    'normalized': [u'Whatever',\n",
       "     u'you',\n",
       "     u'say',\n",
       "     u'sir',\n",
       "     u'Jefferson',\n",
       "     u'will',\n",
       "     u'pay',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'behavior'],\n",
       "    'original': 'Whatever you say, sir, Jefferson will pay for his behavior',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Whatever',\n",
       "     u'you',\n",
       "     u'say',\n",
       "     u'sir',\n",
       "     u'Jefferson',\n",
       "     u'will',\n",
       "     u'pay',\n",
       "     u'for',\n",
       "     u'his',\n",
       "     u'behavior']},\n",
       "   {'line#': 10,\n",
       "    'normalized': [u'Shh', u'Talk', u'less'],\n",
       "    'original': 'Shh. Talk less',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Shh', u'Talk', u'less']},\n",
       "   {'line#': 11,\n",
       "    'normalized': [u'I\\u2019ll', u'use', u'the', u'press'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll use the press',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019ll', u'use', u'the', u'press']},\n",
       "   {'line#': 12,\n",
       "    'normalized': [u'I\\u2019ll',\n",
       "     u'write',\n",
       "     u'under',\n",
       "     u'a',\n",
       "     u'pseudonym',\n",
       "     u'you\\u2019ll',\n",
       "     u'see',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'do',\n",
       "     u'to',\n",
       "     u'him'],\n",
       "    'original': 'I\\xe2\\x80\\x99ll write under a pseudonym, you\\xe2\\x80\\x99ll see what I can do to him\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019ll',\n",
       "     u'write',\n",
       "     u'under',\n",
       "     u'a',\n",
       "     u'pseudonym',\n",
       "     u'you\\u2019ll',\n",
       "     u'see',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'can',\n",
       "     u'do',\n",
       "     u'to',\n",
       "     u'him']},\n",
       "   {'line#': 13,\n",
       "    'normalized': [u'I', u'need', u'you', u'to', u'draft', u'an', u'address'],\n",
       "    'original': 'I need you to draft an address',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'need', u'you', u'to', u'draft', u'an', u'address']},\n",
       "   {'line#': 14,\n",
       "    'normalized': [u'Yes',\n",
       "     u'He',\n",
       "     u'resigned',\n",
       "     u'You',\n",
       "     u'can',\n",
       "     u'finally',\n",
       "     u'speak',\n",
       "     u'your',\n",
       "     u'mind'],\n",
       "    'original': 'Yes! He resigned. You can finally speak your mind\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Yes',\n",
       "     u'He',\n",
       "     u'resigned',\n",
       "     u'You',\n",
       "     u'can',\n",
       "     u'finally',\n",
       "     u'speak',\n",
       "     u'your',\n",
       "     u'mind']},\n",
       "   {'line#': 15,\n",
       "    'normalized': [u'No',\n",
       "     u'he\\u2019s',\n",
       "     u'stepping',\n",
       "     u'down',\n",
       "     u'so',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'run',\n",
       "     u'for',\n",
       "     u'President'],\n",
       "    'original': 'No, he\\xe2\\x80\\x99s stepping down so he can run for President',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'No',\n",
       "     u'he\\u2019s',\n",
       "     u'stepping',\n",
       "     u'down',\n",
       "     u'so',\n",
       "     u'he',\n",
       "     u'can',\n",
       "     u'run',\n",
       "     u'for',\n",
       "     u'President']},\n",
       "   {'line#': 16,\n",
       "    'normalized': [u'Ha', u'Good', u'luck', u'defeating', u'you', u'sir'],\n",
       "    'original': 'Ha. Good luck defeating you, sir',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Ha', u'Good', u'luck', u'defeating', u'you', u'sir']},\n",
       "   {'line#': 17,\n",
       "    'normalized': [u'I\\u2019m',\n",
       "     u'stepping',\n",
       "     u'down',\n",
       "     u'I\\u2019m',\n",
       "     u'not',\n",
       "     u'running',\n",
       "     u'for',\n",
       "     u'President'],\n",
       "    'original': 'I\\xe2\\x80\\x99m stepping down. I\\xe2\\x80\\x99m not running for President',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I\\u2019m',\n",
       "     u'stepping',\n",
       "     u'down',\n",
       "     u'I\\u2019m',\n",
       "     u'not',\n",
       "     u'running',\n",
       "     u'for',\n",
       "     u'President']},\n",
       "   {'line#': 18,\n",
       "    'normalized': [u'I\\u2019m', u'sorry', u'what'],\n",
       "    'original': 'I\\xe2\\x80\\x99m sorry, what?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I\\u2019m', u'sorry', u'what']},\n",
       "   {'line#': 19,\n",
       "    'normalized': [u'One', u'last', u'time'],\n",
       "    'original': 'One last time',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'One', u'last', u'time']},\n",
       "   {'line#': 20,\n",
       "    'normalized': [u'Relax', u'have', u'a', u'drink', u'with', u'me'],\n",
       "    'original': 'Relax, have a drink with me',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Relax', u'have', u'a', u'drink', u'with', u'me']},\n",
       "   {'line#': 21,\n",
       "    'normalized': [u'One', u'last', u'time'],\n",
       "    'original': 'One last time',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'One', u'last', u'time']},\n",
       "   {'line#': 22,\n",
       "    'normalized': [u'Let\\u2019s', u'take', u'a', u'break', u'tonight'],\n",
       "    'original': 'Let\\xe2\\x80\\x99s take a break tonight',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Let\\u2019s', u'take', u'a', u'break', u'tonight']},\n",
       "   {'line#': 23,\n",
       "    'normalized': [u'And',\n",
       "     u'then',\n",
       "     u'we\\u2019ll',\n",
       "     u'teach',\n",
       "     u'them',\n",
       "     u'how',\n",
       "     u'to',\n",
       "     u'say',\n",
       "     u'goodbye'],\n",
       "    'original': 'And then we\\xe2\\x80\\x99ll teach them how to say goodbye',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'then',\n",
       "     u'we\\u2019ll',\n",
       "     u'teach',\n",
       "     u'them',\n",
       "     u'how',\n",
       "     u'to',\n",
       "     u'say',\n",
       "     u'goodbye']},\n",
       "   {'line#': 24,\n",
       "    'normalized': [u'To', u'say', u'goodbye'],\n",
       "    'original': 'To say goodbye',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'To', u'say', u'goodbye']},\n",
       "   {'line#': 25,\n",
       "    'normalized': [u'You', u'and', u'I'],\n",
       "    'original': 'You and I',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You', u'and', u'I']},\n",
       "   {'line#': 26,\n",
       "    'normalized': [u'No', u'sir', u'why'],\n",
       "    'original': 'No, sir, why?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'No', u'sir', u'why']},\n",
       "   {'line#': 27,\n",
       "    'normalized': [u'I', u'wanna', u'talk', u'about', u'neutrality'],\n",
       "    'original': 'I wanna talk about neutrality',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I', u'wanna', u'talk', u'about', u'neutrality']},\n",
       "   {'line#': 28,\n",
       "    'normalized': [u'Sir',\n",
       "     u'with',\n",
       "     u'Britain',\n",
       "     u'and',\n",
       "     u'France',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'verge',\n",
       "     u'of',\n",
       "     u'war',\n",
       "     u'is',\n",
       "     u'this',\n",
       "     u'the',\n",
       "     u'best',\n",
       "     u'time'],\n",
       "    'original': 'Sir, with Britain and France on the verge of war, is this the best time\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Sir',\n",
       "     u'with',\n",
       "     u'Britain',\n",
       "     u'and',\n",
       "     u'France',\n",
       "     u'on',\n",
       "     u'the',\n",
       "     u'verge',\n",
       "     u'of',\n",
       "     u'war',\n",
       "     u'is',\n",
       "     u'this',\n",
       "     u'the',\n",
       "     u'best',\n",
       "     u'time']},\n",
       "   {'line#': 29,\n",
       "    'normalized': [u'I',\n",
       "     u'want',\n",
       "     u'to',\n",
       "     u'warn',\n",
       "     u'against',\n",
       "     u'partisan',\n",
       "     u'fighting'],\n",
       "    'original': 'I want to warn against partisan fighting',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'want',\n",
       "     u'to',\n",
       "     u'warn',\n",
       "     u'against',\n",
       "     u'partisan',\n",
       "     u'fighting']},\n",
       "   {'line#': 30,\n",
       "    'normalized': [u'But'],\n",
       "    'original': 'But\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'But']},\n",
       "   {'line#': 31,\n",
       "    'normalized': [u'Pick', u'up', u'a', u'pen', u'start', u'writing'],\n",
       "    'original': 'Pick up a pen, start writing',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Pick', u'up', u'a', u'pen', u'start', u'writing']},\n",
       "   {'line#': 32,\n",
       "    'normalized': [u'I',\n",
       "     u'wanna',\n",
       "     u'talk',\n",
       "     u'about',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'learned'],\n",
       "    'original': 'I wanna talk about what I have learned',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wanna',\n",
       "     u'talk',\n",
       "     u'about',\n",
       "     u'what',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'learned']},\n",
       "   {'line#': 33,\n",
       "    'normalized': [u'The',\n",
       "     u'hard',\n",
       "     u'won',\n",
       "     u'wisdom',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'earned'],\n",
       "    'original': 'The hard-won wisdom I have earned',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'hard',\n",
       "     u'won',\n",
       "     u'wisdom',\n",
       "     u'I',\n",
       "     u'have',\n",
       "     u'earned']},\n",
       "   {'line#': 34,\n",
       "    'normalized': [u'As',\n",
       "     u'far',\n",
       "     u'as',\n",
       "     u'the',\n",
       "     u'people',\n",
       "     u'are',\n",
       "     u'concerned'],\n",
       "    'original': 'As far as the people are concerned',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'As',\n",
       "     u'far',\n",
       "     u'as',\n",
       "     u'the',\n",
       "     u'people',\n",
       "     u'are',\n",
       "     u'concerned']},\n",
       "   {'line#': 35,\n",
       "    'normalized': [u'You',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'serve',\n",
       "     u'you',\n",
       "     u'could',\n",
       "     u'continue',\n",
       "     u'to',\n",
       "     u'serve'],\n",
       "    'original': 'You have to serve, you could continue to serve\\xe2\\x80\\x94',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'You',\n",
       "     u'have',\n",
       "     u'to',\n",
       "     u'serve',\n",
       "     u'you',\n",
       "     u'could',\n",
       "     u'continue',\n",
       "     u'to',\n",
       "     u'serve']},\n",
       "   {'line#': 36,\n",
       "    'normalized': [u'No', u'One', u'last', u'time'],\n",
       "    'original': 'No! One last time',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'No', u'One', u'last', u'time']},\n",
       "   {'line#': 37,\n",
       "    'normalized': [u'The', u'people', u'will', u'hear', u'from', u'me'],\n",
       "    'original': 'The people will hear from me',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The', u'people', u'will', u'hear', u'from', u'me']},\n",
       "   {'line#': 38,\n",
       "    'normalized': [u'One', u'last', u'time'],\n",
       "    'original': 'One last time',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'One', u'last', u'time']},\n",
       "   {'line#': 39,\n",
       "    'normalized': [u'And', u'if', u'we', u'get', u'this', u'right'],\n",
       "    'original': 'And if we get this right',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'And', u'if', u'we', u'get', u'this', u'right']},\n",
       "   {'line#': 40,\n",
       "    'normalized': [u'We\\u2019re',\n",
       "     u'gonna',\n",
       "     u'teach',\n",
       "     u'em',\n",
       "     u'how',\n",
       "     u'to',\n",
       "     u'say'],\n",
       "    'original': 'We\\xe2\\x80\\x99re gonna teach \\xe2\\x80\\x98em how to say',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We\\u2019re',\n",
       "     u'gonna',\n",
       "     u'teach',\n",
       "     u'em',\n",
       "     u'how',\n",
       "     u'to',\n",
       "     u'say']},\n",
       "   {'line#': 41,\n",
       "    'normalized': [u'Goodbye'],\n",
       "    'original': 'Goodbye',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Goodbye']},\n",
       "   {'line#': 42,\n",
       "    'normalized': [u'You', u'and', u'I'],\n",
       "    'original': 'You and I\\xe2\\x80\\x94',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You', u'and', u'I']},\n",
       "   {'line#': 43,\n",
       "    'normalized': [u'Mr',\n",
       "     u'President',\n",
       "     u'they',\n",
       "     u'will',\n",
       "     u'say',\n",
       "     u'you\\u2019re',\n",
       "     u'weak'],\n",
       "    'original': 'Mr. President, they will say you\\xe2\\x80\\x99re weak',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Mr',\n",
       "     u'President',\n",
       "     u'they',\n",
       "     u'will',\n",
       "     u'say',\n",
       "     u'you\\u2019re',\n",
       "     u'weak']},\n",
       "   {'line#': 44,\n",
       "    'normalized': [u'No', u'they', u'will', u'see', u'we\\u2019re', u'strong'],\n",
       "    'original': 'No, they will see we\\xe2\\x80\\x99re strong',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'No', u'they', u'will', u'see', u'we\\u2019re', u'strong']},\n",
       "   {'line#': 45,\n",
       "    'normalized': [u'Your', u'position', u'is', u'so', u'unique'],\n",
       "    'original': 'Your position is so unique',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Your', u'position', u'is', u'so', u'unique']},\n",
       "   {'line#': 46,\n",
       "    'normalized': [u'So',\n",
       "     u'I\\u2019ll',\n",
       "     u'use',\n",
       "     u'it',\n",
       "     u'to',\n",
       "     u'move',\n",
       "     u'them',\n",
       "     u'along'],\n",
       "    'original': 'So I\\xe2\\x80\\x99ll use it to move them along',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'So',\n",
       "     u'I\\u2019ll',\n",
       "     u'use',\n",
       "     u'it',\n",
       "     u'to',\n",
       "     u'move',\n",
       "     u'them',\n",
       "     u'along']},\n",
       "   {'line#': 47,\n",
       "    'normalized': [u'Why', u'do', u'you', u'have', u'to', u'say', u'goodbye'],\n",
       "    'original': 'Why do you have to say goodbye?',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Why', u'do', u'you', u'have', u'to', u'say', u'goodbye']},\n",
       "   {'line#': 48,\n",
       "    'normalized': [u'If',\n",
       "     u'I',\n",
       "     u'say',\n",
       "     u'goodbye',\n",
       "     u'the',\n",
       "     u'nation',\n",
       "     u'learns',\n",
       "     u'to',\n",
       "     u'move',\n",
       "     u'on'],\n",
       "    'original': 'If I say goodbye, the nation learns to move on',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'If',\n",
       "     u'I',\n",
       "     u'say',\n",
       "     u'goodbye',\n",
       "     u'the',\n",
       "     u'nation',\n",
       "     u'learns',\n",
       "     u'to',\n",
       "     u'move',\n",
       "     u'on']},\n",
       "   {'line#': 49,\n",
       "    'normalized': [u'It', u'outlives', u'me', u'when', u'I\\u2019m', u'gone'],\n",
       "    'original': 'It outlives me when I\\xe2\\x80\\x99m gone',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'It', u'outlives', u'me', u'when', u'I\\u2019m', u'gone']},\n",
       "   {'line#': 50,\n",
       "    'normalized': [u'Like', u'the', u'scripture', u'says'],\n",
       "    'original': 'Like the scripture says:',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Like', u'the', u'scripture', u'says']},\n",
       "   {'line#': 51,\n",
       "    'normalized': [u'Everyone',\n",
       "     u'shall',\n",
       "     u'sit',\n",
       "     u'under',\n",
       "     u'their',\n",
       "     u'own',\n",
       "     u'vine',\n",
       "     u'and',\n",
       "     u'fig',\n",
       "     u'tree'],\n",
       "    'original': '\\xe2\\x80\\x9cEveryone shall sit under their own vine and fig tree',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Everyone',\n",
       "     u'shall',\n",
       "     u'sit',\n",
       "     u'under',\n",
       "     u'their',\n",
       "     u'own',\n",
       "     u'vine',\n",
       "     u'and',\n",
       "     u'fig',\n",
       "     u'tree']},\n",
       "   {'line#': 52,\n",
       "    'normalized': [u'And',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'shall',\n",
       "     u'make',\n",
       "     u'them',\n",
       "     u'afraid'],\n",
       "    'original': 'And no one shall make them afraid.\\xe2\\x80\\x9d',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'And',\n",
       "     u'no',\n",
       "     u'one',\n",
       "     u'shall',\n",
       "     u'make',\n",
       "     u'them',\n",
       "     u'afraid']},\n",
       "   {'line#': 53,\n",
       "    'normalized': [u'They\\u2019ll',\n",
       "     u'be',\n",
       "     u'safe',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'nation',\n",
       "     u'we\\u2019ve',\n",
       "     u'made'],\n",
       "    'original': 'They\\xe2\\x80\\x99ll be safe in the nation we\\xe2\\x80\\x99ve made',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'They\\u2019ll',\n",
       "     u'be',\n",
       "     u'safe',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'nation',\n",
       "     u'we\\u2019ve',\n",
       "     u'made']},\n",
       "   {'line#': 54,\n",
       "    'normalized': [u'I',\n",
       "     u'wanna',\n",
       "     u'sit',\n",
       "     u'under',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'vine',\n",
       "     u'and',\n",
       "     u'fig',\n",
       "     u'tree'],\n",
       "    'original': 'I wanna sit under my own vine and fig tree',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'wanna',\n",
       "     u'sit',\n",
       "     u'under',\n",
       "     u'my',\n",
       "     u'own',\n",
       "     u'vine',\n",
       "     u'and',\n",
       "     u'fig',\n",
       "     u'tree']},\n",
       "   {'line#': 55,\n",
       "    'normalized': [u'A', u'moment', u'alone', u'in', u'the', u'shade'],\n",
       "    'original': 'A moment alone in the shade',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'A', u'moment', u'alone', u'in', u'the', u'shade']},\n",
       "   {'line#': 56,\n",
       "    'normalized': [u'At',\n",
       "     u'home',\n",
       "     u'in',\n",
       "     u'this',\n",
       "     u'nation',\n",
       "     u'we\\u2019ve',\n",
       "     u'made'],\n",
       "    'original': 'At home in this nation we\\xe2\\x80\\x99ve made',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'At',\n",
       "     u'home',\n",
       "     u'in',\n",
       "     u'this',\n",
       "     u'nation',\n",
       "     u'we\\u2019ve',\n",
       "     u'made']},\n",
       "   {'line#': 57,\n",
       "    'normalized': [u'One', u'last', u'time'],\n",
       "    'original': 'One last time',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'One', u'last', u'time']},\n",
       "   {'line#': 58,\n",
       "    'normalized': [u'One', u'last', u'time'],\n",
       "    'original': 'One last time',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'One', u'last', u'time']},\n",
       "   {'line#': 59,\n",
       "    'normalized': [u'Though',\n",
       "     u'in',\n",
       "     u'reviewing',\n",
       "     u'the',\n",
       "     u'incidents',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'administration',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'unconscious',\n",
       "     u'of',\n",
       "     u'intentional',\n",
       "     u'error',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'nevertheless',\n",
       "     u'too',\n",
       "     u'sensible',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'defects',\n",
       "     u'not',\n",
       "     u'to',\n",
       "     u'think',\n",
       "     u'it',\n",
       "     u'probable',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'may',\n",
       "     u'have',\n",
       "     u'committed',\n",
       "     u'many',\n",
       "     u'errors',\n",
       "     u'I',\n",
       "     u'shall',\n",
       "     u'also',\n",
       "     u'carry',\n",
       "     u'with',\n",
       "     u'me'],\n",
       "    'original': 'Though, in reviewing the incidents of my administration, I am unconscious of intentional error, I am nevertheless too sensible of my defects not to think it probable that I may have committed many errors. I shall also carry with me',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Though',\n",
       "     u'in',\n",
       "     u'reviewing',\n",
       "     u'the',\n",
       "     u'incidents',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'administration',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'unconscious',\n",
       "     u'of',\n",
       "     u'intentional',\n",
       "     u'error',\n",
       "     u'I',\n",
       "     u'am',\n",
       "     u'nevertheless',\n",
       "     u'too',\n",
       "     u'sensible',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'defects',\n",
       "     u'not',\n",
       "     u'to',\n",
       "     u'think',\n",
       "     u'it',\n",
       "     u'probable',\n",
       "     u'that',\n",
       "     u'I',\n",
       "     u'may',\n",
       "     u'have',\n",
       "     u'committed',\n",
       "     u'many',\n",
       "     u'errors',\n",
       "     u'I',\n",
       "     u'shall',\n",
       "     u'also',\n",
       "     u'carry',\n",
       "     u'with',\n",
       "     u'me']},\n",
       "   {'line#': 60,\n",
       "    'normalized': [u'The', u'hope'],\n",
       "    'original': 'The hope',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The', u'hope']},\n",
       "   {'line#': 61,\n",
       "    'normalized': [u'That', u'my', u'country', u'will'],\n",
       "    'original': 'That my country will',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'That', u'my', u'country', u'will']},\n",
       "   {'line#': 62,\n",
       "    'normalized': [u'View', u'them', u'with', u'indulgence'],\n",
       "    'original': 'View them with indulgence;',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'View', u'them', u'with', u'indulgence']},\n",
       "   {'line#': 63,\n",
       "    'normalized': [u'And', u'that'],\n",
       "    'original': 'And that',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'And', u'that']},\n",
       "   {'line#': 64,\n",
       "    'normalized': [u'After',\n",
       "     u'forty',\n",
       "     u'five',\n",
       "     u'years',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'dedicated',\n",
       "     u'to',\n",
       "     u'its',\n",
       "     u'service',\n",
       "     u'with',\n",
       "     u'an',\n",
       "     u'upright',\n",
       "     u'zeal'],\n",
       "    'original': 'After forty-five years of my life dedicated to its service with an upright zeal',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'After',\n",
       "     u'forty',\n",
       "     u'five',\n",
       "     u'years',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'dedicated',\n",
       "     u'to',\n",
       "     u'its',\n",
       "     u'service',\n",
       "     u'with',\n",
       "     u'an',\n",
       "     u'upright',\n",
       "     u'zeal']},\n",
       "   {'line#': 65,\n",
       "    'normalized': [u'The',\n",
       "     u'faults',\n",
       "     u'of',\n",
       "     u'incompetent',\n",
       "     u'abilities',\n",
       "     u'will',\n",
       "     u'be'],\n",
       "    'original': 'The faults of incompetent abilities will be',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'The',\n",
       "     u'faults',\n",
       "     u'of',\n",
       "     u'incompetent',\n",
       "     u'abilities',\n",
       "     u'will',\n",
       "     u'be']},\n",
       "   {'line#': 66,\n",
       "    'normalized': [u'Consigned',\n",
       "     u'to',\n",
       "     u'oblivion',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'myself',\n",
       "     u'must',\n",
       "     u'soon',\n",
       "     u'be',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'mansions',\n",
       "     u'of',\n",
       "     u'rest'],\n",
       "    'original': 'Consigned to oblivion, as I myself must soon be to the mansions of rest',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Consigned',\n",
       "     u'to',\n",
       "     u'oblivion',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'myself',\n",
       "     u'must',\n",
       "     u'soon',\n",
       "     u'be',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'mansions',\n",
       "     u'of',\n",
       "     u'rest']},\n",
       "   {'line#': 67,\n",
       "    'normalized': [u'I',\n",
       "     u'anticipate',\n",
       "     u'with',\n",
       "     u'pleasing',\n",
       "     u'expectation',\n",
       "     u'that',\n",
       "     u'retreat',\n",
       "     u'in',\n",
       "     u'which',\n",
       "     u'I',\n",
       "     u'promise',\n",
       "     u'myself',\n",
       "     u'to',\n",
       "     u'realize',\n",
       "     u'the',\n",
       "     u'sweet',\n",
       "     u'enjoyment',\n",
       "     u'of',\n",
       "     u'partaking',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'midst',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'fellow',\n",
       "     u'citizens',\n",
       "     u'the',\n",
       "     u'benign',\n",
       "     u'influence',\n",
       "     u'of',\n",
       "     u'good',\n",
       "     u'laws'],\n",
       "    'original': 'I anticipate with pleasing expectation that retreat in which I promise myself to realize the sweet enjoyment of partaking, in the midst of my fellow-citizens, the benign influence of good laws',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'anticipate',\n",
       "     u'with',\n",
       "     u'pleasing',\n",
       "     u'expectation',\n",
       "     u'that',\n",
       "     u'retreat',\n",
       "     u'in',\n",
       "     u'which',\n",
       "     u'I',\n",
       "     u'promise',\n",
       "     u'myself',\n",
       "     u'to',\n",
       "     u'realize',\n",
       "     u'the',\n",
       "     u'sweet',\n",
       "     u'enjoyment',\n",
       "     u'of',\n",
       "     u'partaking',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'midst',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'fellow',\n",
       "     u'citizens',\n",
       "     u'the',\n",
       "     u'benign',\n",
       "     u'influence',\n",
       "     u'of',\n",
       "     u'good',\n",
       "     u'laws']},\n",
       "   {'line#': 68,\n",
       "    'normalized': [u'Under',\n",
       "     u'a',\n",
       "     u'free',\n",
       "     u'government',\n",
       "     u'the',\n",
       "     u'ever',\n",
       "     u'favorite',\n",
       "     u'object',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'heart',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'happy',\n",
       "     u'reward',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'trust'],\n",
       "    'original': 'Under a free government, the ever-favorite object of my heart, and the happy reward, as I trust',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Under',\n",
       "     u'a',\n",
       "     u'free',\n",
       "     u'government',\n",
       "     u'the',\n",
       "     u'ever',\n",
       "     u'favorite',\n",
       "     u'object',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'heart',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'happy',\n",
       "     u'reward',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'trust']},\n",
       "   {'line#': 69,\n",
       "    'normalized': [u'Of',\n",
       "     u'our',\n",
       "     u'mutual',\n",
       "     u'cares',\n",
       "     u'labors',\n",
       "     u'and',\n",
       "     u'dangers'],\n",
       "    'original': 'Of our mutual cares, labors, and dangers.',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Of',\n",
       "     u'our',\n",
       "     u'mutual',\n",
       "     u'cares',\n",
       "     u'labors',\n",
       "     u'and',\n",
       "     u'dangers']},\n",
       "   {'line#': 70,\n",
       "    'normalized': [u'The', u'hope'],\n",
       "    'original': 'The hope',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'The', u'hope']},\n",
       "   {'line#': 71,\n",
       "    'normalized': [u'View', u'them', u'with', u'indulgence'],\n",
       "    'original': 'View them with indulgence',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'View', u'them', u'with', u'indulgence']},\n",
       "   {'line#': 72,\n",
       "    'normalized': [u'After',\n",
       "     u'forty',\n",
       "     u'five',\n",
       "     u'years',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'dedicated',\n",
       "     u'to',\n",
       "     u'its',\n",
       "     u'service',\n",
       "     u'with',\n",
       "     u'an',\n",
       "     u'upright',\n",
       "     u'zeal'],\n",
       "    'original': 'After forty-five years of my life dedicated to its service with an upright zeal',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'After',\n",
       "     u'forty',\n",
       "     u'five',\n",
       "     u'years',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'life',\n",
       "     u'dedicated',\n",
       "     u'to',\n",
       "     u'its',\n",
       "     u'service',\n",
       "     u'with',\n",
       "     u'an',\n",
       "     u'upright',\n",
       "     u'zeal']},\n",
       "   {'line#': 73,\n",
       "    'normalized': [u'Consigned',\n",
       "     u'to',\n",
       "     u'oblivion',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'myself',\n",
       "     u'must',\n",
       "     u'soon',\n",
       "     u'be',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'mansions',\n",
       "     u'of',\n",
       "     u'rest'],\n",
       "    'original': 'Consigned to oblivion, as I myself must soon be to the mansions of rest',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Consigned',\n",
       "     u'to',\n",
       "     u'oblivion',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'myself',\n",
       "     u'must',\n",
       "     u'soon',\n",
       "     u'be',\n",
       "     u'to',\n",
       "     u'the',\n",
       "     u'mansions',\n",
       "     u'of',\n",
       "     u'rest']},\n",
       "   {'line#': 74,\n",
       "    'normalized': [u'I',\n",
       "     u'anticipate',\n",
       "     u'with',\n",
       "     u'pleasing',\n",
       "     u'expectation',\n",
       "     u'that',\n",
       "     u'retreat',\n",
       "     u'in',\n",
       "     u'which',\n",
       "     u'I',\n",
       "     u'promise',\n",
       "     u'myself',\n",
       "     u'to',\n",
       "     u'realize',\n",
       "     u'the',\n",
       "     u'sweet',\n",
       "     u'enjoyment',\n",
       "     u'of',\n",
       "     u'partaking',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'midst',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'fellow',\n",
       "     u'citizens',\n",
       "     u'the',\n",
       "     u'benign',\n",
       "     u'influence',\n",
       "     u'of',\n",
       "     u'good',\n",
       "     u'laws'],\n",
       "    'original': 'I anticipate with pleasing expectation that retreat in which I promise myself to realize the sweet enjoyment of partaking, in the midst of my fellow-citizens, the benign influence of good laws',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'I',\n",
       "     u'anticipate',\n",
       "     u'with',\n",
       "     u'pleasing',\n",
       "     u'expectation',\n",
       "     u'that',\n",
       "     u'retreat',\n",
       "     u'in',\n",
       "     u'which',\n",
       "     u'I',\n",
       "     u'promise',\n",
       "     u'myself',\n",
       "     u'to',\n",
       "     u'realize',\n",
       "     u'the',\n",
       "     u'sweet',\n",
       "     u'enjoyment',\n",
       "     u'of',\n",
       "     u'partaking',\n",
       "     u'in',\n",
       "     u'the',\n",
       "     u'midst',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'fellow',\n",
       "     u'citizens',\n",
       "     u'the',\n",
       "     u'benign',\n",
       "     u'influence',\n",
       "     u'of',\n",
       "     u'good',\n",
       "     u'laws']},\n",
       "   {'line#': 75,\n",
       "    'normalized': [u'Under',\n",
       "     u'a',\n",
       "     u'free',\n",
       "     u'government',\n",
       "     u'the',\n",
       "     u'ever',\n",
       "     u'favorite',\n",
       "     u'object',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'heart',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'happy',\n",
       "     u'reward',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'trust'],\n",
       "    'original': 'Under a free government, the ever-favorite object of my heart, and the happy reward, as I trust',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Under',\n",
       "     u'a',\n",
       "     u'free',\n",
       "     u'government',\n",
       "     u'the',\n",
       "     u'ever',\n",
       "     u'favorite',\n",
       "     u'object',\n",
       "     u'of',\n",
       "     u'my',\n",
       "     u'heart',\n",
       "     u'and',\n",
       "     u'the',\n",
       "     u'happy',\n",
       "     u'reward',\n",
       "     u'as',\n",
       "     u'I',\n",
       "     u'trust']},\n",
       "   {'line#': 76,\n",
       "    'normalized': [u'Of',\n",
       "     u'our',\n",
       "     u'mutual',\n",
       "     u'cares',\n",
       "     u'labors',\n",
       "     u'and',\n",
       "     u'dangers'],\n",
       "    'original': 'Of our mutual cares, labors, and dangers.',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Of',\n",
       "     u'our',\n",
       "     u'mutual',\n",
       "     u'cares',\n",
       "     u'labors',\n",
       "     u'and',\n",
       "     u'dangers']},\n",
       "   {'line#': 77,\n",
       "    'normalized': [u'One', u'last', u'time'],\n",
       "    'original': 'One last time',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'One', u'last', u'time']},\n",
       "   {'line#': 78,\n",
       "    'normalized': [u'George', u'Washington\\u2019s', u'going', u'home'],\n",
       "    'original': 'George Washington\\xe2\\x80\\x99s going home!',\n",
       "    'speakers': ['ALL WOMEN'],\n",
       "    'tokenized': [u'George', u'Washington\\u2019s', u'going', u'home']},\n",
       "   {'line#': 79,\n",
       "    'normalized': [u'Teach', u'em', u'how', u'to', u'say', u'goodbye'],\n",
       "    'original': 'Teach \\xe2\\x80\\x98em how to say goodbye',\n",
       "    'speakers': ['HAMILTON'],\n",
       "    'tokenized': [u'Teach', u'em', u'how', u'to', u'say', u'goodbye']},\n",
       "   {'line#': 80,\n",
       "    'normalized': [u'You', u'and', u'I'],\n",
       "    'original': 'You and I',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'You', u'and', u'I']},\n",
       "   {'line#': 81,\n",
       "    'normalized': [u'Going', u'home'],\n",
       "    'original': 'Going home',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Going', u'home']},\n",
       "   {'line#': 82,\n",
       "    'normalized': [u'History', u'has', u'its', u'eyes', u'on', u'you'],\n",
       "    'original': 'History has its eyes on you',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'History', u'has', u'its', u'eyes', u'on', u'you']},\n",
       "   {'line#': 83,\n",
       "    'normalized': [u'We\\u2019re', u'gonna', u'teach', u'em', u'how', u'to'],\n",
       "    'original': 'We\\xe2\\x80\\x99re gonna teach \\xe2\\x80\\x98em how to',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'We\\u2019re', u'gonna', u'teach', u'em', u'how', u'to']},\n",
       "   {'line#': 84,\n",
       "    'normalized': [u'Say', u'goodbye'],\n",
       "    'original': 'Say goodbye!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Say', u'goodbye']},\n",
       "   {'line#': 85,\n",
       "    'normalized': [u'Teach', u'em', u'how', u'to'],\n",
       "    'original': 'Teach \\xe2\\x80\\x98em how to',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Teach', u'em', u'how', u'to']},\n",
       "   {'line#': 86,\n",
       "    'normalized': [u'Say', u'goodbye'],\n",
       "    'original': 'Say goodbye!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Say', u'goodbye']},\n",
       "   {'line#': 87,\n",
       "    'normalized': [u'To', u'say', u'goodbye'],\n",
       "    'original': 'To say goodbye!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'To', u'say', u'goodbye']},\n",
       "   {'line#': 88,\n",
       "    'normalized': [u'Say', u'goodbye'],\n",
       "    'original': 'Say goodbye!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'Say', u'goodbye']},\n",
       "   {'line#': 89,\n",
       "    'normalized': [u'One', u'last', u'time'],\n",
       "    'original': 'One last time!',\n",
       "    'speakers': ['WASHINGTON'],\n",
       "    'tokenized': [u'One', u'last', u'time']},\n",
       "   {'line#': 90,\n",
       "    'normalized': [u'George', u'Washington\\u2019s', u'going', u'home'],\n",
       "    'original': 'George Washington\\xe2\\x80\\x99s going home',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'George', u'Washington\\u2019s', u'going', u'home']},\n",
       "   {'line#': 91,\n",
       "    'normalized': [u'George', u'Washington\\u2019s', u'going', u'home'],\n",
       "    'original': 'George Washington\\xe2\\x80\\x99s going home',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'George', u'Washington\\u2019s', u'going', u'home']},\n",
       "   {'line#': 92,\n",
       "    'normalized': [u'George', u'Washington\\u2019s', u'going', u'home'],\n",
       "    'original': 'George Washington\\xe2\\x80\\x99s going home',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'George', u'Washington\\u2019s', u'going', u'home']},\n",
       "   {'line#': 93,\n",
       "    'normalized': [u'George', u'Washington\\u2019s', u'going', u'home'],\n",
       "    'original': 'George Washington\\xe2\\x80\\x99s going home',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'George', u'Washington\\u2019s', u'going', u'home']},\n",
       "   {'line#': 94,\n",
       "    'normalized': [u'Teach', u'em', u'how', u'to', u'say', u'goodbye'],\n",
       "    'original': 'Teach \\xe2\\x80\\x98em how to say goodbye!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Teach', u'em', u'how', u'to', u'say', u'goodbye']},\n",
       "   {'line#': 95,\n",
       "    'normalized': [u'Teach', u'em', u'how'],\n",
       "    'original': 'Teach \\xe2\\x80\\x98em how!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Teach', u'em', u'how']},\n",
       "   {'line#': 96,\n",
       "    'normalized': [u'Say', u'goodbye'],\n",
       "    'original': 'Say goodbye!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Say', u'goodbye']},\n",
       "   {'line#': 97,\n",
       "    'normalized': [u'Say', u'goodbye'],\n",
       "    'original': 'Say goodbye!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'Say', u'goodbye']},\n",
       "   {'line#': 98,\n",
       "    'normalized': [u'One', u'last', u'time'],\n",
       "    'original': 'One last time!',\n",
       "    'speakers': ['COMPANY'],\n",
       "    'tokenized': [u'One', u'last', u'time']}],\n",
       "  'track': 'One Last Time',\n",
       "  'track#': '9'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamilton_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf8' codec can't decode byte 0x92 in position 32: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-835ab5864440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/processed/hamilton_data.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhamilton_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Bart/anaconda/envs/py27/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bart/anaconda/envs/py27/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bart/anaconda/envs/py27/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bart/anaconda/envs/py27/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bart/anaconda/envs/py27/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Bart/anaconda/envs/py27/lib/python2.7/json/encoder.pyc\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_key_separator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0m_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;34m'null'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf8' codec can't decode byte 0x92 in position 32: invalid start byte"
     ]
    }
   ],
   "source": [
    "with open('../data/processed/hamilton_data.json', 'w') as f:\n",
    "    json.dump(hamilton_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
